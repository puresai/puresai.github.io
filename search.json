[{"title":"Laravel限流","path":"/2025/02/28/525/","content":"Laravel 11 中使用 Redis::throttle 进行速率限制在 Laravel 11 中，Redis::throttle 是一个强大的工具，用于实现对 API 或特定操作的速率限制。通过使用 Redis 作为后端存储，Redis::throttle 可以有效地控制用户在一定时间内可以执行的请求次数。本文将介绍如何使用 Redis::throttle，其主要方法、注意事项，并与 RateLimiter 进行对比。 1. Redis::throttle 的基本使用Redis::throttle 是 Laravel 提供的一个基于 Redis 的速率限制工具。它允许你轻松地限制某个操作在特定时间内的执行次数。 1.1 基本语法use Illuminate\\Support\\Facades\\Redis;Redis::throttle(&#x27;key&#x27;)-&gt;allow(10)-&gt;every(60)-&gt;then(function () &#123; // 正常执行操作&#125;, function () &#123; // 超过速率限制时的回调&#125;); key: 用于标识速率限制的唯一键。 allow(10): 在指定的时间窗口内允许的最大请求次数。 every(60): 时间窗口的长度（以秒为单位）。 then: 当请求未超过限制时执行的回调。 第二个回调函数是可选的，用于处理超过限制时的逻辑。 1.2 示例假设你希望限制用户每分钟只能发送 5 条消息： use Illuminate\\Support\\Facades\\Redis;Redis::throttle(&#x27;send-message:&#x27; . $user-&gt;id)-&gt;allow(5)-&gt;every(60)-&gt;then(function () use ($user) &#123; // 发送消息的逻辑 $this-&gt;sendMessage($user, $message);&#125;, function () &#123; // 超过限制时的处理 return response(&#x27;Too many attempts. Please try again later.&#x27;, 429);&#125;); 在这个例子中，send-message: 加上用户 ID 作为键，确保每个用户的速率限制是独立的。 2. 主要方法2.1 allow(int $maxAttempts)设置在一定时间窗口内允许的最大请求次数。 2.2 every(int $decaySeconds)设置时间窗口的长度（以秒为单位）。 2.3 then(callable $callback, callable $failureCallback = null) $callback: 当请求未超过限制时执行的回调。 $failureCallback: 当请求超过限制时执行的回调（可选）。 2.4 block(int $timeout)设置当请求超过限制时，阻塞用户的时间（以秒为单位）。在这段时间内，用户无法再次发起请求。 Redis::throttle(&#x27;key&#x27;)-&gt;allow(10)-&gt;every(60)-&gt;block(10)-&gt;then(function () &#123; // 正常执行操作&#125;, function () &#123; // 超过速率限制时的回调&#125;); 在这个例子中，如果用户超过了速率限制，他们将被阻塞 10 秒。 3. 注意事项3.1 Redis 连接确保你的 Laravel 应用已经正确配置了 Redis 连接。你可以在 .env 文件中设置 REDIS_HOST、REDIS_PASSWORD 等参数。 3.2 键的唯一性Redis::throttle 的键必须是唯一的，通常你会使用用户 ID、IP 地址或其他唯一标识符来构造键。 3.3 阻塞时间使用 block 方法时，确保设置的阻塞时间合理，避免用户长时间无法操作。 3.4 分布式环境在分布式环境中，Redis::throttle 可以很好地工作，因为 Redis 是一个集中式的存储系统。确保所有服务器都连接到同一个 Redis 实例。 4. 与 RateLimiter 的对比Laravel 还提供了 RateLimiter 工具，它与 Redis::throttle 类似，但有一些区别： 4.1 配置方式RateLimiter 通常在 app/Providers/RouteServiceProvider.php 中配置，而 Redis::throttle 可以在代码中直接使用。 use Illuminate\\Cache\\RateLimiting\\Limit;use Illuminate\\Support\\Facades\\RateLimiter;RateLimiter::for(&#x27;api&#x27;, function ($request) &#123; return Limit::perMinute(60)-&gt;by($request-&gt;user()?-&gt;id ?: $request-&gt;ip());&#125;); 4.2 灵活性Redis::throttle 更加灵活，可以在任何地方使用，而 RateLimiter 通常用于路由中间件中。 4.3 使用场景 Redis::throttle 更适合在代码中直接控制速率限制，例如在服务类或控制器中。一般是分钟级别。 RateLimiter 更适合在全局范围内对路由进行速率限制。秒级。 4.4 性能两者都基于 Redis，性能差异不大。选择使用哪个工具主要取决于你的使用场景和偏好。 5. 总结Redis::throttle 是 Laravel 中一个非常实用的速率限制工具，特别适合在代码中直接控制操作的执行频率。通过合理使用 allow、every 和 block 方法，你可以轻松实现对用户请求的限制。与 RateLimiter 相比，Redis::throttle 更加灵活，适合在特定场景下使用。 在实际开发中，根据需求选择合适的工具，可以有效提升应用的稳定性和用户体验。","tags":["Laravel"],"categories":["PHP"]},{"title":"2024,这一年","path":"/2025/01/28/2024/","content":"大家新年快乐！ 去年没写年终总结，所以也就没有计划比对。 工作工作时长明显短于去年，少有时长超过9小时，大部分时间在5-7小时。工作内容也没有太大变动，没有太大突破。相比去年，很多任务要顺手得多，效率也高了不少。 3月份吉隆坡聚会了一次，难得和同事一起，玩得很开心。发现几个同事线上线下判若两人。 一晃这份工作已经做了2年多，毕业后最长的一段工作经历了，哈哈。可以很好做到 WLB，团队氛围极好。 学习尴尬，今年没有完整读完一本书。技术类书籍也就是需要的时候看看，没有完整阅读。育儿类的书倒是看了些。 英语方面，从去年12月底到本月25号，流利说一共394天，打卡388天，334小时。边学边用，有提高，但开会我还是不太能听懂，看来得试试其他方法提高听力了。第一次出国，英文大胆说，别人也能懂。 没有输入，输出自然少了，今年公众号没有更新，博客文章也是近五年最少的一年。 生活主题词——奔波。 很忙的一年，居家办公，但行驶里程超过前面2年。琐事很多，上半年妻子怀孕，每天 24 小时几乎满满当当，下半年孩子出生，依旧很忙。还好家人的帮助，让我能安心工作。 湿疹10月中旬再次爆发，至今未愈，试着看看中医，调理一阵有没有效果。 side projects合作了几个小项目，有时候会很忙，不影响工作生活的前提下，会继续做做。 尝试做产品，目前还在初始阶段。 总结感谢我的妻子，对我近乎无条件的支持。 感谢我的母亲，对我的包容和理解。 感谢我的同事伙伴，对我的帮助与支持。 感谢家人朋友的支持。 感谢我的宝宝。 新年计划 做好达达的支持工作 做2个有用的产品 突破？ 作息调整，控制湿疹 甲辰正月初五于扬州2025年02月02日","tags":["oneyear"],"categories":["oneyear"]},{"title":"Python3虚拟环境venv","path":"/2024/11/24/520/","content":"多项目共存的服务器，每个项目依赖的包可能不一样，比如项目A需要 utilset 0.0.3, 项目B需要utilset 0.4，这时候就需要隔离开，venv就是用来为一个应用创建一套“隔离”的Python运行环境。 venv 支持创建轻量的“虚拟环境”，每个虚拟环境将拥有它们自己独立的安装在其 site 目录中的 Python 软件包集合。 虚拟环境是在现有的 Python 安装版基础之上创建的，这被称为虚拟环境的“基础”Python，并且还可选择与基础环境中的软件包隔离开来，这样只有在虚拟环境中显式安装的软件包才是可用的。 创建mkdir puresaicd puresai➜ puresai ls -lhtotal 0➜ puresai python3 -m venv .➜ puresai ls -lh total 8drwxr-xr-x 12 sai staff 384B Nov 24 19:45 bindrwxr-xr-x 2 sai staff 64B Nov 24 19:45 includedrwxr-xr-x 3 sai staff 96B Nov 24 19:45 lib-rw-r--r-- 1 sai staff 111B Nov 24 19:45 pyvenv.cfg 可以发现有几个文件夹和一个pyvenv.cfg文件： 激活bin目录下有个 activate，Linux/Mac用 source bin/activate，Windows用bin/activate.bat激活该venv环境。 puresai$ source bin/activate(puresai) $ 注意到命令提示符变了，有个(puresai)前缀，表示当前环境是一个名为puresai的Python环境。 下面正常安装各种第三方包，并运行python命令： pip3 install utilset==0.0.3Collecting utilset==0.0.3 Using cached utilset-0.0.3-py3-none-any.whl (4.8 kB)Installing collected packages: utilsetSuccessfully installed utilset-0.0.3WARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.You should consider upgrading via the &#x27;/Users/sai/puresai/bin/python3 -m pip install --upgrade pip&#x27; command.(puresai) 在venv环境下，用pip安装的包都被安装到 puresai 这个环境下，具体目录是 puresai/lib/python3.x/site-packages，因此，系统Python环境不受任何影响。也就是说，puresai 环境是专门针对puresai这个应用创建的。 退出当前的 puresai 环境，使用deactivate命令： (puresai) $ deactivate 此时就回到了正常的环境，现在pip或python均是在系统Python环境下执行。 完全可以针对每个应用创建独立的Python运行环境，这样就可以对每个应用的Python环境进行隔离。 原理venv是如何创建“独立”的Python运行环境的呢？原理很简单，就是把系统Python链接或复制一份到venv的环境，用命令source activate进入一个venv环境时，venv会修改相关环境变量，让命令python和pip均指向当前的venv环境。 如果不再使用某个venv，例如puresai，删除它也很简单。首先确认该venv没有处于“激活”状态，然后直接把整个目录puresai删掉就行。 参考 venv","tags":["python"],"categories":["python"]},{"title":"排查Linux磁盘空间不足的问题","path":"/2024/10/24/530/","content":"最近几天收到监控通知服务器 A 磁盘剩余小于10% 的情况。 排查大文件： [root@syskf175 ~]# find / -type f -size +100M -exec ls -lh &#123;&#125; \\;-r--------. 1 root root 128T Oct 24 17:32 /proc/kcorefind: ‘/proc/30420/task/30420/fdinfo/5’: No such file or directoryfind: ‘/proc/30420/fdinfo/6’: No such file or directory-rw-------. 1 root root 128M Oct 24 13:26 /sys/devices/pci0000:00/0000:00:0f.0/resource1_wc-rw-------. 1 root root 128M Oct 24 13:26 /sys/devices/pci0000:00/0000:00:0f.0/resource1-rw-r--r--. 1 root root 169M Apr 13 2024 /var/lib/rpm/Packages-rw-r-----. 1 root root 1.1G Oct 24 17:32 /var/lib/docker/containers/3138d971f20379b6c956f1766ec643232e677d622adf37c83520860f54c57415/3138d971f20379b6c956f1766ec643232e677d622adf37c83520860f54c57415-json.log-rw-r-----. 1 root root 1.6G Oct 22 10:30 /var/lib/docker/containers/dcc20350d4e75259ac2999565c23717d809f457c198b6e7c338e1ca1460a1404/dcc20350d4e75259ac2999565c23717d809f457c198b6e7c338e1ca1460a1404-json.log-rw-r-----. 1 root root 29G Oct 24 17:32 /var/lib/docker/containers/ff9662f09d5348efd572445db6b0716b6397e3341e6e538703aac722cepuresai/ff9662f09d5348efd572445db6b0716b6397e3341e6e538703aac722cepuresai-json.log-rw-r--r--. 1 root root 147M Apr 3 2024 /var/cache/yum/x86_64/7/updates/gen/primary_db.sqlite-rw-r--r--. 1 root root 102M Apr 13 2024 /usr/lib/locale/locale-archive-rwxr-xr-x. 1 root root 138M Feb 14 2022 /usr/lib64/firefox/libxul.so 能看到有个 29G 的大文件，考虑是 docker 容器日志，保留意义不大。 清空即可： truncate -s 0 /var/lib/docker/containers/ff9662f09d5348efd572445db6b0716b6397e3341e6e538703aac722cepuresai/ff9662f09d5348efd572445db6b0716b6397e3341e6e538703aac722cepuresai-json.log 看到剩余空间足够了，不用挂载新磁盘了。","tags":["Linux"],"categories":["Linux"]},{"title":"python3读取csv _csv.Error: line contains NUL","path":"/2024/09/22/525/","content":"python3 读取稍大一点的 CSV 文件时，经常会出现这个错误: for row in csv_reader: _csv.Error: line contains NUL 出现 _csv.Error: line contains NUL 错误通常是因为 CSV 文件中存在不可见的 NUL 字符（空字符），这会干扰 Python 的 csv.reader。这是文件读取的问题，通常发生在文件编码或格式异常时。 所以替换掉就行： with open(&quot;puresai.csv&quot;, &quot;r&quot;, encoding=&quot;utf-8&quot;, newline=&#x27;&#x27;) as f: # 替换掉 NUL 字符 content = f.read().replace(&#x27;\\0&#x27;, &#x27;&#x27;) csv_reader = csv.reader(content.splitlines()) # 逐行读取数据 for row in csv_reader: count += 1 .... 运行时有发现会被 Killed, 估计是文件太大，内存爆了，改成按行替换就行。 with open(&quot;puresai.csv&quot;, &quot;r&quot;, encoding=&quot;utf-8&quot;, newline=&#x27;&#x27;) as f: # 使用 csv 模块逐行读取 CSV 数据 csv_reader = csv.reader((line.replace(&#x27;\\0&#x27;, &#x27;&#x27;) for line in f)) # 逐行去除 NUL 字符 # 逐行读取数据 for row in csv_reader: count += 1 ... 高频问题，记录一下，希望对你有用。","tags":["python"],"categories":["python"]},{"title":"mysql如何使用不定数量的查询","path":"/2024/08/16/471/","content":"where in 查询是很常见的，但你知道 python3 中怎么写吗？ 话不多说直接上 sample import pymysqlimport configsql = &quot;&quot;&quot;SELECT abc, MAX(last_updated) as last_updatedFROM xxxWHERE abc IN (&#123;&#125;)&quot;&quot;&quot;class Runner(object): ... def phone_exist(self, abc): sai = [] placeholders = &quot;, &quot;.join([&quot;%s&quot;] * len(abc)) query = trovo_sql.format(placeholders) self.cursor.execute(query, abc) rows = self.cursor.fetchall() for row in rows: sai.append(row[&quot;abc&quot;]) return sai return sai","tags":["python"],"categories":["python"]},{"title":"解决webman事务不生效的问题","path":"/2024/08/07/521/","content":"背景上周 QA 反馈给我说，任务添加失败了，但任务记录多了一条，我想我用了事务按理不应该啊。 定位检查代码逻辑检查项目代码，（使用的 webman ） Db::beginTransaction();try &#123; // 省略业务代码 throw new \\Exception(&#x27;mode 错误&#x27;);&#125; catch (\\Exception $e ) &#123; Db::rollback();&#125; 逻辑看似无误，失败后确实提示了，但也确实多了条数据。 查手册查手册 https://www.workerman.net/doc/webman/others/transaction.html 看到 这里特别需要注意的是必须使用\\Throwable而不能使用\\Exception，因为业务处理过程中可能触发Error，它并不属于Exception 修改Exception 为 Throwable，本地测试，还是一样的情况。 社区搜索然后排查是不是connection 指定问题（搜索社区问题），发现我使用的 Model 没有指定，按逻辑是集成了父类 protected $connection = ‘plugin.admin.mysql’; 尝试直接指定下，protected $connection = ‘mysql’; 然后， Db::connection(&#x27;mysql&#x27;)-&gt;beginTransaction();try&#123; // 省略业务代码 throw new \\Exception(&#x27;mode 错误&#x27;);&#125; catch (\\Throwable $e) &#123; Db::connection(&#x27;mysql&#x27;)-&gt;rollback();&#125; 再次测试，添加任务失败后，没有新增一条记录，自增值夜添加了一个，说明事务回滚成功了。 好了，这次 debug 说明也恰好写出来具体的排查步骤。你有什么想法，欢迎评论区留言！","tags":["webman"],"categories":["webman"]},{"title":"python3查询es超时","path":"/2024/08/01/520/","content":"scroll 查询是很常见的，当使用时，提示错误， socket.timeout: The read operation timed outDuring handling of the above exception, another exception occurred: 而 python 的 scroll 查询是没有查询时间设置的。这是我们可以通过修改 es 连接的超时参数来处理。 es = Elasticsearch(hosts=url, timeout=60, retry_on_timeout=True) 改动之后， 就 ok 了。","tags":["python"],"categories":["python"]},{"title":"检查是否在企业微信中","path":"/2024/04/21/512/","content":"就是根据 userAgent 判断，注意下 企业微信环境 UA 也会包含 micromessenger， 注意下就行。 let ua = window.navigator.userAgent.toLowerCase();if (ua.indexOf(&quot;wxwork&quot;) != -1) &#123; console.log(&quot;企业微信环境&quot;)&#125; else if (ua.indexOf(&quot;micromessenger&quot;) != -1) &#123; console.log(&quot;微信环境&quot;)&#125; else &#123; console.log(&quot;其他&quot;)&#125;","categories":["js"]},{"title":"做一个简单的服务器监控企业微信通知","path":"/2024/04/14/511/","content":"代码逻辑简单，检查服务器磁盘内存CPU占用，超过设定的阈值就发送企业微信通知。 主要代码import psutilimport requestsimport jsonimport loggingimport clickimport osfrom datetime import datetimeimport socketclass ServerMonitor: def __init__(self, webhook_url, threshold=90, server_name=&quot;Server&quot;): self.webhook_url = webhook_url self.threshold = threshold self.server_name = server_name logging.basicConfig( level=logging.INFO, handlers=[ logging.FileHandler(f&quot;&#123;os.path.basename(__file__)&#125;.log&quot;, &quot;a&quot;, &quot;utf-8&quot;), ], format=&quot;%(asctime)s %(levelname)s %(message)s&quot;, datefmt=&quot;%m-%d %H:%M:%S&quot;, ) def check_server_status(self): cpu_percent = psutil.cpu_percent(interval=1) cpu_count = psutil.cpu_count() memory = psutil.virtual_memory() disk_usage = psutil.disk_usage(&#x27;/&#x27;) system_load = psutil.getloadavg() if (cpu_percent &gt; self.threshold or memory.percent &gt; self.threshold or disk_usage.percent &gt; self.threshold or system_load[0] &gt; self.threshold): return True else: return False def send_notification(self): disk_usage = psutil.disk_usage(&#x27;/&#x27;) memory = psutil.virtual_memory() cpu_count = psutil.cpu_count() system_load = psutil.getloadavg() current_time = datetime.now().strftime(&quot;%Y-%m-%d %H:%M:%S&quot;) msg = f&quot;&#123;self.server_name&#125; &#123;current_time&#125; &quot; msg += f&quot;**CPU利用率：** &#123;psutil.cpu_percent(interval=1)&#125;% (&#123;cpu_count&#125; cores) &quot; msg += f&quot;**内存使用：** &#123;memory.percent&#125;% (内存总大小：&#123;self.bytes_to_gb(memory.total)&#125;GB) &quot; msg += f&quot;**磁盘利用率：** &#123;disk_usage.percent&#125;% (剩余磁盘空间：&#123;self.bytes_to_gb(disk_usage.free)&#125;GB) &quot; msg += f&quot;**系统负载：** &#123;system_load[0]:.2f&#125; &quot; is_exception = self.check_server_status() if is_exception: logging.info(&quot;服务器运行%s: %s&quot;, &#x27;异常&#x27; if is_exception else &#x27;正常&#x27;, msg) if is_exception: msg += f&quot;&lt;font color=&#x27;warning&#x27;&gt;**服务器运行异常, 请尽快处理!**&lt;/font&gt; &quot; else: msg += f&quot;服务器运行正常 &quot; message = &#123;&quot;msgtype&quot;: &quot;markdown&quot;, &quot;markdown&quot;: &#123;&quot;content&quot;: msg&#125;&#125; response = requests.post( self.webhook_url, data=json.dumps(message), headers=&#123;&#x27;Content-Type&#x27;: &#x27;application/json&#x27;&#125;) if response.status_code == 200: logging.info(&quot;消息发送成功！&quot;) else: logging.error(f&quot;消息发送失败: &#123;response.status_code&#125;&quot;) else: logging.info(&quot;服务器运行正常: %s&quot;, msg) @staticmethod def bytes_to_gb(bytes): gb = bytes / (1024**3) return round(gb, 2)@click.command()@click.option(&quot;--webhook_url&quot;, required=True, help=&quot;企业微信机器人的Webhook&quot;)@click.option(&quot;--threshold&quot;, default=90, required=True, help=&quot;告警阈值&quot;)@click.option(&quot;--server_name&quot;, default=&quot;Server&quot;, required=True, help=&quot;服务器名称&quot;)def main(webhook_url, threshold, server_name): server_monitor = ServerMonitor(webhook_url, threshold, server_name) server_monitor.send_notification()if __name__ == &quot;__main__&quot;: main() 定时任务直接放 crontab 就行，比如每5分之检查一次。 crontab -e */5 * * * * /usr/bin/python3 /root/monitor.py --webhook_url=&quot;https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=xxx&quot; --server_name=&quot;puresai blog&quot; --threshold=90 &gt;/dev/null 2&gt;&amp;1 &amp;","tags":["python"],"categories":["python"]},{"title":"如何发布一个pip包","path":"/2024/03/21/510/","content":"准备注册号账号： https://pypi.org/account/register/ 编码code pip install buildpip install twinepip install setuptools wheeltouch setup.py setup.py from setuptools import setupfrom os import pathprint(path.abspath(path.dirname(__file__)))with open( path.join(path.abspath(path.dirname(__file__)), &#x27;README.md&#x27;), encoding=&#x27;utf-8&#x27;) as f: long_description = f.read()setup( name=&#x27;utilset&#x27;, version=&#x27;0.0.1&#x27;, author=&#x27;puresai&#x27;, url=&#x27;https://github.com/puresai/utilset&#x27;, description=&quot;util sets&quot;, long_description_content_type=&quot;text/markdown&quot;, long_description=long_description, packages=[&#x27;utilset&#x27;], install_requires=[], platforms=[&quot;all&quot;], classifiers=[ &#x27;Intended Audience :: Developers&#x27;, &#x27;Operating System :: OS Independent&#x27;, &#x27;Natural Language :: Chinese (Simplified)&#x27;, &#x27;Programming Language :: Python :: 3.5&#x27;, &#x27;Programming Language :: Python :: 3.6&#x27;, &#x27;Programming Language :: Python :: 3.7&#x27;, &#x27;Programming Language :: Python :: 3.8&#x27;, &#x27;Topic :: Software Development :: Libraries&#x27; ],) deploy python3 setup.py checkrm -rf distpython3 -m buildpython3 -m twine upload dist/* apitokenupload 之前是可以输入用户名密码的，但是几年有所变化，可以使用 apitoken 上传。 可以点击前往 https://pypi.org/manage/account/ 新建一个 apitoken，然后新建个 ~/.pypirc [distutils] index-servers=pypi[pypi] repository: https://upload.pypi.org/legacy/ username = __token__ password = pypi-xxxx-xxx source ~/.pypirc 然后上传就行，成功上传后就可以在pypi账户下看到自己的项目 https://pypi.org/manage/projects/了，可以 install 后使用了。","tags":["python"],"categories":["python"]},{"title":"vue深度选择器-子组件样式","path":"/2024/01/28/506/","content":"vue 每次编译后的 class 可能都是不一样的，name这种情况，怎么去修改 CSS 呢？ 单独加个 class 设置 使用 deep .bg-greg :deep(.van-grid-item__content)&#123; background: #bbb;&#125;","tags":["vue"],"categories":["debug"]},{"title":"MySQL大量数据insert失败的问题","path":"/2024/01/19/505/","content":"昨天处理数据发现，有个表的主键是VARCHAR类型，数据量超一亿，不方便遍历，删主键再加主键操作超时，提示建议建个新表，然后 insert。 下面是我的步骤: 新建表： CREATE TABLE `sai_new` ( `id` BIGINT UNSIGNED AUTO_INCREMENT PRIMARY KEY, `fid` VARCHAR(20) NOT NULL, `xxx` VARCHAR(32) NOT NULL) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci ROW_FORMAT=COMPRESSED; 插入数据： INSERT INTO `sai_new` (`fid`, `xxx`, `live_city`) SELECT `id`, `xxx`, `live_city` FROM `sai_13_old`; 这步很慢，最后直接报错。 ERROR 1206 (HY000): The total number of locks exceeds the lock table size SHOW VARIABLES LIKE &#x27;innodb_buffer_pool_size&#x27;;+-------------------------+-------------+| Variable_name | Value |+-------------------------+-------------+| innodb_buffer_pool_size | 134217728 |+-------------------------+-------------+1 row in set (0.08 sec) 调大： SET GLOBAL innodb_buffer_pool_size = 13421772800; 看下有没有改成功: 可以使用上面的目录，也可以这样。12.5G，增大为原来的100倍。 SELECT @@innodb_buffer_pool_size/1024/1024/1024;+------------------------------------------+| @@innodb_buffer_pool_size/1024/1024/1024 |+------------------------------------------+| 12.500000000000 |+------------------------------------------+1 row in set (0.26 sec) 继续 insert, 奖励了2小时45分36秒后，数据迁移成功。 话说这磁盘写入也是真的慢。 innodb_buffer_pool_sizeinnodb_buffer_pool_size 是缓冲池大小，必须始终等于 innodb_buffer_pool_chunk_size * innodb_buffer_pool_instances 或其倍数。主要影响读，且要注意这个参数增大会增大内存占用。 更多看手册： 15.8.3.1 Configuring InnoDB Buffer Pool Size","tags":["mysql"],"categories":["MySQL"]},{"title":"issues python3","path":"/2023/12/01/501/","content":"Just for record python3 pip install timeout pip3 install lxml raise ReadTimeoutError(self._pool, None, &quot;Read timed out.&quot;) pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host=&#39;files.pythonhosted.org&#39;, port=443): Read timed out. pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple lxml ‘int’ object does not support indexingpgsql = &quot;&quot;&quot;SELECT id, employee_count FROM companyWHERE id = %s&quot;&quot;&quot;pg_cursor.execute(pgsql, (row[&quot;member_id&quot;])) pg_cursor.execute(pgsql, (row[“member_id”],)) not all arguments converted during string formattingIncorrect number of arguments most likely due to a circular importpython3 marisa_trie.pyTraceback (most recent call last): File “/Users/sai/Documents/user-sai/ignore/marisa_trie.py”, line 1, in import marisa_trie File “/Users/sai/Documents/user-sai/ignore/marisa_trie.py”, line 3, in trie = marisa_trie.Trie([u’key1’, u’key2’, u’key12’])AttributeError: partially initialized module ‘marisa_trie’ has no attribute ‘Trie’ (most likely due to a circular import) rename filename to another name","tags":["python"],"categories":["python"]},{"title":"python3合并list并去重","path":"/2023/11/24/500/","content":"最简单的是遍历，就不赘述了。下面介绍转成set 方法 转成 setproduct_id_list = [&#x27;10047&#x27;, &#x27;8156&#x27;, &#x27;10788&#x27;, &#x27;12&#x27;]current = [&#x27;1&#x27;, &#x27;200&#x27;, &#x27;10047&#x27;, &#x27;34&#x27;]product_id_list.extend(current)print(&#x27;,&#x27;.join(set(product_id_list)))# 也可以这样写product_ids = &#x27;,&#x27;.join((item) for item in set(product_id_list))print(product_ids)","tags":["python"],"categories":["python"]},{"title":"使用mpdf生成pdf","path":"/2023/11/07/490/","content":"html 生成 pdf 是很常见的场景，有很多实现方式，这里我使用的是 mpdf。 对于如何寻找需要的库，我一般是 github 上按语言去搜索，用star倒序排，一般会尝试用前面几个且比较活跃的项目，然后看效果与需求匹配度。 安装必须开启 PHP mbstring 和 gd 扩展。某些高级功能可能需要额外的扩展，例如用于压缩输出和嵌入资源（例如字体）的 zlib 、用于生成条形码的 bcmath 或用于字符集的 xml 转换和 SVG 处理。 使用 composer 安装即可。 composer require mpdf/mpdf 使用$mpdf = new \\Mpdf\\Mpdf([ &#x27;autoScriptToLang&#x27; =&gt; true, &#x27;autoLangToFont&#x27; =&gt; true]);$html = &#x27;&lt;div style=&quot;margin: 0 auto; width: 600px; padding: 40px 20px; font-size: 20px;&quot;&gt;&lt;div style=&quot;font-size: 50px; padding: 16px 0; text-align: center; color: red; font-weight: 900; border-bottom: 4px solid red;&quot;&gt; 这是一个测试pdf&lt;/div&gt;&lt;div style=&quot;line-height: 40px; margin-top: 30px; height: 500px; margin-top: 30px; letter-spacing: 2px;&quot;&gt; &lt;p style=&quot;text-indent: 2em; &quot;&gt; 感谢puresai的大力支持！ &lt;/p&gt;&lt;/div&gt;&lt;div style=&quot;height: 40px; text-align: right; letter-spacing: 2px;&quot;&gt;&lt;/div&gt;&lt;div style=&quot;line-height: 32px; text-align: right; letter-spacing: 1px;&quot;&gt;&#x27;. date(&#x27;Y年m月d日&#x27;).&#x27;&lt;/div&gt;&lt;/div&gt;&#x27;;$mpdf-&gt;WriteHTML($html);$path = dirname(__DIR__).&#x27;/public/pdf/puresai.pdf&#x27;;$mpdf-&gt;OutputFile($path); 使用非常简单，来看一下效果。 感谢 https://github.com/mpdf/mpdf","tags":["php"],"categories":["php"]},{"title":"python3发送slack通知","path":"/2023/10/04/497/","content":"from slack_sdk import WebClientfrom slack_sdk.errors import SlackApiErrorToken = &quot;xoxb-xx-xx-xxx&quot;client = WebClient(token=Token)channel_id = &quot;xxx&quot;try: result = client.chat_postMessage(channel=channel_id, text=&quot;Hello!&quot;) print(result)except SlackApiError as e: print(f&quot;Error: &#123;e&#125;&quot;)","tags":["python"],"categories":["python"]},{"title":"企业微信审批接口踩坑","path":"/2023/09/11/496/","content":"我对接的是企业内部应用的api。 对接有几点要注意： 不使用应用的模板，貌似是个阉割版 审批模板要预先设置，对于服务端api对接来说，不能修改，如果是jssdk调用审批流程引擎，可以自定义流程 审批回调设置时，需要先验证一下，验证走的是GET请求，不是POST请求 有问题社区提问，社区的官方回答还是非常快的 审批应用可以单独设置分级管理员 审批可见范围要注意，不能设置的比模板可见范围还小","tags":["php"],"categories":["php"]},{"title":"python3实现bitmap","path":"/2023/08/11/492/","content":"我已经封装，可以直接使用。 import unittestfrom utilset import Bitmapclass TestBitmap(unittest.TestCase): def test_bitmap(self): bm = Bitmap.Bitmap(10) bm.set(2) bm.set(7) self.assertTrue(bm.test(2)) self.assertFalse(bm.test(3))if __name__ == &quot;__main__&quot;: unittest.main() 源码： import arrayclass BitMap(object): BITMASK = [0x01, 0x02, 0x04, 0x08, 0x10, 0x20, 0x40, 0x80] BIT_CNT = [bin(i).count(&quot;1&quot;) for i in range(256)] def __init__(self, maxnum=0): nbytes = (maxnum + 7) // 8 self.bitmap = array.array(&quot;B&quot;, [0 for i in range(nbytes)]) def __del__(self): pass def set(self, pos): &quot;&quot;&quot; Set the value of bit@pos to 1 &quot;&quot;&quot; self.bitmap[pos // 8] |= self.BITMASK[pos % 8] def reset(self, pos): &quot;&quot;&quot; Reset the value of bit@pos to 0 &quot;&quot;&quot; self.bitmap[pos // 8] &amp;= ~self.BITMASK[pos % 8] def flip(self, pos): &quot;&quot;&quot; Flip the value of bit@pos &quot;&quot;&quot; self.bitmap[pos // 8] ^= self.BITMASK[pos % 8] def count(self): &quot;&quot;&quot; Count bits set &quot;&quot;&quot; return sum([self.BIT_CNT[x] for x in self.bitmap]) def size(self): &quot;&quot;&quot; Return size &quot;&quot;&quot; return len(self.bitmap) * 8 def test(self, pos): &quot;&quot;&quot; Return bit value &quot;&quot;&quot; return (self.bitmap[pos // 8] &amp; self.BITMASK[pos % 8]) != 0 def any(self): &quot;&quot;&quot; Test if any bit is set &quot;&quot;&quot; return self.count() &gt; 0 def none(self): &quot;&quot;&quot; Test if no bit is set &quot;&quot;&quot; return self.count() == 0 def all(self): &quot;&quot;&quot; Test if all bits are set &quot;&quot;&quot; return (self.count() + 7) // 8 * 8 == self.size() def nonzero(self): &quot;&quot;&quot; Get all non-zero bits &quot;&quot;&quot; return [i for i in range(self.size()) if self.test(i)] def tostring(self): &quot;&quot;&quot; Convert BitMap to string &quot;&quot;&quot; return &quot;&quot;.join([(&quot;%s&quot; % bin(x)[2:]).zfill(8) for x in self.bitmap[::-1] ]) def __str__(self): &quot;&quot;&quot; Overloads string operator &quot;&quot;&quot; return self.tostring() def __getitem__(self, item): &quot;&quot;&quot; Return a bit when indexing like a array &quot;&quot;&quot; return self.test(item) def __setitem__(self, key, value): &quot;&quot;&quot; Sets a bit when indexing like a array &quot;&quot;&quot; if value is True: self.set(key) elif value is False: self.reset(key) else: raise Exception(&quot;Use a boolean value to assign to a bitfield&quot;) def tohexstring(self): &quot;&quot;&quot; Returns a hexadecimal string &quot;&quot;&quot; val = self.tostring() st = &quot;&#123;0:0x&#125;&quot;.format(int(val, 2)) return st.zfill(len(self.bitmap) * 2) @classmethod def fromhexstring(cls, hexstring): &quot;&quot;&quot; Construct BitMap from hex string &quot;&quot;&quot; bitstring = format( int(hexstring, 16), &quot;0&quot; + str(len(hexstring) / 4) + &quot;b&quot;) return cls.fromstring(bitstring) @classmethod def fromstring(cls, bitstring): &quot;&quot;&quot; Construct BitMap from string &quot;&quot;&quot; nbits = len(bitstring) bm = cls(nbits) for i in range(nbits): if bitstring[-i - 1] == &quot;1&quot;: bm.set(i) elif bitstring[-i - 1] != &quot;0&quot;: raise Exception(&quot;Invalid bit string!&quot;) return bm 参考： https://github.com/wanji/bitmap","tags":["python"],"categories":["python"]},{"title":"解决移动端点击放大出现x轴滚动条问题","path":"/2023/08/02/492/","content":"测试一个移动端项目时，点击输入框准备输入时，却放大切出现x轴方向的固定条，如何解决这个问题呢？ 解决其实很简单，我们可以加一行 meta 声明。 &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0, user-scalable=0&quot;&gt; 这行 meta 标签的作用是让当前viewport的宽度等于设备的宽度，同时不允许用户手动缩放这样就不会出现横向滚动条。 属性说明 width: 控制 viewport 的大小，可以指定的一个值或者特殊的值，如 device-width 为设备的宽度（单位为缩放为 100% 时的 CSS 的像素）。 height: 和 width 相对应，指定高度。 initial-scale: 初始缩放值。这是一个浮点值，是页面大小的一个乘数。例如，如果你设置初始缩放为 1.0，那么这个页面不缩放。 maximum-scale:最大缩放。即允许的最大缩放程度。这也是一个浮点值，用以指出页面大小与屏幕大小相比的最大乘数。例如，如果你将这个值设置为2.0，那么这个页面最多能放大2倍。 minimum-scale:最小缩放。即允许的最小缩放程度。类比 maximum-scale user-scalable:用户调整缩放。即用户是否能改变页面缩放程度。如果设置为yes则是允许用户对其进行改变，反之为no。默认值是yes。也可以是0和1。注意：如果你将其设置为no，那么minimum-scale 和 maximum-scale都将被忽略，因为根本不可能缩放。 另外： target-densitydpi:值可以为一个数值或 high-dpi 、 medium-dpi、 low-dpi、 device-dpi 这几个字符串中的一个。安卓中支持，当 target-densitydpi=device-dpi 时， css中的1px会等于物理像素中的1px。 参考 禁止移动端safari浏览器双击放大事件 移动端适配之三：使用meta标签设置viewport","tags":["web"],"categories":["web"]},{"title":"Vant多图压缩后上传的解决过程","path":"/2023/07/25/491/","content":"前一阵用 Vant 写一个项目，遇到多图压缩上传的问题，今天就解决过程做一个简单的分享，希望对你有所帮助。 使用 van-uploader 组件&lt;van-uploader v-model=&quot;images&quot; multiple :after-read=&quot;afterRead&quot; upload-icon=&quot;plus&quot; /&gt; afterRead 实现上传操作，对应的后端代码较简单，我这里就省略了（其实就是返回状态和地址）。这里为了效果，增加了上传中，上传成功这些状态。 const afterRead = (file) =&gt; &#123; if (file instanceof Array) &#123; file.forEach((v, i) =&gt; &#123; v.status = &#x27;uploading&#x27;; v.message = &#x27;上传中...&#x27;; uploadImage(v.file).then((res)=&gt;&#123; ... v.status = &#x27;success&#x27;; v.message = &#x27;上传成功&#x27;; &#125;).catch((err) =&gt; &#123; v.status = &#x27;failed&#x27;; v.message = &#x27;上传失败&#x27;; &#125;) &#125;) &#125; else &#123; file.status = &#x27;uploading&#x27;; file.message = &#x27;上传中...&#x27;; uploadImage(file.file).then((res)=&gt;&#123; console.log(res) ... file.status = &#x27;success&#x27;; file.message = &#x27;上传成功&#x27;; &#125;).catch((err) =&gt; &#123; file.status = &#x27;failed&#x27;; file.message = &#x27;上传失败&#x27;; &#125;) &#125;&#125; 压缩压缩其实可以后端实现，也可以前端压缩后上传，还可以第三方sdk，这里为了简单（成本），直接选择前端压缩后上传。 前端压缩可以自己实现，我的js 水平一般般，这里直接使用现成的 compressorjs，这也是 Vant 推荐使用的。 照着官网的例子，我们发现 before-read 支持返回 Promise。 const beforeRead = (file) =&gt; new Promise(resolve =&gt; &#123; new Compressor(file, &#123; strict: false, quality: 0.6, // 压缩质量 maxWidth: 1980, // 最大宽度 maxHeight: 1980, convertTypes: [&#x27;image/jpeg&#x27;], // 转换格式 convertSize: 500000, // 500k 文件类型包含在convertTypes列表中的文件，其文件大小超过此值的文件将被转换为jpeg。 success: resolve, error(err) &#123; showFailToast(err.message); &#125;, &#125;); &#125;); 测试上传单张，没毛病。上传多张就发现慢得很，为啥慢？一是没压缩，二是我的带宽小。 解决这里是因为多张上传，file 其实是一个数组，没经过压缩。 那我想，那行，那我就判断一下： if (Array.isArray(file)) &#123; let compressPromises = []; file.forEach(function(v)&#123; compressPromises.push(new Promise(resolve =&gt; &#123; new Compressor(file, &#123; strict: false, quality: 0.6, maxWidth: 1980, maxHeight: 1980, convertTypes: [&#x27;image/jpeg&#x27;], convertSize: 500000, success: resolve, error(err) &#123; showFailToast(err.message); &#125;, &#125;); &#125;)); &#125;) return compressPromises&#125; else &#123; return new Promise(resolve =&gt; &#123; new Compressor(file, &#123; strict: false, quality: 0.6, maxWidth: 1980, maxHeight: 1980, convertTypes: [&#x27;image/jpeg&#x27;], convertSize: 500000, success: resolve, error(err) &#123; showFailToast(err.message); &#125;, &#125;); &#125;)&#125; 测试一波， 原图2.5M，这里还是2M多。这又是为毛？？？？ before-read 确实支持返回 Promise，但我们上面的compressPromises并不是 Promise，而是一个 Promise 数组。 继续改，怎么把这些 Promise 合起来呢？ 查看Promise 文档，有这个方法 Promise.all() 。 继续改： 既然通用，我们不妨稍微封装下。 import Compressor from &#x27;compressorjs&#x27;import &#123; showFailToast &#125; from &#x27;vant&#x27;function compressorOne(file)&#123; return new Promise(resolve =&gt; &#123; new Compressor(file, &#123; strict: false, quality: 0.6, maxWidth: 1980, maxHeight: 1980, convertTypes: [&#x27;image/jpeg&#x27;], convertSize: 500000, success: resolve, error(err) &#123; showFailToast(err.message); &#125;, &#125;); &#125;)&#125;export function compressor(file)&#123; if (Array.isArray(file)) &#123; let compressPromises = []; file.forEach(function(v)&#123; compressPromises.push(compressorOne(v)); &#125;) return Promise.all(compressPromises) &#125; else &#123; return compressorOne(file) &#125;&#125; beforeRead 这里直接调用封装的 compressor const beforeRead = (file) =&gt; &#123; return compressor(file)&#125; 测试。 可以看到 size 确实比之前小了很多，只有200k了。 PS: 对于 compressorjs 的参数可以按需调整 总结这里其实费时间的主要是多图压缩的封装，其他都不怎么费事。遇到问题，如果是比较常用的，我的建议是先去搜索，搜索有两块，一块浏览器，一块是 github 项目的 issue。一般都能找到答案，但也可能并不能解决，我们就自己查找文档甚至阅读源码。剩下就是代入测试。","tags":["vant"],"categories":["vant"]},{"title":"Python中strip多字符慎重使用","path":"/2023/07/22/490/","content":"Python中strip，是非常常用的，经常用来去除空格，但最近发现一个坑，如果是多字符使用strip，千万慎重。 看例子： &gt;&gt;&gt; str = &#x27;abc123abc&#x27;&gt;&gt;&gt; print(str.strip(&#x27;a&#x27;))bc123abc&gt;&gt;&gt; print(str.strip(&#x27;abc&#x27;))123&gt;&gt;&gt; print(str.strip(&#x27;ab&#x27;))c123abc&gt;&gt;&gt; print(str.strip(&#x27;cba&#x27;))123&gt;&gt;&gt; print(str.strip(&#x27;cc&#x27;))abc123ab&gt;&gt;&gt; print(str.strip(&#x27;ca&#x27;))bc123ab&gt;&gt;&gt; print(str.strip(&#x27;cbaass&#x27;))123 print(str.strip(&#39;cba&#39;)) 这个返回123就比较诡异了。 建议去除多字符还是考虑使用 replace , strip 不适合。","tags":["python"],"categories":["python"]},{"title":"人人都用得上的写作课4","path":"/2023/05/28/484/","content":"本文是极客时间专栏《人人都用得上的写作课》的笔记。 细节打磨 细节的抓取必须来源于观察，这是最基本的方法。 精确联想 联想共情的细节 联想那些让你觉得异常、会产生反差的细节 借助道具运用人物、事件身边与之关系密切的东西，来凸显它的特点。 逐步细化细节就是要把模糊的变成具体的。 注意事项: 详略得当 不要无用的细节 遣词造句基本原则是：要正确地使用语法、句法和词语，不要出现病句与错句。 基本方法是：培养语感。 词语： 精确凝练（修饰尽可能是为了主题服务，能省则省） 动态感表达 句式： 语句顺序 打破常规（让句子有快有慢，让句子有不同的视角。） 有效修改三步修改法： 先增后减宏观把握全篇，注意叙述距离。 两个视角： 内部视角（呈现） 概述性视角（表单）论据处理 连贯性 寻找那些细小而多余的结构，找东西替换它或者删掉它。 设计一个好的路标，当然，如果这个路标没有意义，那就不要用它。 修改文章的时候，你一定要读出来，也可以默念。要知道，语感可以极大限度地帮助你的修改。","tags":["reading"],"categories":["reading"]},{"title":"人人都用得上的写作课3","path":"/2023/05/07/483/","content":"本文是极客时间专栏《人人都用得上的写作课》的笔记。 开篇制胜寻找神秘或冲突哪些问题是读者最关心的，哪些因素是最能让他们有代入感的。确定最精彩的元素。 三步走 记录最神秘、冲突的部分 拆分这个部分，拆分成任务、事件、地点、时间等，找出其中1-2个小元素放大 为这些放大的特质建立画面 两种开头模式 综述型 谢梦遥《国王在领地》 细节型 《外卖骑手，困在系统里》 生动叙事叙述节奏郁达夫《故都的秋》 速度感 – 是通过短句、简单句式来实现的。相反，如果你写的句式过于复杂，它就会拖慢你的表达。 力量感 – 排比， 调整句子的语序（关键的词语放在开头或者结尾） 变化感 – 句式句型的变化 杨继斌《富士康“八连跳”自杀之谜》 叙事策略（递进） 多线叙事 电视剧《沉默的真相》 环线叙事 电影《恐怖的邮轮》 多线叙事，它的应用很广泛，关键是要围绕主题确定主线；环形叙事，它比较适合那种，事件或者人物难以逃脱宿命的题材，生活中也很常见。 人物出场最根本的方法就是要有神秘感、要有冲突 使用引语 制作悬念 细节描写 环境描述 《红楼梦》王熙凤的出场 进阶： 不仅可以制造悬念，还可以制造错觉和冲突。另外，还有两个常见的写作技巧：用环境昭示人物的命运，让环境与命运相呼应；让主角晚登场，从而避免这个主角给读者带来的陌生感。 微信公众号往事叉烧的文章《冯小刚王朔们的黑历史》叶京的出场","tags":["reading"],"categories":["reading"]},{"title":"人人都用得上的写作课2","path":"/2023/04/29/482/","content":"本文是极客时间专栏《人人都用得上的写作课》的笔记。 如何打造好的写作主题？优质的输入是输出的刚需。 打开宽度：跨领域思考（发散思维） 适合于开放性话题 不同的分类意味着不同的观察视角。 政治角度 经济角度 文化角度….. 挖掘深度：由表及里（逻辑思维） 适用于对某个现象的分析，关键点是细致观察 打开宽度：跨领域思考。这种方法适用于开放性议题的写作，比如女性议题、法治议题等。要想真正掌握这个方法，平日里一定要多加练习，锻炼自己的发散思维。 挖掘深度：由表及里。这种方法适用于分析现象的写作，比如事故原因等等。掌握这个方法的关键则是多问为什么，在探究答案的过程中，往往会有意想不到的收获。 谋篇布局 如何为你的文章找到主心骨？ 怎么在主心骨的基础上长出骨架？ 怎么展开骨架？ 主心骨–一句话法则一个句子清晰地概括整篇文章。先确定价值（找关键词），再高度概括。 三段式结构 触发–导火索 冲突–找到矛盾，让读者对内容产生认同。 解决–别忘了根据解决部分的内容，想出一个有韵味的收尾。 展开骨架 时间 空间","tags":["reading"],"categories":["reading"]},{"title":"人人都用得上的写作课1","path":"/2023/04/25/481/","content":"本文是极客时间专栏《人人都用得上的写作课》的笔记。 如何阅读帮助写作？ 优质的输入是输出的刚需 写作是建立在阅读量的基础上的，一定要多看。 读什么？阅读树： 根 – 经典作品 – 顺序是先读基本原理，再读通史。（不局限特定领域） 枝干 – 期刊、行业新闻、分析报告、政府发布的信息等 叶 – 自媒体、社媒 怎么读？区分式阅读： 深度阅读 – 经典 泛读 提炼观点： 理解观点（边读边划重点） 剔除问题 学会联想 过去读过的 自己曾经的体验，感悟 正在发生的事 随时记录 有章法（分类：观点、表现手法、自我感想） 记录灵感 好文章的标志 行文节奏：简单即美 文字表述：确保准确，再看词藻 主题刻画：鲜明与否，突出与否 “以正合” – 用读者熟悉的解读方式、熟悉的意象去讲你的主题，“以奇胜” – 强调作者自己的思考，利用你的独特观察创造性地去解释读者没有注意到的东西。 写作误区 在克服恶习上，迟到总比不做强。 滥用形容词和连词 滥用不仅指使用形容词不准确，还有堆砌形容词 不滥用，不是不用，而是用精当 想不出来精准的形容词就不要用 连词用得过多，会影响句子的节奏和美感 除非逻辑表达容易混淆，否则，慎用连词 中西文化 滥用被字句（中文的正常表达，是主语 + 动词 + 名词，要改变句式顺序，一定要有特别的原因。） 喜欢用弱动词，比如：造成、进行 此类动词 喜欢用从句 随意堆砌段落缺乏逻辑思维总结 写作的第一要务就是要清楚的表达信息 信息分三类： 记述信息：用于描述事物的情况和现象信息 评价信息：价值判断 规范信息：事物应该有的状态以及人该采取的行动我们要根据不同的文本，使用不同的信息。比如，对专业论文来讲，多用记述信息，因为准确；对科普文章，就要多用些评价信息，方便理解。","tags":["reading"],"categories":["reading"]},{"title":"excel计算空白数量","path":"/2023/04/09/480/","content":"最近经常使用 excel 做一些统计，备注一下。 统计某列不为空数量=COUNTA(O2:O1657)=COUNTA(Q2:Q1657) 统计某列为空数量=COUNTBLANK(J2:J3319) 统计某两列都为空数量=COUNTIFS(M2:M12095,&quot;&quot;,O2:O12095,&quot;&quot;)=COUNTIFS(O2:O1657,&quot;&quot;,Q2:Q1657,&quot;&quot;) 统计某两列都为空数量总行数减去上面的","tags":["office"],"categories":["office"]},{"title":"MySQL的exists","path":"/2023/02/13/473/","content":"相较于 in，exists 其实没有特别高频的使用。exists 语句并不那么容易读。今天我们来使用一下: mock dataCREATE TABLE `users` ( `id` int unsigned NOT NULL AUTO_INCREMENT, `name` varchar(255) NOT NULL, `status` tinyint(1) NOT NULL DEFAULT &#x27;1&#x27;, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;CREATE TABLE `user_logs` ( `id` int unsigned NOT NULL AUTO_INCREMENT, `user_id` int unsigned NOT NULL, `content` varchar(255) NOT NULL, `created_at` timestamp NULL DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci; 插入测试数据: INSERT INTO `users`(id, name) VALUES(1, &#x27;sai&#x27;);INSERT INTO `users`(id, name) VALUES(2, &#x27;os&#x27;);INSERT INTO `users`(id, name) VALUES(3, &#x27;jack&#x27;);INSERT INTO `users`(id, name) VALUES(4, &#x27;kai&#x27;);INSERT INTO `users`(id, name) VALUES(5, &#x27;tom&#x27;);INSERT INTO `users`(id, name) VALUES(6, &#x27;peter&#x27;);INSERT INTO `users`(id, name) VALUES(7, &#x27;li&#x27;);INSERT INTO `users`(id, name) VALUES(8, &#x27;bob&#x27;);INSERT INTO `users`(id, name) VALUES(9, &#x27;wuliuqi&#x27;);INSERT INTO `users`(id, name) VALUES(10, &#x27;awesome&#x27;);INSERT INTO `user_logs`(user_id, content) VALUES(1, &#x27;create post&#x27;);INSERT INTO `user_logs`(user_id, content) VALUES(1, &#x27;delete post: 1&#x27;);INSERT INTO `user_logs`(user_id, content) VALUES(1, &#x27;delete post: 55&#x27;);INSERT INTO `user_logs`(user_id, content) VALUES(2, &#x27;delete post: 23&#x27;);INSERT INTO `user_logs`(user_id, content) VALUES(3, &#x27;delete post:34&#x27;);INSERT INTO `user_logs`(user_id, content) VALUES(4, &#x27;delete post:40&#x27;);INSERT INTO `user_logs`(user_id, content) VALUES(4, &#x27;add post&#x27;);INSERT INTO `user_logs`(user_id, content) VALUES(4, &#x27;delete post:99&#x27;);INSERT INTO `user_logs`(user_id, content) VALUES(4, &#x27;delete post:140&#x27;); 判断是否存在我们使用 exists 判断某条记录是否存在: mysql&gt; select exists (select * from `users` where id = 1);+---------------------------------------------+| exists (select * from `users` where id = 1) |+---------------------------------------------+| 1 |+---------------------------------------------+1 row in set (0.00 sec)mysql&gt; select exists (select * from `users` where id = 13);+----------------------------------------------+| exists (select * from `users` where id = 13) |+----------------------------------------------+| 0 |+----------------------------------------------+1 row in set (0.00 sec) 子查询exists 更多用于子查询: SELECT * FROM `user_logs` WHERE EXISTS ( SELECT * FROM `users` WHERE `users`.id = `user_logs`.user_id and `users`.id = 1); 你知道会输出什么吗? 当我第一次看到这个语句时是这么理解的, where 后面的是1，所以会列出所有的 user_logs 。 显然我的理解是: SELECT * FROM `user_logs` WHERE 1; 但输出打脸了 😢 +----+---------+-----------------+---------------------+| id | user_id | content | created_at |+----+---------+-----------------+---------------------+| 1 | 1 | create post | 2023-02-14 08:54:59 || 2 | 1 | delete post: 1 | 2023-02-14 08:54:59 || 3 | 1 | delete post: 55 | 2023-02-14 08:54:59 |+----+---------+-----------------+---------------------+3 rows in set (0.00 sec) 其实上面的语句与下面的语句结果一致的。 SELECT * FROM `user_logs` WHERE user_id in ( SELECT id FROM `users` WHERE `users`.id = 1); SELECT `user_logs`.* FROM `user_logs` LEFT JOIN `users` ON `users`.id = `user_logs`.user_id WHERE `users`.id = 1; in 还是 exists对于很多博客中提到的 in 适合于外表大而子查询表小的情况，exists 适合于外表小而子查询表大的情况，其实并不准确。MySQL 手册中提到，如果没有使用 materialization ，优化器又是会重写查询，即可能会将 in 转成 exists。那么这种情况性能其实是没什么差别的。但是给大表加索引一般是有效的。 参考 Optimizing Subqueries with Materialization","tags":["mysql"],"categories":["MySQL"]},{"title":"Redis hyperloglog误判","path":"/2023/02/05/472/","content":"HyperLogLog 是 Redis 的一种数据类型。在 Redis 里面，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基 数。这和计算基数时，元素越多耗费内存就越多的集合形成鲜明对比。HyperLogLog 的典型应用场景就是计算 uv。 但是 HyperLogLog 是存在误判的，官方介绍其标准误差为0.81%，所以如果你想精确的统计 uv，仅仅使用 HyperLogLog 是不够的。 我们不妨测试下： import Redisimport hashlibdef md5(text: str): return hashlib.md5(text.encode()).hexdigest()Redis_conn = Redis.Redis(host=&quot;localhost&quot;, port=6379, db=0)Redis_conn.auth(&quot;123456&quot;)for i in range(1000): if Redis_conn.pfadd(&quot;hyperloglog-test&quot;, md5(str(i))) == 0: print(i) 输出如下： ➜ user-sai git:(main) ✗ python3 codesnippets/python/hyperloglog.py193294406527579588616688706764770846872876880888941975984991 可以看到是有一些误判的。 因而，如果需要很精确地做类似去重计数任务， HyperLogLog 并不是一个好的方案，即便 HyperLogLog 又快又节省内存。 参考： Redis new data structure: the HyperLogLog","tags":["Redis"],"categories":["Redis"]},{"title":"2022,这一年","path":"/2023/01/21/2022/","content":"先祝福各位除夕快乐，兔年吉祥顺意。 又到了自己年终总结的时候了，看了下去年的计划，完成得都不怎么样，罢了罢了。 如果用一个词描述即将过去的一年，我想没有比“魔幻”更好的了。这一年发生了很多事，有些事也许这一辈子再也不想经历了，但又感觉好不真切。也许生活就是这般荒诞无常。 生活没有什么比得而失去更让人遗憾的了。年中有一阵我对琐事有一种很强的无力感，不知所措，但又不得不疲于应付，这感觉很糟。当事情失去控制的感觉，真的让人很难受，只能被迫接受，不知道这是不是三十而立的必经之路。 让我感受最深的是，陪伴是很重要的，她不至于让我跌入情感的深渊，更多的是让我从这无助中找到希望。感谢我的妻子，这一年跟我经历了那么多，但一直不断激励我，包容我，而她自己一直保持积极的心态，给予我充分的信任。 工作因为某些原因最终离职了，索性离开了南京，去到扬州，空窗几个月后，最终机缘巧合之下找了一份 remote 工作。这是年初没有料到的，也算是因祸得福吧！没想到这么快能结束异地，这也算是让妻子幸福感提升的一件事吧！ 新的工作真的要感谢同事的信任和帮助、友善，如今也算融入其中了吧！ 工作的主要语言也在转变为 python、sql，想想这些年，使用过的编程语言，js、php、go、python，行业有电商、教育、游戏、O2O等。真的是计划赶不上变化。感受就是好好学习吧，不管是深度度还是广度，在你有所余力的时候，多学一些总没坏处。 学习从五月份决定考研，到端午节之后开始备考看书，再到失业全职考研，再到回家考研。没料到的是，考试前一天晚上开始发烧，凌晨五点左右才睡着，第二天坚持完上午的考试，出考场整个人都有点虚脱，全身酸疼，下楼能明显感觉腿在抖。回到宾馆叫唤了好一会，实在受不了才吃了退烧药，午休后精神好多了，坚持考完下午的英语二。 好在只有一天考试，也算不幸中的万幸。暂时也不想那么多，成绩出来再说其他的吧！ 对于非全考研，我的建议是尽早确定尽早准备，别信什么三个月上岸，踏踏实实准备按计划走才是王道。 虽然 2022 这一年太过魔幻，但多少总有些成长，不感激这一年，感激我自己，感激身边人，经历了这一切，仍然心存善良，充满希望。 过去就让它过去吧，不如”吃饭时吃饭，睡觉时睡觉”。最后，照例立一下 flag： 新年计划： 技术学习，ts\\react 运动减重 读书 30 本 拍视频 最后，希望大家新的一年身体健康，人民币多一年，烦恼少一点。 壬寅除夕于安庆2022年01月31日","tags":["oneyear"],"categories":["oneyear"]},{"title":"python如何跳出多层循环","path":"/2023/01/13/471/","content":"php break 后面是可以带数量，表示跳出的层数，python如何跳出多层循环呢？ 以 python3 代码为例，有以下几种方法。 打包函数，使用 returndef sai(): for i in range(10): for j in range(10): if i + j &gt; 13: return i, jprint(sai()) 将循环逻辑打包成一个单独的函数，满足条件直接 return 变量标记def flag(): btn = False for i in range(10): for j in range(10): if i + j &gt; 13: btn = True break if btn: break print(i, j)flag() 使用 btn 标记，btn == True 则继续跳出。 for/elsedef loop(): for i in range(10): for j in range(10): if i + j &gt; 13: break else: continue break print(i, j)loop() raise Exceptionclass Break(Exception): passtry: for i in range(10): for j in range(10): if i + j &gt; 13: raise Breakexcept Break: print(i, j) 总感觉这个方法不太优雅。 以上几种方法就是针对多层循环的跳出，我个人倾向于抽象个函数，当然了，习惯哪种如你所想。 如果有其他好的方式，欢迎分享。","tags":["python"],"categories":["python"]},{"title":"git pull 一直失败","path":"/2023/01/09/470/","content":"最近在服务器上使用 git pull 遇到了一些问题，如果你也遇到，希望我的分享对你有所帮助。 No such file or directory.先是遇到这个错误 git pullWarning: Identity file /home/sai/.ssh/sai not accessible: No such file or directory. 提示是没有文件，我们去新建一下即可。 但是应该新建文件里面是什么内容呢？ 查看了下 git config git config -lsafe.directory=/src/abccore.repositoryformatversion=0core.filemode=truecore.bare=falsecore.logallrefupdates=truecore.sshcommand=ssh -i ~/.ssh/sairemote.origin.url=git@github.com:puresai/code.git 可以看到定义了 sshcommand 对于 core.sshCommand 如果设置了这个变量，当git fetch和git push需要连接到远程系统时，它们将使用指定的命令而不是ssh。该命令与GIT_SSH_COMMAND环境变量的形式相同，在设置环境变量时将被覆盖。 我们复制 ~/.ssh/id_rsa 即可。 cp ~/.ssh/id_rsa ~/.ssh/sai 完成这一步之后，有遇到问题。 git pullERROR: Repository not found.fatal: Could not read from remote repository.Please make sure you have the correct access rightsand the repository exists. 这个问题花了我不少时间，去github ssh keys 发现服务器上的 id_rsa.pub 已经加了。 最后重新生成 ssh-keygen -t rsa -C &quot;puresai&quot; 需要一步步确认，会发现 id_rsa.pub 和 id_rsa 已经生成。前往 github 添加 id_rsa.pub 。 git pullAlready up to date.","tags":["git"],"categories":["CI"]},{"title":"python如何遍历list并删除元素","path":"/2022/11/14/461/","content":"在开发场景中，python 遍历list并删除其中部分元素是很常见的场景。我们简化一下： 现在有一个list [1,2,4,-1,-4,1,9,-7,0], 如何删除list中为负数的元素。 聪明如我，不难想到，遍历判断删除呗！soeasy！ l = [1,2,4,-1,-4,1,9,-7,0]for item in l: if item &lt; 0: l.remove(item)print(l) 我们运行一下，看一下输出： [1, 2, 4, -4, 1, 9, 0] Wow~ remove 函数用于移除列表中某个值的第一个匹配项 好办，我使用index删除。 l = [1,2,4,-1,-4,1,9,-7,0]for (i, item) in enumerate(l): if item &lt; 0: del l[i]print(l) 再来一波： [1, 2, 4, -4, 1, 9, 0] 额额。貌似不对，我们不妨打印一下： l = [1,2,4,-1,-4,1,9,-7,0]for (i, item) in enumerate(l): print(l) if item &lt; 0: del l[i]print(l) python3 test_list.py[1, 2, 4, -1, -4, 1, 9, -7, 0][1, 2, 4, -1, -4, 1, 9, -7, 0][1, 2, 4, -1, -4, 1, 9, -7, 0][1, 2, 4, -1, -4, 1, 9, -7, 0][1, 2, 4, -4, 1, 9, -7, 0][1, 2, 4, -4, 1, 9, -7, 0][1, 2, 4, -4, 1, 9, -7, 0][1, 2, 4, -4, 1, 9, 0] 能看出来删除后其实 index 变化，导致部分元素漏删了。 那么到底如何正确操作呢？ filterl = [1,2,4,-1,-4,1,9,-7,0]def filter_small(item): if item &lt; 0: return False return Truetmplist = filter(filter_small, l)print(list(tmplist)) 需要注意python2和Python3的filter是有区别哈！ [1, 2, 4, 1, 9, 0] 语法糖l = [1,2,4,-1,-4,1,9,-7,0]l = [x for x in l if x &gt;= 0]print(l) 注意这里条件，是&gt;=0，就是把非整数保留。 倒序遍历正向遍历删除元素index变化，那我倒序遍历没毛病吧 l = [1,2,4,-1,-4,1,9,-7,0]for item in range(len(l) - 1, -1, -1): if l[item] &lt; 0: del l[item]print(l) 当然了，其实还有其他方法，比如创建个新的 list，判断后插入，这也是很简单的。 关于list遍历删除就介绍这么多了，写完代码务必老老实实各种情况测试好，不要想当然，就匆匆发布哟！","tags":["python"],"categories":["python"]},{"title":"Problems encountered when using mysql8, and how to solve them","path":"/2022/10/31/460/","content":"environment osx 12.5.1 mysql8.0.30 Public Key Retrieval is not alloweddb manager: DBeaver Right click your connection, choose “Edit Connection” On the “Connection settings” screen (main screen) click on “Edit Driver Settings” Click on “Connection properties”, (In recent versions it named “Driver properties”) Right click the “user properties” area and choose “Add new property” Add two properties: “useSSL”(false) and “allowPublicKeyRetrieval”(true) Forget password Click system settings On the “system settings” panel, Click on the MySQL icon below Click ‘Initailize Database’ button Then enter a new password, and select a type of the password encryption Restart the MySQL reference https://stackoverflow.com/questions/50379839/connection-java-mysql-public-key-retrieval-is-not-allowed","tags":["mysql"],"categories":["MySQL"]},{"title":"MySQL大批量数据导入","path":"/2022/10/22/450/","content":"目标千万行的的 json 数据或者 CSV 快速导入 MYSQL 的场景。 解决方案脚本代码使用 php / python 或者你熟悉的语言，按行解析，插入。 tips： 一次解析多行，提交效率 分组插入，减少 MySQL 插入次数 注意内存 每次解析的行数和每次插入的行数按具体情况 ，主要考虑运行内存和MySQL的压力情况。 load data对于 CSV 我们可以直接使用 SQL，可以直接运行，或者配合其他脚本使用。 LOAD DATA LOCAL INFILE &#x27;/xxx.csv&#x27; INTO TABLE linkedinFIELDS TERMINATED BY &#x27;,&#x27; LINES TERMINATED BY &#x27; &#x27; IGNORE 1 LINES (@C1,@C2,@C3,@C4)set company=@C1,website=upper(@C2),address=concat(@C3, &quot;-&quot;,@C4),imported_at=now(),zip=if(now()&lt;&#x27;1988-01-01&#x27;,&#x27;1&#x27;,&#x27;2&#x27;);LOAD DATA LOCAL INFILE &#x27;/puresai.json&#x27; INTO TABLE oscomeFIELDS TERMINATED BY &#x27;,&#x27; LINES TERMINATED BY &#x27;\\r &#x27;; mysqlimport对于 CSV 我们可以直接使用 ./mysqlimport -u root -p --local --delete --fields-terminated-by=&quot;,&quot; --lines-terminated-by=&quot;\\r &quot; --ignore-lines=1 --columns=company,website testdata &#x27;/puresai.csv&#x27; MySQL Shellmysqlsh mysql://root:123456@127.0.0.1:3366 -- util import-table puresai.json &quot;data_b*&quot; data_d.tsv.zst --schema=mydb --table=twitter --osBucketName=mybucketmysql-py&gt; util.import_table([&quot;./puresai.csv&quot;],&#123;&quot;schema&quot;:&quot;testdata&quot;,&quot;table&quot;:&quot;test&quot;,&quot;dialect&quot;:&quot;csv&quot;,&quot;columns&quot;:[1,2,3,4,5,6,7,8,9,10,11,12],&quot;decodeColumns&quot;:&#123;&quot;company&quot;:&quot;@1&quot;,&quot;website&quot;:&quot;@2&quot;,&quot;url&quot;:&quot;@3&quot;,&quot;address&quot;:&quot;@4&quot;,&quot;zip&quot;:&quot;@5&quot;,&#125;,&quot;skipRows&quot;:1,&quot;showProgress&quot;:True,&quot;threads&quot;: 3&#125;);mysql-py&gt; util.import_table([&quot;./puresai.json.gz&quot;],&#123;&quot;schema&quot;:&quot;testdata&quot;,&quot;table&quot;:&quot;twitter&quot;,&quot;dialect&quot;:&quot;json&quot;,&quot;columns&quot;:[1,2,3,4,5,6,7,8,9,10,11,12],&quot;decodeColumns&quot;:&#123;&quot;id&quot;:&quot;@1&quot;,&quot;name&quot;:&quot;@2&quot;&#125;,&quot;skipRows&quot;:1,&quot;showProgress&quot;:True,&quot;threads&quot;: 3&#125;); 总结对于 CSV 或者格式化文本使用 mysqlimport、load data 都是不错的选择，而脚本解析是最有普适性的，假如需要打印日志、进度或者字段变更，使用 php/python 等去解析更为灵活。","tags":["mysql"],"categories":["MySQL"]},{"title":"VSCode 插件推荐","path":"/2022/09/29/441/","content":"VSCode 插件推荐： git插件 颜值扩展 效率提升 拓展工具 摸 🐟 鱼","tags":["VSCode"],"categories":["开源到"]},{"title":"kubernete实战篇-PVC","path":"/2022/09/16/435/","content":"Kubernetes 对于有状态的日期应用或者对于数据需要持久化的应用，就需要更可靠的存储来保存应用产生的重要数据了。这里需要的就是持久卷（PersistentVolume）和 持久卷申领（PersistentVolumeClaim）。 涉及的知识点： PV PVC StorageClass StatefulSet Service 持久卷（PersistentVolume，PV）是集群中的一块存储，可以事先供应，或者使用存储类（Storage Class）来动态供应。 持久卷是集群资源，就像节点也是集群资源一样。PV 持久卷和普通的 Volume 一样，也是使用 卷插件来实现的，只是它们拥有独立于任何使用 PV 的 Pod 的生命周期。 此 API 对象中记述了存储的实现细节，无论其背后是 NFS、iSCSI 还是特定于云平台的存储系统。 持久卷申领（PersistentVolumeClaim，PVC）表达的是用户对存储的请求。概念上与 Pod 类似。 Pod 会耗用节点资源，而 PVC 申领会耗用 PV 资源。Pod 可以请求特定数量的资源（CPU 和内存）；同样 PVC 申领也可以请求特定的大小和访问模式 （例如，可以要求 PV 卷能够以 ReadWriteOnce、ReadOnlyMany 或 ReadWriteMany 模式之一来挂载，参见访问模式）。 下面以 influxdb 为例子： # 单独弄个Namespace influxdbapiVersion: v1kind: Namespacemetadata: name: influxdb---# 配置文件弄个ConfigMap，便于修改apiVersion: v1kind: ConfigMapmetadata: name: influxdb-config namespace: influxdbdata: influxdb.conf: &gt;- [meta] dir = &quot;/var/lib/influxdb/meta&quot; [coordinator] log-queries-after = &quot;60s&quot; max-select-series = 10000 write-timeout = &quot;30s&quot; [data] dir = &quot;/var/lib/influxdb/data&quot; engine = &quot;tsm1&quot; wal-dir = &quot;/var/lib/influxdb/wal&quot; cache-max-memory-size = &quot;0&quot; cache-snapshot-memory-size = &quot;256m&quot; index-version = &quot;tsi1&quot; max-index-log-file-size = &quot;64k&quot; max-series-per-database = 3000000 max-values-per-tag = 100000---## PersistentVolumeClaimapiVersion: v1kind: PersistentVolumeClaimmetadata: name: influxdb-data namespace: influxdbspec: accessModes: - ReadWriteOnce storageClassName: csi-xxx # 需自定义 resources: requests: storage: 16Gi # 按需配置，存储数据较多可适当放大---# influxdb 有状态应用apiVersion: apps/v1kind: StatefulSetmetadata: labels: app: influxdb name: influxdb namespace: influxdbspec: replicas: 1 selector: matchLabels: app: influxdb serviceName: influxdb template: metadata: labels: app: influxdb spec: containers: - image: influxdb:1.8.10 name: influxdb ports: - containerPort: 8086 name: influxdb volumeMounts: - mountPath: /var/lib/influxdb name: data - name: influxdb-config mountPath: /etc/influxdb/influxdb.conf readOnly: true subPath: influxdb.conf volumes: - name: data persistentVolumeClaim: claimName: influxdb-data - name: timezone-config # 时区 hostPath: path: /usr/share/zoneinfo/Asia/Shanghai - name: influxdb-config configMap: defaultMode: 0600 name: influxdb-config---# 提高端口，方便其他 pod 调用apiVersion: v1kind: Servicemetadata: name: influxdb namespace: influxdbspec: ports: - name: influxdb port: 8086 targetPort: 8086 selector: app: influxdb type: ClusterIP","tags":["k8s-learing"],"categories":["k8s-learing"]},{"title":"kubernete实战篇-CronJob","path":"/2022/08/31/434/","content":"涉及的知识点： CronJob kubectl delete, kubectl logs CronJob 有点类似Linux的crontab。 # cronjob.yamlapiVersion: batch/v1kind: CronJobmetadata: name: hellospec: # ┌───────────── 分钟 (0 - 59) # │ ┌───────────── 小时 (0 - 23) # │ │ ┌───────────── 月的某天 (1 - 31) # │ │ │ ┌───────────── 月份 (1 - 12) # │ │ │ │ ┌───────────── 周的某天 (0 - 6)（周日到周一） # │ │ │ │ │ 或者是 sun，mon，tue，web，thu，fri，sat # │ │ │ │ │ # │ │ │ │ │ # * * * * * schedule: &quot;*/1 * * * *&quot; jobTemplate: spec: template: spec: containers: - name: hello image: busybox imagePullPolicy: IfNotPresent args: - /bin/sh - -c - date; sleep 30; echo Hello, puresai from the Kubernetes cluster restartPolicy: OnFailure kubectl apply -f cronjob.yaml 运行没问题，加入发现job有问题，需要立即终止怎么办呢？如何删除正在运行的 job？ kubectl delete pod xxx 可以看见立即生成了另一个，继续delete。 kubectl delete pod xxx –grace-period 0 –force 虽然强制杀死了一个，但还是生成了一个，有一次失败了。 虽然删除对应的pod，但是k8s会认为这个pod执行失败，重新生成一个新的pod，所以我们应该删除源头 cronjob，然后杀掉执行中的pod。PS: cj 是 cronjob的别名 kubectl delete cj hellokubectl delete pod xxx –grace-period 0 –force","tags":["k8s-learing"],"categories":["k8s-learing"]},{"title":"kubernete实战篇-公布应用","path":"/2022/08/22/433/","content":"涉及的知识点： Ingress LoadBalancer Ingress我们可以使用之前部署Deployment的Service，具体实现： apiVersion: networking.k8s.io/v1kind: Ingressmetadata: # Ingress 的名字，仅用于标识 name: sai-ingress spec: # Ingress 中定义 L7 路由规则 rules: # 根据 virtual hostname 进行路由（请使用您自己的域名） - host: sai.puresai.com http: paths: - path: &quot;/&quot; pathType: Prefix backend: service: name: sai # 指定后端的 Service 为之前创建的 sai port: number: 80 LoadBalancer在使用支持外部负载均衡器的云提供商的服务时，设置 type 的值为 &quot;LoadBalancer&quot;， 将为 Service 提供负载均衡器。 负载均衡器是异步创建的，关于被提供的负载均衡器的信息将会通过 Service 的 status.loadBalancer 字段发布出去。 apiVersion: v1kind: Servicemetadata: name: sai-lbspec: selector: app: sai ports: - protocol: TCP port: 80 targetPort: 80 clusterIP: 10.0.171.239 type: LoadBalancerstatus: loadBalancer: ingress: - ip: 192.0.2.127 来自外部负载均衡器的流量将直接重定向到后端 Pod 上，不过实际它们是如何工作的，这要依赖于云提供商。 比如使用ucloud： apiVersion: v1kind: Servicemetadata: name: ucloud-nginx-out-tcp-new labels: app: ucloud-nginx-out-tcp-new annotations: # 代表ULB网络类型，outer为外网，inner为内网；outer为默认值，此处可省略。 &quot;service.beta.kubernetes.io/ucloud-load-balancer-type&quot;: &quot;outer&quot; # 表示ULB协议类型，tcp与udp等价，表示ULB4；http与httpS等价，表示ULB7；tcp为默认值，此处可省略。 &quot;service.beta.kubernetes.io/ucloud-load-balancer-vserver-protocol&quot;: &quot;tcp&quot; # bandwidth下默认为2Mpbs,建议显式声明带宽大小，避免费用超标。 &quot;service.beta.kubernetes.io/ucloud-load-balancer-eip-bandwidth&quot;: &quot;2&quot; # 付费模式，支持month，year，dynamic，默认为month &quot;service.beta.kubernetes.io/ucloud-load-balancer-eip-chargetype&quot;: &quot;month&quot; # 付费时长，默认为1，chargetype为dynimic时无效 &quot;service.beta.kubernetes.io/ucloud-load-balancer-eip-quantity&quot;: &quot;1&quot; spec: type: LoadBalancer ports: - protocol: TCP port: 80 targetPort: 80 selector: app: ucloud-nginx-out-tcp-new","tags":["k8s-learing"],"categories":["k8s-learing"]},{"title":"kubernete实战篇-Deployment部署","path":"/2022/08/11/431/","content":"我们以部署一个可访问http服务的为例，涉及的知识点： ConfigMap Service Deployment kubectl port-forward 编写yaml# sai-config.yaml# 定义 ConfigMapapiVersion: v1kind: ConfigMapmetadata: # 元数据，定义基本属性和信息 name: sai-config # 名称data: config.yaml: |- name: sai0556 mode: debug addr: :8080 hi: w~o~w---# 定义 ServiceapiVersion: v1kind: Servicemetadata: name: sai labels: # 标签 app: saispec: # 描述 ports: - protocol: TCP port: 80 # Service的虚拟端口 targetPort: 8080 # 容器暴露的端口 selector: # 选择器，对应下面的 Deployment的 labels app: sai---# 定义 DeploymentapiVersion: apps/v1kind: Deploymentmetadata: name: saispec: replicas: 1 # 创建应用程序实例个数 selector: # 标签选择器 matchLabels: # 选择包含标签app:sai的资源 app: sai template: # 模板 metadata: labels: app: sai spec: containers: - name: sai image: puresai/k8s-configmap-sai:0.2 imagePullPolicy: IfNotPresent command: - &#x27;/app/puresai&#x27; volumeMounts: # 数据卷挂载 - name: config mountPath: /app/config.yaml readOnly: true subPath: config.yaml volumes: # 挂载的具体信息，这里使用的 configMap - name: config configMap: defaultMode: 0600 name: sai-config 应用kubectl apply -f sai-config.yaml 测试使用 kubectl 查看 kubectl get deploymentkubectl get service 测试： # port-forward 可以将集群映射到本地，方便debugkubectl port-forward svc/sai 8088:80 可以看到请求是成功！ http://127.0.0.1:8088/ 当然，也可以使用 NodePort apiVersion: v1kind: Servicemetadata: name: sai labels: # 标签 app: saispec: # 描述 type: NodePort ports: - protocol: TCP port: 8080 nodePort: 31080 selector: app: sai","tags":["k8s-learing"],"categories":["k8s-learing"]},{"title":"kubernete实战篇-外部服务","path":"/2022/08/10/432/","content":"涉及的知识点： Service Endpoints 外部服务 Service需注意 Service 是一个不带 selector 的，否则就会自动创建 Endpoint，name 保持一致即可。 apiVersion: v1kind: Servicemetadata: name: to-externalspec: type: NodePort ports: - port: 80 nodePort: 31081 protocol: TCP---apiVersion: v1kind: Endpointsmetadata: name: to-externalsubsets:- addresses: - ip: 11.50.24.32 ports: - port: 80 这样就可以通过 http://127.0.0.1:31081 访问了。","tags":["k8s-learing"],"categories":["k8s-learing"]},{"title":"kubernetes基础篇-镜像","path":"/2022/08/01/423/","content":"镜像 image镜像名称如果你不指定仓库的主机名，Kubernetes 认为你在使用 Docker 公共仓库。在镜像名称之后，你可以添加一个标签（Tag）。 镜像标签可以包含小写字母、大写字母、数字、下划线（_）、句点（.）和连字符（-）。 关于在镜像标签中何处可以使用分隔字符（_、- 和 .）还有一些额外的规则。 如果你不指定标签，Kubernetes 认为你想使用标签 latest。 镜像拉取策略imagePullPolicy： IfNotPresent：只有当镜像在本地不存在时才会拉取。 Always：每当 kubelet 启动一个容器时，kubelet 会查询容器的镜像仓库， 将名称解析为一个镜像摘要。 如果 kubelet 有一个容器镜像，并且对应的摘要已在本地缓存，kubelet 就会使用其缓存的镜像； 否则，kubelet 就会使用解析后的摘要拉取镜像，并使用该镜像来启动容器。 Never：Kubelet 不会尝试获取镜像。如果镜像已经以某种方式存在本地， kubelet 会尝试启动容器；否则，会启动失败。 默认镜像拉取策略当你（或控制器）向 API 服务器提交一个新的 Pod 时，你的集群会在满足特定条件时设置 imagePullPolicy 字段： 如果你省略了 imagePullPolicy 字段，并且容器镜像的标签是 :latest， imagePullPolicy 会自动设置为 Always。 如果你省略了 imagePullPolicy 字段，并且没有指定容器镜像的标签， imagePullPolicy 会自动设置为 Always。 如果你省略了 imagePullPolicy 字段，并且为容器镜像指定了非 :latest 的标签， imagePullPolicy 就会自动设置为 IfNotPresent。 使用私有仓库从私有仓库读取镜像时可能需要密钥。 凭证可以用以下方式提供: 配置节点向私有仓库进行身份验证 所有 Pod 均可读取任何已配置的私有仓库 需要集群管理员配置节点 预拉镜像 所有 Pod 都可以使用节点上缓存的所有镜像 需要所有节点的 root 访问权限才能进行设置 在 Pod 中设置 ImagePullSecrets 只有提供自己密钥的 Pod 才能访问私有仓库 特定于厂商的扩展或者本地扩展 如果你在使用定制的节点配置，你（或者云平台提供商）可以实现让节点 向容器仓库认证的机制 more镜像","tags":["k8s-learing"],"categories":["k8s-learing"]},{"title":"kubernetes基础篇-kubectl","path":"/2022/07/31/422/","content":"kubectlKubectl 命令行工具管理 Kubernetes 集群。 kubectl 在 $HOME/.kube 目录中查找一个名为 config 的配置文件。 你可以通过设置 KUBECONFIG 环境变量或设置 –kubeconfig 参数来指定其它 kubeconfig 文件。 安装macOS# installbrew install kubectl # testkubectl version --client# 自动补全工具echo source &lt;(kubectl completion zsh) &gt;&gt; ~/.zshrc 语法使用以下语法 kubectl 从终端窗口运行命令： kubectl [command] [TYPE] [NAME] [flags] 其中 command、TYPE、NAME 和 flags 分别是： command：指定要对一个或多个资源执行的操作，例如 create、get、describe、delete。 TYPE：指定资源类型。资源类型不区分大小写， 可以指定单数、复数或缩写形式。例如，以下命令输出相同的结果: kubectl get pod pod1kubectl get pods pod1kubectl get po pod1 NAME：指定资源的名称。名称区分大小写。 如果省略名称，则显示所有资源的详细信息 kubectl get pods。 在对多个资源执行操作时，你可以按类型和名称指定每个资源，或指定一个或多个文件： 要按类型和名称指定资源： 要对所有类型相同的资源进行分组，请执行以下操作：TYPE1 name1 name2 name&lt;#&gt;。 例子：kubectl get pod example-pod1 example-pod2 分别指定多个资源类型：TYPE1/name1 TYPE1/name2 TYPE2/name3 TYPE&lt;#&gt;/name&lt;#&gt;。 例子：kubectl get pod/example-pod1 replicationcontroller/example-rc1 用一个或多个文件指定资源：-f file1 -f file2 -f file&lt;#&gt; 使用 YAML 而不是 JSON 因为 YAML 更容易使用，特别是用于配置文件时。 例子：kubectl get -f ./pod.yaml flags: 指定可选的参数。例如，可以使用 -s 或 -server 参数指定 Kubernetes API 服务器的地址和端口。 PS: 从命令行指定的参数会覆盖默认值和任何相应的环境变量。 如果你需要帮助，从终端窗口运行 kubectl help 。 查看更多操作 示例：常用操作使用以下示例集来帮助你熟悉运行常用 kubectl 操作： kubectl apply - 以文件或标准输入为准应用或更新资源。 # 使用 example-service.yaml 中的定义创建服务。kubectl apply -f example-service.yaml# 使用 example-controller.yaml 中的定义创建 replication controller。kubectl apply -f example-controller.yaml# 使用 &lt;directory&gt; 路径下的任意 .yaml, .yml, 或 .json 文件 创建对象。kubectl apply -f &lt;directory&gt; kubectl get - 列出一个或多个资源。 # 以纯文本输出格式列出所有 pod。kubectl get pods# 以纯文本输出格式列出所有 pod，并包含附加信息(如节点名)。kubectl get pods -o wide# 以纯文本输出格式列出具有指定名称的副本控制器。提示：你可以使用别名 &#x27;rc&#x27; 缩短和替换 &#x27;replicationcontroller&#x27; 资源类型。kubectl get replicationcontroller &lt;rc-name&gt;# 以纯文本输出格式列出所有副本控制器和服务。kubectl get rc,services# 以纯文本输出格式列出所有守护程序集，包括未初始化的守护程序集。kubectl get ds --include-uninitialized# 列出在节点 server01 上运行的所有 podkubectl get pods --field-selector=spec.nodeName=server01 kubectl describe - 显示一个或多个资源的详细状态，默认情况下包括未初始化的资源。 # 显示名称为 &lt;node-name&gt; 的节点的详细信息。kubectl describe nodes &lt;node-name&gt;# 显示名为 &lt;pod-name&gt; 的 pod 的详细信息。kubectl describe pods/&lt;pod-name&gt;# 显示由名为 &lt;rc-name&gt; 的副本控制器管理的所有 pod 的详细信息。# 记住：副本控制器创建的任何 pod 都以复制控制器的名称为前缀。kubectl describe pods &lt;rc-name&gt;# 描述所有的 pod，不包括未初始化的 podkubectl describe pods Note: kubectl get 命令通常用于检索同一资源类型的一个或多个资源。 它具有丰富的参数，允许你使用 -o 或 --output 参数自定义输出格式。你可以指定 -w 或 --watch 参数以开始观察特定对象的更新。 kubectl describe 命令更侧重于描述指定资源的许多相关方面。它可以调用对 API 服务器 的多个 API 调用来为用户构建视图。 例如，该 kubectl describe node 命令不仅检索有关节点的信息，还检索在其上运行的 pod 的摘要，为节点生成的事件等。 kubectl delete - 从文件、stdin 或指定标签选择器、名称、资源选择器或资源中删除资源。 # 使用 pod.yaml 文件中指定的类型和名称删除 pod。kubectl delete -f pod.yaml# 删除所有带有 &#x27;&lt;label-key&gt;=&lt;label-value&gt;&#x27; 标签的 Pod 和服务。kubectl delete pods,services -l &lt;label-key&gt;=&lt;label-value&gt;# 删除所有 pod，包括未初始化的 pod。kubectl delete pods --all kubectl exec - 对 pod 中的容器执行命令。 # 从 pod &lt;pod-name&gt; 中获取运行 &#x27;date&#x27; 的输出。默认情况下，输出来自第一个容器。kubectl exec &lt;pod-name&gt; -- date# 运行输出 &#x27;date&#x27; 获取在容器的 &lt;container-name&gt; 中 pod &lt;pod-name&gt; 的输出。kubectl exec &lt;pod-name&gt; -c &lt;container-name&gt; -- date# 获取一个交互 TTY 并运行 /bin/bash &lt;pod-name &gt;。默认情况下，输出来自第一个容器。kubectl exec -ti &lt;pod-name&gt; -- /bin/bash kubectl logs - 打印 Pod 中容器的日志。 # 从 pod 返回日志快照。kubectl logs &lt;pod-name&gt;# 从 pod &lt;pod-name&gt; 开始流式传输日志。这类似于 &#x27;tail -f&#x27; Linux 命令。kubectl logs -f &lt;pod-name&gt;","tags":["k8s-learing"],"categories":["k8s-learing"]},{"title":"kubernetes基础篇-组件","path":"/2022/07/29/422/","content":"Kubernetes组件控制平面组件（Control Plane Components）控制平面的组件对集群做出全局决策(比如调度)，以及检测和响应集群事件（例如，当不满足部署的 replicas 字段时，启动新的 pod）。 控制平面组件可以在集群中的任何节点上运行。 然而，为了简单起见，设置脚本通常会在同一个计算机上启动所有控制平面组件， 并且不会在此计算机上运行用户容器。 请参阅使用 kubeadm 构建高可用性集群 中关于跨多机器控制平面设置的示例。 kube-apiserverAPI 服务器是 Kubernetes 控制面的组件， 该组件公开了 Kubernetes API。 API 服务器是 Kubernetes 控制面的前端。 Kubernetes API 服务器的主要实现是 kube-apiserver。 kube-apiserver 设计上考虑了水平伸缩，也就是说，它可通过部署多个实例进行伸缩。 你可以运行 kube-apiserver 的多个实例，并在这些实例之间平衡流量。 etcdetcd 是兼具一致性和高可用性的键值数据库，可以作为保存 Kubernetes 所有集群数据的后台数据库。 您的 Kubernetes 集群的 etcd 数据库通常需要有个备份计划。 要了解 etcd 更深层次的信息，请参考 etcd 文档。 kube-scheduler控制平面组件，负责监视新创建的、未指定运行节点（node）的 Pods，选择节点让 Pod 在上面运行。 调度决策考虑的因素包括单个 Pod 和 Pod 集合的资源需求、硬件/软件/策略约束、亲和性和反亲和性规范、数据位置、工作负载间的干扰和最后时限。 kube-controller-manager运行控制器进程的控制平面组件。 从逻辑上讲，每个控制器都是一个单独的进程， 但是为了降低复杂性，它们都被编译到同一个可执行文件，并在一个进程中运行。 这些控制器包括: 节点控制器（Node Controller）: 负责在节点出现故障时进行通知和响应 任务控制器（Job controller）: 监测代表一次性任务的 Job 对象，然后创建 Pods 来运行这些任务直至完成 端点控制器（Endpoints Controller）: 填充端点(Endpoints)对象(即加入 Service 与 Pod) 服务帐户和令牌控制器（Service Account &amp; Token Controllers）: 为新的命名空间创建默认帐户和 API 访问令牌 cloud-controller-manager云控制器管理器是指嵌入特定云的控制逻辑的 控制平面组件。 云控制器管理器使得你可以将你的集群连接到云提供商的 API 之上， 并将与该云平台交互的组件同与你的集群交互的组件分离开来。 cloud-controller-manager 仅运行特定于云平台的控制回路。 如果你在自己的环境中运行 Kubernetes，或者在本地计算机中运行学习环境， 所部署的环境中不需要云控制器管理器。 与 kube-controller-manager 类似，cloud-controller-manager 将若干逻辑上独立的 控制回路组合到同一个可执行文件中，供你以同一进程的方式运行。 你可以对其执行水平扩容（运行不止一个副本）以提升性能或者增强容错能力。 下面的控制器都包含对云平台驱动的依赖： 节点控制器（Node Controller）: 用于在节点终止响应后检查云提供商以确定节点是否已被删除 路由控制器（Route Controller）: 用于在底层云基础架构中设置路由 服务控制器（Service Controller）: 用于创建、更新和删除云提供商负载均衡器 Node 组件节点组件在每个节点上运行，维护运行的 Pod 并提供 Kubernetes 运行环境。 kubelet一个在集群中每个节点（node）上运行的代理。 它保证容器（containers）都 运行在 Pod 中。 kubelet 接收一组通过各类机制提供给它的 PodSpecs，确保这些 PodSpecs 中描述的容器处于运行状态且健康。 kubelet 不会管理不是由 Kubernetes 创建的容器。 kube-proxykube-proxy 是集群中每个节点上运行的网络代理， 实现 Kubernetes 服务（Service） 概念的一部分。 kube-proxy 维护节点上的网络规则。这些网络规则允许从集群内部或外部的网络会话与 Pod 进行网络通信。 如果操作系统提供了数据包过滤层并可用的话，kube-proxy 会通过它来实现网络规则。否则， kube-proxy 仅转发流量本身。 容器运行时（Container Runtime）容器运行环境是负责运行容器的软件。 Kubernetes 支持容器运行时，例如 Docker、 containerd、CRI-O 以及 Kubernetes CRI (容器运行环境接口) 的其他任何实现。 插件（Addons）插件使用 Kubernetes 资源（DaemonSet、 Deployment等）实现集群功能。 因为这些插件提供集群级别的功能，插件中命名空间域的资源属于 kube-system 命名空间。 下面描述众多插件中的几种。有关可用插件的完整列表，请参见 插件（Addons）。 DNS尽管其他插件都并非严格意义上的必需组件，但几乎所有 Kubernetes 集群都应该 有集群 DNS， 因为很多示例都需要 DNS 服务。 集群 DNS 是一个 DNS 服务器，和环境中的其他 DNS 服务器一起工作，它为 Kubernetes 服务提供 DNS 记录。 Kubernetes 启动的容器自动将此 DNS 服务器包含在其 DNS 搜索列表中。 Web 界面Dashboard 是 Kubernetes 集群的通用的、基于 Web 的用户界面。 它使用户可以管理集群中运行的应用程序以及集群本身并进行故障排除。 Kuboard 是一款基于Kubernetes的微服务管理界面，相较于Dashboard 概念更强大。 容器资源监控容器资源监控 将关于容器的一些常见的时间序列度量值保存到一个集中的数据库中，并提供用于浏览这些数据的界面。 集群层面日志集群层面日志 机制负责将容器的日志数据 保存到一个集中的日志存储中，该存储能够提供搜索和浏览接口。","tags":["k8s-learing"],"categories":["k8s-learing"]},{"title":"kubernetes基础篇-概念","path":"/2022/07/24/421/","content":"Kubernetes 是什么？Kubernetes 是用于自动部署，扩展和管理容器化应用程序的开源系统。 Kubernetes 这个名字源于希腊语，意为“舵手”或“飞行员”。k8s 这个缩写是因为 k 和 s 之间有八个字符的关系。 Kubernetes在 2014 年实现开源，源自Google内部编排工具 Borg 。 部署回溯1. 传统部署时代： 早期，各个组织机构在物理服务器上运行应用程序。无法为物理服务器中的应用程序定义资源边界，这会导致资源分配问题。 例如，如果在物理服务器上运行多个应用程序，则可能会出现一个应用程序占用大部分资源的情况， 结果可能导致其他应用程序的性能下降。 一种解决方案是在不同的物理服务器上运行每个应用程序，但是由于资源利用不足而无法扩展， 并且维护许多物理服务器的成本很高。 2. 虚拟化部署时代： 作为解决方案，引入了虚拟化。虚拟化技术允许你在单个物理服务器的 CPU 上运行多个虚拟机（VM）。 虚拟化允许应用程序在 VM 之间隔离，并提供一定程度的安全，因为一个应用程序的信息 不能被另一应用程序随意访问。 虚拟化技术能够更好地利用物理服务器上的资源，并且因为可轻松地添加或更新应用程序 而可以实现更好的可伸缩性，降低硬件成本等等。 每个 VM 是一台完整的计算机，在虚拟化硬件之上运行所有组件，包括其自己的操作系统。 3. 容器部署时代： 容器类似于 VM，但是它们具有被放宽的隔离属性，可以在应用程序之间共享操作系统（OS）。 因此，容器被认为是轻量级的。容器与 VM 类似，具有自己的文件系统、CPU、内存、进程空间等。 由于它们与基础架构分离，因此可以跨云和 OS 发行版本进行移植。 容器因具有许多优势而变得流行起来。下面列出的是容器的一些好处： 敏捷应用程序的创建和部署：与使用 VM 镜像相比，提高了容器镜像创建的简便性和效率。 持续开发、集成和部署：通过快速简单的回滚（由于镜像不可变性），支持可靠且频繁的 容器镜像构建和部署。 关注开发与运维的分离：在构建/发布时而不是在部署时创建应用程序容器镜像， 从而将应用程序与基础架构分离。 可观察性：不仅可以显示操作系统级别的信息和指标，还可以显示应用程序的运行状况和其他指标信号。 跨开发、测试和生产的环境一致性：在便携式计算机上与在云中相同地运行。 跨云和操作系统发行版本的可移植性：可在 Ubuntu、RHEL、CoreOS、本地、 Google Kubernetes Engine 和其他任何地方运行。 以应用程序为中心的管理：提高抽象级别，从在虚拟硬件上运行 OS 到使用逻辑资源在 OS 上运行应用程序。 松散耦合、分布式、弹性、解放的微服务：应用程序被分解成较小的独立部分， 并且可以动态部署和管理 - 而不是在一台大型单机上整体运行。 资源隔离：可预测的应用程序性能。 资源利用：高效率和高密度。 Kubernetes的功能Kubernetes 提供以下特性: 服务发现和负载均衡 存储编排 自动部署和回滚 自动完成集装计算 自我修复 密钥与配置管理 Kubernetes 的边界Kubernetes 不是传统的、包罗万象的 PaaS（平台即服务）系统。 由于 Kubernetes 在容器级别而不是在硬件级别运行，它提供了 PaaS 产品共有的一些普遍适用的功能， 例如部署、扩展、负载均衡、日志记录和监视。 但是，Kubernetes 不是单体系统，默认解决方案都是可选和可插拔的。 Kubernetes 提供了构建开发人员平台的基础，但是在重要的地方保留了用户的选择和灵活性。 Kubernetes： 不限制支持的应用程序类型。 Kubernetes 旨在支持极其多种多样的工作负载，包括无状态、有状态和数据处理工作负载。 如果应用程序可以在容器中运行，那么它应该可以在 Kubernetes 上很好地运行。 不部署源代码，也不构建你的应用程序。 持续集成(CI)、交付和部署（CI/CD）工作流取决于组织的文化和偏好以及技术要求。 不提供应用程序级别的服务作为内置服务，例如中间件（例如，消息中间件）、 数据处理框架（例如，Spark）、数据库（例如，mysql）、缓存、集群存储系统 （例如，Ceph）。这样的组件可以在 Kubernetes 上运行，并且/或者可以由运行在 Kubernetes 上的应用程序通过可移植机制（例如， 开放服务代理）来访问。 不要求日志记录、监视或警报解决方案。 它提供了一些集成作为概念证明，并提供了收集和导出指标的机制。 不提供或不要求配置语言/系统（例如 jsonnet），它提供了声明性 API， 该声明性 API 可以由任意形式的声明性规范所构成。 不提供也不采用任何全面的机器配置、维护、管理或自我修复系统。 此外，Kubernetes 不仅仅是一个编排系统，实际上它消除了编排的需要。 编排的技术定义是执行已定义的工作流程：首先执行 A，然后执行 B，再执行 C。 相比之下，Kubernetes 包含一组独立的、可组合的控制过程， 这些过程连续地将当前状态驱动到所提供的所需状态。 如何从 A 到 C 的方式无关紧要，也不需要集中控制，这使得系统更易于使用 且功能更强大、系统更健壮、更为弹性和可扩展。","tags":["k8s-learing"],"categories":["k8s-learing"]},{"title":"jwt验证失败的问题","path":"/2022/07/20/410/","content":"jwt 应该是非常常用的，我们项目中也有用到，最近出现几次问题，记录一下，或许能帮助到大家。 PS: 我们使用的是 github.com/dgrijalva/jwt-go Token not active yet前面几个月出现过提示 Token not active yet，后面越来越频繁，原因其实就是 nbf 这个时间戳比验证 jwt 的时间迟。 Token used before issued, Couldn’t handle this token这两天出现一次 Couldn’t handle this token， 打印日志知道是 Token used before issued，原因是 iat 这个时间戳比验证 jwt 的时间迟。 其实解决比较简单，把那两个时间减去60s。 根本原因应该是多台服务器时间不一致，可能差了一丢丢，出现签发时间比验证时间迟的情况，也可以考虑同步时间（我为啥不用—因为有点麻烦） jwt 文档和工具参考： rfc7519 jwt.io","tags":["jwt"],"categories":["jwt"]},{"title":"深入剖析Kubernetes之Pod","path":"/2022/07/05/409/","content":"Pod，是 Kubernetes 项目中的最小编排单位，实际上是在扮演传统基础设施里“虚拟机”的角色；而容器，则是这个虚拟机里运行的用户程序。 凡是调度、网络、存储，以及安全相关的属性，基本上是 Pod 级别的。 🌰 apiVersion: v1kind: Podmetadata: name: lifecycle-demospec: containers: - name: lifecycle-demo-container image: nginx lifecycle: postStart: exec: command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;echo Hello from the postStart handler &gt; /usr/share/message&quot;] preStop: exec: command: [&quot;/usr/sbin/nginx&quot;,&quot;-s&quot;,&quot;quit&quot;] 生命周期Pod 生命周期：(主要体现在 Pod API 对象的Status 部分) Pending。这个状态意味着，Pod 的 YAML 文件已经提交给了 Kubernetes，API 对象已经被创建并保存在 Etcd 当中。但是，这个 Pod 里有些容器因为某种原因而不能被顺利创建。比如，调度不成功。 Running。这个状态下，Pod 已经调度成功，跟一个具体的节点绑定。它包含的容器都已经创建成功，并且至少有一个正在运行中。 Succeeded。这个状态意味着，Pod 里的所有容器都正常运行完毕，并且已经退出了。这种情况在运行一次性任务时最为常见。 Failed。这个状态下，Pod 里至少有一个容器以不正常的状态（非 0 的返回码）退出。这个状态的出现，意味着你得想办法 Debug 这个容器的应用，比如查看 Pod 的 Events 和日志。 Unknown。这是一个异常状态，意味着 Pod 的状态不能持续地被 kubelet 汇报给 kube-apiserver，这很有可能是主从节点（Master 和 Kubelet）间的通信出现了问题。 更进一步地，Pod 对象的 Status 字段，还可以再细分出一组 Conditions。这些细分状态的值包括：PodScheduled、Ready、Initialized，以及 Unschedulable。它们主要用于描述造成当前 Status 的具体原因是什么。 比如，Pod 当前的 Status 是 Pending，对应的 Condition 是 Unschedulable，这就意味着它的调度出现了问题。 Projected VolumeKubernetes 支持的 Projected Volume 一共有四种： Secret ConfigMap Downward API ServiceAccountToken SecretSecret 最典型的使用场景，莫过于存放数据库的 Credential 信息，比如下面这个例子： apiVersion: v1kind: Podmetadata: name: test-projected-volume spec: containers: - name: test-secret-volume image: busybox args: - sleep - &quot;86400&quot; volumeMounts: - name: mysql-cred mountPath: &quot;/projected-volume&quot; readOnly: true volumes: - name: mysql-cred projected: sources: - secret: name: user - secret: name: pass 这里用到的数据库的用户名、密码，正是以 Secret 对象的方式交给 Kubernetes 保存的。完成这个操作的指令，如下所示： cat ./username.txtsaicat ./password.txt123456 kubectl create secret generic user --from-file=./username.txtkubectl create secret generic pass --from-file=./password.txt 其中，username.txt 和 password.txt 文件里，存放的就是用户名和密码；而 user 和 pass，则是我为 Secret 对象指定的名字。而我想要查看这些 Secret 对象的话，只要执行一条 kubectl get 命令就可以了： kubectl get secretsNAME TYPE DATA AGEuser Opaque 1 51spass Opaque 1 51s 需要注意的是，Secret 对象要求这些数据必须是经过 Base64 转码的，以免出现明文密码的安全隐患。 ConfigMap与 Secret 的区别在于，ConfigMap 保存的是不需要加密的、应用所需的配置信息。而 ConfigMap 的用法几乎与 Secret 完全相同：你可以使用 kubectl create configmap 从文件或者目录创建 ConfigMap，也可以直接编写 ConfigMap 对象的 YAML 文件。 Downward API它的作用是：让 Pod 里的容器能够直接获取到这个 Pod API 对象本身的信息。 apiVersion: v1kind: Podmetadata: name: test-downwardapi-volume labels: zone: us-est-coast cluster: test-cluster1 rack: rack-22spec: containers: - name: client-container image: k8s.gcr.io/busybox command: [&quot;sh&quot;, &quot;-c&quot;] args: - while true; do if [[ -e /etc/podinfo/labels ]]; then echo -en &#x27; &#x27;; cat /etc/podinfo/labels; fi; sleep 5; done; volumeMounts: - name: podinfo mountPath: /etc/podinfo readOnly: false volumes: - name: podinfo projected: sources: - downwardAPI: items: - path: &quot;labels&quot; fieldRef: fieldPath: metadata.labels 在这个 Pod 的 YAML 文件中，我定义了一个简单的容器，声明了一个 projected 类型的 Volume。只不过这次 Volume 的数据来源，变成了 Downward API。而这个 Downward API Volume，则声明了要暴露 Pod 的 metadata.labels 信息给容器。 通过这样的声明方式，当前 Pod 的 Labels 字段的值，就会被 Kubernetes 自动挂载成为容器里的 /etc/podinfo/labels 文件。 PS:需要注意的是，Downward API 能够获取到的信息，一定是 Pod 里的容器进程启动之前就能够确定下来的信息。而如果你想要获取 Pod 容器运行后才会出现的信息，比如，容器进程的 PID，那就肯定不能使用 Downward API 了，而应该考虑在 Pod 里定义一个 sidecar 容器。 ServiceAccountToken一种特殊的 Secret 为了方便使用，Kubernetes 已经为你提供了一个的默认“服务账户”（default Service Account）。并且，任何一个运行在 Kubernetes 里的 Pod，都可以直接使用这个默认的 Service Account，而无需显示地声明挂载它。 容器健康检查和恢复机制apiVersion: v1kind: Podmetadata: labels: test: liveness name: test-liveness-execspec: containers: - name: liveness image: busybox args: - /bin/sh - -c - touch /tmp/healthy; sleep 30; rm -rf /tmp/healthy; sleep 600 livenessProbe: exec: command: - cat - /tmp/healthy initialDelaySeconds: 5 periodSeconds: 5 在这个 Pod 中，我们定义了一个有趣的容器。它在启动之后做的第一件事，就是在 /tmp 目录下创建了一个 healthy 文件，以此作为自己已经正常运行的标志。而 30 s 过后，它会把这个文件删除掉。 与此同时，我们定义了一个这样的 livenessProbe（健康检查）。它的类型是 exec，这意味着，它会在容器启动后，在容器里面执行一句我们指定的命令，比如：“cat /tmp/healthy”。这时，如果这个文件存在，这条命令的返回值就是 0，Pod 就会认为这个容器不仅已经启动，而且是健康的。这个健康检查，在容器启动 5 s 后开始执行（initialDelaySeconds: 5），每 5 s 执行一次（periodSeconds: 5）。 你不妨尝试一下运行这个pod，暴露一个健康减产 url 和 监听端口是非常常见的。 对于 Web 服务应用， PS：Kubernetes 中并没有 Docker 的 Stop 语义。所以虽然是 Restart（重启），但实际却是重新创建了容器。 restartPolicy，改变 Pod 的恢复策略 Always：在任何情况下，只要容器不在运行状态，就自动重启容器； OnFailure: 只在容器 异常时才自动重启容器； Never: 从来不重启容器。 记住如下两个基本的设计原理即可： 只要 Pod 的 restartPolicy 指定的策略允许重启异常的容器（比如：Always），那么这个 Pod 就会保持 Running 状态，并进行容器重启。否则，Pod 就会进入 Failed 状态 。 对于包含多个容器的 Pod，只有它里面所有的容器都进入异常状态后，Pod 才会进入 Failed 状态。 更详细推荐看看： Pod 的生命周期 kubernetes之容器探针(liveness and readiness probe) PodPreset开发人员只需要提交一个基本的、非常简单的 Pod YAML，Kubernetes 就可以自动给对应的 Pod 对象加上其他必要的信息，比如 labels，annotations，volumes 等等。而这些信息，可以是运维人员事先定义好的。 🌰 apiVersion: settings.k8s.io/v1alpha1kind: PodPresetmetadata: name: allow-databasespec: selector: matchLabels: role: frontend # 这里很重要 env: - name: DB_PORT value: &quot;6379&quot; volumeMounts: - mountPath: /cache name: cache-volume volumes: - name: cache-volume emptyDir: &#123;&#125;---apiVersion: v1kind: Podmetadata: name: sai labels: app: sai role: frontend # 这里很重要spec: containers: - name: website image: nginx ports: - containerPort: 80 kubectl get pod sai -o yamlapiVersion: v1kind: Podmetadata: name: sai labels: app: sai role: frontend annotations: podpreset.admission.kubernetes.io/podpreset-allow-database: &quot;resource version&quot;spec: containers: - name: website image: nginx volumeMounts: - mountPath: /cache name: cache-volume ports: - containerPort: 80 env: - name: DB_PORT value: &quot;6379&quot; volumes: - name: cache-volume emptyDir: &#123;&#125; 这个时候，我们就可以清楚地看到，这个 Pod 里多了新添加的 labels、env、volumes 和 volumeMount 的定义，它们的配置跟 PodPreset 的内容一样。此外，这个 Pod 还被自动加上了一个 annotation 表示这个 Pod 对象被 PodPreset 改动过。 需要说明的是，PodPreset 里定义的内容，只会在 Pod API 对象被创建之前追加在这个对象本身上，而不会影响任何 Pod 的控制器的定义。","tags":["k8s"],"categories":["k8s"]},{"title":"深入剖析Kubernetes之容器基础篇","path":"/2022/07/01/406/","content":"容器本身没有价值，有价值的是“容器编排”。 进程int pid = clone(main_function, stack_size, SIGCHLD, NULL); int pid = clone(main_function, stack_size, CLONE_NEWPID | SIGCHLD, NULL); 隔离用户运行在容器里的应用进程，跟宿主机上的其他进程一样，都由宿主机操作系统统一管理，只不过这些被隔离的进程拥有额外设置过的 Namespace 参数。而 Docker 项目在这里扮演的角色，更多的是旁路式的辅助和管理工作。 基于 Linux Namespace 的隔离机制相比于虚拟化技术也有很多不足之处，其中最主要的问题就是：隔离得不彻底。 首先，既然容器只是运行在宿主机上的一种特殊的进程，那么多个容器之间使用的就还是同一个宿主机的操作系统内核。 其次，在 Linux 内核中，有很多资源和对象是不能被 Namespace 化的，最典型的例子就是：时间。 Linux Control GroupLinux Cgroups 最主要的作用，就是限制一个进程组能够使用的资源上限，包括 CPU、内存、磁盘、网络带宽等等。 mount -t cgroupcgroup on /sys/fs/cgroup/systemd type cgroup (rw,nosuid,nodev,noexec,relatime,xattr,release_agent=/usr/lib/systemd/systemd-cgroups-agent,name=systemd)cgroup on /sys/fs/cgroup/devices type cgroup (rw,nosuid,nodev,noexec,relatime,devices)cgroup on /sys/fs/cgroup/cpuset type cgroup (rw,nosuid,nodev,noexec,relatime,cpuset)cgroup on /sys/fs/cgroup/cpu,cpuacct type cgroup (rw,nosuid,nodev,noexec,relatime,cpuacct,cpu)cgroup on /sys/fs/cgroup/blkio type cgroup (rw,nosuid,nodev,noexec,relatime,blkio)cgroup on /sys/fs/cgroup/pids type cgroup (rw,nosuid,nodev,noexec,relatime,pids)cgroup on /sys/fs/cgroup/memory type cgroup (rw,nosuid,nodev,noexec,relatime,memory)cgroup on /sys/fs/cgroup/perf_event type cgroup (rw,nosuid,nodev,noexec,relatime,perf_event)cgroup on /sys/fs/cgroup/hugetlb type cgroup (rw,nosuid,nodev,noexec,relatime,hugetlb)cgroup on /sys/fs/cgroup/freezer type cgroup (rw,nosuid,nodev,noexec,relatime,freezer)cgroup on /sys/fs/cgroup/net_cls,net_prio type cgroup (rw,nosuid,nodev,noexec,relatime,net_prio,net_cls) 进入 /sys/fs/cgroup/cpu 目录下： root@ubuntu:/sys/fs/cgroup/cpu$ mkdir containerroot@ubuntu:/sys/fs/cgroup/cpu$ ls container/cgroup.clone_children cpu.cfs_period_us cpu.rt_period_us cpu.shares notify_on_releasecgroup.procs cpu.cfs_quota_us cpu.rt_runtime_us cpu.stat tasks 这个目录就称为一个“控制组”。你会发现，操作系统会在你新创建的 container 目录下，自动生成该子系统对应的资源限制文件。 现在，我们在后台执行这样一条脚本： while : ; do : ; done &amp;[1] 226 显然，它执行了一个死循环，可以把计算机的 CPU 吃到 100%，根据它的输出，我们可以看到这个脚本在后台运行的进程号（PID）是 226。 这样，我们可以用 top 指令来确认一下 CPU 有没有被打满： $ top%Cpu0 :100.0 us, 0.0 sy, 0.0 ni, 0.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st 在输出里可以看到，CPU 的使用率已经 100% 了（%Cpu0 :100.0 us）。 而此时，我们可以通过查看 container 目录下的文件，看到 container 控制组里的 CPU quota 还没有任何限制（即：-1），CPU period 则是默认的 100 ms（100000 us）： cat /sys/fs/cgroup/cpu/container/cpu.cfs_quota_us -1cat /sys/fs/cgroup/cpu/container/cpu.cfs_period_us 100000 接下来，我们可以通过修改这些文件的内容来设置限制。 比如，向 container 组里的 cfs_quota 文件写入 20 ms（20000 us）： echo 20000 &gt; /sys/fs/cgroup/cpu/container/cpu.cfs_quota_us 结合前面的介绍，你应该能明白这个操作的含义，它意味着在每 100 ms 的时间里，被该控制组限制的进程只能使用 20 ms 的 CPU 时间，也就是说这个进程只能使用到 20% 的 CPU 带宽。 接下来，我们把被限制的进程的 PID 写入 container 组里的 tasks 文件，上面的设置就会对该进程生效了： echo 226 &gt; /sys/fs/cgroup/cpu/container/tasks 我们可以用 top 指令查看一下： $ top%Cpu0 : 20.3 us, 0.0 sy, 0.0 ni, 79.7 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st 可以看到，计算机的 CPU 使用率立刻降到了 20%（%Cpu0 : 20.3 us）。 除 CPU 子系统外，Cgroups 的每一项子系统都有其独有的资源限制能力，比如： blkio，为​​​块​​​设​​​备​​​设​​​定​​​I/O 限​​​制，一般用于磁盘等设备； cpuset，为进程分配单独的 CPU 核和对应的内存节点； memory，为进程设定内存使用的限制。 Linux Cgroups 的设计还是比较易用的，简单粗暴地理解呢，它就是一个子系统目录加上一组资源限制文件的组合。而对于 Docker 等 Linux 容器项目来说，它们只需要在每个子系统下面，为每个容器创建一个控制组（即创建一个新目录），然后在启动容器进程之后，把这个进程的 PID 填写到对应控制组的 tasks 文件中就可以了。 docker run -it --cpu-period=100000 --cpu-quota=20000 ubuntu /bin/bash 资源目录中： cat /sys/fs/cgroup/cpu/docker/5d5c9f67d/cpu.cfs_period_us 100000cat /sys/fs/cgroup/cpu/docker/5d5c9f67d/cpu.cfs_quota_us 20000 Cgroups 对资源的限制能力也有很多不完善的地方，被提及最多的自然是 /proc 文件系统的问题。 众所周知，Linux 下的 /proc 目录存储的是记录当前内核运行状态的一系列特殊文件，用户可以通过访问这些文件，查看系统以及当前正在运行的进程的信息，比如 CPU 使用情况、内存占用率等，这些文件也是 top 指令查看系统信息的主要数据来源。 但是，你如果在容器里执行 top 指令，就会发现，它显示的信息居然是宿主机的 CPU 和内存数据，而不是当前容器的数据。 造成这个问题的原因就是，/proc 文件系统并不知道用户通过 Cgroups 给这个容器做了什么样的资源限制，即：/proc 文件系统不了解 Cgroups 限制的存在。 在生产环境中，这个问题必须进行修正，否则应用程序在容器里读取到的 CPU 核数、可用内存等信息都是宿主机上的数据，这会给应用的运行带来非常大的困惑和风险。这也是在企业中，容器化应用碰到的一个常见问题，也是容器相较于虚拟机另一个不尽如人意的地方。 [DOCKER基础技术：LINUX NAMESPACE（上）]https://coolshell.cn/articles/17010.html) 对 Docker 项目来说，它最核心的原理实际上就是为待创建的用户进程： 启用 Linux Namespace 配置； 设置指定的 Cgroups 参数； 切换进程的根目录（Change Root）。 另外，需要明确的是，rootfs 只是一个操作系统所包含的文件、配置和目录，并不包括操作系统内核。在 Linux 操作系统中，这两部分是分开存放的，操作系统只有在开机启动时才会加载指定版本的内核镜像。 所以说，rootfs 只包括了操作系统的“躯壳”，并没有包括操作系统的“灵魂”。 Docker 公司在实现 Docker 镜像时并没有沿用以前制作 rootfs 的标准流程，而是做了一个小小的创新： Docker 在镜像的设计中，引入了层（layer）的概念。也就是说，用户制作镜像的每一步操作，都会生成一个层，也就是一个增量 rootfs。 当然，这个想法不是凭空臆造出来的，而是用到了一种叫作联合文件系统（Union File System）的能力。","tags":["k8s"],"categories":["k8s"]},{"title":"深入剖析Kubernetes之Docker篇","path":"/2022/07/01/405/","content":"初出茅庐PaaS 之所以能够帮助用户大规模部署应用到集群里，是因为它提供了一套应用打包的功能。然而一旦用上了 PaaS，用户就必须为每种语言、每种框架，甚至每个版本的应用维护一个打好的包。这个打包过程，没有任何章法可循，更麻烦的是，明明在本地运行得好好的应用，却需要做很多修改和配置工作才能在 PaaS 里运行起来。而这些修改和配置，并没有什么经验可以借鉴，基本上得靠不断试错，直到你摸清楚了本地应用和远端 PaaS 匹配的“脾气”才能够搞定。 最后结局是，确实是能一键部署了，但是为了实现这个一键部署，用户为每个应用打包的工作可谓一波三折，费尽心机。 Docker 的出现改变了这一现状，Docker 镜像解决了打包整个根本性的问题。这也成为了 Docker 项目成功的关键。 所谓 Docker 镜像，其实就是一个压缩包。大多数 Docker 镜像是直接由一个完整操作系统的所有文件和目录构成的，所以这个压缩包里的内容跟你本地开发和测试环境用的操作系统是完全一样的。 Docker 镜像最厉害的地方在于，只要有这个压缩包在手，你就可以使用某种技术创建一个“沙盒”，在“沙盒”中解压这个压缩包，然后就可以运行你的程序了。更重要的是，这个压缩包包含了完整的操作系统文件和目录，也就是包含了这个应用运行所需要的所有依赖，所以你可以先用这个压缩包在本地进行开发和测试，完成之后，再把这个压缩包上传到云端运行。 在这个过程中，你完全不需要进行任何配置或者修改，因为这个压缩包赋予了你一种极其宝贵的能力：本地环境和云端环境的高度一致！ 那么只需要： docker build &quot;某个镜像&quot;docker run &quot;整个镜像&quot; Docker 项目给 PaaS 世界带来的“降维打击”，其实是提供了一种非常便利的打包机制。这种机制直接打包了应用运行所需要的整个操作系统，从而保证了本地环境和云端环境的高度一致，避免了用户通过“试错”来匹配两种不同运行环境之间差异的痛苦过程。 崭露头角Docker 项目之所以能取得如此高的关注，一方面是它解决了应用打包和发布这一困扰运维人员多年的技术难题；而另一方面，就是因为它第一次把一个纯后端的技术概念，通过非常友好的设计和封装，交到了最广大的开发者群体手里。 解决了应用打包这个根本性的问题，同开发者与生俱来的的亲密关系，再加上 PaaS 概念已经深入人心的完美契机，成为 Docker 这个技术上看似平淡无奇的项目一举走红的重要原因。 Docker 项目从发布之初就全面发力，从技术、社区、商业、市场全方位争取到的开发者群体，实际上是为此后吸引整个生态到自家“PaaS”上的一个铺垫。只不过这时，“PaaS”的定义已经全然不是 Cloud Foundry 描述的那个样子，而是变成了一套以 Docker 容器为技术核心，以 Docker 镜像为打包标准的、全新的“容器化”思路。 群雄并起Docker 公司在 2014 年就已经定好了平台化的发展方向，并且绝对不会跟 CoreOS 在平台层面开展任何合作，在 2014 年 12 月的 DockerCon 上发布了 Swarm 。 # 单机 Docker 项目：docker run &quot;我的容器&quot;# 多机 Docker 项目：docker run -H &quot;我的 Swarm 集群 API 地址&quot; &quot;我的容器&quot; Fig 项目第一次提出了“容器编排”（Container Orchestration）的概念，被收购后改名为 Compose，它成了 Docker 公司到目前为止第二大受欢迎的项目，一直到今天也依然被很多人使用。 由此，Docker 公司 Docker Compose、Swarm 和 Machine“三件套”，在重新定义 PaaS 的方向上走出了最关键的一步。 而 Mesos 社区凭借超大规模集群的管理经验和通过 Marathon 实现了诸如应用托管和负载均衡的 PaaS 功能之后，进化成了一个高度成熟的 PaaS 项目组合 Mesos+Marathon，从而占据了容器化浪潮中的一席之地。 CoreOS、RedHat 完全在这一时期被 Docker 公司压制了。 尘埃落定2014 年 6 月，Google 公司诞生 Kubernetes 项目。而这个项目，不仅挽救了当时的 CoreOS 和 RedHat，还如同当年 Docker 项目的横空出世一样，再一次改变了整个容器市场的格局。 Docker 急速扩张的同时，社区也出现对 Docker 公司商业化战略的种种顾虑的声音。Docker 公司在 Docker 开源项目的发展上，始终保持着绝对的权威和发言权，并在多个场合用实际行动挑战到了其他玩家（比如，CoreOS、RedHat，甚至谷歌和微软）的切身利益。 2015 年 6 月 22 日，由 Docker 公司牵头，CoreOS、Google、RedHat 等公司共同宣布，Docker 公司将 Libcontainer 捐出，并改名为 RunC 项目，交由一个完全中立的基金会管理，然后以 RunC 为依据，大家共同制定一套容器和镜像的标准和规范 OCI（ Open Container Initiative ）。OCI 的提出，意在将容器运行时和镜像的实现从 Docker 项目中完全剥离出来。这样做，一方面可以改善 Docker 公司在容器技术上一家独大的现状，另一方面也为其他玩家不依赖于 Docker 项目构建各自的平台层能力提供了可能。 OCI 并没有改变 Docker 一家独大的现状，但 Google、RedHat 等开源基础设施领域玩家们，共同牵头发起了一个名为 CNCF（Cloud Native Computing Foundation）的基金会改变了社区的格局。 CNCF 基金会的目的其实很容易理解：它希望，以 Kubernetes 项目为基础，建立一个由开源基础设施领域厂商主导的、按照独立基金会方式运营的平台级社区，来对抗以 Docker 公司为核心的容器商业生态。 而为了打造出这样一个围绕 Kubernetes 项目的“护城河”，CNCF 社区就需要至少确保两件事情： Kubernetes 项目必须能够在容器编排领域取得足够大的竞争优势 CNCF 社区必须以 Kubernetes 项目为核心，覆盖足够多的场景 在容器编排领域，Kubernetes 项目需要面对来自 Docker 公司和 Mesos 社区两个方向的压力。不难看出，Swarm 和 Mesos 实际上分别从两个不同的方向讲出了自己最擅长的故事：Swarm 擅长的是跟 Docker 生态的无缝集成，而 Mesos 擅长的则是大规模集群的调度与管理。 这两个方向，也是大多数人做容器集群管理项目时最容易想到的两个出发点。也正因为如此，Kubernetes 项目如果继续在这两个方向上做文章恐怕就不太明智了。 所以这一次，Kubernetes 选择的应对方式是：Borg。 如果你看过 Kubernetes 项目早期的 GitHub Issue 和 Feature 的话，就会发现它们大多来自于 Borg 和 Omega 系统的内部特性，这些特性落到 Kubernetes 项目上，就是 Pod、Sidecar 等功能和设计模式。 这就解释了，为什么 Kubernetes 发布后，很多人“抱怨”其设计思想过于“超前”的原因：Kubernetes 项目的基础特性，并不是几个工程师突然“拍脑袋”想出来的东西，而是 Google 公司在容器化基础设施领域多年来实践经验的沉淀与升华。这，正是 Kubernetes 项目能够从一开始就避免同 Swarm 和 Mesos 社区同质化的重要手段。 CNCF 实现了目标一之后的任务就是，如何把这些先进的思想通过技术手段在开源社区落地，并培育出一个认同这些理念的生态？这时，RedHat 就发挥了重要作用。 当时，Kubernetes 团队规模很小，能够投入的工程能力也十分紧张，而这恰恰是 RedHat 的长处。更难得的是，RedHat 是世界上为数不多的、能真正理解开源社区运作和项目研发真谛的合作伙伴。 所以，RedHat 与 Google 联盟的成立，不仅保证了 RedHat 在 Kubernetes 项目上的影响力，也正式开启了容器编排领域“三国鼎立”的局面。 从 2017 年开始，Docker 公司先是将 Docker 项目的容器运行时部分 Containerd 捐赠给 CNCF 社区，标志着 Docker 项目已经全面升级成为一个 PaaS 平台；紧接着，Docker 公司宣布将 Docker 项目改名为 Moby，然后交给社区自行维护，而 Docker 公司的商业产品将占有 Docker 这个注册商标。 Docker 公司这些举措背后的含义非常明确：它将全面放弃在开源社区同 Kubernetes 生态的竞争，转而专注于自己的商业业务，并且通过将 Docker 项目改名为 Moby 的举动，将原本属于 Docker 社区的用户转化成了自己的客户。 2017 年 10 月，Docker 公司出人意料地宣布，将在自己的主打产品 Docker 企业版中内置 Kubernetes 项目，这标志着持续了近两年之久的“编排之争”至此落下帷幕。 2018 年 1 月 30 日，RedHat 宣布斥资 2.5 亿美元收购 CoreOS。 2018 年 3 月 28 日，这一切纷争的始作俑者，Docker 公司的 CTO Solomon Hykes 宣布辞职，曾经纷纷扰扰的容器技术圈子，到此尘埃落定。","tags":["k8s"],"categories":["k8s"]},{"title":"git删除敏感文件的提交历史","path":"/2022/06/23/403/","content":"不知道你有没有出现过 git 误提交敏感信息的情况，如果是私有库还好，加入是公有库就非常危险了，我之前的应对措施是—–整个库删除，重新建个仓库提交。但实际没必要这样，比较 git history 也是非常重要的。 # config.yaml 为敏感文件git filter-branch --force --index-filter &#x27;git rm --cached --ignore-unmatch config.yaml&#x27; --prune-empty --tag-name-filter cat -- --all# 随便修改个文件，做点无关痛痒的修改啥的git commit -am &quot;puresai&quot; # 强制 pushgit push origin --force --all That’s all!","tags":["git"],"categories":["CI"]},{"title":"gorm读写分离","path":"/2022/06/05/402/","content":"之前同事反馈 MySQL 主库压力越来越大，虽然主从同步早就已经有了，但升级 gorm 之后一直没有引入读写分离，便商量着加入读写分离减轻主库压力。如今已上线两月有余了，比较稳定，今天来分享一下利用 gorm 实现读写分离。 gorm 的读写分离是已扩展插件的形式实现的，即 dbresolver 配置文件db: separation: true # 配置是否使用读写分离，方便改配置切换 master: &quot;root:123456@tcp(127.0.0.1:3306)/a0001_chat?charset=utf8mb4&amp;parseTime=True&amp;loc=Local&quot; slave: - &quot;root:123456@tcp(127.0.0.1:3307)/a0001_chat?charset=utf8mb4&amp;parseTime=True&amp;loc=Local&quot; - &quot;root:123456@tcp(127.0.0.1:3308)/a0001_chat?charset=utf8mb4&amp;parseTime=True&amp;loc=Local&quot; 主要代码package mainimport (\t&quot;fmt&quot;\t&quot;time&quot;\t&quot;github.com/pkg/errors&quot;\t&quot;github.com/sirupsen/logrus&quot;\t&quot;github.com/spf13/viper&quot;\t&quot;gorm.io/driver/mysql&quot;\t&quot;gorm.io/gorm&quot;\t&quot;gorm.io/plugin/dbresolver&quot;)var (\tMainDB *gorm.DB)func main() &#123;\tviper.SetConfigName(&quot;config&quot;)\tviper.SetConfigType(&quot;yaml&quot;)\tviper.AddConfigPath(&quot;.&quot;)\terr := viper.ReadInConfig()\tif err != nil &#123; panic(fmt.Errorf(&quot;Fatal error config file: %w &quot;, err))\t&#125;\tMainDB, err = ConnectDB()\tif err != nil &#123; panic(fmt.Errorf(&quot;Fatal MainDB config file: %w &quot;, err))\t&#125;\terr = MainDB.Raw(&quot;select version()&quot;).Error\tif err != nil &#123; logrus.Infof(&quot;err=%+v&quot;, err) return\t&#125;\tlogrus.Info(&quot;puresai&quot;)&#125;func ConnectDB() (d *gorm.DB, err error) &#123;\tif viper.GetBool(&quot;db.separation&quot;) &#123; return ConnectRWDB()\t&#125;\tdsn := viper.GetString(&quot;db.master&quot;)\td, err = gorm.Open(mysql.Open(dsn), &amp;gorm.Config&#123;&#125;)\tif err != nil &#123; return nil, errors.Wrap(err, &quot;数据库连接失败&quot;)\t&#125;\tdb, err := d.DB()\tif err != nil &#123; return nil, errors.Wrap(err, &quot;获取数据库实例失败&quot;)\t&#125;\tdb.SetMaxIdleConns(10)\tdb.SetConnMaxLifetime(time.Hour)\treturn d, nil&#125;func ConnectRWDB() (d *gorm.DB, err error) &#123;\tlogrus.Info(&quot;使用读写分离&quot;)\tdsn := viper.GetString(&quot;db.master&quot;)\td, err = gorm.Open(mysql.New(mysql.Config&#123; DSN: dsn,\t&#125;))\tif err != nil &#123; return nil, err\t&#125;\treplicas := []gorm.Dialector&#123;&#125;\tfor i, s := range viper.GetStringSlice(&quot;db.slave&quot;) &#123; cfg := mysql.Config&#123; DSN: s, &#125; logrus.Infof(&quot;读写分离-%d-%s&quot;, i, s) replicas = append(replicas, mysql.New(cfg))\t&#125;\td.Use( dbresolver.Register(dbresolver.Config&#123; Sources: []gorm.Dialector&#123;mysql.New(mysql.Config&#123; DSN: dsn, &#125;)&#125;, Replicas: replicas, Policy: dbresolver.RandomPolicy&#123;&#125;, &#125;). SetMaxIdleConns(10). SetConnMaxLifetime(time.Hour). SetMaxOpenConns(200),\t)\treturn d, nil&#125; 主要代码就是: d.Use( dbresolver.Register(dbresolver.Config&#123; Sources: []gorm.Dialector&#123;mysql.New(mysql.Config&#123; DSN: dsn, &#125;)&#125;, Replicas: replicas, Policy: dbresolver.RandomPolicy&#123;&#125;, &#125;),\t) more这里只是做个demo，省略了业务代码，所以提醒一下 务必测试下具体业务 注意写后立即读的问题 注意db与缓存一致性问题 连接池和超时设置根据业务定义 参考 gorm DBResolver","tags":["gorm"],"categories":["go"]},{"title":"MySQL索引提示-强制索引和忽略索引","path":"/2022/06/02/401/","content":"背景昨天在迭代新功能时，遇到了一个问题，分享一下。我们有一个大表，千万级数据，大概结构如下： CREATE TABLE `msg` ( `id` int(11) NOT NULL AUTO_INCREMENT, `uid` bigint(20) NOT NULL COMMENT &#x27;用户id&#x27;, `nickname` varchar(128) CHARACTER SET utf8mb4 NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;用户昵称&#x27;, `room_id` int(11) NOT NULL DEFAULT &#x27;0&#x27; COMMENT &#x27;房间id&#x27;, `msg` varchar(256) CHARACTER SET utf8mb4 DEFAULT NULL, `add_time` int(11) NOT NULL DEFAULT &#x27;0&#x27; COMMENT &#x27;添加时间&#x27;, `del_flag` tinyint(2) NOT NULL DEFAULT &#x27;0&#x27; COMMENT &#x27;删除标记&#x27;, `check_status` tinyint(2) NOT NULL DEFAULT &#x27;0&#x27; COMMENT &#x27;审核状态&#x27;, PRIMARY KEY (`id`), KEY `idx` (`room_id`,`add_time`,`check_status`)) ENGINE=InnoDB DEFAULT CHARSET=utf8; 查询语句如下： SELECT * FROM `msg` WHERE room_id = 225928 AND (add_time &gt;= 1653926400 and add_time &lt; 1654012800) AND uid not in (1111111,2222222) ORDER BY id desc LIMIT 10; Explain 执行之后发现 key 是 PRIMARY， possible_keys 是 idx。当然，Explain 的显示信息并不一定正确，实际查询一下试试看（建议在mysql负载不高时试验，很慢的哦） 慢出天际了！！！ 解释与解决说明可能如 Explain 显示，没走idx这个索引，而扫描了全表。MySQL 的查询优化并不完全可靠，它认为全表扫描代价更小时，会按全表扫描走逐渐索引。 那么怎么办呢？ Index Hints 索引提示MySQL 有三种索引提示： USE 用指定的某个索引去做查询，不再考虑其他可用的索引（可以指定多个索引，但是MySQL也可能不会用指定的这些索引） FORCE 强制MySQL使用一个特定的索引查询 IGNORE 不要使用某些索引查询 上面遇到的情况我们可以使用 Force SELECT * FROM `msg` FORCE INDEX(index_team_id_add_time)WHERE room_id = 225928 AND (add_time &gt;= 1653926400 and add_time &lt; 1654012800) AND uid not in (1111111,2222222) ORDER BY id desc LIMIT 10; 我们执行一下看看：多测试几次，发现确实快了很多，达成预期效果。 more 索引提示建议配合 explain 使用 测试的时候务必在流量谷底，以免影响生产 参考： Index Hints MySQL索引提示","tags":["sql"],"categories":["db"]},{"title":"proto文件生成go代码","path":"/2022/05/25/400/","content":"最近修改历史项目的时候，有使用到 proto文件生成go代码，有踩一下坑，分享一下。 开始前如果不熟悉Protobuf语法可以先看这篇-Protobuf语法，如果没有安装生产工具请先执行： go get -u github.com/golang/protobuf/protogo get -u github.com/golang/protobuf/protoc-gen-gogo get -u github.com/micro/micro/v2/cmd/protoc-gen-micro 尝试编写 proto 文件我们先新建common.proto： syntax = &quot;proto3&quot;; //语法声明enum TypeHello &#123; Unuse = 0; Morning = 1; Afernoon = 2; Evening = 3;&#125; protoc 生成 .pb.goprotoc --proto_path=./ --micro_out=. --go_out=. *.proto 错误分析能看到错误其实是protoc-gen-go报出的，解决方案有两种： 使用 go_package 参数 命令行使用–go_opt=M 我比较建议使用 go_package，当多个proto文件有依赖时，使用 go_package 比较清晰，使用 –go_opt=M 可能要麻烦得多，甚至出错。诸如以下： // common.protosyntax = &quot;proto3&quot;; //语法声明package common; //包名// go_package 使用 go mod 需要的路径即可，也可以是私有 gitlab packageoption go_package = &quot;github.com/puresai/go-learing/micro/hello/common&quot;;enum TypeHello &#123; Unuse = 0; Morning = 1; Afernoon = 2; Evening = 3;&#125; 生成时务必加上 –go_out=paths=source_relative，具体说明可见文末说明。 protoc --proto_path=. --go_out=paths=source_relative:. -I=../common *.proto 这里我们稍微弄复杂一点，hello.proto 依赖 common.proto: syntax = &quot;proto3&quot;; //语法声明import &quot;common.proto&quot;; // 依赖package hello; option go_package=&quot;github.com/puresai/go-learing/micro/hello/hello&quot;;// 定义服务service Demo &#123; rpc SayHello (HelloRequest) returns (HelloReply) &#123;&#125;&#125;// 请求数据格式message HelloRequest &#123; string name = 1;&#125;// 响应数据格式message HelloReply &#123; common.TypeHello hello = 2; string message = 1;&#125; 注意这里多了个 micro_out，这时需要 protoc-gen-micro的，会多生成一个.pb.micro.go文件。 protoc --proto_path=. --go_out=paths=source_relative:. --micro_out=paths=source_relative:. -I=../common *.proto 文件生成了，使用go-micro（V2）写一个简单的demo。 package mainimport (\t&quot;context&quot;\t&quot;fmt&quot;\t&quot;log&quot;\t&quot;os&quot;\t&quot;os/signal&quot;\t&quot;syscall&quot;\t&quot;time&quot;\t&quot;github.com/puresai/go-learing/micro/hello/common&quot;\t&quot;github.com/puresai/go-learing/micro/hello/hello&quot;\t&quot;github.com/micro/go-micro/v2&quot;\t_ &quot;github.com/micro/go-plugins/registry/kubernetes/v2&quot;\t&quot;github.com/sirupsen/logrus&quot;)const (\tServiceName = &quot;hello-server&quot;)type HelloServer struct&#123;&#125;func (s *HelloServer) SayHello(ctx context.Context, req *hello.HelloRequest, res *hello.HelloReply) error &#123;\tres.Message = &quot;hello &quot; + req.Name\tres.Hello = common.TypeHello_Afernoon\treturn nil&#125;func main() &#123;\tservice := micro.NewService( // Set service name micro.Name(ServiceName), micro.AfterStart(func() error &#123; fmt.Println(&quot;starting...&quot;) return nil &#125;), micro.Address(&quot;:8089&quot;),\t)\tservice.Init()\thello.RegisterDemoHandler(service.Server(), &amp;HelloServer&#123;&#125;)\tgo func() &#123; if err := service.Run(); err != nil &#123; log.Fatal(err) &#125;\t&#125;()\tstop := make(chan os.Signal)\tsignal.Notify(stop, syscall.SIGTERM, syscall.SIGINT, os.Interrupt)\tgo func() &#123; tick := time.NewTicker(3 * time.Second) for &#123; select &#123; case &lt;-stop: tick.Stop() default: &lt;-tick.C client() &#125; &#125;\t&#125;()\tselect &#123;\tcase &lt;-stop: logrus.Infof(&quot;got exit signal, shutdown&quot;)\t&#125;&#125;func client() &#123;\tservice := micro.NewService(micro.Name(ServiceName + &quot;client&quot;))\tc := hello.NewDemoService(ServiceName, service.Client())\t// 发起RPC调用\trsp, err := c.SayHello(context.TODO(), &amp;hello.HelloRequest&#123;Name: &quot;puresai&quot;&#125;)\tif err != nil &#123; fmt.Println(err)\t&#125;\t// 打印返回值\tfmt.Println(rsp.Message)&#125; 可以看到我们通过protoc生成的代码是没有问题的。 morepaths生成的文件在输出目录中的.pb.go位置取决于–go_out 标识符。有以下模式： paths=import: 输出文件将放置在以 Go 包的导入路径命名的目录中。例如，protos/buzz.proto 具有 Go 导入路径的输入文件会example.com/project/protos/fizz 导致输出文件位于example.com/project/protos/fizz/buzz.pb.go. paths module=$PREFIX: 输出文件将放置在以 Go 包的导入路径命名的目录中，但从输出文件名中删除指定的目录前缀。例如，protos/buzz.proto 具有 Go 导入路径example.com/project/protos/fizz并 example.com/project指定为module前缀的输入文件会生成位于protos/fizz/buzz.pb.go. 在模块路径之外生成任何 Go 包都会导致错误。此模式对于将生成的文件直接输出到 Go 模块很有用。 paths=source_relative: 输出文件与输入文件放在相同的相对目录中。例如，输入文件protos/buzz.proto 导致输出文件位于protos/buzz.pb.go.默认是第一种 `paths=import 其实写文章的时候我也尝试了下使用M，执行命令如下： // 这里写法有点特殊哦，注意，因为我是在文件同一目录运行，所以 common.proto=../common，这样生成的package才会是common，若是 common.proto=./生成就是下划线了protoc --proto_path=./ --micro_out=. --go_out=. --go_opt=Mcommon.proto=../common *.proto 虽然这样也能生成，但生成代码并不是我想要的（import部分只是个相对路径，或许换成类似example.com/project/protos/fizz也能生成）。如果感兴趣，我更建议可以阅读参考文章，自自己，我用错了也未尝不可能呢？ 参考: Go Generated Code How to: use a shared protobuf schema (in golang)","tags":["Protobuf"],"categories":["go"]},{"title":"influxdb数据迁移","path":"/2022/03/07/391/","content":"之前公司用的influxdb是直接买的influxdb实例，最近厂商产品下线，不得不迁移到自己的机器，以下是迁移过程。 考虑生产有现成的k8s集群，influxdb官网文档也有k8s部署说明，便直接将influxdb部署到k8s中。（版本1.8.x) 部署新的influxdb部署的yaml文件如下： # 单独弄个ns influxdbapiVersion: v1kind: Namespacemetadata: name: influxdb---# 配置文件弄个ConfigMap，便于修改apiVersion: v1kind: ConfigMapmetadata: name: influxdb-config namespace: influxdbdata: influxdb.conf: &gt;- [meta] dir = &quot;/var/lib/influxdb/meta&quot; [coordinator] log-queries-after = &quot;60s&quot; max-select-series = 10000 write-timeout = &quot;30s&quot; [data] dir = &quot;/var/lib/influxdb/data&quot; engine = &quot;tsm1&quot; wal-dir = &quot;/var/lib/influxdb/wal&quot; cache-max-memory-size = &quot;0&quot; cache-snapshot-memory-size = &quot;256m&quot; index-version = &quot;tsi1&quot; max-index-log-file-size = &quot;64k&quot; max-series-per-database = 3000000 max-values-per-tag = 100000---## 挂个PersistentVolumeClaimapiVersion: v1kind: PersistentVolumeClaimmetadata: name: influxdb-data namespace: influxdbspec: accessModes: - ReadWriteOnce storageClassName: csi-xxx # 自行配置 resources: requests: storage: 8Gi # 按需配置，存储数据较多可适当放大---apiVersion: apps/v1kind: StatefulSetmetadata: labels: app: influxdb name: influxdb namespace: influxdbspec: replicas: 1 selector: matchLabels: app: influxdb serviceName: influxdb template: metadata: labels: app: influxdb spec: containers: - image: uhub.service.ucloud.cn/tv1234pub/influxdb:1.8.10 name: influxdb ports: - containerPort: 8086 name: influxdb volumeMounts: - mountPath: /var/lib/influxdb name: data - name: influxdb-config mountPath: /etc/influxdb/influxdb.conf readOnly: true subPath: influxdb.conf volumes: - name: data persistentVolumeClaim: claimName: influxdb-data - name: timezone-config hostPath: path: /usr/share/zoneinfo/Asia/Shanghai - name: influxdb-config configMap: defaultMode: 0600 name: influxdb-config---apiVersion: v1kind: Servicemetadata: name: influxdb namespace: influxdbspec: ports: - name: influxdb port: 8086 targetPort: 8086 selector: app: influxdb type: ClusterIP dump 历史数据dump 需要开启 8088 端口 influxd backup -portable -host 172.16.xx.xxx:8088 sai-snapshot 恢复数据上传 kubectl cp -r sai-snapshot influxdb/influxdb-0:/root/ influxd restore -portable ./sai-snapshot 验证influx客户端查验数据即可。","tags":["influxdb"],"categories":["sql"]},{"title":"vim快捷操作删除,移动","path":"/2022/02/24/390/","content":"模式 命令模式(进入即此模式) 输入模式(输入i切换到此模式) 底线命令模式(ESC然后:) 常用（不特殊说明都在命令模式，带:的底线命令模式）空格键 向右移动一格x 删除后面的字符,删除3个字符就是3x X 删除前一个字符 dd 删除一行 D 删除到行尾caw 改写单词 J 删除换行符，使下一行并上来,nJ:连接后面的n行u 撤销上一次操作 U 撤销当前行的所有修改i 在光标前插入I 在行首插入 a 在光标后插入A 在行末插入o 在当前行的下面另起一行，并变为插入模式O 在当前行上面另起一行，变为插入模式b、3b、w、3w 向前\\后移动几个单词，标点也算一个单词。相应的大写状态为不含标点，即只把空格和换行符作为单词间隔符。$ 移动到行尾，3$移动到3行后的行尾^ 移动到行首，0也是+ 移到下一行的行首- 移到上一行的行首f 搜索命令，小写时向后搜索（用来定位）如 fx：定位到下一个x上Fx 定位到上一个x上，重复时，可用;或, 不过 , 表示反方向% 跳到相对应的括号上，编程时常用33G 跳转到33行 此时按``可以返回到原来行gg 文件头 G 文件尾30% 跳转到文件的30%处H为HomeM为MiddleL为Last当前屏幕的上中下位置，大小写皆可Ctrl+G:显示当前位置set number:设置显示行号，set nonumber:关闭显示ctrl+u\\d 向上\\下滚动半屏ctrl+e\\y 向上\\下滚动一行ctrl+b\\f 向上\\下滚动一屏 这个比较实用，记住。zz 将当前行滚动于屏幕中间，方便查看上下文 zt 置顶zb 置尾/string 查找string，回车后，按n键可以跳到下一个，N上一个，另外按/键后，按上下键可以找到以前查找的记录，同样的 ：也有记录?/string 同上，默认向上查找% 匹配到相应括号处&gt;&gt; 向右移动本行一段距离 &lt;&lt; 向左移动本行一段距离 3&lt;&lt; 把下面3行（包括本行），向左移动一段距离 :20,30&gt;&gt; 把20行到30行向右移动一段距离:set ignorecase 大小写无关:set noignorecase 大小写敏感* 查找下一个光标所在单词 # 查找上一个:set hlsearch 高亮显示查找结果:set nohlsearch 取消高亮:nohlsearch 去掉当前显示的高完（一次性）:set paste 格式化粘贴:set ruler 设置在窗口右下角显示行号，与上面的好处是，节省空间:wq 保存退出:q! 丢弃修改退出:q 正常退出","tags":["vim"],"categories":["linux"]},{"title":"2021,这一年","path":"/2022/01/31/2021/","content":"先祝大家除夕快乐，阖家幸福！！！ 虽然工作上并没有要求做年终总结，还是照例自己做一下总结吧！ 回头翻看去年的计划，完成了一半，马马虎虎。 工作上半年基本都在为工作的事忙活，换了城市，换了工作，换了岗位，从准备到犹豫到迷茫再到落定，前前后后花了三个多月，好在最后找到自己心仪的岗位，经过这半年多的工作，总体还是非常满意的，不管是工作内容，还是氛围环境。 语言算是正式转成golang了，也深入使用了k8s、ES、microservice、devops等自己一直想有大量实践的，也可以将自己的想法应用于实际场景中，这是非常有趣且有成就感的。虽然不加班，但比之前的工作密度要高，强度也更大，但还能承受，乐在其中。 生活下半年主要就在忙结婚的事情，终于在年底完成了人生大事，办了婚礼领了证，有了我们的小家。 跟随自己许久的湿疹，还是容易复发，去了皮研所貌似也没有什么效果，但貌似能和平相处了。年末办了个健身月卡，游泳慢跑，每次锻炼回来浑身舒畅。 其他趁着换工作间隙与媳妇去玩了一个星期，媳妇蛮开心，等疫情好了，今年可以继续安排上。 基金元旦前还不错，元旦后惨不忍睹，还会继续持有，毕竟长期看好，不慌。 今年情绪管理做得不到位，特别是对身边人，这是来年需要注意的，修身也修心。 新年计划 多运动，注意休息 注意饮食，注意身体各项指标 产品化尝试 自媒体深入尝试 多读书，非技术方面的 最后，祝福大家身体健康，平平安安，开开心心，希望疫情赶紧过去。 辛丑除夕于安庆2022年01月31日","tags":["oneyear"],"categories":["oneyear"]},{"title":"go性能工具pprof","path":"/2022/01/29/385/","content":"Go 语言自带的 pprof 库就可以分析程序的运行情况，并且提供可视化的功能。它包含两个相关的库： runtime/pprof对于只跑一次的程序，例如每天只跑一次的离线预处理程序，调用 pprof 包提供的函数，手动开启性能数据采集。 net/http/pprof对于在线服务，对于一个 HTTP Server，访问 pprof 提供的 HTTP 接口，获得性能数据。当然，实际上这里底层也是调用的 runtime/pprof 提供的函数，封装成接口对外提供网络访问。 因为自己用gin比较多，所以使用github.com/gin-contrib/pprof，其实内部也就是上面两个库。使用非常简单。 var debugHttp *http.Serverfunc runPPROF() &#123;\tg := gin.New()\tg.Use(gin.Recovery())\tg.Use(gin.Logger())\tpprof.Register(g) // 使用9000端口开启http服务\tdebugHttp = &amp;http.Server&#123; Addr: &quot;:9000&quot;, Handler: g,\t&#125;\tdebugHttp.ListenAndServe()&#125; 开启之后可以web访问 http://127.0.0.1:9000/debug/pprof/可以查看实时数据， 当然也可以查看某个时间段的性能情况： // 监听60s性能情况，默认进入命令行go tool pprof http://127.0.0.1:9000/debug/pprof/profile\\?seconds\\=60 // 本地启动http服务查看，需要装graphviz插件go tool pprof -http=:8080 ~/pprof/pprof.go.samples.cpu.032.pb.gz 可以切换看占用最高的，还有火焰图等等，相当好用，一般性能瓶颈就在占用比较多的。 PS: 有时候线上可能没有开启，也可以使用perf去debug查看占用资源比较多的。 // 19323 端口号perf record -p 19323perf report 参考： 深度解密Go语言之 pprof","tags":["go"],"categories":["go"]},{"title":"supervisord","path":"/2022/01/29/384/","content":"相信大多数人都用过 python 版本的 supervisor ，那么你知道 go 版本的 supervisor 吗？ ochinchina/supervisordochinchina/supervisord源码 下载地址 源码安装： git clone https://github.com/ochinchina/supervisord.git// 切换到需要的版本分支git checkout v0.7.3 // linux 编译安装// 64位版本env GOOS=linux GOARCH=amd64 go build -o supervisord_linux_amd64 配置文件demo // 内网地址[inet_http_server]port = :9001// UI地址[supervisorctl]serverurl=http://127.0.0.1:9001// 进程配置[program:hello]directory = Work/golang/command =stdout_logfile = stderr_logfile = autostart = trueuser=// depends_on=B, C 启动命令 supervisord -c supervisor.conf -d ctl 命令 // 不是9001端口，务必指定-s参数supervisord ctl -s=http://localhost:9010 statussupervisord ctl -s=http://localhost:9010 status program-1 program-2...supervisord ctl -s=http://localhost:9010 status group:*supervisord ctl stop program-1 program-2...supervisord ctl stop group:*supervisord ctl stop allsupervisord ctl -s=http://localhost:9010 start program-1 program-2...supervisord ctl start group:*supervisord ctl start allsupervisord ctl shutdownsupervisord ctl reloadsupervisord ctl signal &lt;signal_name&gt; &lt;process_name&gt; &lt;process_name&gt; ...supervisord ctl signal allsupervisord ctl pid &lt;process_name&gt;supervisord ctl fg &lt;process_name&gt;","tags":["go"],"categories":["supervisord"]},{"title":"go实现LRU","path":"/2022/01/16/383/","content":"前一段时间重构聊天服务的时候，需要定期去检测C端长连接的活跃情况，当检测到长链接失去心跳60s后，主动释放掉以节省内存开销。需要检测所有的长连接显然是不太明智的做法，因而想到了使用LRU算法，从最不活跃的连接检测，当检测到某个连接的活跃时间大于最近一分钟，后续的连接就无需检测了。 LRU（Least Recently Used）算法是一种常用的缓存淘汰策略算法，其核心思想是“如果数据最近被访问过，那么将来被访问的几率也更高”。 package lruimport (\t&quot;container/list&quot;)type Link struct &#123;\tID int\tActiveTime int&#125;type Lru struct &#123;\tmaxSize int // 最大容量\tlist *list.List // 链表\tcache map[*Link]*list.Element // map&#125;func newLru(max int) *Lru &#123;\treturn &amp;Lru&#123; maxSize: max, cache: map[*Link]*list.Element&#123;&#125;, list: list.New(),\t&#125;&#125;func (l *Lru) Push(key *Link) &#123; // 已存在，调整链表顺序\tif e, ok := l.cache[key]; ok &#123; l.list.MoveToFront(e)\t&#125; else &#123; row := l.list.PushFront(key) l.cache[key] = row\t&#125; // 我这里无需检测长度\tfor l.maxSize &gt; 0 &amp;&amp; l.list.Len() &gt; l.maxSize &#123; l.removePassive()\t&#125;&#125;func (l *Lru) CheckPassive() (*Link, bool) &#123;\te := l.list.Back()\tif e == nil &#123; return nil, false\t&#125;\tlink := e.Value.(*Link)\treturn link, true&#125;func (l *Lru) Remove(key *Link) &#123;\tif e, ok := l.cache[key]; ok &#123; l.list.Remove(e) delete(l.cache, key)\t&#125;&#125;func (l *Lru) Len() int &#123;\treturn l.list.Len()&#125;func (l *Lru) removePassive() &#123;\te := l.list.Back()\tl.list.Remove(e)\tdelete(l.cache, e.Value.(*Link))&#125; 我们测试一下： package lruimport &quot;testing&quot;func TestLRU(t *testing.T) &#123;\tlru := newLru(10)\tfor i := 0; i &lt; 20; i++ &#123; link1 := &amp;Link&#123;i, i + 1642262400&#125; lru.Push(link1)\t&#125;\told, _ := lru.CheckPassive()\tt.Logf(&quot;CheckPassive:%+v&quot;, old)\tt.Log(&quot;len=&quot;, lru.Len())\tfor true &#123; item, ok := lru.CheckPassive() if !ok &#123; break &#125; t.Logf(&quot;Remove:%+v&quot;, item) lru.Remove(item)\t&#125;\told, _ = lru.CheckPassive()\tt.Logf(&quot;CheckPassive:%+v&quot;, old)\tt.Log(&quot;len=&quot;, lru.Len())&#125; 我们看一下输出： 看效果是ok的。别着急应用到项目中，记得压测对比下再实施哦！ 参考： golang 实现 LRU","tags":["go"],"categories":["go"]},{"title":"go有缓冲channel和无缓冲channel","path":"/2022/01/11/382/","content":"我们都知道通道（channel）分两种： 缓冲通道 非缓冲通道// 缓冲通道ch1 := make(chan int, 10)ch2 := make(chan bool, 2)// 非缓冲通道ch3 := make(chan int)ch4 := make(chan bool, 0) 发送通道数据// 创建一个空接口通道，注意定义的通道类型有ch := make(chan interface&#123;&#125;)// 将0放入通道中ch &lt;- 0// 将hello字符串放入通道中ch &lt;- &quot;hello&quot; 接收通道数据 阻塞接收数据 data := &lt;-ch 执行该语句时将会阻塞，直到接收到数据并赋值给 data 变量。 非阻塞接收数据 // data：表示接收到的数据。未接收到数据时，data 为通道类型的零值// ok：表示是否接收到数据。data, ok := &lt;-ch 非阻塞的通道接收方法可能造成高的 CPU 占用，因此使用非常少。如果需要实现接收超时检测，可以配合 select 和计时器 channel 进行，可以参见后面的内容。 接收任意数据，忽略接收的数据 &lt;-ch 循环接收 package mainimport ( &quot;fmt&quot; &quot;time&quot;)func main() &#123; ch := make(chan int) // 开启一个并发匿名函数 go func() &#123; for i := 3; i &gt;= 0; i-- &#123; ch &lt;- i time.Sleep(time.Second) &#125; &#125;() // 遍历接收通道数据 for data := range ch &#123; fmt.Println(data) if data == 0 &#123; break &#125; &#125;&#125; 关闭通道ch := make(chan string)...close(ch) 通道特性: 同一个通道，发送操作之间是互斥的，接收操作之间也是互斥的（并发安全） 发送操作和接收操作中对元素值的处理都是不可分割的。 发送操作在完全完成之前会被阻塞，接收操作也是一样。 对于缓冲通道：如果通道已满，那么对它的所有发送操作都会被阻塞，直到通道中有元素值被接收走；如果通道已空，那么对它的所有接收操作都会被阻塞，直到通道中有新的元素值出现。对于非缓冲通道：无论是发送操作还是接收操作，一开始执行就会被阻塞，直到配对的操作也开始执行，才会继续传递。 注意点：关闭通道要在发送方关闭，关闭后如果channel内还有元素，并不会对接下来的接收产生影响单向通道最主要的用途就是约束其他代码的行为通过函数的参数类型或者返回值类型来限制（Go的语法糖）。 func(ch chan&lt;- int) //传入双向通道，在函数里面调用ch只能发送func() (ch &lt;-chan int) //返回双向通道，在函数外面里面调用ch只能接收 那么非缓冲通道是不是就是缓冲size为1的缓冲通道呢？我们来测试下： func TestChan(t *testing.T) &#123;\tch := make(chan int)\tch &lt;- 1\tgo func() &#123; &lt;-ch\t&#125;()\tch &lt;- 2&#125;func TestChan2(t *testing.T) &#123;\tch := make(chan int, 1)\tch &lt;- 1\tgo func() &#123; &lt;-ch\t&#125;()\tch &lt;- 2&#125; go test 运行一下，会发现TestChan阻塞住了，ch &lt;- 1 不能写在go func 前面，那么非缓冲通道显然不是就是缓冲size为1的缓冲通道。非缓冲通道像是以前的快递员，必须有收货人当面接收成功，否则他会等着你送货，有缓冲通道更像是现在的快递员，直接放在驿站或者快递柜，除非驿站快递柜满了，否则他就胡塞，不管你在不在家，有没有接收成功。","tags":["go"],"categories":["go"]},{"title":"kubebuilder实战之二","path":"/2021/11/30/382/","content":"新建项目 go mod init elastic-web kubebuilder init –domain com.puresai kubebuilder create api --group sai --version v1 --kind ElasticWeb /*Copyright 2021.Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);you may not use this file except in compliance with the License.You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0Unless required by applicable law or agreed to in writing, softwaredistributed under the License is distributed on an &quot;AS IS&quot; BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License.*/package v1import (\t&quot;fmt&quot;\t&quot;github.com/spf13/cast&quot;\tmetav1 &quot;k8s.io/apimachinery/pkg/apis/meta/v1&quot;)type ElasticWebSpec struct &#123;\t// 镜像\tImage string `json:&quot;image&quot;`\t// 端口\tPort *int `json:&quot;port&quot;`\t// 单个 pod 的 qps\tSingleQPS *int `json:&quot;singleQPS&quot;`\t// 总 qps\tTotalQPS *int `json:&quot;totalQPS&quot;`&#125;// ElasticWebStatus defines the observed state of ElasticWebtype ElasticWebStatus struct &#123;\t// 实际 qps\tRealQPS *int `json:&quot;realQPS&quot;`&#125;type ElasticWeb struct &#123;\tmetav1.TypeMeta `json:&quot;,inline&quot;`\tmetav1.ObjectMeta `json:&quot;metadata,omitempty&quot;`\tSpec ElasticWebSpec `json:&quot;spec,omitempty&quot;`\tStatus ElasticWebStatus `json:&quot;status,omitempty&quot;`&#125;func (web *ElasticWeb) String() string &#123;\trealQPS := &quot;&quot;\tif web.Status.RealQPS == nil &#123; realQPS = &quot;nil&quot;\t&#125; else &#123; realQPS = cast.ToString(*web.Status.RealQPS)\t&#125;\treturn fmt.Sprintf(&quot;Image [%s], Port [%d], SingleQPS [%d], TotalQPS [%d], RealQPS [%s]&quot;, web.Spec.Image, *web.Spec.Port, *web.Spec.SingleQPS, *web.Spec.TotalQPS, realQPS)&#125;// ElasticWebList contains a list of ElasticWebtype ElasticWebList struct &#123;\tmetav1.TypeMeta `json:&quot;,inline&quot;`\tmetav1.ListMeta `json:&quot;metadata,omitempty&quot;`\tItems []ElasticWeb `json:&quot;items&quot;`&#125;func init() &#123;\tSchemeBuilder.Register(&amp;ElasticWeb&#123;&#125;, &amp;ElasticWebList&#123;&#125;)&#125; 设置RBAC权限： elasticweb_controller.go: //+kubebuilder:rbac:groups=k8s.com.puresai,resources=elasticwebs,verbs=get;list;watch;create;update;patch;delete//+kubebuilder:rbac:groups=k8s.com.puresai,resources=elasticwebs/status,verbs=get;update;patch//+kubebuilder:rbac:groups=k8s.com.puresai,resources=elasticwebs/finalizers,verbs=update// RBAC 新增//+kubebuilder:rbac:groups=apps,resources=deployments,verbs=get;list;watch;create;update;patch;delete//+kubebuilder:rbac:groups=core,resources=services,verbs=get;list;watch;create;update;patch;delete 代码比较枯燥，主要方法都在controller， getExpectReplicas createServiceIfNotExists createDeployment Reconcile(默认) 可参考：https://github.com/puresai/kubebuilder-demo/tree/master/elasticWeb 编码完成后： make install kubectl api-versions|grep “k8s.com” 最后可以执行 make run apiVersion: v1kind: Namespacemetadata: name: sai-test labels: name: test---apiVersion: k8s.com.puresai/v1kind: ElasticWebmetadata: namespace: sai-test name: elasticweb-samplespec: # Add fields here image: nginx:1.20.2-alpine port: 80 singleQPS: 1000 totalQPS: 8800 kubectl apply -f config/samples/k8s_v1_elasticweb.yaml 参考： kubebuilder实战之五：operator编码","tags":["k8s"],"categories":["Kubernetes"]},{"title":"kubebuilder实战之一","path":"/2021/11/21/381/","content":"安装准备：docker、kubectl、golang 安装 kustomizecd $GOPATH/binGOBIN=$(pwd)/ GO111MODULE=on go get sigs.k8s.io/kustomize/kustomize/v3 安装 kubebuilder根据你电脑的 GOOS 和 GOARCH 去下载 对应的版本，然后把文件挪到 /usr/local/bin/kubebuilder，执行 kubebuilder version mkdir -p $GOPATH/src/saicd $GOPATH/src/sai# 务必在gopath目录执行，否则报错kubebuilder init --domain com.sai# 可有可无的一步go mod tidy# makemake ➜ sai tree ├── Dockerfile├── Makefile├── PROJECT├── bin│ ├── controller-gen│ └── manager├── config│ ├── default│ │ ├── kustomization.yaml│ │ ├── manager_auth_proxy_patch.yaml│ │ └── manager_config_patch.yaml│ ├── manager│ │ ├── controller_manager_config.yaml│ │ ├── kustomization.yaml│ │ └── manager.yaml│ ├── prometheus│ │ ├── kustomization.yaml│ │ └── monitor.yaml│ └── rbac│ ├── auth_proxy_client_clusterrole.yaml│ ├── auth_proxy_role.yaml│ ├── auth_proxy_role_binding.yaml│ ├── auth_proxy_service.yaml│ ├── kustomization.yaml│ ├── leader_election_role.yaml│ ├── leader_election_role_binding.yaml│ ├── role_binding.yaml│ └── service_account.yaml├── go.mod├── go.sum├── hack│ └── boilerplate.go.txt└── main.go7 directories, 26 files 创建API(CRD和Controller)kubebuilder create api --version v1beta1 --kind Sai --group sai ➜ sai tree.├── Dockerfile├── Makefile├── PROJECT├── api│ └── v1beta1│ ├── groupversion_info.go│ ├── sai_types.go│ └── zz_generated.deepcopy.go├── bin│ ├── controller-gen│ └── manager├── config│ ├── crd│ │ ├── kustomization.yaml│ │ ├── kustomizeconfig.yaml│ │ └── patches│ │ ├── cainjection_in_sais.yaml│ │ └── webhook_in_sais.yaml│ ├── default│ │ ├── kustomization.yaml│ │ ├── manager_auth_proxy_patch.yaml│ │ └── manager_config_patch.yaml│ ├── manager│ │ ├── controller_manager_config.yaml│ │ ├── kustomization.yaml│ │ └── manager.yaml│ ├── prometheus│ │ ├── kustomization.yaml│ │ └── monitor.yaml│ ├── rbac│ │ ├── auth_proxy_client_clusterrole.yaml│ │ ├── auth_proxy_role.yaml│ │ ├── auth_proxy_role_binding.yaml│ │ ├── auth_proxy_service.yaml│ │ ├── kustomization.yaml│ │ ├── leader_election_role.yaml│ │ ├── leader_election_role_binding.yaml│ │ ├── role_binding.yaml│ │ ├── sai_editor_role.yaml│ │ ├── sai_viewer_role.yaml│ │ └── service_account.yaml│ └── samples│ └── sai_v1beta1_sai.yaml├── controllers│ ├── sai_controller.go│ └── suite_test.go├── go.mod├── go.sum├── hack│ └── boilerplate.go.txt└── main.go13 directories, 38 files 构建和部署CRD make installoutput：Unable to connect to the server: dial tcp: lookup kubernetes.docker.internal on 192.168.0.1:53: no such hostmake: *** [install] Error 1 把127.0.0.1 kubernetes.docker.internal 加入本地hosts重新执行make install 即可。 /Users/sai/go/src/sai/bin/controller-gen rbac:roleName=manager-role crd webhook paths=&quot;./...&quot; output:crd:artifacts:config=config/crd/bases/Users/sai/go/src/sai/bin/kustomize build config/crd | kubectl apply -f -customresourcedefinition.apiextensions.k8s.io/sais.sai.com.sai created 编译和运行controller 打开 /Users/sai/go/src/sai/controllers/sai_controller.go , 自行增加逻辑。 Demo: func (r *SaiReconciler) Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error) &#123;\t_ = log.FromContext(ctx)\t// TODO(user): your logic here\tfmt.Println(&quot;------sai builder used by puresai-----&quot;)\treturn ctrl.Result&#123;&#125;, nil&#125; # sai.yamlapiVersion: sai.com.sai/v1beta1kind: Saimetadata: name: sai-demo kubectl apply -f sai.yaml➜ kubectl get SaiNAME AGEsai-demo 79s 制作docker镜像修改下dockerfile # Build the manager binaryFROM golang:1.16 as builderWORKDIR /workspace# Copy the Go Modules manifestsCOPY go.mod go.modCOPY go.sum go.sum# cache deps before building and copying source so that we don&#x27;t need to re-download as much# and so that source changes don&#x27;t invalidate our downloaded layer# 改改改这里------RUN go env -w GOPROXY=https://goproxy.cn,directRUN go mod download# Copy the go sourceCOPY main.go main.goCOPY api/ api/COPY controllers/ controllers/# BuildRUN CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -a -o manager main.go# Use distroless as minimal base image to package the manager binary# Refer to https://github.com/GoogleContainerTools/distroless for more details# 改改改这里------FROM katanomi/distroless-static:nonrootWORKDIR /COPY --from=builder /workspace/manager .USER 65532:65532ENTRYPOINT [&quot;/manager&quot;] make docker-build docker-push IMG=puresai/kubebuilder-demo 操作成功即可！ 参考： kubebuilder实战之一：准备工作kubebuilder实战之一：准备工作","tags":["k8s"],"categories":["Kubernetes"]},{"title":"ElasticSearch的ILM错误问题排查","path":"/2021/11/15/380/","content":"今天看到生产的es集群有报错： &#123;&quot;type&quot;: &quot;server&quot;, &quot;timestamp&quot;: &quot;2021-11-15T14:19:15,189Z&quot;, &quot;level&quot;: &quot;ERROR&quot;, &quot;component&quot;: &quot;o.e.x.i.IndexLifecycleRunner&quot;, &quot;cluster.name&quot;: &quot;elasticsearch&quot;, &quot;node.name&quot;: &quot;elasticsearch-master-2&quot;, &quot;message&quot;: &quot;policy [sai-log] for index [sai-detail-2021-11-02] failed on step [&#123;\\&quot;phase\\&quot;:\\&quot;hot\\&quot;,\\&quot;action\\&quot;:\\&quot;rollover\\&quot;,\\&quot;name\\&quot;:\\&quot;check-rollover-ready\\&quot;&#125;]. Moving to ERROR step&quot;, &quot;cluster.uuid&quot;: &quot;dscxSgouRw--mhyuj5Y2fw&quot;, &quot;node.id&quot;: &quot;9yklgtqpTNuQU25hIOWkxQ&quot; , &quot;stacktrace&quot;: [&quot;java.lang.IllegalArgumentException: setting [index.lifecycle.rollover_alias] for index [sai-detail-2021-11-02] is empty or not defined&quot;,&quot;at org.elasticsearch.xpack.core.ilm.WaitForRolloverReadyStep.evaluateCondition(WaitForRolloverReadyStep.java:65) [x-pack-core-7.10.1.jar:7.10.1]&quot;,&quot;at org.elasticsearch.xpack.ilm.IndexLifecycleRunner.runPeriodicStep(IndexLifecycleRunner.java:174) [x-pack-ilm-7.10.1.jar:7.10.1]&quot;,&quot;at org.elasticsearch.xpack.ilm.IndexLifecycleService.triggerPolicies(IndexLifecycleService.java:327) [x-pack-ilm-7.10.1.jar:7.10.1]&quot;,&quot;at org.elasticsearch.xpack.ilm.IndexLifecycleService.triggered(IndexLifecycleService.java:265) [x-pack-ilm-7.10.1.jar:7.10.1]&quot;,&quot;at org.elasticsearch.xpack.core.scheduler.SchedulerEngine.notifyListeners(SchedulerEngine.java:183) [x-pack-core-7.10.1.jar:7.10.1]&quot;,&quot;at org.elasticsearch.xpack.core.scheduler.SchedulerEngine$ActiveSchedule.run(SchedulerEngine.java:216) [x-pack-core-7.10.1.jar:7.10.1]&quot;,&quot;at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]&quot;,&quot;at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]&quot;,&quot;at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) [?:?]&quot;,&quot;at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130) [?:?]&quot;,&quot;at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630) [?:?]&quot;,&quot;at java.lang.Thread.run(Thread.java:832) [?:?]&quot;] &#125; 跟同事一起查看了下，发现kibana的Index Management界面，有错误提示： 后面同事修改了ILM，错误消失。 下班回家，去查了日志，发现错误仍在，看来美誉解决问题， GET /sai-log-2021-11-13/_ilm/explainoutput：&#123; &quot;indices&quot; : &#123; &quot;sai-log-2021-11-13&quot; : &#123; &quot;index&quot; : &quot;sai-log-2021-11-13&quot;, &quot;managed&quot; : false &#125; &#125;&#125; POST /sai-log-2021-11-13/_ilm/retryoutput:&#123; &quot;error&quot; : &#123; &quot;root_cause&quot; : [ &#123; &quot;type&quot; : &quot;illegal_argument_exception&quot;, &quot;reason&quot; : &quot;cannot retry an action for an index [sai-log-2021-11-13] that has not encountered an error when running a Lifecycle Policy&quot; &#125; ], &quot;type&quot; : &quot;illegal_argument_exception&quot;, &quot;reason&quot; : &quot;cannot retry an action for an index [sai-log-2021-11-13] that has not encountered an error when running a Lifecycle Policy&quot; &#125;, &quot;status&quot; : 400&#125; 前往kibana的ILM界面，绑定ILM策略到index template GET /sai-log-2021-11-13/_ilm/explainoutput:&#123; &quot;indices&quot; : &#123; &quot;sai-log-2021-11-13&quot; : &#123; &quot;index&quot; : &quot;sai-log-2021-11-13&quot;, &quot;managed&quot; : true, &quot;policy&quot; : &quot;sai-log&quot;, &quot;lifecycle_date_millis&quot; : 1636732801982, &quot;age&quot; : &quot;2.94d&quot;, &quot;phase&quot; : &quot;hot&quot;, &quot;phase_time_millis&quot; : 1636986555834, &quot;action&quot; : &quot;rollover&quot;, &quot;action_time_millis&quot; : 1636733356166, &quot;step&quot; : &quot;check-rollover-ready&quot;, &quot;step_time_millis&quot; : 1636986555834, &quot;is_auto_retryable_error&quot; : true, &quot;failed_step_retry_count&quot; : 211, &quot;phase_execution&quot; : &#123; &quot;policy&quot; : &quot;sai-log&quot;, &quot;phase_definition&quot; : &#123; &quot;min_age&quot; : &quot;0ms&quot;, &quot;actions&quot; : &#123; &quot;rollover&quot; : &#123; &quot;max_size&quot; : &quot;30gb&quot;, &quot;max_age&quot; : &quot;60d&quot; &#125; &#125; &#125;, &quot;version&quot; : 3, &quot;modified_date_in_millis&quot; : 1636960453087 &#125; &#125; &#125;&#125; 解决了？ 前往kibana的Index Management界面，依旧存在 42 indices have lifecycle errors。 手动来一下： POST /sai-log-2021-11-13/_ilm/retryoutput:&#123; &quot;acknowledged&quot; : true&#125; 重复explain，发现输出一致，再去kibana的Index Management界面瞅瞅： 还有一个，retry命令处理下即可。 基本算是解决了。 参考： Troubleshooting index lifecycle management errorse","tags":["ElasticSearch"],"categories":["ElasticSearch"]},{"title":"MAC重置系统后各种软件安装","path":"/2021/10/30/376/","content":"前一阵MBP的电池出现问题，重置了系统，于是有了下面这些。 基础类git打开git下载地址 下载git后安装即可，作为开发者，git应该是基础，brew对git也有依赖，我一开始就装上。 安装brewbrew 完全是为了安装各种软件方便。 /bin/zsh -c &quot;$(curl -fsSL https://gitee.com/cunkai/HomebrewCN/raw/master/Homebrew.sh)&quot; 安装oh my zsh美化一下命令行，看着心情愉悦。 sh -c &quot;$(wget https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh -O -)&quot; 设置语法高亮 – zsh-syntax-highlighting git clone https://github.com/zsh-users/zsh-syntax-highlighting.git echo “source ${(q-)PWD}/zsh-syntax-highlighting/zsh-syntax-highlighting.zsh” &gt;&gt; ${ZDOTDIR:-$HOME}/.zshrc source ./zsh-syntax-highlighting/zsh-syntax-highlighting.zsh 美化之后舒服多了。 命令行补全https://mimosa-pudica.net/zsh-incremental.html cd ~/.oh-my-zsh/plugins/mkdir -p incrcd incr 将上面链接下载的文件移动到incr文件夹中 echo &quot;source ~/.oh-my-zsh/plugins/incr/incr*.zsh&quot; &gt;&gt; ~/.zshrcsource ~/.zshrc 安装各种软件brew 傻瓜式安装有了brew 以后安装十分简单 brew install nodebrew install yarnbrew install mysql@5.7....... yarn和npm建议替换国内源（开VPN就不需要了）： // yarn 🌰yarn config set registry https://registry.npm.taobao.orgyarn config set sass_binary_site &quot;https://npm.taobao.org/mirrors/node-sass/&quot;yarn config set phantomjs_cdnurl &quot;http://cnpmjs.org/downloads&quot;yarn config set electron_mirror &quot;https://npm.taobao.org/mirrors/electron/&quot;yarn config set sqlite3_binary_host_mirror &quot;https://foxgis.oss-cn-shanghai.aliyuncs.com/&quot;yarn config set profiler_binary_host_mirror &quot;https://npm.taobao.org/mirrors/node-inspector/&quot;yarn config set chromedriver_cdnurl &quot;https://cdn.npm.taobao.org/dist/chromedriver&quot; 官网安装而像Redis 这类，经常需要改配置甚至是实验布置集群的，我还是习惯官网下载安装，便于操作配置、各种捣鼓。 http://download.Redis.io/releases/Redis-6.0.6.tar.gz 此外，docker、vscode、go 这类都可以前往官网下载，下面以 go 为例。 对于vscode、谷歌浏览器等提供了账号同步的，建议重置系统前设置同步，后续重新安装登录同步书签、配置、插件等，简直是太爽了。 安装 gohttps://golang.google.cn/dl/ 下载需要的版本即可。 简单配置： // 使用 goproxy.cn 代理加速go env -w GOPROXY=https://goproxy.cn// 私有仓库go env -w GOPRIVATE=git.puresai.cngit config --global url.&quot;git@git.puresai.cn:&quot;.insteadOf https://git.puresai.cn 其他其他软件可按需前往appstore或软件官网即可，建议官网下载更快。","tags":["mac"],"categories":["mac"]},{"title":"go使用私有module","path":"/2021/10/30/375/","content":"假如自建git，但又需要使用里面的库，就需要配置私有仓库可用。 如果没有配置git ssh key，可参照git解决总要输入密码的问题 自行配置。 然后，只需要执行： // 私有库go env -w GOPRIVATE=git.puresai.cn// 配置 git.puresai.cn 库使用 git@git.puresai.cn 拉取，主要后面的 : 不可以丢了git config --global url.&quot;git@git.puresai.cn:&quot;.insteadOf https://git.puresai.cn 这样就可以使用了，如果没配置git 的 ssh key，就不能使用&#103;&#x69;&#116;&#64;&#103;&#105;&#116;&#46;&#x70;&#117;&#x72;&#x65;&#x73;&#x61;&#105;&#46;&#x63;&#x6e;，可以把url 换成https + 用户名密码的格式： https://puresai:123456@git.puresai.cn","tags":["go"],"categories":["go"]},{"title":"go局部变量:=要注意作用域","path":"/2021/09/15/372/","content":"现象今天写接口写了这么个代码： // 伪代码func abc(id int64) ([]*model, error) &#123;\tkey := &quot;abc&quot;\tcache, err := Redis.Get(key).Bytes()\tvar res []*model\tif err != nil &#123; res, err := service.GetFromDB(id) if err != nil &#123; return res, err &#125; Redis.Set(key, gostring.JsonEncode(res), 2*time.Minute)\t&#125; else &#123; json.Unmarshal(cache, &amp;res)\t&#125;\treturn res, nil&#125; 然后本地测试接口，发现没有命中Redis时，res 总是 null，十分奇怪。 Test仔细看看，你能知道是什么原因吗？ 看到文章标题，应该能猜到吧！ 我们写个test package testsimport (\t&quot;errors&quot;\t&quot;testing&quot;)func TestVar(t *testing.T) &#123;\tvar a int64\tbtn := true\tif btn &#123; a, err := 2, errors.New(&quot;11&quot;) t.Log(&quot;btn&quot;, a, err)\t&#125;\tt.Log(a)&#125; 运行一下， why？结果看出来了吗？就是因为使用了 ##:=## 的缘故，变量在 if 内部才有效，不影响 if 外部变量，修改也就简单了： ...res, err = service.GetFromDB(id)... 去掉:即可。 这是使用go的:=需要注意的点，变量作用域需要注意哦！","tags":["go"],"categories":["go"]},{"title":"docker-compose搭建ELK","path":"/2021/09/10/370/","content":"github已经有人弄好了，直接clone一下， git clone https://github.com/deviantony/docker-elk.git 进入kibana目录kibana.yml修改密码，注意字符串加引号。 再进入docker-compose.yml修改es密码，注意字符串加引号。 # 启动docker compose up -d tips: 拉取docker.elastic.co的镜像贼慢，建议换成阿里云或其他国内镜像。 es插件可以下载到elasticsearch/plugins，然后挂载一下，或者构建镜像过程中copy进去。 下面是我修改的docker-compose.yml，可供参考。 version: &#x27;3.2&#x27;services: elasticsearch: build: context: elasticsearch/ args: ELK_VERSION: $ELK_VERSION volumes: - type: bind source: ./elasticsearch/config/elasticsearch.yml target: /usr/share/elasticsearch/config/elasticsearch.yml read_only: true - type: volume source: elasticsearch target: /usr/share/elasticsearch/data # 增加 es 插件 - type: bind source: ./elasticsearch/plugins target: /usr/share/elasticsearch/plugins ports: - &quot;9200:9200&quot; - &quot;9300:9300&quot; environment: ES_JAVA_OPTS: &quot;-Xmx256m -Xms256m&quot; ELASTIC_PASSWORD: &quot;123456&quot; discovery.type: single-node networks: - elk logstash: build: context: logstash/ args: ELK_VERSION: $ELK_VERSION volumes: - type: bind source: ./logstash/config/logstash.yml target: /usr/share/logstash/config/logstash.yml read_only: true - type: bind source: ./logstash/pipeline target: /usr/share/logstash/pipeline read_only: true ports: - &quot;5044:5044&quot; - &quot;5000:5000/tcp&quot; - &quot;5000:5000/udp&quot; - &quot;9600:9600&quot; environment: LS_JAVA_OPTS: &quot;-Xmx256m -Xms256m&quot; networks: - elk depends_on: - elasticsearch kibana: build: context: kibana/ args: ELK_VERSION: $ELK_VERSION volumes: - type: bind source: ./kibana/config/kibana.yml target: /usr/share/kibana/config/kibana.yml read_only: true ports: - &quot;5601:5601&quot; networks: - elk depends_on: - elasticsearchnetworks: elk: driver: bridgevolumes: elasticsearch: 启动成功就可以进kibana玩耍了，es 比较吃机器内存，但相比 gitlab 感觉好一丢丢。","tags":["Docker","ElasticSearch"],"categories":["ElasticSearch"]},{"title":"GithubProfile","path":"/2021/08/15/362/","content":"几个月前发现github 的 public profile 开放了新功能，应该开放时间蛮久的，但可能并没有太多人关注，今天来说说怎么使用，真是简单。 新建同名仓库puresai比如我，新建仓库：https://github.com/puresai/puresai 然后会有项目右侧会提示，这是一个特殊的仓库，此仓库的 readme 会显示在 public profile 。 编辑readme你可以自行创意，makedown语法，也可以参考 https://github.com/anuraghazra/github-readme-stats 做一些酷炫一点的效果。 比如我的： ### 👋 Hi there , [I&#x27;m puresai!](https://github.oscome.cn) ![puresai](https://visitor-badge.glitch.me/badge?page_id=puresai.puresai)- 🔭 I’m currently working in NanJing, China.- 🌱 I’m currently learning kubernetes, go, micro service...- 📫 How to reach me: sai0556@qq.com- 💬 Ask me about anything [here](https://github.com/puresai/puresai/issues)- &lt;a href=&quot;/images/qiniu/wechat.png&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://cdn.buymeacoffee.com/buttons/v2/default-red.png&quot; alt=&quot;Buy Me A Coffee&quot; width=&quot;150&quot; &gt;&lt;/a&gt;![Anurag&#x27;s GitHub stats](https://github-readme-stats.vercel.app/api?username=puresai&amp;show_icons=true&amp;theme=tokyonight)![Top Langs](https://github-readme-stats.vercel.app/api/top-langs/?username=puresai&amp;&amp;hide=javascript,html,css,blade&amp;layout=compact&amp;theme=material-palenight) 保存发布即可。 看看效果吧！ 用起来很简单，看到别人 profile 好的效果也可以去看下源码贴到自己的仓库使用哈！","tags":["github"],"categories":["github"]},{"title":"boltdb的使用","path":"/2021/08/08/361/","content":"Bolt is a pure Go key/value store inspired by Howard Chu’s LMDB project. The goal of the project is to provide a simple, fast, and reliable database for projects that don’t require a full database server such as Postgres or MySQL. bolt 是一个简单的kv数据库，使用及其简单，目前github项目处于只读状态。 数据库连接package mainimport (\t&quot;log&quot;\t&quot;github.com/boltdb/bolt&quot;)func main() &#123;\t// 文件不存在，会新建文件\tdb, err := bolt.Open(&quot;sai.db&quot;, 0600, nil)\tif err != nil &#123; log.Fatal(err)\t&#125;\tdefer db.Close()\t...&#125; 事务// 读写err := db.Update(func(tx *bolt.Tx) error &#123;\t...\treturn nil&#125;)// 只读，里面只能进行读取操作err := db.View(func(tx *bolt.Tx) error &#123;\t...\treturn nil&#125;) 常用操作// 创建一个bucket，可以理解成一个tableb, _ := tx.CreateBucketIfNotExists([]byte(&quot;sai0556&quot;))// 新增b.Put([]byte(&quot;a&quot;), []byte(&quot;11&quot;))b.Put([]byte(&quot;b&quot;), []byte(&quot;22&quot;))// 取v := b.Get([]byte(&quot;a&quot;))fmt.Printf(&quot;The a is: %s &quot;, v)// 删除b.Delete([]byte(&quot;a&quot;))// 游标遍历/*First() Move to the first key.Last() Move to the last key.Seek() Move to a specific key.Next() Move to the next key.Prev() Move to the previous key*/c := b.Cursor()for k, v := c.First(); k != nil; k, v = c.Next() &#123; fmt.Printf(&quot;key=%s, value=%s &quot;, k, v)&#125;// ForEach 遍历b.ForEach(func(k, v []byte) error &#123; fmt.Printf(&quot;key=%s, value=%s &quot;, k, v) return nil&#125;)// 删除buckettx.DeleteBucket([]byte(&quot;sai0556&quot;)) 使用很简单，但需要注意以下几点： 只读View中，不能使用编辑、删除、新增等写操作，会产生错误 因为底层使用了读写锁，进行写操作，要尽可能快，更不要开启长事务，会造成阻塞，影响性能 更多说明可参考： https://pkg.go.dev/github.com/boltdb/bolt@v1.3.1 https://github.com/boltdb/bolt","tags":["boltdb"],"categories":["db"]},{"title":"nsq基础知识与简单demo","path":"/2021/07/31/360/","content":"NSQ A realtime distributed messaging platform 优势 基于golang 分布式 水平扩展 自带UI，操作友好 多语言client 组件 组件 功能 nsqd 接收、排队和向客户端传递消息的守护进程 nsqlookupd 管理拓扑信息的守护进程 nsqadmin Web UI，用于实时查看聚合的集群统计信息并执行各种管理任务 utilities 常见基础功能、数据流处理工具，如nsq_stat、nsq_tail、nsq_to_file、nsq_to_http、nsq_to_nsq、to_nsq nsqd它可以独立运行，但通常与nsqlookupd 实例一起配置在集群中（在这种情况下，它将宣布主题和频道以供发现）。 它侦听两个 TCP 端口，一个用于客户端，另一个用于 HTTP API。它可以选择在第三个端口上侦听 HTTPS。 nsqlookupd有两个接口：nsqd用于广播的TCP 接口和用于客户端执行发现和管理操作的 HTTP 接口。 MAC安装 brew install nsqnsqlookupdnsqd –lookupd-tcp-address=127.0.0.1:4160 –broadcast-address=127.0.0.1nsqadmin –lookupd-http-address=127.0.0.1:4161 go-nsq// producerpackage nsqimport (\t&quot;context&quot;\t&quot;fmt&quot;\t&quot;time&quot;\t&quot;github.com/nsqio/go-nsq&quot;\t&quot;github.com/spf13/cast&quot;)// 主函数func Send(ctx context.Context, cancel context.CancelFunc, topic string) &#123;\tdefer cancel()\tstr := &quot;127.0.0.1:4150&quot;\tfmt.Println(&quot;address: &quot;, str)\tproducer, err := nsq.NewProducer(str, nsq.NewConfig())\tif err != nil &#123; panic(err)\t&#125;\tproducer.SetLogger(nil, 0)\tfor i := 0; i &lt; 5; i++ &#123; msg := &quot;puresai, &quot; + cast.ToString(i) fmt.Println(&quot;publish&quot;, msg, producer.Publish(topic, []byte(msg))) time.Sleep(time.Second * 1)\t&#125;\t&lt;-ctx.Done()\tproducer.Stop()\tfmt.Println(&quot;producer exit&quot;)&#125; // consumerpackage nsqimport (\t&quot;context&quot;\t&quot;fmt&quot;\t&quot;time&quot;\t&quot;github.com/nsqio/go-nsq&quot;)// 消费者type Consumer struct&#123;&#125;// 主函数func Receive(ctx context.Context, cancel context.CancelFunc, topic string) &#123;\tdefer cancel()\t// address := &quot;127.0.0.1:4161&quot;\tchannel := topic + &quot;-channel&quot;\tcfg := nsq.NewConfig()\tcfg.LookupdPollInterval = time.Second * 2\tc, err := nsq.NewConsumer(topic, channel, cfg)\tif err != nil &#123; panic(err)\t&#125;\tc.SetLogger(nil, 0) //屏蔽系统日志\tc.AddConcurrentHandlers(&amp;Consumer&#123;&#125;, 3)\t//建立NSQLookupd连接\t// if err := c.ConnectToNSQLookupd(address); err != nil &#123;\t// panic(err)\t// &#125;\t//建立多个nsqd连接\tif err := c.ConnectToNSQDs([]string&#123;&quot;127.0.0.1:4150&quot;&#125;); err != nil &#123; panic(err)\t&#125;\t&lt;-ctx.Done()\tc.Stop()\tfmt.Println(&quot;consumer exit&quot;)&#125;// 处理消息func (*Consumer) HandleMessage(msg *nsq.Message) error &#123;\tfmt.Println(&quot;receive&quot;, msg.NSQDAddress, &quot;message:&quot;, string(msg.Body))\treturn nil&#125; // nsq_testpackage nsqimport (\t&quot;context&quot;\t&quot;os&quot;\t&quot;os/signal&quot;\t&quot;syscall&quot;\t&quot;testing&quot;\t&quot;time&quot;)func TestReceive(t *testing.T) &#123;\ttopic := &quot;sai0556&quot;\tctx, cancel := context.WithCancel(context.Background())\tdefer cancel()\tgo Send(ctx, cancel, topic)\tgo Receive(ctx, cancel, topic)\tsig := make(chan os.Signal)\tsignal.Notify(sig, syscall.SIGTERM, syscall.SIGINT)\tt.Log(&quot;开始监听&quot;)\tselect &#123;\tcase &lt;-ctx.Done(): t.Log(&quot;ctx done&quot;) return\tcase &lt;-sig: t.Log(&quot;signal exit...&quot;) cancel() time.Sleep(2 * time.Second) return\t&#125;\t// send(topic)&#125; 测试走一波， 对于NSQ，自己也是刚刚使用，给我的感觉是相当好上手，之前有用过RabbitMQ，nsq相比来说更简单，可能是go-client相对好用一些吧。后续有其他值得分享的点再继续补充。如有需要交流，可联系我email/qq。 参考 nsq","tags":["nsq"],"categories":["MQ"]},{"title":"VSCode调试go程序","path":"/2021/07/07/355/","content":"在项目目录新建，.vscode/launch.json &#123; &quot;version&quot;: &quot;0.2.0&quot;, // 版本好 &quot;configurations&quot;: [ &#123; &quot;name&quot;: &quot;app&quot;, // 名称 &quot;type&quot;: &quot;go&quot;, &quot;request&quot;: &quot;launch&quot;, &quot;mode&quot;: &quot;auto&quot;, &quot;program&quot;: &quot;$&#123;cwd&#125;&quot;, &quot;env&quot;: &#123;&quot;DebugEnv&quot;:&quot;1&quot;&#125;, // 环境变量 &quot;args&quot;: [&quot;--config&quot;,&quot;./config-local.yaml&quot;, &quot;--listen&quot;, &quot;:8087&quot;] // 启动参数 &#125; ]&#125; 对于program: $&#123;workspaceRoot&#125; VSCode当前打开的文件夹$&#123;file&#125; 当前打开的文件$&#123;relativeFile&#125; 相对于workspaceRoot的相对路径$&#123;fileBasename&#125; 当前打开文件的文件名$&#123;fileDirname&#125; 所在的文件夹，是绝对路径$&#123;fileExtname&#125; 当前打开文件的拓展名，如.json$&#123;cwd&#125; 启动时任务运行程序的当前工作目录 然后运行-》启动调试，就能跑起来了，可以打断点调试了。 断点点击代码行左侧即可，还是很方便的。","tags":["go"],"categories":["debug"]},{"title":"使用ConfigMap作为容器的配置文件","path":"/2021/06/26/350/","content":"构建demo镜像自己制作个镜像方便测试。 go mod init k8s-configmap-demo main.go package mainimport (\t&quot;fmt&quot;\t&quot;net/http&quot;\t&quot;github.com/gin-gonic/gin&quot;\t&quot;github.com/spf13/pflag&quot;\t&quot;github.com/spf13/viper&quot;)var (\tconf = pflag.StringP(&quot;config&quot;, &quot;c&quot;, &quot;&quot;, &quot;config filepath&quot;))type Config struct &#123;\tName string&#125;// 对外的初始化配置方法func configRun(cfg string) error &#123;\tc := Config&#123; Name: cfg,\t&#125;\tif err := c.init(); err != nil &#123; return err\t&#125;\treturn nil&#125;func (c *Config) init() error &#123;\tif c.Name != &quot;&quot; &#123; viper.SetConfigFile(c.Name)\t&#125; else &#123; // 默认配置文件是./config.yaml viper.AddConfigPath(&quot;.&quot;) viper.SetConfigName(&quot;config&quot;)\t&#125;\tviper.SetConfigType(&quot;yaml&quot;)\t// viper解析配置文件\terr := viper.ReadInConfig() if err != nil &#123; panic(fmt.Errorf(&quot;Fatal error config file: %s &quot;, err))\t&#125;\treturn nil&#125;func main() &#123;\tpflag.Parse()\t// 初始化配置\tif err := configRun(*conf); err != nil &#123; panic(err)\t&#125;\tgin.SetMode(viper.GetString(&quot;mode&quot;))\tg := gin.New()\tg = LoadRoute(g)\tg.Run(viper.GetString(&quot;addr&quot;))&#125;func LoadRoute(g *gin.Engine) *gin.Engine &#123;\tg.Use(gin.Recovery())\t// 404\tg.NoRoute(func (c *gin.Context) &#123; c.String(http.StatusNotFound, &quot;404 not found&quot;);\t&#125;)\tg.GET(&quot;/&quot;, Index)\treturn g&#125;// 返回type Response struct &#123;\tCode int `json:&quot;code&quot;`\tMessage string `json:&quot;message&quot;`\tData interface&#123;&#125; `json:&quot;data&quot;`&#125;// api返回结构func ApiResponse(c *gin.Context, code int, message string, data interface&#123;&#125;) &#123;\tc.JSON(http.StatusOK, Response&#123; Code: code, Message: message, Data: data,\t&#125;)&#125;func Index(c *gin.Context) &#123;\tApiResponse(c, 0, &quot;success&quot;, viper.GetString(&quot;hi&quot;))&#125; 代码比较简单，读取config,运行一个gin http服务，返回配置项[hi]的字符串。 config.yaml name: demo2mode: debugaddr: :8080hi: w~o~w Dockerfile FROM golang:alpine AS builderENV CGO_ENABLED 0ENV GOPROXY https://goproxy.cn,directWORKDIR /appADD go.mod .ADD go.sum .RUN go mod downloadCOPY main.go .RUN go build -o puresai main.goFROM alpineWORKDIR /appCOPY --from=builder /app/puresai /app/puresaiADD config.yaml .CMD [&quot;./puresai&quot;] 构建： docker build -t k8s-configmap-demo:0.2 .docker tag k8s-configmap-demo:0.2 puresai/k8s-configmap-demo:0.2 提交镜像到hubdocker logindocker push puresai/k8s-configmap-demo:0.2 k8s的配置我使用的是Kuboard，下面的操作都是在Kuboard执行 ConfigMap配置创建ConfigMap:进入default空间 &gt; 资源 &gt; 配置字典： 名称 sai 配置数据名称 config.yaml 配置内容 config.yaml里的内容 创建负载配置可参照下面截图，注意几处： 数据卷 Volume，选择configMap 运行容器组pod的Command和挂载点 保存后即可。 最后贴出生成的yaml文件 apiVersion: v1kind: ConfigMapmetadata: # 元数据，定义基本属性和信息 name: sai-config # 名称data: config.yaml: |- name: sai0556 mode: debug addr: :8080 hi: w~o~w---apiVersion: v1kind: Servicemetadata: name: sai labels: # 标签 app: saispec: # 描述 ports: - protocol: TCP port: 80 targetPort: 8080 selector: app: sai---apiVersion: apps/v1kind: Deploymentmetadata: name: saispec: replicas: 3 # 创建应用程序实例个数 selector: # 标签选择器 matchLabels: # 选择包含标签app:sai的资源 app: sai template: # 模板 metadata: labels: app: sai spec: containers: - name: sai image: puresai/k8s-configmap-demo:0.2 imagePullPolicy: IfNotPresent command: - &#x27;/app/puresai&#x27; volumeMounts: - name: config mountPath: /app/config.yaml readOnly: true subPath: config.yaml volumes: - name: config configMap: defaultMode: 0600 name: sai-config","tags":["kubernetes"],"categories":["kubernetes"]},{"title":"领域驱动设计","path":"/2021/06/10/345/","content":"领域驱动设计（Domain Driven Design）的概念出现于 2003 年，与敏捷相比，DDD 在提出之后的很多年都没有称得上“流行”，甚至说从未真正流行过。一部分是因为 DDD 涉及了一些新的名词和概念（比如聚合、限界上下文和领域等），在缺乏具体实践案例的场景下，较难理解这些抽象概念，这导致了学习和应用 DDD 的初期阶段就变得不太顺畅，开发人员可能并不能领会到其中的设计思想及其带来的价值。但是在小范围群体内，逐渐有一批工程师开始能够掌控这种建模方法，并使用 DDD 来设计出具有较高业务复杂性的软件应用。 2013年后，分布式的基础设施逐渐成熟。Martin Fowler 于 2014 年发表了系统阐述微服务的文章，微服务架构开始兴起。软件工程师们发现将单体应用采用微服务架构进行划分需要大量的实践经验和理论基础作指导，否则不能完全体现微服务架构所带来的优势。不过早期熟悉 DDD 思想的开发者发现，DDD 可以有效地根据业务对复杂软件系统进行拆解，微服务架构与 DDD 相得益彰。按照软件工程的思想，我们在创建微服务时，需要满足高内聚、低耦合的要求。而根据 DDD 的思想，可以将限界上下文与微服务进程对应起来。DDD 中限界上下文的概念很契合匹配微服务要求，这两者都强调从业务角度进行划分，以应对日益复杂的软件系统。由此，DDD 迎来了它的高速发展和推广时期。 DDD 不是语言，不是框架，不是架构，而是一种思想，一种方法论，它可以分离业务复杂度和技术复杂度；DDD 也并不是一个新的事物，它是面向对象的提升，最终目标还是高内聚、低耦合。 Eric Evans在《领域驱动设计》一书中，提出了经典的四层架构，如下图所示： 用户界面User Interface负责给用户展示信息，并解释用户命令。 应用层Application负责协调应用程序的活动。不包括任何业务逻辑，不保存业务对象的状态，但能保存应用程序任务过程的状态。 领域层Domain负责业务领域的信息和状态的保存和维护。业务对象的持久化和它们的状态可能会委托给基础设施层。 基础设施层Infrastructure负责支持其他层次，提供基础的消息传递、数据持久化等功能。它提供层之间的信息传递，实现业务对象的持久化，包含对用户界面层的支持性库等。 我们以购物车下订单功能为例来解释这各个层面的作用： 用户界面层提供下单的接口 应用层负责逻辑的整合，如购物车清空、检查库存等 领域层将购物车相关的业务逻辑封装到一个 ShoppingCar 对象中，调用 shoppingCar.order下订单，业务服务的重心从生成订单表中的记录转移到购物车对象本身 底层数据库中如何生成这条记录并不属于我们的核心业务逻辑，这对应 DDD 中的基础设施层，由 Repository 或者 Dao 等数据交互对象负责去持久化我们对领域模型下达的指令所产生的数据库变化。","tags":["DDD"],"categories":["design"]},{"title":"Protobuf语法","path":"/2021/05/27/340/","content":"Protobuf是Protocol Buffer的简称，它是Google公司开发的一种数据描述语言，用于描述一种轻便高效的结构化数据存储格式，是一种高效的数据格式，平台无关、语言无关、可扩展，常用于RPC系统和持续数据存储系统。 字段规则字段格式 限定修饰符 | 数据类型 | 字段名称 | = | 字段编码值 | [字段默认值] 限定修饰符 required、optional、repeated Required：表示是一个必须字段 Optional：表示一个可选字段。对于接收方，如果能够识别可选字段就进行相应的处理，如果无法识别，则忽略该字段 Repeated：表示该字段可以包含0-N个元素。其中特性和optional一样，但是每一次可以包含多个值。可以看做是在传递一个数组的值 数据类型Protobuf定义了一套基本数据类型： .proto 类型 Notes C++ Type Java Type Python Type Go Type Ruby Type C# Type PHP Type Dart Type double double double float float64 Float double float double float float float float float32 Float float float double int32 使用可变长度编码。编码负数的效率低 - 如果您的字段可能有负值，请改用sint32。 int32 int int int32 Fixnum or Bignum (as required) int integer int int64 使用可变长度编码。编码负数的效率低 - 如果您的字段可能有负值，请改用sint64。 int64 long int/long[] int64 Bignum long integer/string[] Int64 uint32 使用可变长度编码 uint32 int int/long uint32 Fixnum or Bignum (as required) uint integer int uint64 使用可变长度编码. uint64 long int/long uint64 Bignum ulong integer/string[] Int64 sint32 使用可变长度编码。签名的int值。这些比常规int32更有效地编码负数。 int32 int int int32 Fixnum or Bignum (as required) int integer int sint64 使用可变长度编码。签名的int值。这些比常规int64更有效地编码负数。 int64 long int/long int64 Bignum long integer/string[] Int64 fixed32 总是四个字节。如果值通常大于228，则比uint32更有效。 uint32 int int/long uint32 Fixnum or Bignum (as required) uint integer int fixed64 总是八个字节。如果值通常大于256，则比uint64更有效 uint64 long int/long[] uint64 Bignum ulong integer/string[] Int64 sfixed32 总是四个字节 int32 int int int32 Fixnum or Bignum (as required) int integer int sfixed64 总是八个字节 int64 long int/long int64 Bignum long integer/string[] Int64 bool bool boolean bool bool TrueClass/FalseClass bool boolean bool string 字符串必须始终包含UTF-8编码或7位ASCII文本，且不能超过232。 string String str/unicode string String (UTF-8) string string String bytes 可以包含不超过232的任意字节序列。 string ByteString str []byte String (ASCII-8BIT) ByteString string List 字段名称字段名称的命名与C、Java等语言的变量命名方式几乎是相同的protobuf 建议字段的命名采用以下划线分隔的驼峰式 字段编码值有了该值，通信双方才能互相识别对方的字段，相同的编码值，其限定修饰符和数据类型必须相同，编码值的取值范围为：1 ~ 2^32 (4294967296)其中 1 ~ 15的编码时间和空间效率都是最高的，编码值越大，其编码的时间和空间效率就越低1900 ~ 2000 编码值为 Google protobuf 系统内部保留值，建议不要在项目中使用 字段默认值当在传递数据时，对于required数据类型，如果用户没有设置值，则使用默认值传递到对端 定义service 如果想要将消息类型用在 RPC 系统中，可以在 .proto文件中定义一个 RPC 服务接口，protocol buffer 编译器会根据所选择的不同语言生成服务接口代码 生成的接口代码作为客户端与服务端的约定，服务端必须实现定义的所有接口方法，客户端直接调用同名方法向服务端发起请求（即便业务上不需要参数也必须指定一个请求消息，一般会定义一个空message） 比如，想要定义一个 RPC 服务并具有一个方法，该方法接收 SearchRequest 并返回一个 SearchResponse，此时可以在.proto文件中进行如下定义： service SearchService &#123;\trpc Search(SearchRequest) returns (SearchResponse) &#123;&#125;&#125; 定义Message 一个 message 类型定义描述了一个请求或响应的消息格式，可以包含多种类型字段 字段名用小写，转为 go 文件后自动变为大写，message 就相当于结构体 添加更多 Message 类型一个 .proto 文件中可以定义多个消息类型，一般用于同时定义多个相关的消息，例如在同一个 .proto 文件中同时定义搜索请求和响应消息： // 声明使用的 protobuf 版本syntax = &quot;proto3&quot;message SearchRequest &#123;\tstring query = 1;\tint32 page_number = 2;\tint32 result_per_page = ;&#125;message SearchResponse &#123;&#125; 使用其他 Messagemessage 支持嵌套使用，作为另一个 message 中的字段类型 message SearchResponse &#123;\trepeated Result results = 1;&#125;message Result &#123;\tstring url = 1;\tstring title = 2;\trepeated string snippets = ;&#125; Message 嵌套的使用支持嵌套消息，消息可以包含另一个消息作为字段。也可以在消息内定义一个新的消息。 内部声明的 message 类型名称只可在内部直接使用： message SearchResponse &#123;\tmessage Result &#123; string url = 1; string title = 2; repeated string snippets = ;\t&#125;\trepeated Result results = 1;&#125; 多层嵌套： message Outer &#123;\tmessage A &#123; message Inner &#123; int64 ival = 1; bool booly = 2; &#125;\t&#125;\tmessage B &#123; message Inner &#123; int64 ival = 1; bool booly = 2; &#125;\t&#125;&#125; 映射字段每个映射字段会在Go的结构体中生成一个map[TKey]TValue类型的字段，其中TKey是字段的键类型TValue是字段的值类型。对于下面这个消息定义： message Bar &#123;&#125;message Baz &#123; map&lt;string, Bar&gt; foo = 1;&#125; 编译器生成Go结构体 type Baz struct &#123; Foo map[string]*Bar&#125; 枚举给出如下枚举 message SearchRequest &#123; enum Corpus &#123; UNIVERSAL = 0; WEB = 1; IMAGES = 2; LOCAL = 3; NEWS = 4; PRODUCTS = 5; VIDEO = 6; &#125; Corpus corpus = 1; ...&#125; 编译器将会生成一个枚举类型和一系列该类型的常量。 .proto 文件编译代码 通过定义好的 .proto 文件生成 Go、PHP、Java、Python等代码，需要安装编译器 protoc。 使用 protobuf 编译器不同的语言生成的代码格式不同，比如Go：生成一个 .pb.go 文件，每个消息类型对应一个结构体。 具体protoc安装和代码生成可见：gRPC初体验 也有看到部分项目使用protobuf去替代json去进行前后端数据交换。 参考： Protobuf 语法 Protobuf语言指南 Protobuf生成Go代码指南","tags":["Protobuf"],"categories":["go"]},{"title":"golang的单引号双引号反引号","path":"/2021/04/29/335/","content":"单引号Single quote，表示byte类型或rune类型，对应 uint8和int32类型，默认是 rune 类型。byte用来强调数据是raw data，而不是数字；而rune用来表示Unicode的code point。 双引号Double quote，表示字符串，实际上是字符数组。可以用索引号访问某字节，也可以用len()函数来获取字符串所占的字节长度。 反引号Back quote，表示字符串字面量，与双引号不同，它不支持任何转义序列，但支持换行书写。字面量 raw literal string 的意思是，你定义时写的啥样，它就啥样，你有换行，它就换行。你写转义字符，它也就展示转义字符。 a := &#x27;a&#x27;b := &quot;b aa&quot;c := `c3ww`var d byte = &#x27;d&#x27;fmt.Println(b)fmt.Println(c)fmt.Printf(&quot;Single quote type:%T &quot;, a)fmt.Printf(&quot;Double quote type:%T &quot;, b)fmt.Printf(&quot;Back quote type:%T &quot;, c)fmt.Printf(&quot;Single quote type:%T &quot;, d)output:------baac 3wwSingle quote type:int32Double quote type:stringBack quote type:stringSingle quote type:uint8","tags":["go"],"categories":["go"]},{"title":"MAC安装rabbitmq扩展","path":"/2021/04/29/333/","content":"PHP结合rabbitMQ需要安装amqp扩展，之前又在windows安装，今天尝试mac安装一下。 下载 前去amqp，下载需要的版本。 安装 phpize// --with-php-config 路径自己修改./configure --with-php-config=xxx/php-configmake &amp;&amp; make install 如果没装rabbitmq-c，应该会报错。 configure: error: Please reinstall the librabbitmq distribution itself or (re)install librabbitmq development package if it available in your system 下载rabbitmq-c cd rabbitmq-c-0.8.0./configure --prefix=/usr/local/rabbitmq-cmake &amp;&amp; make install 重新编译amqp ./configure --with-php-config=xxx/php-config --with-amqp --with-librabbitmq-dir=/usr/local/rabbitmq-c/make &amp;&amp; make install make时提示缺少amqp_ssl_socket.hfatal error: ‘amqp_ssl_socket.h’ file not found#include &lt;amqp_ssl_socket.h&gt; 这里可以看一下 https://github.com/alanxz/rabbitmq-c/issues/463 然后可以把rabbitmq-c的librabbitmq下amqp_ssl_socket.h文件copy到amqp扩展目录，重新编译即可。 安装成功记得在ini加入extension=”amqp.so”，最后可以使用php -m","tags":["PHP"],"categories":["PHP"]},{"title":"Redis对象底层数据结构","path":"/2021/03/23/source/","content":"Redis对象底层数据结构 编码常量 编码所对应的底层数据结构 REDIS_ENCODING_INT long 类型的整数 REDIS_ENCODING_EMBSTR embstr 编码的简单动态字符串 REDIS_ENCODING_RAW 简单动态字符串 REDIS_ENCODING_HT 字典 REDIS_ENCODING_LINKEDLIST 双端链表 REDIS_ENCODING_ZIPLIST 压缩列表 REDIS_ENCODING_INTSET 整数集合 REDIS_ENCODING_SKIPLIST 跳跃表 Redis string类型转换 我们可能以为Redis在内部存储string都是用sds的数据结构实现的，其实在整个Redis的数据存储过程中为了提高性能，内部做了很多优化。整体选择顺序应该是： 整数，存储字符串长度小于21且能够转化为整数的字符串。 EmbeddedString，存储字符串长度小于39的字符串（REDIS_ENCODING_EMBSTR_SIZE_LIMIT）。 SDS，剩余情况使用sds进行存储。 embstr和sds的区别在于内存的申请和回收 embstr的创建只需分配一次内存，而raw为两次（一次为sds分配对象，另一次为RedisObject分配对象，embstr省去了第一次）。相对地，释放内存的次数也由两次变为一次。 embstr的RedisObject和sds放在一起，更好地利用缓存带来的优势 缺点：Redis并未提供任何修改embstr的方式，即embstr是只读的形式。对embstr的修改实际上是先转换为raw再进行修改。 Redis list数据结构 Redis list数据结构底层采用压缩列表ziplist或linkedlist两种数据结构进行存储，首先以ziplist进行存储，在不满足ziplist的存储要求后转换为linkedlist列表。 当列表对象同时满足以下两个条件时，列表对象使用ziplist进行存储，否则用linkedlist存储。 列表对象保存的所有字符串元素的长度小于64字节 列表对象保存的元素数量小于512个。 Redis hash底层存储结构Redis的哈希对象的底层存储可以使用ziplist（压缩列表）和hashtable。当hash对象可以同时满足一下两个条件时，哈希对象使用ziplist编码。 哈希对象保存的所有键值对的键和值的字符串长度都小于64字节 哈希对象保存的键值对数量小于512个 Redis的hash架构就是标准的hashtab的结构，通过挂链解决冲突问题。 Redis set底层存储Redis的集合对象set的底层存储结构特别神奇，底层使用了intset和hashtable两种数据结构存储的，intset我们可以理解为数组，hashtable就是普通的哈希表（key为set的值，value为null）。是不是觉得用hashtable存储set是一件很神奇的事情。 set的底层存储intset和hashtable是存在编码转换的，使用intset存储必须满足下面两个条件，否则使用hashtable，条件如下： 结合对象保存的所有元素都是整数值 集合对象保存的元素数量不超过512个 zset底层存储结构 zset底层的存储结构包括ziplist或skiplist，在同时满足以下两个条件的时候使用ziplist，其他时候使用skiplist，两个条件如下： 有序集合保存的元素数量小于128个 有序集合保存的所有元素的长度小于64字节 当ziplist作为zset的底层存储结构时候，每个集合元素使用两个紧挨在一起的压缩列表节点来保存，第一个节点保存元素的成员，第二个元素保存元素的分值。 当skiplist作为zset的底层存储结构的时候，使用skiplist按序保存元素及分值，使用dict来保存元素和分值的映射关系。 Redis string底层数据结构 Redis list底层数据结构 Redis hash底层数据结构 Redis set底层数据结构 Redis zset底层数据结构 Redis为何要定义字符串为SDSRedis是底层使用的是C语言，在C语言中没有字符串这种数据类型，字符串大都是通过字符数组实现的，但是使用字符数组有以下不足： 字符数组的长度都是固定，容易发生空指针异常 获取字符数组的长度的时候需要遍历数组，时间复杂度高 字符数组长度发生改变之后需要重新分配内存 使用\\0表示结尾，在存储二进制会出现问题。 //动态字符串，数组的长度是可变的。struct sdshdr &#123; unsigned int len;//记录当前串的长度。 unsigned int free;//记录剩余的有效长度。 char buf[];//真正的字符串位置。&#125;; Redis就自己实现了SDS来解决上面的问题，SDS相对C字符串数组的优点： 长度达到一定标准会有相应的扩容（小于1M，free增加len，大于1M，每次增加1M），从而解决内存溢出的问题。 在SDS的内部定义了字符串的长度，使用时可以直接获取，复杂度O(1)，解决获取长度时间复杂度高的问题。 SDS是空间预分配，惰性释放内存的，从而减少分配内存的次数 SDS根据长度判断结束的位置，从而解决二进制不安全的问题。","tags":["Redis"],"categories":["Redis"]},{"title":"goroutine","path":"/2021/03/19/323/","content":"From: 弄懂goroutine调度原理 线程实现模型 goroutine简介 golang语言作者Rob Pike说，“Goroutine是一个与其他goroutines 并发运行在同一地址空间的Go函数或方法。一个运行的程序由一个或更多个goroutine组成。它与线程、协程、进程等不同。它是一个goroutine“。 goroutine通过通道来通信，而协程通过让出和恢复操作来通信； goroutine 通过Golang 的调度器进行调度，而协程通过程序本身调度； 简单的说就是Golang自己实现了协程并叫做goruntine（本文称Go协程），且比协程更强大。 goroutine调度原理上面说到Go协程是通过Golang的调度器进行调度的，其中调度器的线程模型为两级线程模型。 有关两级线程模型的介绍，可以看文章最后。 我们来看下Golang实现的两级线程模型是怎样的。首先要知道这三个字母代表的含义 M：代表内核级的线程 P：全程Processor，代表运行Go协程所需要的资源（上下文环境） G：代表Go协程我们先看下为实现调度Golang定义了这些数据结构存M，P，G 名称 作用范围 描述 全局M列表 Go的运行时 存放所有M的单向链表 全局P列表 Go的运行时 存放所有P的数组 全局G列表 Go的运行时 存放所有G的切片 调度器的空闲M列表 调度器 存放空闲M的单向链表 调度器的空闲P列表 调度器 存放空闲P的单向链表 调度器的自由G列表 调度器 存放自由G的单向链表（有两个） 调度器的可运行G队列 调度器 存放可运行G的队列 P的自由G列表 本地P 存放当前P中自由G的单向链表 P的可运行G队列 本地P 存放当前P中可运行G的队列 然后从上往下解析Go的两级线程模型图 M和内核线程之间是一对一的关系，一个M在其生命周期中，只会和一个内核线程关联，所以不会出现对内核线程的频繁切换； Golang的运行时执行系统监控和垃圾回收等任务时候会导致创建M，M空闲时不会被销毁，而是放到一个调度器的空闲M列表中，等待与P关联，M默认数量为10000 P和M之间是多对多的关系，P和G之间是一对多的关系，他们的关联是易变的，由Golang的调度器完成调度； Golang的运行时按规则调度，让P和不同的M建立或断开关联，使得P中的G能够及时获得运行时机 P的数量默认为CPU总核心数，最大为256，当P没有可运行的G时候（P的可运行G队列为空），P会被放到调度器的空闲P列表中，等待M与它关联； P有可能会被销毁，如运行时用runtime.GOMAXPROCS把P的数量从32降到16时，剩余16个会被销毁，它们原来的G会先转到调度器可运行的G队列和自由G列表 每个P中有可运行的G队列（如图中最下面的那行G）和自由G列表（图中未画出来），当G的代码执行完后，该G不会被销毁，而是被放到P的自由G列表或调度器的自由G列表。如果程序新建了Go协程，调度器会在自由G列表中取一个G，然后把Go协程的函数赋值到G中（如果自由G列表为空，就创建一个G）； 可见Golang调度器在调度时很大程度复用了M，P，G 在Go程序初始化后，调度器首先进行一轮调度，此时用M去搜索可运行的G。其中我们的main函数也是一个G，找到可运行的G后就执行它； 至于怎么找可运行的G呢？答案是到处找，想尽办法找（这里只列出一部分地方）。 从本地P的可运行的G队列找 从调度器的可运行的G队列找 从其他P的可运行的G队列找 P的可运行G队列最大只能存放长度为256的G，当队列满后，调度器会把一半的G转到调度器的可运行G队列。 系统监控上面大概描述了关于goroutine调度的流程。现在还存在一个问题，那就是当Go协程很多（并发量大）时候，显然G是不能一直执行下去的，因为也需要把执行机会留给其他的G。此时Golang运行时的系统监控就起作用了。一般情况，当G运行时间超过10ms后，该G就会被系统告知需要停止了，让其他G运行。（这里情况比较复杂，并不能确保每个G都能被公平执行） 以下特殊情况该G不需要停止 P的可运行G队列为空（没有其他G可运行） 有空闲的M在寻找可运行的G（没有其他G可运行） 空闲的P（还有P闲着） 总结Golang以两级线程实现模型，自己实现goruntine和调度器，优势在于并行和非常低的资源使用。 主要体现 内存消耗方面（每个Go协程占的内存远小于线程占的内存） 切换(调度)开销方面 线程切换涉及模式切换(从用户态切换到内核态) 此外，Go协程执行任务完成的顺序并不都是按我们预期的那样（程序不加以控制的情况下），特别在一些耗时较长的任务中。且每个Go协程执行的时间也不是绝对公平的。 线程实现模型线程实现模型主要分为：用户级线程模型，内核级线程模型和两级线程模型。他们的区别在于线程与内核线程之间的对应关系。 以下我们将分析这三种线程实现模型的特点： 用户级线程模型 多对一关系用户级线程模型为多对一关系。即，一个进程中的所有线程对应一个内核线程； 处理速度快、移植性强；线程的创建、调度、同步等操作由应用程序来处理，不需要让CPU从用户态切换到内核态。所以用户级线程模型在速度快，且移植性强； 并非真正的并发运行如果线程IO操作过程中被阻塞，那么用户空间的其他线程都会被阻塞，因为这些线程无法被内核调度。 内核级线程模型（1）一对一关系内核级线程模型为一对一关系，一个用户线程对应一个内核线程；（2）资源消耗较大，速度较慢进程对线程的创建、终止、切换和同步都必须通过内核提供的系统调用来完成，对内核的调度的调度器造成很大的负担；（3）是真正的并发运行用户线程和内核线程是一对一的关系，线程由内核来管理和调度。当某一线程阻塞时候，不会影响到其他线程。 两级线程模型 多对多的关系两级线程模型是集前面两种模型的优点而设计的，是多对多的关系； 资源消耗较小，速度较快，是真正的并发运行两级线程模型中，一个进程对应多个内核线程，进程中的线程由程序管理和调度并通过映射关系映射到内核线程上。这样即便有线程阻塞后，也不会影响到其他线程； 实现的复杂度大用户线程与内核线程的映射关系需要程序来实现，实现的复杂度大。幸运的是，Golang为我们实现了两级线程模型，这使得它在处理并发问题上更有优势。","tags":["go"],"categories":["go"]},{"title":"Redis的过期策略以及内存淘汰机制","path":"/2021/03/14/volatile/","content":"Redis采用的是定期删除+惰性删除策略。 为什么不用定时删除策略? 定时删除,用一个定时器来负责监视key,过期则自动删除。虽然内存及时释放，但是十分消耗CPU资源。在大并发请求下，CPU要将时间应用在处理请求，而不是删除key，因此没有采用这一策略. 定期删除+惰性删除是如何工作的呢? 定期删除，Redis默认每个100ms检查，是否有过期的key，有过期key则删除。需要说明的是，Redis不是每个100ms将所有的key检查一次，而是随机抽取进行检查(如果每隔100ms,全部key进行检查，Redis岂不是卡死)。因此，如果只采用定期删除策略，会导致很多key到时间没有删除。 于是，惰性删除派上用场。也就是说在你获取某个key的时候，Redis会检查一下，这个key如果设置了过期时间那么是否过期了？如果过期了此时就会删除。 采用定期删除+惰性删除就没其他问题了么? 不是的，如果定期删除没删除key。然后你也没即时去请求key，也就是说惰性删除也没生效。这样，Redis的内存会越来越高。那么就应该采用内存淘汰机制。 在Redis.conf中有一行配置 maxmemory-policy volatile-lru 该配置就是配内存淘汰策略的 noeviction：当内存使用超过配置的时候会返回错误，不会驱逐任何键 allkeys-lru：加入键的时候，如果过限，首先通过LRU算法驱逐最久没有使用的键 volatile-lru：加入键的时候如果过限，首先从设置了过期时间的键集合中驱逐最久没有使用的键 allkeys-random：加入键的时候如果过限，从所有key随机删除 volatile-random：加入键的时候如果过限，从过期键的集合中随机驱逐 volatile-ttl：从配置了过期时间的键中驱逐马上就要过期的键 volatile-lfu：从所有配置了过期时间的键中驱逐使用频率最少的键 allkeys-lfu：从所有键中驱逐使用频率最少的键 一般的经验规则: 使用allkeys-lru策略：当预期请求符合一个幂次分布(二八法则等)，比如一部分的子集元素比其它其它元素被访问的更多时，可以选择这个策略。 使用allkeys-random：循环连续的访问所有的键时，或者预期请求分布平均（所有元素被访问的概率都差不多） 使用volatile-ttl：要采取这个策略，缓存对象的TTL值最好有差异 volatile-lru 和 volatile-random策略，当你想要使用单一的Redis实例来同时实现缓存淘汰和持久化一些经常使用的键集合时很有用。未设置过期时间的键进行持久化保存，设置了过期时间的键参与缓存淘汰。不过一般运行两个实例是解决这个问题的更好方法。 为键设置过期时间也是需要消耗内存的，所以使用allkeys-lru这种策略更加节省空间，因为这种策略下可以不为键设置过期时间。 LRURedis配置中和LRU有关的有三个： maxmemory: 配置Redis存储数据时指定限制的内存大小，比如100m。当缓存消耗的内存超过这个数值时, 将触发数据淘汰。该数据配置为0时，表示缓存的数据量没有限制, 即LRU功能不生效。64位的系统默认值为0，32位的系统默认内存限制为3GB maxmemory_policy: 触发数据淘汰后的淘汰策略 maxmemory_samples: 随机采样的精度，也就是随即取出key的数目。该数值配置越大, 越接近于真实的LRU算法，但是数值越大，相应消耗也变高，对性能有一定影响，样本值默认为5。 我们知道，LRU算法需要一个双向链表来记录数据的最近被访问顺序，但是出于节省内存的考虑，Redis的LRU算法并非完整的实现。Redis并不会选择最久未被访问的键进行回收，相反它会尝试运行一个近似LRU的算法，通过对少量键进行取样，然后回收其中的最久未被访问的键。通过调整每次回收时的采样数量maxmemory-samples，可以实现调整算法的精度。 根据Redis作者的说法，每个Redis Object可以挤出24 bits的空间，但24 bits是不够存储两个指针的，而存储一个低位时间戳是足够的，Redis Object以秒为单位存储了对象新建或者更新时的unix time，也就是LRU clock，24 bits数据要溢出的话需要194天，而缓存的数据更新非常频繁，已经足够了。 Redis的键空间是放在一个哈希表中的，要从所有的键中选出一个最久未被访问的键，需要另外一个数据结构存储这些源信息，这显然不划算。最初，Redis只是随机的选3个key，然后从中淘汰，后来算法改进到了N个key的策略，默认是5个。 Redis3.0之后又改善了算法的性能，会提供一个待淘汰候选key的pool，里面默认有16个key，按照空闲时间排好序。更新时从Redis键空间随机选择N个key，分别计算它们的空闲时间idle，key只会在pool不满或者空闲时间大于pool里最小的时，才会进入pool，然后从pool中选择空闲时间最大的key淘汰掉。 真实LRU算法与近似LRU的算法可以通过下面的图像对比： 浅灰色带是已经被淘汰的对象，灰色带是没有被淘汰的对象，绿色带是新添加的对象。可以看出，maxmemory-samples值为5时Redis 3.0效果比Redis 2.8要好。使用10个采样大小的Redis 3.0的近似LRU算法已经非常接近理论的性能了。 数据访问模式非常接近幂次分布时，也就是大部分的访问集中于部分键时，LRU近似算法会处理得很好。 Redis为什么不使用原生LRU算法？ 原生LRU算法需要 双向链表 来管理数据，需要额外内存 数据访问时涉及数据移动，有性能损耗 Redis现有数据结构需要改造 LFU在LFU算法中，可以为每个key维护一个计数器。每次key被访问的时候，计数器增大。计数器越大，可以约等于访问越频繁。 上述简单算法存在两个问题： 在LRU算法中可以维护一个双向链表，然后简单的把被访问的节点移至链表开头，但在LFU中是不可行的，节点要严格按照计数器进行排序，新增节点或者更新节点位置时，时间复杂度可能达到O(N)。 只是简单的增加计数器的方法并不完美。访问模式是会频繁变化的，一段时间内频繁访问的key一段时间之后可能会很少被访问到，只增加计数器并不能体现这种趋势。 第一个问题很好解决，可以借鉴LRU实现的经验，维护一个待淘汰key的pool。第二个问题的解决办法是，记录key最后一个被访问的时间，然后随着时间推移，降低计数器。 Redis对象的结构如下： typedef struct RedisObject &#123; unsigned type:4; unsigned encoding:4; unsigned lru:LRU_BITS; /* LRU time (relative to global lru_clock) or * LFU data (least significant 8 bits frequency * and most significant 16 bits access time). */ int refcount; void *ptr;&#125; robj; 在LRU算法中，24 bits的lru是用来记录LRU time的，在LFU中也可以使用这个字段，不过是分成16 bits与8 bits使用： 16 bits 8 bits+----------------+--------++ Last decr time | LOG_C |+----------------+--------+ 高16 bits用来记录最近一次计数器降低的时间ldt，单位是分钟，低8 bits记录计数器数值counter。 LFU配置Redis4.0之后为maxmemory_policy淘汰策略添加了两个LFU模式： volatile-lfu：对有过期时间的key采用LFU淘汰算法 allkeys-lfu：对全部key采用LFU淘汰算法 还有2个配置可以调整LFU算法： lfu-log-factor 10lfu-decay-time 1 lfu-log-factor可以调整计数器counter的增长速度，lfu-log-factor越大，counter增长的越慢。 lfu-decay-time是一个以分钟为单位的数值，可以调整counter的减少速度 参考： Redis中的LRU淘汰策略分析 Redis中的LFU算法 玩转Redis-8种数据淘汰策略及近似LRU、LFU原理","tags":["Redis"],"categories":["Redis"]},{"title":"k8s的安装（Mac）","path":"/2021/03/13/320/","content":"印象中之前mac装k8s挺麻烦，之前装的版本较低v1.14.7。最近总提示我更新，刚好更新一下，顺便记录下过程。 下载 下载安装[docker-desktop]https://www.docker.com/products/docker-desktop 修改Docker Engine配置，修改镜像源&#123; &quot;registry-mirrors&quot;: [ &quot;https://docker.mirrors.ustc.edu.cn&quot;, &quot;https://hub-mirror.c.163.com&quot;, &quot;http://f1361db2.m.daocloud.io&quot; ], &quot;experimental&quot;: false, &quot;features&quot;: &#123; &quot;buildkit&quot;: true &#125;&#125; 安装k8s.gcr.io等组件git clone https://github.com/AliyunContainerService/k8s-for-docker-desktop.git//切换到你的k8s版本，我的是v1.19.7git checkout v1.19.7 执行 ./load_images.sh 安装k8s依赖。4. Enable Kubernetes，重启，Kubernetes启动比Docker慢多了，稍微等一会就好。 安装kubernetes/dashboard项目地址：https://github.com/kubernetes/dashboard kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.2.0/aio/deploy/recommended.yaml 如果执行超时，可以把yaml文件下载到本地运行。 kubectl get pod --namespace=kubernetes-dashboardoutput:NAME READY STATUS RESTARTS AGEdashboard-metrics-scraper-79c5968bdc-xvrzd 1/1 Running 0 4m13skubernetes-dashboard-9f9799597-9kmbk 1/1 Running 0 4m13s 可以看到成功安装ubernetes-dashboard。 启动kubectl proxy 登录打开浏览器：http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/#/login 选择Token登录，用下方命令获取token，登录成功，可以看到界面。 获取tokenkubectl -n kube-system describe $(kubectl -n kube-system get secret -n kube-system -o name | grep namespace) | grep token","tags":["k8s"],"categories":["devops"]},{"title":"Redis基础类型、常用知识","path":"/2021/03/08/base/","content":"主要类型 字符串（strings，bitmaps） 散列（hashes） 列表（lists） 集合（sets） 有序集合（sorted sets） hyperloglogs 发布订阅（pub/sub） 地理空间（geospatial） Stream（5.0版本新增） 关于命令我推荐看这两个： http://doc.Redisfans.com/ http://www.Redis.cn/commands.html 应用场景strings 缓存 分布式锁（setnx） 签到统计（setbit） 计数（incr） hashes 缓存 用户标签 lists 队列 sets 交集并集 数据去重 zset 排行榜 延时任务 限流 hyperloglogs uv统计（ip统计） pub/sub 发布订阅（不是特别可靠） geospatial 附近的人 Stream 队列 发布订阅 其他利用事务实现秒杀以php代码为例： WATCH命令可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行。监控一直持续到EXEC命令（事务中的命令是在EXEC之后才执行的，所以在MULTI命令后可以修改WATCH监控的键值） // 库存为5//实例化Redis$Redis = new Redis();//连接$Redis-&gt;connect(&#x27;127.0.0.1&#x27;, 6379);$key = &#x27;sale&#x27;;$Redis-&gt;setnx($key, 0); // 此项不预定义亦可，保证key唯一就行$Redis-&gt;watch($key); //监视一个(或多个) key ，如果在事务执行之前这个(或这些) key 被其他命令所改动，那么事务将被打断。$sale_num = $Redis-&gt;get($key);if ($sale_num &gt; 4) &#123;\texit();&#125;$Redis-&gt;multi(); //标记事务$Redis-&gt;incr($key); //销量+1sleep(1); //模拟真实环境$ret = $Redis-&gt;exec(); // 事务块内所有命令的返回值，按命令执行的先后顺序排列。if ($ret) &#123; // 自定义的一个基于medoo的dbclass\tinclude &#x27;db.php&#x27;;\t$db = new db([ &#x27;database_type&#x27; =&gt; &#x27;mysql&#x27;, &#x27;database_name&#x27; =&gt; &#x27;test&#x27;, &#x27;server&#x27; =&gt; &#x27;puresai&#x27;, &#x27;username&#x27; =&gt; &#x27;puresai&#x27;, &#x27;password&#x27; =&gt; &#x27;*&#x27;, &#x27;charset&#x27; =&gt; &#x27;utf8&#x27;\t]);\t$db-&gt;update(&#x27;goods&#x27;, [&quot;stock_num[-]&quot; =&gt; 1], [&#x27;id&#x27; =&gt; 1]);&#125; 布隆过滤器 布隆过滤器（Bloom Filter）是1970年由布隆提出的。它实际上是一个很长的二进制向量和一系列随机映射函数。布隆过滤器可以用于检索一个元素是否在一个集合中。 php实现推荐看看这篇文章： https://github.oscome.cn/2019/05/21/188/ 当然，Redis自己也有第三方模块： https://github.com/RedisBloom/RedisBloom git clone https://github.com/RedisBloom/RedisBloom.gitcd Redisbloommake/path/to/Redis-server --loadmodule ./Redisbloom.so Bloom：向过滤器添加新项,如果尚不存在，则会为您创建一个新的过滤器 127.0.0.1:6379&gt; BF.ADD newFilter foo(integer) 1 Bloom：检查过滤器中是否存在项 127.0.0.1:6379&gt; BF.EXISTS newFilter foo(integer) 1127.0.0.1:6379&gt; BF.EXISTS newFilter notpresent(integer) 0 限流Redis-cell// 提前安装rust哟git clone https://github.com/brandur/Redis-cell.gitcd Redis-cellcargo build --releasecp target/release/libRedis_cell.dylib /path/to/modules/Redis-server --loadmodule /path/to/modules/libRedis_cell.so 该模块只有1条指令cl.throttle，它的参数和返回值都略显复杂，接下来让我们来看看这个指令具体该如何使用。 &gt; cl.throttle limitThrot 15 30 60 1 ▲ ▲ ▲ ▲ ▲ | | | | └───── need 1 quota (可选参数，默认值也是1) | | └──┴─────── 30 operations / 60 seconds 这是漏水速率 | └───────────── 15 capacity 这是漏斗容量&gt; └─────────────────── key 上面这个指令的意思是允许频率为每 60s 最多 30 次(漏水速率)，漏斗的初始容量为 15，也就是说一开始可以取 15 个，然后才开始受漏水速率的影响。我们看到这个指令中漏水速率变成了 2 个参数，替代了之前的单个浮点数。用两个参数相除的结果来表达漏水速率相对单个浮点数要更加直观一些。 &gt; cl.throttle limitThrot 15 30 60 11) (integer) 0 # 0 表示允许，1表示拒绝2) (integer) 15 # 漏斗容量capacity3) (integer) 14 # 漏斗剩余空间left_quota4) (integer) -1 # 如果拒绝了，需要多长时间后再试(漏斗有空间了，单位秒)5) (integer) 2 # 多长时间后，漏斗完全空出来(left_quota==capacity，单位秒)","tags":["Redis"],"categories":["Redis"]},{"title":"Redis使用单线程为什么这么快","path":"/2021/02/28/quick/","content":"Redis6.0引入了多线程。实际上多线程只是用来处理网络数据的读写和协议解析，执行命令仍然是单一工作线程。 Redis 采用的是基于内存的采用的是单进程单线程模型的 KV 数据库，由 C 语言编写。官方提供的数据是可以达到100k+的qps。这个数据不比采用单进程多线程的同样基于内存的 KV 数据库 Memcached 差。 Redis 快的主要原因有： 完全基于内存 数据结构简单，对数据操作也简单 使用多路 I/O 复用模型,非阻塞IO 采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗 使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis直接自己构建了VM机制，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求 多路 I/O 复用模型多路 I/O 复用模型是利用 select、poll、epoll 可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有 I/O 事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll 是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络 IO 的时间消耗），且 Redis 在内存中操作数据的速度非常快（内存内的操作不会成为这里的性能瓶颈），主要以上两点造就了 Redis 具有很高的吞吐量。 和 Memcached 不同，Redis 并没有直接使用 Libevent，而是自己完成了一个非常轻量级的对 select、epoll、evport、kqueue 这些通用的接口的实现。在不同的系统调用选用适合的接口，linux 下默认是 epoll。因为 Libevent 比较重，更通用，代码量也就很庞大，拥有很多 Redis 用不上的功能，Redis 为了追求“轻巧”并且去除依赖，就选择自己去封装了一套。 单进程单线程好处 代码更清晰，处理逻辑更简单 不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗 不存在多进程或者多线程导致的切换而消耗 CPU","tags":["Redis"],"categories":["Redis"]},{"title":"go的GC机制","path":"/2021/02/27/319/","content":"Golang的标记清除如下图所示，通过gcmarkBits位图标记span的块是否被引用。对应内存分配中的bitmap区。 三色标记 白色：对象未被标记，gcmarkBits对应的位为0（该对象将会在本次GC中被清理） 灰色：对象已被标记，但这个对象包含的子对象未标记 黑色：对象已被标记，且这个对象包含的子对象也已标记，gcmarkBits对应的位为1（该对象不会在本次GC中被清理） 例如，当前内存中有A~F一共6个对象，根对象a,b本身为栈上分配的局部变量，根对象a、b分别引用了对象A、B, 而B对象又引用了对象D，则GC开始前各对象的状态如下图所示: 初始状态下所有对象都是白色的。 接着开始扫描根对象a、b; 由于根对象引用了对象A、B,那么A、B变为灰色对象，接下来就开始分析灰色对象，分析A时，A没有引用其他对象很快就转入黑色，B引用了D，则B转入黑色的同时还需要将D转为灰色，进行接下来的分析。 灰色对象只有D，由于D没有引用其他对象，所以D转入黑色。标记过程结束 最终，黑色的对象会被保留下来，白色对象会被回收掉。 GC的触发 阈值：默认内存扩大一倍，启动gc 定期：默认2min触发一次gc，src/runtime/proc.go:forcegcperiod 手动：runtime.gc() STWstop the world是gc的最大性能问题，对于gc而言，需要停止所有的内存变化，即停止所有的goroutine，等待gc结束之后才恢复。 标记-清除(mark and sweep)算法的STW(stop the world)操作，就是runtime把所有的线程全部冻结掉，所有的线程全部冻结意味着用户逻辑是暂停的。这样所有的对象都不会被修改了，这时候去扫描是绝对安全的。 Go如何减短这个过程呢？标记-清除(mark and sweep)算法包含两部分逻辑：标记和清除。 我们知道Golang三色标记法中最后只剩下的黑白两种对象，黑色对象是程序恢复后接着使用的对象，如果不碰触黑色对象，只清除白色的对象，肯定不会影响程序逻辑。所以： 清除操作和用户逻辑可以并发。 标记操作和用户逻辑也是并发的，用户逻辑会时常生成对象或者改变对象的引用，那么标记和用户逻辑如何并发呢？这里就让说到golang的写屏障了。 GC流程 Sweep Termination: 对未清扫的span进行清扫, 只有上一轮的GC的清扫工作完成才可以开始新一轮的GC Mark: 扫描所有根对象, 和根对象可以到达的所有对象, 标记它们不被回收 Mark Termination: 完成标记工作, 重新扫描部分根对象(要求STW) Sweep: 按标记结果清扫span 目前整个GC流程会进行两次STW(Stop The World), 第一次是Mark阶段的开始, 第二次是Mark Termination阶段. 第一次STW会准备根对象的扫描, 启动写屏障(Write Barrier)和辅助GC(mutator assist). 第二次STW会重新扫描部分根对象, 禁用写屏障(Write Barrier)和辅助GC(mutator assist). 需要注意的是, 不是所有根对象的扫描都需要STW, 例如扫描栈上的对象只需要停止拥有该栈的G.从go 1.9开始, 写屏障的实现使用了Hybrid Write Barrier, 大幅减少了第二次STW的时间. 写屏障因为go支持并行GC， GC的扫描和go代码可以同时运行，这样带来的问题是GC扫描的过程中go代码有可能改变了对象的依赖树。 例如开始扫描时发现根对象A和B，B拥有C的指针。 GC先扫描A，A放入黑色 B把C的指针交给A GC再扫描B，B放入黑色 C在白色，会回收；但是A其实引用了C。 为了避免这个问题, go在GC的标记阶段会启用写屏障(Write Barrier). 启用了写屏障(Write Barrier)后， GC先扫描A，A放入黑色 B把C的指针交给A 由于A在黑色，所以C放入灰色 C没有子对象，放入黑色 扫描B，B没有子对象，放入黑色 即使A可能会在稍后丢掉C, 那么C就在下一轮回收。 开启写屏障之后，当指针发生改变, GC会认为在这一轮的扫描中这个指针是存活的, 所以放入灰色。 其他常见gc机制 引用计数 复制收集 分代收集 GC 的触发时机的两种形式 主动触发，通过调用 runtime.GC 来触发 GC，此调用阻塞式地等待当前 GC 运行完毕。 被动触发，分为两种方式： 使用系统监控，当超过两分钟没有产生任何 GC 时，强制触发 GC。 使用步调（Pacing）算法，其核心思想是控制内存增长的比例。 参考： Golang GC(垃圾回收机制) [11. 触发 GC 的时机是什么？](https://www.bookstack.cn/read/qcrao-Go-Questions/spilt.11.GC-GC.md#11. 触发 GC 的时机是什么？)","tags":["go"],"categories":["go"]},{"title":"成为会带团队的技术人","path":"/2021/02/14/318/","content":"本文是拉勾专栏《成为会带团队的技术人》的笔记，图基本也来源于专栏，自己以前也有带团队经验，但自我感觉做得不够好，这个专栏给我很多启发。 技术人三要素 技术人三要素：稳定性、债务、架构 稳定性怎么衡量系统稳定性？一般来讲，通过统计系统不可用的时长或次数就可以对稳定性进行量化，比如业内常说 4 个 9 的可用性（即 1 年内 99.99% 的时间系统是可用的，不可用时长仅为 52.6 分钟）。 针对稳定性的提高也可以看作围绕事故的治理，可以从事故发生的前、中、后分阶段来看对应的关键点。 事故的类型：可用性事故、资损类事故。 事故前预防：主动治理减少系统的风险隐患，重点在变更管控、可用性设计、应急预案与演练。 事故中应急：“止血、恢复”。 事故后复盘：目的不是追责，不是甩锅，而是查根因、改进架构、完善应急、总结经验。 事故的类型从事故特性上看，我们可以分为可用性事故和资损类事故。 可用性事故：技术原因导致系统部分或者全部功能不可用，业务没办法正常完成对应流程或者提供对应服务。比如因为网络、接口 Bug 等原因，用户没办法登录、商品列表不显示等。 资损类事故：系统的功能都能正常使用，但因为逻辑、计算等原因让业务的某一方产生了资金损失。比如某电商部门错发无门槛优惠券、某公司商户清结算少打款给商户等等。 故障处理的生命周期 故障处理的生命周期，可以分为 4 个阶段：发现异常、排查问题、判断决策、恢复处理。这 4 个阶段对应的行动并不是完全串行的，虽然有一定的依赖关系，但在实际的处理过程中应该并行展开。类似 fork/join 的模式，不断完成小任务、不断汇总信息，不断做出判断与决策，形成循环直到故障恢复。 故障发现 总的来说，人工的被动反馈在时间和速度上有较强的不确定性，很容易出现“小故障 * 长时间 = 大事故”的情形。而纯粹的技术指标监控又会忽略掉接口正常响应，但是业务异常的场景，只有两者结合，通过监控告警，最大程度上缩短故障感知的时间，才能早发现早解决，减少业务影响。 故障排查 直接锁定：最近的代码更新与异常现象间有直接的逻辑关联，进而可以直接锁定到故障点。比如，刚对下单接口进行了发布变更，客户反馈大量失败，可以基本断定是刚才的发布导致。 排除法：当干扰因素过多（用户、订单等几个系统同时发生变更，引起订单异常），很难直接锁定到故障点，就要结合业务场景，在整条下单链路上及关联代码进行自查自证，通过排除法锁定故障。 故障决策 业务决策非常复杂，能否第一时间止损很大程度上取决于技术 Leader 的现场反应和操作， 要注意故障决策的两个关键点 ： 一定要有明确的决策人、主导者和有效的沟通方式（钉钉群、多人电话会议等），让信息可以通畅地交流出来，并且决策人可以根据情况做判断与取舍，形成所有人明确的处理结论，最好还能落成文档，可追溯。 比如，第一时间停止错误红包的发放，确保故障没有增量，并把决策第一时间同步给团队成员，并同步相关负责人后续的动作，对已发放的红包，明确要求负责人汇总各类关键信息（红包数量、涉及金额、涉及用户数、有效时长、可能资损等）。 所有的信息一定要数据化，不同的数据量级会导致决策不同，比如红包错发 5W 可能只是暂停发放，但是存量红包依然可以核销，损失公司可以承担。但是如果错发 5000W，大概就要涉及一系列的调整，这是非常影响决策的。 故障恢复 应急“三板斧”：回滚、重启大法、降级限流。 如何有价值地做事后复盘？你可以从时长、现象、处理时间轴、根因、改进计划这几个维度进行复盘， 在以下几个方面进行深究： 事故时长：1-5-10(即 1 分钟发现、5 分钟响应、10 分钟恢复) 是否达成，如果没有是为什么？哪个环节用时最多，如何提高和改善？ 事故根因：根因不等于直接原因，一个事故的直接原因往往并不复杂，但是根因可能是多个维度的缺失，需要像剥洋葱一样一层层找下去。拿库存接口变更这个Case来说，直接原因就是某段代码逻辑变更导致，但是应该在测试、发布、监控、应急影响、预案设计等多个环节展开去看，根因的挖掘并不忌讳“吹毛求疵”。 事故改进措施：由点推到面、明确到人、明确时间。与根因类似，要结合多个维度形成组合拳的改进点，避免一次性动作，要将重点放在对未来、对同类问题的预防上。核心就是如果再一次发生类似的问题，这些改进措施是不是能起到作用。 关于事后复盘，我们就是要深挖事故如何发生的、如何处理的、未来怎么预防。但要避免情绪化，在复盘会上的反思、感悟、懊恼没有任何意义，如何带领团队把精力放在改进措施的落实以及事故前的治理上更有价值。另外，你需要留出时间让团队伙伴进行内部 Review，避免为了开会而复盘。 没有质量的交付，再多再快都毫无意义。 变更会引起90%以上的故障 变更需要监控 有效的监控要回答三个问题： 是否有问题发生？ 哪里发生了问题？ 发生了什么问题？ 有效灰度必须有耐心 灰度从来不是为了测试，也不等于 A/B Test。它本身是为了对抗“未知的不确定性”。 要想实现灰度的有效性，关键点在于时间和流量。 时间：每个灰度阶段至少有 5 ~ 10 min 的观察，在监控、日志和各方反馈没有异常后再扩大灰度范围，确保一些运行时异常或量变积累质变的问题可以暴露出来。 流量：有时一些业务场景需要特定的触发条件，比如满足某些条件的用户或满足某些条件的订单，那么在灰度时就不能仅通过单位时间内有没有异常来判断，还要确保有足够的有效流量。 回滚就是变更的“后悔药” 要知道，系统并不是天然可以无缝回滚的，想要系统具备回滚的能力，在设计与实现阶段需要付出额外的精力。可回滚的本质是系统的兼容性设计与实现，比如常见的“只增不改”，一个 API 内要调整很多实现逻辑才能满足新业务的需求，此时不妨直接新增一个 API ，两个 API 保持参数一致，那么一旦新 API 有异常直接切换回旧的 API 即可。 所以，不论是灰度计划还是回滚策略都应该在架构设计阶段就去考虑，结合排期、风险程度、成本投入这些方面，要做好评估与平衡。 坚守 Design For Failure 的架构理念“Design for failure and nothing will fail”，最早是 AWS 的一条最佳实践，即面向失败进行系统设计。可以理解为：考虑系统所有可能发生故障或不可用的情形，并假设这些可能都会发生，倒逼自己设计足够健壮的系统。 将经验教训沉淀下来 历史是最好的老师，我建议你总结并分析过去发生过的事故，并结合常规分布式系统的可用性风险，以此梳理出一个围绕事故隐患的风险点 Checklist，在需求迭代或者架构设计时，通过它高效地找到系统实现的薄弱环节。 除了完善 Checklist，在团队普及这种设计理念之外，更关键的是将这些解决方案沉淀成设计原则，让研发人员可以在实际中落地。 通过演练验证预案设计 设计并实现了自己的故障演练系统，日常主动制造事故上下文来验证我们的设计与系统是否可靠。 把稳定性当作机制与文化去建设系统稳定性结果好坏很大程度上取决于技术 Leader 的重视程度，如果一个团队的管理者都不能身体力行的去重视它，而仅仅只是喊喊口号，那就不要指望团队成员能认真地对待这件事。 新人 Landing 从稳定性学习开始 每人不低于 35% 的稳定性 KPI 好的坏的都要在阳光之下晒一晒 建立资损概念的宏观认知从广义上来看，存在理论损失也应该算资损， 比如因为搜索推荐系统出问题（不论什么原因）导致这一阶段广告的收入减少，或者因系统 Bug 导致用户取消订单的申请被默认同意（虽然原本商户可能也会做同意处理，但是申诉的话平台依然要赔付），类似预计收益减少或者因系统问题产生赔付的场景都应算为资损。 资损防控的三个关键 防：资金视角做风险点识别 监：一致性与正确性双核对 针对资损感知的核心思想是：基于线上业务结果收拢进行监控，基于线下业务场景扩散进行核对。 与可用性监控围绕接口的技术指标不同，资损更关注的是数据核对，监控的并不是运行状态而是运行结果，并且资损监控的粒度要求非常高，精细到每一笔交易、每一次金额计算、每一个红包发放。所以资损监控的有效性很依赖于场景的覆盖率，仅覆盖几个关键场景是不足以规避资损风险的，除了要定期梳理外，每次系统有变更或者新功能时，都需检查是否有新的核对点，以及旧有核对公式是否需要调整。 控：资金拦截 + 资产控制 除了防和监，资损防控的关键主要在“控”字上，我们希望在问题发生后第一时间止损，这就需要技术在系统层面对资金和资产有很强的控制能力。这种能力的表现就是： 不仅可以通过预案将某些场景与链路降级，还可以拦截资金的流出和资产的使用，同时具备快速订正错误数据的能力。 在我们开始处理资损事故时，会有三个共性的需求。 问题止血不新增：核心是关闭问题产生源头，往往通过业务场景降级来实现，比如对错误红包或者满减活动进行下线。 控制资金流出：核心是对资金和资产进行拦截与冻结，避免外流后损失无法修正，比如禁止用户下单时勾选使用有问题的红包。 存量数据订正：核心是捞取问题数据后可以快速地批量处理，比如批量更改红包的金额、甚至直接将红包无效。 虽然其中一些操作对用户体验是有损的，但有而不用是一回事儿，无能为力则是另外一回事儿，其中： 资金拦截的能力主要从资金的流入和流出这两端进行把控。以红包而言就是管控其创建与核销。在红包创建时，有预算系统进行管控，避免无限制地生成红包进而超发。在红包核销时，由交易和营销系统进行验证，确保订单上下文以及红包合法，避免问题红包被核销进而造成无法挽回的资损。 资产管控的能力则是资产的快速锁定和数据订正展开，以红包而言，如果不同模版不同活动的红包都有一个统一的批次号，就可以通过这个标记快速捞取某一批有问题的数据。同时如果提前准备批量订正的脚本，或者有订正数据的平台，就可以快速修改红包金额、使用时间、使用门槛等关键信息，甚至批量无效所有问题红包。 你需要注意，这些能力的实现更多依赖于技术 Leader 在日常需求迭代和架构设计时，是否有意识引导团队加强这方面的建设。大部分的预案思路来源于过去已经发生的问题，或者对未来可能发生问题的假设，将预案常态化是你重点关注并推进落地的。 除了建设预案，还要有预案演练，以此保证预案的有效性。技术 Leader 更应该鼓励测试和开发的同学主动做攻防演练，寻找漏洞、验证止损方案、及时发现并修复问题。 技术债务技术债务在研发领域类似于“金融债务”的概念，大部分情况下是说因为人为妥协，系统的设计和实现没有遵循最佳实践，所以虽然短期做到了快速交付，但也制约了系统未来的可扩展性，并且埋下了稳定性的风险隐患。 重视技术债务的原因 影响系统扩展和需求交付 恶性循环导致人员流失 技术债务的恶性循环会影响开发团队的生产力，并降低团队的士气和成员的驱动力，而低生产率导致团队只能优先交付功能，这就推迟了技术债务的解决，从而进一步增加技术债务。 如何从循环的债务困境中突围而出？1.债务的 Owner 是技术 Leader 要想解决技术债务，你需要找到技术与业务的平衡点，我的经验是“内外双修”： 内：加强团队的战斗力，减少债务产生的机会，增强债务处理的能力。 外：深刻地理解业务，并且做好与其他协作方（尤其是产品、业务）的沟通。这样你才能理解协作方想解决什么问题，他们以为要么A、要么B才能解决的问题，既懂技术又懂业务的你能否找到方案C？ 建议：面对选择题时不要只看到可选项，要永远寻找第三条路。如果实在没有其他选择，在技术妥协的同时，做好沟通，让协作方明白方案的临时性以及对未来的影响，争取到承诺在未来给你足够时间解决这些问题。 通过 CheckList 识别债务 建立一个债务 Review 的 CheckList ，并且不断完善。技术债务从表象上可以做一些细分： 通过现象我们就可以反推出一些导致现象的原因，将这些原因结合系统的架构进行分类，就会形成一个个具体的关注点。这些关注点往往是结合我们之前踩过的坑、发生过的问题，以及编码、架构上广为遵守的一些最佳实践所形成的，这样你就可以制定出一个较为详细的 CheckList 用以具体的债务识别（下图供参考）。 有计划地分级偿债 关键链路优先： 并非所有糟糕的设计与实现都能产生严重后果，即使能，它们发生的概率也不一样，而关键链路意味着业务影响最大，同时日常的改动频率和事故风险也较高，优先解决它的收益是最大的。 历史事故命中优先： 一些设计与实现在过往导致过线上真实问题的发生，不管是否发生在本系统还是当前团队，都相当于已经被证实过的这类债务的严重性，所以应该尽早修复它们，避免类似问题反复发生。 可扩展性优先： 在 CheckList 以及债务现象中我们可以发现，有些问题影响了系统未来的演进，增加了迭代成本，有些问题影响系统的维护，比如代码风格没有统一、缺少文档，在处理时应该优先处理影响可扩展性的问题，后续逐步处理影响可维护性的问题。 权责清晰优先： 一些问题在处理时受到历史架构、组织分工（康威定律）的影响，会导致系统的权责不清晰，这类系统的推进和改造往往需要花费更多的时间精力，并且从顶层设计出发去重新考量，所以权责清晰的部分可以优先处理。 总的来说，通过对技术债务进行分级，实质上也是一个问题分治的过程，将大问题切分成一个个小问题，这样就可以将它们加入日常的迭代中，形成一个分期偿还技术债务的计划，逐步减少技术债务，减轻负担让团队与系统可以轻装上阵。 正视债务做好预防 除此之外，预防永远胜于治疗，技术债务汇总预防的关键点在于那些“原本未知”的技术债务要逐渐减少，大家对于实现质量的追求不能止步于“测试没有明显 Bug”，写出能运行的代码是不够的，还要易维护易扩展。 可以从几个方面着手： 提升团队认识，通过项目复盘、系统重构、事故 Review 等各种机会，通过实际的案例让研发同学清楚技术债务对团队产生的负担，以及对个人能力提升的影响。 建立机制流程，比如在方案设计阶段向下深挖一下实现的要点，更多资深的开发参与到架构评审，或者促进团队形成 code review 的习惯并且达成一个共识标准以提升系统质量。 确保资源投入，在通过债务识别和分级后，将还债的投入提前计算到每次迭代中，确保有一定的资源投入其中。 一些常见的误区 通过 CheckList 做债务识别，然后定期诊断、水平扫描、债务定级、分期偿还来做技术债务的处理，最终在团队认识、机制氛围、资源保障上下功夫做预防，这就是技术债务管理的核心思路。 而这个过程中，有一些问题是日常你很容易走入误区的，我简单总结了一下几个注意点： 存在即合理，动态变化才是王道。 不要总想着毕其功于一役，也几乎不太可能有完美的实现或系统，接受技术债务一定会存在的事实，重点在于控制债务积压的程度，欠债本身不可怕，欠债不知且不还才可怕。 不积跬步无以至千里。我们往往过度轻视日常积累，又过度重视“大事件”产生的影响。日常这里凑合一下，那里妥协一点，没人关注小问题发生的原因。而一旦发生重大的影响，则恨不得把之前的系统全盘推翻重做一遍。 机制流程外还要讲策略和方法。很多技术 Leader 觉得这件事很重要，讲的同时设计了很多流程和机制，不遵守就要承担怎样怎样的后果，这样往往事半功倍。机制流程不是越多越好，也不能光有惩罚而没有激励，同时最重要的是你不能只追杀要结果，要给帮助、给方法、给支持。 大项目：把握关键点，谋定而后动认清异同，做到心中有数 在这个常规流程中，技术团队的重心是把执行做到位，你要更关注过程管控，确保系统交付。 大项目与常规项目的核心差异点，我认为主要在于这个“大”字上，你可以从三个方面去理解。 出发点不同，业务期望更大 规模不同，复杂度更高 结果评判标准不同，影响更大 把握关键点，谋定而后动 关注效果更重于关注交付，这是大项目的核心特征。 不要为了重构而重构，要知道你要的结果是什么。 大项目的失败存在一个共性的问题：围绕业务结果的思考、计划不足，目标的定义不清晰或没有充分同步给所有相关人，项目同学知其然而不知其所以然。连目标都没有共识，何谈执行到位，项目成功？ 所以我认为越是重大的项目，在计划、设计、准备上投入的精力就应该越多，谋定而后动。 WHY（项目为什么做） WHAT（项目做成什么样） WHO（哪些人来一起做项目） HOW（启动项目后如何做） 合理拆分任务（模块）是项目成功的一半 保持风险意识，敬畏墨菲定律 做好充分的准备之后，可以召开立项会，将 WHY、WHAT、WHO、HOW 的信息与思考同步给项目相关人员。通过 Kick Off 会议确定项目的基调、同步必要信息，为项目推进扫清障碍。 如何处理棘手问题问题一：缺兵少将怎么办？项目组人时你要注意以下几点。 当项目开始时，从更大的范围内寻找合适的同学，而不是看你团队有哪些人。 将参与项目的同学在一定时间内的汇报关系和绩效考核汇总到项目组中，由项目负责人根据实际情况重新安排每个人的权责，并确定绩效的绑定关系与比例。 项目交付并不等于结束，所有人的绩效结果都应和项目目标的达成情况紧密且长期关联。 最后，有时不仅要解决“缺兵”的问题，还要认真考虑是否“少将”？要充分考虑当前的人员是否适合做项目的 Owner，以我的经验来看，项目 Owner 几乎决定了项目成败的 80%，如果 Owner 能力不足，你要给予帮助和支持，或者另找他人，乃至上级的帮助，不要在 Owner 的人选上妥协，毕竟项目成败才是关键。 问题二：推不动的到底是人还是事？ 搞明白冲突现象下的利益诉求： 不同关联方产生观点冲突的现象背后其实是利益冲突，你要搞清楚彼此的顾虑。比如我不愿想让某个系统字段落到订单中，主要是考虑到订单系统的可维护以及稳定性，如果你能解决我的顾虑，会容易说服我。 为项目结果适当妥协： 在很多情况下，我们无法做出完美的方案，可能就是要在系统内通过很糟糕的实现去实现需求。项目没有 100% 完美，抓住核心原则不放弃，可控部分适当妥协换取项目前进是很好的策略。 通过项目地位和决策机制推动项目： 大项目往往是公司重大战略下的产物，一般情况下，不会有人去反对公司的某项既定战略，而你可以通过大项目的重要性在体系内争取更多的资源和帮助。如果你面临一些冲突，要学会利用决策机制，通过更高级别成员的沟通决策拿到解决方案。 问题三：一定会有项目变更吗？常见的变化往往有两种： 项目演进过程中识别出之前未能识别或考虑缺失的点，导致方案需要调整。 出自老板的需求变更，很多情况下都是要新增内容。 3个重点 驾驭大项目是你的试金石和分水岭，对自己职业规划有一定要求的同学一定不要放过打磨修炼的机会。 在大项目中，往往人的问题会比技术与系统的问题难解决，因为与人相关的问题未必完全理性和逻辑，那么此时你也不妨看看感性的沟通与交流是不是有更好的效果。 时刻牢记你将项目按时上线没有故障只是做到了60分，更关键的是业务效果，所以除了盯紧开发过程外，还要在最开始的业务与产品设计阶段就投身其中。 业务理解：深入业务是做好架构的前提为什么技术要理解业务？产品需求不等于业务诉求同样的，技术 Leader 可能会花时间参加各种会议，尤其是产品需求的会，在会上如果仅仅是听“自己团队应该做什么”，而没有思考和探究业务的根本诉求，那么就我的经验来说，技术团队不可避免的会成为工具人。Leader 缺乏独立思考，人云亦云，最后整个团队都会被拖累，这也是为什么大多数研发团队被产品以及业务按在地上摩擦的原因！ 领域建模的前提是理解业务正因为没有仔细看业务的现状、推测业务的发展、去思考业务上对交易的诉求，我们认识的只是一个个需求，而非整体的从业务维度思考系统的设计，导致系统复杂度越来越高。所以要想设计可靠、简单、真正可持续迭代的系统，深度理解业务就是前提，你对业务的理解程度影响了你对系统未来发展的预判程度。 提升技术团队的使命感你写的每一行代码，线上的每一次发布，都会改变用户的体验，解决实际的问题，你就会发现这份工作的意义。 如何理解业务？ 不要盲信产品（不要盲信产品与 PRD，在讨论 PRD 和执行开发任务之前学会独立思考，深入理解业务想要解决什么问题，需要什么效果或作用，严格把控那些伪需求和无价值需求，防止它们侵占团队的技术资源。） 建立走进业务的机制 业务上多参会多画图（参加评审会，梳理流程图等等） 架构设计：治理好系统复杂度才最务实治理好系统复杂度才最务实C.A.R. Hoare曾说过：“软件设计有两种风格，一种是将软件设计得很复杂，以使其缺陷没那么明显；一种是把软件设计得很简单，以使其没有明显的缺陷”。 系统的结构清晰、即使整体繁杂但是每个局部都相对简单、链路干脆直接，没有不必要的冗余。 衡量复杂度 理解成本高：需要很长时间才能理解系统模块的组成及运作，比如新同学加入或系统交接时，老同学很难讲完整、新同学不容易听明白，要几周甚至1~2个月才能完全了解系统的实现和运作机理。 变更牵连多：哪怕是实现一个小的需求都要改造系统的多个部分、甚至多个系统（上下游等），有的还需要协调其他团队或部门，结果导致迭代成本高，并可能引入更高的风险。 一张图装不下：即你无法在一块白板上清晰且完整地画出系统主要功能场景的架构图，可能是牵连的系统、服务、组件过多或者链路设计不合理导致的。 加人无法解决问题：即便你增加人员也难提高系统的交付速度和产出质量，比如原本3个人负责系统，增加到 6 个人的交付产出可能和 3 个人时所差无几，原因在于复杂度过高并且系统结构模糊，很难通过清晰的分工让生产力最大化。 而你可以结合这 4 点表现特征以及自己的主观感受进一步判断系统的复杂度是否过高，如果系统复杂度过高，可能带来一系列问题：迭代压力大、经常延期、稳定性问题频发等。这时，你要着手治理复杂度，尽力不让问题扩大到难以解决只能重做系统的程度。 复杂度治理的思路“高内聚、低耦合”，系统简化和分治。 简化就是去掉不必要的复杂，让设计与实现保持简单。 分治则是将原本难解决的问题，拆分到可解决的粒度，然后再逐一击破。 常见的拆分方式是垂直拆分和水平分层： 垂直拆分把差异明确可以独立迭代的业务拆分开；水平分层把共性的能力下沉隔离。比如电商场景中，购物车和订单可以分成两个服务，它们虽然在业务流程上前后关联，但是各自具备独立完整的业务场景和生命周期，商品加入购物车未必会交易生成订单，可以各自独立存在；而库存和商品则是强依赖的关系，库存无法独立于商品存在。 拆分与合并不绝对，过度地拆分会导致系统无法高内聚，零散分离的系统，会增加稳定性风险和治理与迭代的代价，并且造成大量的协作成本。Linus也曾说过：把复杂系统拆分成模块，似乎没有降低整个系统的复杂度，它降低的只是子系统的复杂度。而整个系统的复杂度，反而会由于拆分后的模块之间，不得不进行交互，变得更加复杂。 复杂度治理实践 相比 coding 更重视设计 永远做 2 套以上的方案 从 MVP 的视角考虑设计：从 MVP （最小完整业务的角度）去考虑系统要如何设计与实现，先做减法再做加法 关注上下游的实现 坚持“日拱一卒 没必要一定把系统做成中台没必要一定把系统做成中台，不做中台就会落后更是无稽之谈，不过，你可以借鉴中台的思路作为系统设计与演进上的形态参考。 管理三板斧：拿结果、建团队、招聘与解聘 定目标：让你的方向与公司的方向保持一致怎么解读目标？解读目标就是要确保自己做的事儿和公司的方向一致，顺势而为，没有走偏（这里的“势”就是公司的战略和目标），正因为有了目标才有根据目标制定的 KPI，才会有围绕目标的执行动作和最终取得的结果。 目标不是一句口号，它是一个个层层拆解、递进的过程。说白了，解读目标是把公司的方向变成你的方向，把上一层的问题转变成你可以改变的问题。 确保目标解读正确有很多技巧和方法。根据目标逐层分解的特性，可以考虑四个方面。 你的主管，确定你老板的目标是什么； 你自身所在的团队、团队的成员们，根据团队情况确定现状； 与你紧密合作的上下游（研发），比如你是做订单系统的，那么支持属性很重，商户、导购、用户很多研发团队都是你的上下游关联方； 直接对口的业务与产品，这是业务目标拆解、业务痛点、客户诉求的直接来源方。 怎么制定目标？结合 4 个关键点来考虑： “短长”结合：事情分轻重缓急，你一直盯着“急”和“重”，“轻”和“缓”的事情就会转变成“重”和“急”，进入死循环。 要足够聚焦：建议关键目标不要超过 3 个，最多控制在 5 个以内，要找最有客户价值、对公司战略最有帮助的点，目标越少、方向越清晰，当问题发生或者需要判断时越容易做决策，在有限的时间内做出更好的结果。 要有足够的挑战：系统可用性假如去年是 3 个 9，今年考虑业务会发展保守起见还是力保 3 个 9，这样的目标挑战性就不足，也无法体现技术的价值。这个度量是很考验你的。 要让组织有沉淀、个人有成长：通过一个个目标的完成，让参与的同学得到个人能力的提升，未来可以承担更大的职责，组织也在这个过程做能力的积累与沉淀。 结合以上四点，围绕目标和团队一起讨论策略与打法，将目标拆解成几个关键任务，明确到责任人，总结一下就是：定策略、拆任务、细到人。 怎么传递目标？大部分情况下，你会发现信息不对等、传递过程中的损失、个人理解的差异，直接导致不是所有人都清楚“我们要往哪去”。 最后，目标的传递是一个连贯的动作，要落到日常的管理动作、重点项目与任务、KPI 的过程管理这些平日的点滴中。目标要反复讲，要经常对焦，重要的事儿，3 遍是不够的，要说“300 遍！”。 所谓的方向与目标就是：你要往哪去，你要走多远，你要走到哪。清晰的目标就好比沙漠中的指南针，让你能比其他人更快找到水源并生存下去，今天这节课，我提醒你注意这样几点： 解读目标非常重要，切勿陷入极端，要么不解读，要么领导说什么就是什么。 制定目标一定要够聚焦，但切勿只考虑眼前，注意“长短结合”。 注意目标传递，要充分考虑团队成员的感受，选取合适的方式。 追过程：如何用 PDCA 做过程管理？只有掌握过程管理的方法，才会尽可能减少事务往不好方向发展的波动，从而更轻松、更低风险、更稳妥地去拿到结果，让一切尽在掌控。 什么是过程管理？管理就是追求事务的可持续发展，而想要达成这个目标有两个基本点： 管理动作要形成可持续迭代的闭环； 管理动作足够简单到可以复制和个性化升级。 过程管理是为了让你的想法、灵感、不稳定的发挥逐渐规律化，可以持续迭代被你应用，它的本质就是希望结果越来越好，让你原本靠运气或者模糊经验得来的成功可以被复制，让你在项目中灵光一闪的 Idea 变成你的常规能力。 PDCA 模型 Plan（定计划）：围绕着目标明确里程碑，确定关键节点，与执行的员工达成共识。 Do（做执行）：多给员工空间、多走动、多观察、少干预，放手而非放任，你也不能置身事外。 Check（勤检查）：狠抓关键节点做检查、问进展、问困难、给建议、做辅导、协调资源。 Action（复盘调优）：小事尽快复盘、大事分阶段复盘、事后全面复盘，抓住每一次提升和优化的机会。 如何用 PDCA 做过程管理？很多能力和经验是历练出来的，只要过程可控，过程中走一些弯路也未必是坏事，要允许犯错。但是你要注意，放手不等于放任，更不等于不闻不问，你依然要对最终的结果负责。 复盘前：复盘前的核心在于思考复盘的目的和产出是什么。借此，你才可以明确复盘会议主要会聊些什么，哪些人会参加。 复盘中：自省是复盘会的基调，复盘就一个目的“找到团队的不足加以改进，以便在未来取得更好的结果”。所以每个人没必要甩锅，也没必要全盘否定。在复盘的过程中，一定要把问题找准，内部对齐，达成所有人的共识。 复盘后：会议有结论，结论有计划，计划有责任人，责任人有行动，要建立机制保证在复盘会上讨论出的结论能够落地。 总的来说，小事儿尽快复盘，借此向团队成员传授自己的经验；大事儿分阶段复盘，抓住重点矛盾，推动事情的顺利发展而非追求完美；事后全面复盘，不管对个人还是团队，找自己的问题都是 ROI 最高的方式，找到问题的一方才有改善提升的可能。 三个重点： 目标不会自己长腿走向终点，你一定要做好过程管理以取得可靠的结果。 追过程不意味着事无巨细都要做，追哪些、什么时候追、追到什么程度才是你更应该关心的。 复盘是 PDCA 管理动作中的闭环，如果每次都能提高一点点，长期积累的变化就很大了。 奖优罚劣：怎样传递我们”要什么”与“不要什么”？“奖优罚劣”之所以重要，是因为它能让团队形成可持续发展的氛围，是拿结果的闭环。而我们在这个过程中要注意的就是：引导人性而非对抗人性。 什么是奖优、罚劣奖优最终会落到物质和精神上： 物质上的奖优作用大，但是频次较低，比如以半年/年为单位的晋升、调薪，它能够打开成员的天花板，比如拿了A绩效的同学，第二年他依然希望是A而不是B，从而提高对自己的要求与期望，更容易取得好的成绩。 精神上的奖优体现在日常行为上，频次较高，比如你关注和肯定某位成员的行为，在团队内通过邮件、钉钉等方式简单鼓励推广他的行为。 罚劣也会落到物质和精神上，但它是动作而非目的，你要通过罚劣来传递团队不能容忍什么样的行为，以此提醒、鞭策大家。奖优和罚劣是相互依赖的。 “奖优罚劣”的误区： 没有意识到奖优罚劣的示范作用。 你要把“奖优罚劣”当作宣传动作，把结果辐散出去，引导团队风向。 注重罚劣，忽略奖优。 奖惩动作过于儿戏，容易被滥用：“奖惩动作”要建立在尊重的基础上，让成员有收获和反思。 奖优罚劣的关键动作绩效考核我们要从一开始被主观因素影响，逐渐认识到客观的环境与现实，最终在理性与人性中寻找一个平衡，让大家看到付出和能做出好成绩的同学，回报是远远高于其他人的，对于拖整体后退、持续不能改善的同学，团队是不欢迎的。 绩效面谈绩效面谈的核心出发点是通过这次绩效的结果改变某些行为与认识，让团队在未来取得更好的成绩，并不是单纯地通知结果。 面谈流程： 开场定基调 员工自评 主管评价 对焦共识 面谈总结 后续跟进 薪酬激励三个基本原则： 问自己是否敢将资源分配的逻辑与规则在阳光之下讲出来。 不要撒胡椒面，也别做大锅饭，让好的结果超出预期。 面向未来而非现在去做考虑 牢记资源总是有限的，资源分配本身是博弈，有人多就要有人少。这种情况下，平均分配的结果不是普天同庆，而是所有人都不满意，每个人都觉得少。与其如此，不如把资源倾斜到那些你团队最优秀、绩效最好的同学身上，让他们得到预期的收益甚至超出预期。 勤沟通：在信任的基础上，让沟通简单且纯粹要知道，沟通是有目的的，既然沟通的对象是人，我们还希望通过沟通去达到一定的结果（效果），那么就要懂得一定的道理与技巧。 沟通的核心原则沟通是内心想法和思考逻辑的外延，如果你有良好的沟通能力，可以在整个团队中营造公开透明的信任氛围，让信息透明的同时，也让团队成员愿意发出自己的声音。 沟通核心原则的定义是：在相信对方的基础上，让沟通氛围变得“简单且纯粹”。 不同维度的沟通向上沟通有胆量、平行沟通有肺腑、向下沟通有心肝。 向上沟通要有技巧、有原则，认清沟通的目标与目的，不轻易妥协导致更严重的后果。 关于平行沟通有肺腑是指你要真诚沟通，不要油滑套路。 向下沟通有心肝是指有同理心，有尊重的同时要感同身受。 两个具体的沟通场景One One 沟通 接地气，说人话 视人为人 沟通要“勤” 团队沟通与One One沟通不同的是，团队沟通受人数的限制，是一对多的沟通，所以除了参考OneOne沟通的核心点外，你最关键的应该是搭场子，发起团队沟通。 团队沟通目的性更强，频次不高，考验你的控场能力。 建机制：规则流程越建越多，为何效果却越来越差？机制发挥什么作用？两类机制： 与管理相关： 比如为了信息互通，约定每周固定时间通过邮件、会议、IM 等方式，将提前定义好的信息做一个汇总交互（表现为周报、周会等），这就是机制的一种具现。 与技术相关： 比如为了多人协同，制定开发流程、Bug 处理、发布上线流程，甚至在日常实际开发的工作中，往往也先定义 API 契约，然后在联调测试时再真正实现验证，这些约定、契约、流程都是对应机制在落地时的具体表现。 站在团队的角度，建机制尤为重要，你要通过机制让团队有统一的行为与规则，让组织像人一样，言行举止有规律可循。 如何设计一个好的机制？ 规则统一，不自相矛盾 简单有效，便于增删 紧盯整体结果，机制的 ROI 要足够高 机制要怎么落地？ 先说 why： 即机制的内容是什么？为了解决什么问题？你在设计机制时是如何思考的？ 共识的要与不要： 和大家讨论我们要不要这样做？看看大家是怎么想的，通过对话和引导形成一定的结论，有些内容需要保留，有些不合理需要剔除，促成结论最为重要。 承诺行为举止： 确认机制之后，需要让结论形成对各自行为的约束。比如不同的成员认领不同的角色和任务，或者在 IM 中一起公告规则，总之每个成员要与机制的参与感。 先考虑目的， CodeReview 主要是解决两方面的问题：提高代码质量；帮助开发同学认识到如何写出更好的代码。 不同的侧重点设计出来的机制也有所不同，按照我的理解，CodeReview 的主要作用还是帮助大家成长，打造团队内的技术提升氛围，次要才是促进产品质量的提升。 确定了核心想要达成的效果，接下来就可以着手确定机制的内容，这里面要考虑几个方面的内容：可能会遇到的问题（阻力）、机制实施的成本、机制运行的时机和周期、站在一个机制参与者的角度考虑他要做什么。 具体 CodeReview 的机制方案可以参考下图： 知人善用：借事修人，借人成事知人善用的三个关键点 找对人 培养人 养成人 怎么落地执行？ 团队盘点 激发意愿 改善计划 tips 不怕没缺点，就怕没特点： 你借人成事，不能一味地关注他的缺点，而是要寻找其特点，发挥他的擅长点，有缺点不可怕，就怕没特点。 新人做老事，老人做新事： 如果在团队中老人一直做老事，新人做新事，那么会出现老人没有新的提高，新人也要克服很多未知的困难；反之，可以重新激发老人的活力，也让新人有借鉴之处。 不要越俎代庖，什么都自己上： 用人的过程中会出现“事情做错”的情况，一旦你发现这样的情况，千万不要直接去帮他纠正，这样无法帮助团队成员成长，团队成员只会当犯错误时，等着你来帮他解决。好的 Leader一定是要在明知前方有坑（这个坑一定是你能控制的）的情况下，也要让团队成员去踩一回，让其有试错的机会，让每个错误都物有所值。 给机会的同时，给压力和帮助： 很多时候压力是成长的催化剂，有了压力也就有了 120% 的动力，所以把某个任务或职责给到一个同学的时候，也要把适当的压力传递过去，让他感受到事情的重要性。与此同时，时刻关注，该给的帮助一定要给到，不能不闻不问。 既敢于承认错误，也允许别人犯错： 让一个人成长不可能完全不让他犯错，有时一些可控的错误反而可能是事后看最大的收获。同时，也不要认定自己之前的做法都是对的，要意识到，哪怕你之前做成功过，也不意味着你就一定是100%正确的。好的 Leader 在培养团队成员时，既要让团队不怕犯错（敢干事），也要敢于承认自己不足，去改善去提高。 找到人：招聘是 Leader 的责任，不是 HR 的招人不等于盲目加人明确业务目标；盘点团队需求；做出岗位设计；提炼岗位要求。 闻味道、问事实、看能力面试前看简历，面试中更多倾听，面试后速写评价。 问事实（STAR法则，看候选人所说的内容是否真正做过，以及思考过程） 看能力 闻味道（是否和团队匹配） 宁缺毋滥，守住底线关注未来 他是否有能力的同时还有潜力？比如很强的发展欲望或学习能力？ 他身上是否有特质足够吸引你？比如让你觉得当他未来会比你更优秀？ 你是希望与他这样的人一起共事的？ 当他加入团队后，能否将团队氛围激活，形成鲶鱼效应？ 宁缺毋滥 能力水平超过团队 50% 的人以上：确保团队越来越强，而不是越来越弱，有的 Leader会觉得候选人比团队最差的两个人好就可以了，但这样一来，随着时间拉长，你的团队会越来越差。 内心是否非常犹豫？犹豫往往意味着“不想要 &gt; 想要”，如果是迫于业务压力不得不加人，我建议你还是不要勉强，因为有可能本来解决业务压力就可以的问题演变成还要额外解决不适合的新员工的问题。 能落地：90 天试用期，转正时我们要考察什么？ 明确新同学落地的整体节奏 重点抓试用期考核以及工作习惯的养成 转正结束后依然保持跟进 既要帮，也要严“既要帮，也要严”是我定义的“能落地”的核心原则，“帮”与“严”是双向要求：帮是指帮助新同学融入团队（针对的是师兄和 Leader）；严是要让新同学在团队中提升自己，遵守团队的做事原则，发挥自己的能力与价值（针对新同学自己）。 招聘只是开始，让新同学能落地、发挥价值才是最终目标。 明确新同学落地的整体节奏 用迎新打破大家在情感上的壁垒； 给新同学安排“师兄”； 明确新同学的作业与目标（做出一些成绩达到转正）； 明确告知转正应该怎么做（把转正做重、做实）。 转正述职要考核什么转正述职才是真正意义上的招聘结束！ 把控转正时间： 提前半个月跟 HR 或者“师兄”确定转正述职时间点。 建立评委会： 由 Leader 主导，与其合作的伙伴（技术同学、产品或者运营）组成小的评委会（如果团队成员较少，也可以只有 Leader 和 HR）这里要注意，合作伙伴的反馈也许会比较主观，你在参考时要尽量保持客观。 明确考核内容： 硬性要求+软性要求。 成长期的跟进慢慢叠加、主动跟进、树立信心 升级汰换：“心要慈，刀要快”开除人“心要慈，刀要快” No Surprise： 不要突然Fire一个人（离职一定不是一个突发行为），没有任何征兆告诉员工 A“你被开除了”，这是典型的管理失职。如果A存在问题，你应该先告知，然后一边和他一起制定改善计划，一边督促其改正。离职往往是一个可预期的结果，无法满足工作需要或者对团队有其他伤害而 A 依旧无法改变时，为了避免对团队产生持久不利的影响，就需要让他离开。 心要慈、刀要快： 杰克·韦尔奇（Jack Welch）曾经说过这样一句话“如果一个人到了中年之后，还没有被告知自己的弱点，反而在某一天因为节约成本的原因被裁掉了，这是最不公平、最不应该发生的事情。就是因为这个公司太仁慈了，他连出去找工作、提升自我的可能性和机会都没有。”你可能觉得，在情感上解聘一个人非常糟糕，但是换一个角度想，如果你对一个人很不满意，却又不找他谈话，不要求他改进，又不开除他，那么从最终结果看不仅对他很残酷，这种“拉锯战”对团队也是不负责任的。 Happy stay、Happy go： 很多时候，送走一个同学对彼此来说并不是一件糟糕的事，换个角度看，如果他在当前环境下一直无法适配团队，对他来说也是很难受的，这时分开对他对团队都是解脱。尤其是当公司出现变化时，如果一些同学不再合适，换环境来讲对他是新的机会，所以你不要存在太多的情绪，而是要往“好聚好散”的方向上推动。 不要给“白兔”生存机会 白兔看起来人畜无害，繁殖能力极强，大公司里最容易存在的就是“白兔”（不干活的好人）。他们目标和价值观认同度较高，但是业绩长期拖后腿。每一家公司都有这样的人，看着勤勤恳恳，但却拿不到任何结果，如果你纵容白兔的存在，那么长久下去，很容易滋生一群白兔磨洋工，针对这类员工，你前期可以给予改正的机会，如果依旧没有改善，应该毫不犹豫将其送走。 离职面谈“TRF” Train him、Remove him、Fire him Train him 是指如果他能力跟不上，你可以给予其帮助；Remove him 是指如果他的能力和岗位匹配有问题，你要更多地采用转岗的方式，为他的发展打开空间；如果在你给予他机会之后，他还是无法改善，那你就应该 Fire him。 需要避免的： “谈不了”：辞退的事实依据不充分，对离职原因讲不清楚。 “无重点”：对有关问题避重就轻，只说无关痛痒的祝福。 “没技巧”：对员工工作横加指责，面谈完反而加深了矛盾。 “从不谈”：是对员工存在很大偏见，不面谈直接一拍两散。 技术管理的常见痛点晋升：是不是技术到位、项目做好就够了？经过多少“关”才能晋升？晋升步骤： 晋升启动——主管提名——部门提报——述职答辩——结果表决——公司复审——结果公布 提名沟通可以在薪资、年终奖等激励上体现自己对苦劳同学的关注，而对于想要晋升的同学，应该更多给他能力培养的机会，因为对技术同学而言，技术是晋升的基础，战功与业绩也缺一不可，后者是为了证明自己的能力和担当足以承载更多职责。 大部分情况下苦劳不等于功劳，是否具备下一个角色所需要的条件才是晋升考核的侧重点。 资料准备4 个关键词：资料素材来源、证明实力、PPT编写、赛前演练与心理辅导 素材来源于“过去财年总结 + 新财年的规划 + 汇报材料 + 分享材料 + 项目总结”，因为经过沉淀的资料才最有价值。有了一些素材资料后，就要把控准备阶段的核心：通过素材去证明你具备下一职级所需要的能力。 围绕 5 个维度（架构能力、细节把控的能力、工程的能力、团队的能力、技术视野）去梳理和提炼关键信息，准备相关资料。 编写 PPT 将证明你能力的框架可视化，突出重点、内容翔实、数据说话、功劳大于苦劳、突出自我。 在团队内部让有提名的同学预演一遍自己准备的内容，其余同学从中指出存在的问题（是否紧张、是否突出亮点……）争取让他脱稿，逻辑严谨，减少紧张感；一些同学会格外在意晋升这件事，患得患失，所以 Leader 要帮他平缓心态，帮助其建立正确的认知：把晋升当作一次分享和总结，就当是对过去一段时间的回顾，不管结果如何，总有所收获。 晋升答辩 拿结果的能力： 清晰的客户价值产出，有思考沉淀和可复制的方法论； 业务理解能力： 客户视角、前瞻性思考与判断、可以持续提升客户价值。 结果安排晋升答辩之后，无外乎两个结果：晋升成功、失败。作为 Leader，你需要让候选人认识到这两种结果，并告知尽最大的努力，考虑最坏的结果，避免形成落差，候选人离职；如果候选人晋升成功，简单庆祝过后，还需要为其新角色明确新的要求和职责，让他有更明确的努力方向，在团队内发挥更大的作用，不要把晋升当作终点，而是后面工作的起点。 晋升不是奖励，是责任与担当，是为未来做的事。 跨团队：没有汇报线的人和事就是推不动？跨团队事务推进的难点 方案无法达成一致： 你提出的 A 方案与运营团队提出的 B 方案，在实现成本、方式、资源等方面存在很明显差异，陷入僵局。 时间无法达成一致： 协作方赞同 A 方案，但对“一周上线项目”的时间节点有意见，认为至少需要 20 天，这会从“时间无法达成一致”回滚到“方案无法达成一致”，陷入新一轮僵局。 优先级无法达成一致： 协作方赞同 A 方案，对项目用时一周也无异议，但该项目优先级在他那儿没有提到很高，一直有优先级更高的项目插队，导致交付时间一变再变、一拖再拖。 阶段性交付结果不一致： 因为某些原因（线上突发状况、同学请假、人员能力较差……），与你协作团队在配合时交付你的结果质量无法满足你的需求，比如运营给的方案有很大漏洞、技术给的接口 Bug 比功能点还多，你又无法直接管理对方团队的成员，最终即使更正了也可能浪费了额外的时间。 难点产生的原因： 协作方不清楚项目原因和意义，会优先考虑自身利益，根据利益高低推进难度由易到难 协作方有自己当前的工作内容和优先级，突然配合进行其他事务，引入的风险往往较高 各部门对彼此之间的工作方式、团队经验以及当前现状往往不了解 任务细化，跨团队合作受时间、空间等因素影响沟通成本较高，有些问题不知道该找谁 跨团队事务推进的基本态度 不要做情绪的奴隶，先找自己的问题 快刀斩乱麻，避免因复杂的问题陷入沼泽 慢思考，快执行 借力前行，摆事实讲道理，凭职级，行进办法，达成目标。 跨团队事务推进的原则方法 合作前（明确目标，确保信息完整） 合作中（定位问题，借势而为） 合作后（承担责任，公开肯定） 换位思考、摆事实、讲道理、凭职级、借势而行、想尽办法达成目标。 做规划：除了交付和稳定性，还要规划什么？团队规划解决的核心问题是：让你在有限的时间和资源内，明确怎么去创造最大的技术价值（ROI）。而且在做团队规划的过程中，其实是一个深入思考、梳理的过程，你可以复盘过去、梳理当下、展望未来，少走弯路。 做规划要考虑团队现状 明确定位与职责 人员情况 业务情况 一个可以参考的思路是： 盯着业务目标去延展人员和业务，从而判断哪些是依赖项，哪些是前置项？在大部分公司中，技术很难直接创造商业价值，往往还是要依赖于业务，所以把业务作为第一目标，为了达成某个业务结果，需要调整人员结构，招聘一些更厉害的人汰换一些不行的人，研究并实现一些新技术，这是比较自然的。 你的规划中包含了什么？不同的技术团队，在规划时所拟定的内容都是不同的，但你其实都可以提炼成共性的3 部分。 业务结果： 直白说就是业务层面的战绩，你团队打造了一个公司 GMV 占比超过 50%的商城，或者支撑了某个快速发展业务，这些都是业务结果，用业务数字来说话。 技术创新： 由技术人员发起或完成的所有降本提效的动作，但是同样要看优先级和投入产出比。 团队建设： 让团队可以长期健康发展下去，要在 Backup、人员组成、机制建设等多个方面下功夫。 自问： WHY：为什么做业务目标/技术创新/团队建设的规划？ WHAT：是否能说明业务目标/技术创新/团队建设规划解决的问题、价值与作用？ WHO：由谁承担？负责人的优势与跌势是什么？ WHEN：所做的规划着眼于现在还是未来？能否保证长期有价值？ HOW：针对不同的部分，具体的落地细则如何？ HOW MUCH：规划要做到什么程度？是否可以形成可衡量的KPI？ 业务结果你要明确现阶段上级领导关注的重点是什么？是转化、流量、留存、还是产品的用户体验？作为技术Leader ，你和团队成员的到达路径是什么？这是线索来源之一。 技术创新稳定性、效能优化、驱动业务、视野展望 团队建设团队建设的关键不只是知人善用，而是： 团队未来需要什么样的人？ 目前团队成员需要什么样的状态和能力？ 团队成员需要承担什么样的责任？ 总的来说，你希望未来自己的团队成为怎样的团队？以此推导离理想状态多远？怎么缩小差距？ 规划落地时的问题与思路容易出现的问题： 规划不等于计划 规划内容想得太多，做成的少 业务压力大，盲盯痛点，忽视目标 规划最终成了技术Leader的规划 做团队规划是一件比较综合宏观的事情，有时哪怕只是几个人的团队，想做好一份规划而非执行计划也很考验 Leader 的思考深度，某种程度来说，规划是你定义一群人在未来一段时间内做什么、怎么做、最终变成什么样。这个过程中需要考量的点非常多，这些深入的思考也会促进你日常的一些行为和结果，对于团队的季度乃至半年规划我是非常推荐你要定期梳理并落地的，有目标和没目标的团队，还是有很大的差别的。 接手新团队：士气低、交付迟、事故多发，如何下手解决？虽然接手一个问题团队很难，要处理很多问题并且非常辛苦，但是对一个 Leader 的锻炼也是无与伦比的，我见过几乎所有优秀的技术 Leader 都是一次次这样磨炼出来的。毕竟技术管理能力很重要的一个落地场景就是这种情况，也是最能发挥技术 Leader 管理能力价值的场景之一。","tags":["reading"],"categories":["reading"]},{"title":"git知识汇总","path":"/2021/02/13/310/","content":"概念4个区git之所以令人费解，主要是它相比于svn等等传统的版本管理工具，多引入了一个暂存区(Stage)的概念，就因为多了这一个概念，而使很多人疑惑。其实，在初学者来说，每个区具体怎么工作的，我们完全不需要关心，而只要知道有这么4个区就够了： 工作区(Working Area) 暂存区(Stage) 本地仓库(Local Repository) 远程仓库(Remote Repository) 5种状态以上4个区，进入每一个区成功之后会产生一个状态，再加上最初始的一个状态，一共是5种状态。以下我们把这5种状态分别命名为： 未修改(Origin) 已修改(Modified) 已暂存(Staged) 已提交(Committed) 已推送(Pushed) 检查修改已修改，未暂存git diff 已暂存，未提交git diff --cached 已提交，未推送git diff master origin/master 撤销修改了解清楚如何检查各种修改之后，我们开始尝试各种撤销操作。 恢复已修改，未暂存如果我们只是在编辑器里修改了文件，但还没有执行git add .，这时候我们的文件还在工作区，并没有进入暂存区，我们可以用撤销操作 git checkout . 或者 git reset --hard 恢复已暂存，未提交你已经执行了git add .，但还没有执行git commit -m &quot;comment&quot;。这时候你意识到了错误，想要撤销，你可以执行： git resetgit checkout . 或者 git reset --hard git reset只是把修改退回到了git add .之前的状态，也就是说文件本身还处于已修改未暂存状态，你如果想退回未修改状态，还需要执行git checkout .。 或许你已经注意到了，以上两个步骤都可以用同一个命令git reset --hard来完成。是的，就是这个强大的命令，可以一步到位地把你的修改完全恢复到未修改的状态。 恢复已提交，未推送你的手太快，你既执行了git add .，又执行了git commit，这时候你的代码已经进入了你的本地仓库，然而你后悔了，怎么办？不要着急，还有办法。 git reset --hard origin/master 还是这个git reset --hard命令，只不过这次多了一个参数origin/master，正如我们上面讲过的，origin/master代表远程仓库，既然你已经污染了你的本地仓库，那么就从远程仓库把代码取回来吧。 已推送很不幸，你的手实在是太快了，你既git add了，又git commit了，并且还git push了，这时你的代码已经进入远程仓库。如果你想恢复的话，还好，由于你的本地仓库和远程仓库是等价的，你只需要先恢复本地仓库，再强制push到远程仓库就好了： git reset --hard HEAD^git push -f 部分远程仓库设置了禁止强制push，我们可以使用以下方法。 revertgit revert用于反转提交。执行revert命令时要求工作树必须是干净的，git revert用一个新提交来消除一个历史提交所做的任何修改。revert 之后你的本地代码会回滚到指定的历史版本，这时你再 git push 就可以把线上的代码更新。 常用命令 命令 说明 git clone 克隆 git branch (分支名) 创建分支 -D删除分支 git checkout (分支名) 切换分支 -b创建并切换 git checkout (文件名) 撤销此文件修改 git add 将该文件添加到缓存 git status 查看在你上次提交之后是否有修改 git commit 将缓存区内容添加到仓库中 git diff 来查看执行 git status 的结果的详细信息 git reset HEAD 命令用于取消已缓存的内容 git rm 文件 删除文件-f强制删除 git mv 移动文件 git merge 合并分支 git fetch 从远程获取最新版本到本地 git push &lt;远程主机名&gt; &lt;本地分支名&gt;:&lt;远程分支名&gt; 将本地分支的更新，推送到远程主机 git push origin –delete test 删除远程分支test git pull &lt;远程主机名&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt; 将远程存储库中的更改合并到本地分支中 git rebase 命令在另一个分支基础之上重新应用，用于把一个分支的修改合并到当前分支。 git log 命令用于显示提交日志信息。 git reflog 显示每一次命令 git revert 生成一个新的提交来撤销某次提交，此次提交之前的commit都会被保留 git reset HEAD 如果发现错误的将不想暂存的文件被git add进入索引之后，想回退取消，则可以使用 设置用户名邮箱： git config –global user.name “puresai” git config –global user.email “957042781@qq.com“ 几个常见问题与解决方案fatal: No configured push destination.解决：$ git remote add -f -t master -m master origin git://example.com/git.git/fatal: The current branch test has no upstream branch.解决：git push --set-upstream origin test模仿 git clone，但只跟踪选定的分支$ mkdir project.git$ cd project.git$ git init$ git remote add -f -t master -m master origin git://example.com/git.git/$ git merge originfatal：Unable to create &#x27;E:/project/scrm/.git/index.lock&#x27;: File exists.rm -f ./.git/index.lockgit log-p 查看差异-n(n为正整数) 查看最近n次的提交--pretty 按指定格式显示日志信息,可选项有：oneline,short,medium,full,fuller,email,raw以及format:&lt;string&gt;,默认为medium，可以通过修改配置文件来指定默认的方式。e.g. git log (--pretty=)oneline--stat 列出文件的修改行数--sortstat 只显示--stat中最后行数修改添加移除的统计--graph 以简单的图形方式列出提交记录--abbrev-commit 仅显示 SHA-1 的前几个字符，而非所有的 40 个字符。--relative-date 使用较短的相对时间显示（比如，“2 weeks ago”）。--name-only 仅在提交信息后显示已修改的文件清单。--name-status 显示新增、修改、删除的文件清单。 列出tag git tag # 在控制台打印出当前仓库的所有tag git tag -l ‘v0.1.*’ # 搜索符合模式的Tag 打tag git tag分为两种类型：轻量tag和附注tag。轻量tag是指向提交对象的引用，附注Tag则是仓库中的一个独立对象。建议使用附注Tag。 创建轻量Tag git tag v0.1.2-light 创建附注Tag git tag -a v0.1.2 -m “0.1.2版本” 创建轻量Tag不需要传递参数，直接指定Tag名称即可。 创建附注Tag时，参数a即annotated的缩写，指定Tag类型，后附Tag名。参数m指定Tag说明，说明信息会保存在Tag对象中。 切换到Tag与切换分支命令相同，用 git checkout [tagname] 查看Tag信息用git show命令可以查看Tag的版本信息： git show v0.1.2 删除Tag误打或需要修改Tag时，需要先将Tag删除，再打新Tag。 git tag -d v0.1.2 # 删除Tag 参数d即delete的缩写，意为删除其后指定的Tag。 给指定的commit打Tag 打Tag不必要在head之上，也可在之前的版本上打，这需要你知道某个提交对象的校验和（通过git log获取）。 补打Tag git tag -a v0.1.1 9fbc3d0 Tag推送到服务器 通常的git push不会将Tag对象提交到git服务器，我们需要进行显式的操作： git push origin v0.1.2 # 将v0.1.2 Tag提交到git服务器 git push origin –-tags # 将本地所有Tag一次性提交到git服务器 注意：如果想看之前某个Tag状态下的文件，可以这样操作 git tag 查看当前分支下的Tag git checkout v0.21 此时会指向打v0.21 Tag时的代码状态，（但现在处于一个空的分支上） 删除远程分支和tag在Git v1.7.0 之后，可以使用这种语法删除远程分支： git push origin –delete 删除tag这么用： git push origin –delete tag 否则，可以使用这种语法，推送一个空分支到远程分支，其实就相当于删除远程分支： git push origin : 这是删除tag的方法，推送一个空tag到远程tag： git tag -d git push origin :refs/tags/ 重命名远程分支删除远程分支： git push –delete origin devel 重命名本地分支： git branch -m devel develop 推送本地分支： git push origin develop 把本地tag推送到远程 git push –tags # 推送所有tag git push origin :tag # 推送tag","tags":["git"],"categories":["CI"]},{"title":"atomic","path":"/2021/02/13/atomic/","content":"在之前的源码分析中，我们有多次看到atomic的出现，今天不妨我们看一下atomic的源码。 我们看一下atomic的源码文件： 这里说明一下，以.s为后缀的是汇编语言源代码文件，你可以并不懂汇编，没有关系。 主要看下asm.s，看一看到里面有调用runtime ∕ internal ∕ atomic，我们前去看一下这个文件夹，其中有个文件atomic_wasm.go。 atomic提供的是原子操作，atomic包中支持六种类型 int32 uint32 int64 uint64 uintptr unsafe.Pointer 对于每一个类型，支持5种操作，我们以int32分别说明下这些操作： SwapX// 原子性的将新值保存到*addr并返回旧值。func SwapInt32(addr *int32, new int32) (old int32)// 源码func Xchg(ptr *uint32, new uint32) uint32 &#123;\told := *ptr\t*ptr = new\treturn old&#125; CompareAndSwapX// 原子性的比较*addr和old，如果相同则将new赋值给*addr并返回真。func CompareAndSwapInt32(addr *int32, old, new int32) (swapped bool)// 源码func Cas(ptr *uint32, old, new uint32) bool &#123;\tif *ptr == old &#123; *ptr = new return true\t&#125;\treturn false&#125; AddX// 原子性的将val的值添加到*addr并返回新值func AddInt64(addr *int64, delta int64) (new int64)// 源码func Xadd(ptr *uint32, delta int32) uint32 &#123;\tnew := *ptr + uint32(delta)\t*ptr = new\treturn new&#125; LoadX// 原子性的获取*addr的值func LoadInt32(addr *int32) (val int32)// 源码func Load(ptr *uint32) uint32 &#123;\treturn *ptr&#125; StoreX// 原子性的将val的值保存到*addrfunc StoreInt32(addr *int32, val int32)// 源码func Store(ptr *uint32, val uint32) &#123;\t*ptr = val&#125; 源码其实比较简单了，我就不过多说明了。 atomic.Value另外，atomic对支持的类型做了扩展，atomic.Value被设计用来存储任意类型的数据。 type Value struct &#123;\tv interface&#123;&#125;&#125; 为了方便，定义了一个ifaceWords类型，它的作用是将interface&#123;&#125;类型分解，得到其中的两个字段，作为interface的内部表示格式，typ代表原始类型，data代表真正的值。 type ifaceWords struct &#123;\ttyp unsafe.Pointer\tdata unsafe.Pointer&#125; 提供了Store和Load两个方法。 Store func (v *Value) Store(x interface&#123;&#125;) &#123; // x为nil，直接panic\tif x == nil &#123; panic(&quot;sync/atomic: store of nil value into Value&quot;)\t&#125;\t// 将现有的值和要写入的值转换为ifaceWords类型，这样下一步就能获取到它们的原始类型和真正的值\tvp := (*ifaceWords)(unsafe.Pointer(v))\txp := (*ifaceWords)(unsafe.Pointer(&amp;x))\tfor &#123; // 获取现有的值的type typ := LoadPointer(&amp;vp.typ) // 如果typ为nil说明这是第一次调用Store if typ == nil &#123; // 如果是第一次调用，就占住当前的processor，不允许其他goroutine再抢，runtime_procPin方法会先获取当前goroutine runtime_procPin() // 使用CAS操作，先尝试将typ设置为^uintptr(0)这个中间状态 // 如果失败，则证明已经有别的goroutine抢先完成了赋值操作 // 那它就解除抢占锁，继续循环等待 if !CompareAndSwapPointer(&amp;vp.typ, nil, unsafe.Pointer(^uintptr(0))) &#123; runtime_procUnpin() continue &#125; // 如果设置成功，就原子性的更新对应的指针，最后解除抢占锁 StorePointer(&amp;vp.data, xp.data) StorePointer(&amp;vp.typ, xp.typ) runtime_procUnpin() return &#125; // 如果typ为^uintptr(0)说明第一次写入还没有完成，继续循环等待 if uintptr(typ) == ^uintptr(0) &#123; continue &#125; // 如果要写入的类型和现有的类型不一致，则panic if typ != xp.typ &#123; panic(&quot;sync/atomic: store of inconsistently typed value into Value&quot;) &#125; // 更新data，跳出循环 StorePointer(&amp;vp.data, xp.data) return\t&#125;&#125; Load func (v *Value) Load() (x interface&#123;&#125;) &#123; // 将*Value指针类型转换为*ifaceWords指针类型\tvp := (*ifaceWords)(unsafe.Pointer(v))\t// 原子性的获取到v的类型typ的指针\ttyp := LoadPointer(&amp;vp.typ)\t// 如果没有写入或者正在写入，先返回，^uintptr(0)代表过渡状态，这和Store是对应的\tif typ == nil || uintptr(typ) == ^uintptr(0) &#123; return nil\t&#125;\t// 原子性的获取到v的真正的值data的指针，然后返回\tdata := LoadPointer(&amp;vp.data)\txp := (*ifaceWords)(unsafe.Pointer(&amp;x))\txp.typ = typ\txp.data = data\treturn&#125; PS:解读的源码，如无特别说明，版本为1.15.6 参考： go标准库 Go - atomic包使用及atomic.Value源码分析","tags":["gosourcecode"],"categories":["gosourcecode"]},{"title":"搭建http server","path":"/2021/02/12/goexample1/","content":"round one，我们来点简单的，搭建一个简单的http server。 目标： 路由hello接收参数并获取到输出json数据 自定义404 处理超时页面 使用到的库: net/http time encoding/json 我们先搭建起来server： package mainimport (\t&quot;net/http&quot;)func main() &#123;\tsrv := http.Server&#123; Addr: &quot;:8080&quot;, Handler: http.HandlerFunc(defaultHttp),\t&#125;\tsrv.ListenAndServe()&#125;// 默认http处理func defaultHttp(w http.ResponseWriter, r *http.Request) &#123;\tw.Write([]byte(&quot;wow&quot;))&#125; 运行就可以跑起来了。 我们再来定义下json输出格式。 // 自定义返回type JsonRes struct &#123;\tCode int `json:&quot;code&quot;`\tData interface&#123;&#125; `json:&quot;data&quot;`\tMsg string `json:&quot;msg&quot;`\tTimeStamp int64 `json:&quot;timestmap&quot;`&#125;func apiResult(w http.ResponseWriter, code int, data interface&#123;&#125;, msg string) &#123;\tbody, _ := json.Marshal(JsonRes&#123; Code: code, Data: data, Msg: msg, // 获取时间戳 TimeStamp: time.Now().Unix(),\t&#125;) w.Write(body)&#125; 再来看一下接收参数与输出： // 处理hello，并接收参数输出jsonfunc sayHello(w http.ResponseWriter, r *http.Request) &#123; query := r.URL.Query() // 第一种方式，但是没有name参数会报错 // name := query[&quot;name&quot;][0] // 第二种方式 name := query.Get(&quot;name&quot;) apiResult(w, 0, name+&quot; say &quot;+r.PostFormValue(&quot;some&quot;), &quot;success&quot;)&#125; 超时处理： Handler: http.TimeoutHandler(http.HandlerFunc(defaultHttp), 2*time.Second, &quot;Timeout!!!&quot;) 404: http.Error(w, &quot;you lost???&quot;, http.StatusNotFound) 最后加入路由处理： func defaultHttp(w http.ResponseWriter, r *http.Request) &#123;\tpath, httpMethod := r.URL.Path, r.Method\tif path == &quot;/&quot; &#123; w.Write([]byte(&quot;index&quot;)) return &#125;\tif path == &quot;/hello&quot; &amp;&amp; httpMethod == &quot;POST&quot; &#123; sayHello(w, r) return &#125;\tif path == &quot;/sleep&quot; &#123; // 模拟一下业务处理超时 time.Sleep(4*time.Second) return &#125;\tif path == &quot;/path&quot; &#123; w.Write([]byte(&quot;path:&quot;+path+&quot;, method:&quot;+httpMethod)) return &#125;\t// 自定义404\thttp.Error(w, &quot;you lost???&quot;, http.StatusNotFound)&#125; 我们运行起来看下效果： 404效果 hello 首页 超时 这样就完成了一个简单的http server，是不是很简单呢？ 完整代码github","tags":["goexample"],"categories":["goexample"]},{"title":"go+MongoDB实现附近的人","path":"/2021/02/12/goexample10/","content":"在O2O与社交场景中，搜索附近的人、附近的商家是很常见的场景。那么我们如何实现呢？ 接触的方法有： 坐标+球体距离计算公式 基于Redis的geo 基于MongoDB的geohash 前面的demo已经有接触Redis，这里我们就用mongoDB来实现一下。 我们就直接使用官方的实现好了： go.mongodb.org/mongo-driver/mongo 连接opt := options.Client().ApplyURI(&quot;mongodb://root:211111@localhost:27017&quot;)// Connect to MongoDBclient, err := mongo.Connect(context.TODO(), opt)if err != nil &#123;\tlog.Fatal(err)&#125;// Check the connectionerr = client.Ping(context.TODO(), nil)if err != nil &#123;\tlog.Fatal(err)&#125;fmt.Println(&quot;Connected to MongoDB!&quot;) 我们可以设置更多： opt.SetLocalThreshold(3 * time.Second) //只使用与mongo操作耗时小于3秒的opt.SetMaxConnIdleTime(5 * time.Second) //指定连接可以保持空闲的最大毫秒数opt.SetMaxPoolSize(200) //使用最大的连接数opt.SetReadConcern(readconcern.Majority()) //指定查询应返回实例的最新数据确认为，已写入副本集中的大多数成员 model// 坐标type Location struct &#123;\tType string `json:&quot;type&quot; bson:&quot;type&quot;`\tCoordinates []float64 `json:&quot;coordinates&quot; bson:&quot;coordinates&quot;`&#125;// 每个点type Point struct &#123;\tName string `json:&quot;name&quot;`\tAge int `json:&quot;age&quot;`\tCity string `json:&quot;city&quot;`\tLocation Location `json:&quot;location&quot;`&#125; 数据写入我们可以先插入数据 func(mgo *mgo) Start() &#123;\tcollection := mgo.client.Database(DBName).Collection(CollectionName)\t// 设置索引 2dsphere， 很重要\tcollection.Indexes().CreateOne(context.TODO(), mongo.IndexModel&#123; Keys: bson.M&#123;Key: &quot;2dsphere&quot;&#125;,\t&#125;)\ta := Point&#123;&quot;王二&quot;, 18, &quot;杭州&quot;, Location&#123;&quot;Point&quot;, []float64&#123;120.185614,30.300738&#125;&#125;&#125;\tb := Point&#123;&quot;张三&quot;, 25, &quot;杭州&quot;, Location&#123;&quot;Point&quot;, []float64&#123;120.094778,30.310217&#125;&#125;&#125;\tc := Point&#123;&quot;小晴&quot;, 35, &quot;绍兴&quot;, Location&#123;&quot;Point&quot;, []float64&#123;120.603847,30.054237&#125;&#125;&#125;\td := Point&#123;&quot;李四&quot;, 34, &quot;杭州&quot;, Location&#123;&quot;Point&quot;, []float64&#123;120.110893,30.207849&#125;&#125;&#125;\te := Point&#123;&quot;小明&quot;, 24, &quot;北京&quot;, Location&#123;&quot;Point&quot;, []float64&#123;116.435721,39.914031&#125;&#125;&#125;\tf := Point&#123;&quot;吴六&quot;, 25, &quot;杭州&quot;, Location&#123;&quot;Point&quot;, []float64&#123;120.126443,30.33084&#125;&#125;&#125;\th := Point&#123;&quot;于一&quot;, 23, &quot;杭州&quot;, Location&#123;&quot;Point&quot;, []float64&#123;120.28132,30.184083&#125;&#125;&#125;\tj := Point&#123;&quot;小七&quot;, 14, &quot;杭州&quot;, Location&#123;&quot;Point&quot;, []float64&#123;119.73926,30.247639&#125;&#125;&#125;\t// 单条插入\tinsertResult, err := collection.InsertOne(context.TODO(), a)\tif err != nil &#123; log.Fatal(err)\t&#125;\tfmt.Println(&quot;Inserted a single document: &quot;, insertResult.InsertedID)\tps := []interface&#123;&#125;&#123;b, c, d, e, f, h, j&#125;\t// 批量插入\tinsertManyResult, err := collection.InsertMany(context.TODO(), ps)\tif err != nil &#123; log.Fatal(err)\t&#125;\tfmt.Println(&quot;Inserted multiple documents: &quot;, insertManyResult.InsertedIDs)&#125; 注意，设置索引 2dsphere， 很重要！！！ 存储的数据格式 我们查找： func (mgo *mgo) Near() &#123;\tcollection := mgo.client.Database(DBName).Collection(CollectionName) // 查找120.110893,30.2078490坐标附近15000米的人\tcur, err := collection.Find(context.TODO(), bson.D&#123; &#123;Key, bson.D&#123; &#123;&quot;$near&quot;, bson.D&#123; &#123; &quot;$geometry&quot;, Location&#123; &quot;Point&quot;, []float64&#123;120.110893,30.2078490&#125;, &#125;, &#125;, &#123;&quot;$maxDistance&quot;, 15000&#125;, // 单位米 &#125;&#125;, &#125;&#125;,\t&#125;)\tif err != nil &#123; fmt.Println(err) return\t&#125;\tvar results []Point\tfor cur.Next(context.TODO()) &#123; var elem Point err := cur.Decode(&amp;elem) fmt.Println(elem) fmt.Println(cur) if err != nil &#123; fmt.Println(&quot;Could not decode Point&quot;) return &#125; results = append(results, elem)\t&#125;\tfmt.Println(&quot;查找到&quot;, len(results))&#125; 我们不妨运行一下： 能成功查找出了附近的人。 那么，如何计算距离呢？ 可以经纬度计算，也可以直接mongoDB聚合查询，可以自行思索，参考代码点击见github。","tags":["goexample"],"categories":["goexample"]},{"title":"利用gin搭建一个api框架","path":"/2021/02/12/goexample2/","content":"在demo1中，我们简单使用了net/http搭建了一个server，其实在日常开发中，比较少去使用标准库去直接写api，更多的是使用前人搭建好的轮子（我呢，是个不太喜欢重复造轮子的开发者，有开源的靠谱的，直接用就好，自己调整成自己需要的即可），那么说的go的框架，不得不说gin了。 对于gin的介绍，是github上star最多的go框架了，其他不多说，我们上手写起来吧！ 目标： 自定义配置 整合mysql和Redis 独立路由管理 日志 平滑重启 脚本打包 使用到的库： github.com/fsnotify/fsnotify github.com/gin-gonic/gin github.com/go-Redis/Redis github.com/jinzhu/gorm http://github.com/lestrrat-go/file-rotatelogs http://go.uber.org/zap github.com/spf13/pflag github.com/spf13/viper 初始化modules的引入之后，我们就可以不必使用gopath去管理项目目录了，对于modules的基本使用，建议看文章： gomodules 我们开始： go mod init sai0556/demo2-gin-frame 因为我们暂时本地开发： PS：当时理解有误，其实无需做local.com替换，import直接使用sai0556/demo2-gin-frame即可，这里有点多余 // 使用本地modulego mod edit -require=local.com/sai0556/demo2-gin-frame@v1.0.0go mod edit -replace=local.com/sai0556/demo2-gin-frame@v1.0.0=$PWD 可以看到go.mod已生成： module sai0556/demo2-gin-framego 1.13require local.com/sai0556/demo2-gin-frame v1.0.0replace local.com/sai0556/demo2-gin-frame v1.0.0 =&gt; /Users/@/Work/golang/go-example/demo2-gin-frame /Users/@/Work/golang/go-example/demo2-gin-frame 此目录就是项目目录，视具体情况不一 自定义配置与读取：在我们使用Redis和mysql之前，我们先来读取一下配置，配置呢我们使用常见的yaml，当然你也可以使用其他，比如env等。 新建config目录，用来读取与监听配置文件(config.yaml)： package configimport ( &quot;fmt&quot; &quot;github.com/fsnotify/fsnotify&quot; &quot;github.com/spf13/viper&quot;)type Config struct &#123; Name string&#125;// 对外的初始化配置方法func Run(cfg string) error &#123; c := Config&#123; Name: cfg, &#125; if err := c.init(); err != nil &#123; return err &#125; c.watchConfig() return nil&#125;func (c *Config) init() error &#123; if c.Name != &quot;&quot; &#123; viper.SetConfigFile(c.Name) &#125; else &#123; // 默认配置文件是./config.yaml viper.AddConfigPath(&quot;.&quot;) viper.SetConfigName(&quot;config&quot;) &#125; viper.SetConfigType(&quot;yaml&quot;) // viper解析配置文件 err := viper.ReadInConfig() if err != nil &#123; panic(fmt.Errorf(&quot;Fatal error config file: %s &quot;, err)) &#125;\t// 简单打印下配置 fmt.Println(viper.GetString(&quot;name&quot;)) return nil&#125;func (c *Config) watchConfig() &#123; viper.WatchConfig() viper.OnConfigChange(func(e fsnotify.Event) &#123; fmt.Println(&quot;Config file changed:&quot;, e.Name) &#125;)&#125; main: package mainimport ( &quot;github.com/spf13/pflag&quot; &quot;local.com/sai0556/demo2-gin-frame/config&quot;)var ( conf = pflag.StringP(&quot;config&quot;, &quot;c&quot;, &quot;&quot;, &quot;config filepath&quot;))func main() &#123; pflag.Parse() // 初始化配置 if err := config.Run(*conf); err != nil &#123; panic(err) &#125;&#125; 这里有用到大牛spf13的两个包，pflag和viper，命令行参数解析包pflag可以看作flag的进阶版本，在我们这里可以用来指定配置文件，viper是读取配置文件的包，配合fsnotify可以实现配置的热更新。（spf13大神还有其他有用的包，相信在你的go编码生涯会用到的） 写完我们可以运行一下： go run main.go -c ./config.yaml 可以看到有打印出我们配置的name。 整合mysql与Redismysql包我们就选用gorm，Redis的使用比较多的是redigo和go-Redis，redigo曾在我使用中出现过问题，因而我们选择后者，后者也支持连接池。 mysql： package dbimport ( &quot;fmt&quot; &quot;sync&quot; &quot;errors&quot; orm &quot;github.com/jinzhu/gorm&quot; _ &quot;github.com/jinzhu/gorm/dialects/mysql&quot; &quot;github.com/spf13/viper&quot;)type MySqlPool struct &#123;&#125;var instance *MySqlPoolvar once sync.Oncevar db *orm.DBvar err error // 单例模式func GetInstance() *MySqlPool &#123; once.Do(func() &#123; instance = &amp;MySqlPool&#123;&#125; &#125;) return instance&#125;func (pool *MySqlPool) InitPool() (isSuc bool) &#123;\t// 这里有一种常见的拼接字符串的方式 dsn := fmt.Sprintf(&quot;%s:%s@tcp(%s)/%s?charset=%s&quot;, viper.GetString(&quot;db.username&quot;), viper.GetString(&quot;db.password&quot;), viper.GetString(&quot;db.host&quot;), viper.GetString(&quot;db.name&quot;), viper.GetString(&quot;db.charset&quot;)) db, err = orm.Open(&quot;mysql&quot;, dsn) if err != nil &#123; panic(errors.New(&quot;mysql连接失败&quot;)) return false &#125; // 连接数配置也可以写入配置，在此读取 db.DB().SetMaxIdleConns(viper.GetInt(&quot;db.MaxIdleConns&quot;)) db.DB().SetMaxOpenConns(viper.GetInt(&quot;db.MaxOpenConns&quot;)) // db.LogMode(true) return true&#125; 后面获取连接池就可以直接使用 db.GetInstance() Redis： package dbimport ( &quot;fmt&quot; &quot;github.com/spf13/viper&quot; &quot;github.com/go-Redis/Redis&quot;)var RedisClient *Redis.Clientfunc InitRedis() &#123; RedisClient = Redis.NewClient(&amp;Redis.Options&#123; Addr: fmt.Sprintf(&quot;%s:%s&quot;, viper.GetString(&quot;Redis.host&quot;), viper.GetString(&quot;Redis.port&quot;)), Password: viper.GetString(&quot;Redis.auth&quot;), DB: 0, &#125;) _, err := RedisClient.Ping().Result() if err != nil &#123; panic(&quot;Redis ping error&quot;) &#125;&#125; RedisClient就是我们后面可以用的Redis连接池。 在main中加入初始化连接池的代码即可： // 连接mysql数据库btn := db.GetInstance().InitPool()if !btn &#123; log.Println(&quot;init database pool failure...&quot;) panic(errors.New(&quot;init database pool failure&quot;))&#125;// Redisdb.InitRedis() 路由与控制器为了方便路由，我们把路由管理单独到router。 package routerimport ( &quot;net/http&quot; &quot;github.com/gin-gonic/gin&quot; &quot;local.com/sai0556/demo2-gin-frame/controller&quot;)func Load(g *gin.Engine) *gin.Engine &#123; g.Use(gin.Recovery()) // 404 g.NoRoute(func (c *gin.Context) &#123; c.String(http.StatusNotFound, &quot;404 not found&quot;); &#125;) g.GET(&quot;/&quot;, controller.Index) return g&#125; controller: package controllerimport ( &quot;net/http&quot; &quot;github.com/gin-gonic/gin&quot;)// 返回type Response struct &#123; Code int `json:&quot;code&quot;` Message string `json:&quot;message&quot;` Data interface&#123;&#125; `json:&quot;data&quot;`&#125;// api返回结构func ApiResponse(c *gin.Context, code int, message string, data interface&#123;&#125;) &#123; c.JSON(http.StatusOK, Response&#123; Code: code, Message: message, Data: data, &#125;)&#125;func Index(c *gin.Context) &#123; ApiResponse(c, 0, &quot;success&quot;, nil)&#125; 到这呢，基本也就差不多了。 我们来看下完整的main： package main// import 这里我习惯把官方库，开源库，本地module依次分开列出import ( &quot;log&quot; &quot;errors&quot; &quot;github.com/spf13/pflag&quot; &quot;github.com/spf13/viper&quot; &quot;github.com/gin-gonic/gin&quot; &quot;local.com/sai0556/demo2-gin-frame/config&quot; &quot;local.com/sai0556/demo2-gin-frame/db&quot; &quot;local.com/sai0556/demo2-gin-frame/router&quot;)var ( conf = pflag.StringP(&quot;config&quot;, &quot;c&quot;, &quot;&quot;, &quot;config filepath&quot;))func main() &#123; pflag.Parse() // 初始化配置 if err := config.Run(*conf); err != nil &#123; panic(err)\t&#125; // 连接mysql数据库 btn := db.GetInstance().InitPool() if !btn &#123; log.Println(&quot;init database pool failure...&quot;) panic(errors.New(&quot;init database pool failure&quot;)) &#125; // Redis db.InitRedis() gin.SetMode(viper.GetString(&quot;mode&quot;)) g := gin.New() g = router.Load(g) g.Run(viper.GetString(&quot;addr&quot;))&#125; 整合日志这里我们先定义下log： log: level: debug # 日志级别，info，debug，error file_format: &quot;%Y%m%d&quot; # 文件格式 max_save_days: 30 # 保存天数 file_type: one # one, level 单文件存储还是以level级别存储 整合logger： package loggerimport (\t&quot;io&quot;\t&quot;log&quot;\t&quot;time&quot;\t&quot;github.com/lestrrat-go/file-rotatelogs&quot;\t&quot;go.uber.org/zap&quot;\t&quot;go.uber.org/zap/zapcore&quot; &quot;github.com/spf13/viper&quot;)var Logger *zap.Logger var LogLevel stringvar FileFormat string// 初始化日志 loggerfunc init() &#123;\t// 设置一些基本日志格式\tconfig := zapcore.EncoderConfig&#123; MessageKey: &quot;msg&quot;, LevelKey: &quot;level&quot;, EncodeLevel: zapcore.CapitalLevelEncoder, TimeKey: &quot;ts&quot;, EncodeTime: func(t time.Time, enc zapcore.PrimitiveArrayEncoder) &#123; enc.AppendString(t.Format(&quot;2006-01-02 15:04:05&quot;)) &#125;, CallerKey: &quot;file&quot;, EncodeCaller: zapcore.ShortCallerEncoder, EncodeDuration: func(d time.Duration, enc zapcore.PrimitiveArrayEncoder) &#123; enc.AppendInt64(int64(d) / 1000000) &#125;,\t&#125;\tencoder := zapcore.NewConsoleEncoder(config)\tFileFormat, saveType, LogLevel := &quot;%Y%m%d&quot;, &quot;one&quot;, &quot;info&quot;\tif viper.IsSet(&quot;log.file_format&quot;) &#123; FileFormat = viper.GetString(&quot;log.file_format&quot;)\t&#125;\tif viper.IsSet(&quot;log.level&quot;) &#123; LogLevel = viper.GetString(&quot;log.level&quot;)\t&#125;\tif viper.IsSet(&quot;log.save_type&quot;) &#123; saveType = viper.GetString(&quot;log.save_type&quot;)\t&#125;\tlogLevel := zap.DebugLevel\tswitch LogLevel &#123; case &quot;debug&quot;: logLevel = zap.DebugLevel case &quot;info&quot;: logLevel = zap.InfoLevel case &quot;error&quot;: logLevel = zap.ErrorLevel default: logLevel = zap.InfoLevel\t&#125;\tswitch saveType &#123; case &quot;level&quot;: Logger = getLevelLogger(encoder, logLevel, FileFormat) default: Logger = getOneLogger(encoder, logLevel, FileFormat)\t&#125;\t&#125;func getLevelLogger(encoder zapcore.Encoder, logLevel zapcore.Level, fileFormat string) *zap.Logger &#123;\tinfoLevel := zap.LevelEnablerFunc(func(lvl zapcore.Level) bool &#123; return lvl == zapcore.InfoLevel &amp;&amp; lvl &gt;= logLevel\t&#125;)\tdebugLevel := zap.LevelEnablerFunc(func(lvl zapcore.Level) bool &#123; return lvl == zapcore.DebugLevel &amp;&amp; lvl &gt;= logLevel\t&#125;)\terrorLevel := zap.LevelEnablerFunc(func(lvl zapcore.Level) bool &#123; return lvl &gt;= zapcore.ErrorLevel &amp;&amp; lvl &gt;= logLevel\t&#125;)\t// 获取 info、warn日志文件的io.Writer 抽象 getLoggerWriter() 在下方实现\tinfoWriter := getLoggerWriter(&quot;./log/info&quot;, fileFormat)\terrorWriter := getLoggerWriter(&quot;./log/error&quot;, fileFormat)\tdebugWriter := getLoggerWriter(&quot;./log/debug&quot;, fileFormat)\t// 最后创建具体的Logger\tcore := zapcore.NewTee( zapcore.NewCore(encoder, zapcore.AddSync(debugWriter), debugLevel), zapcore.NewCore(encoder, zapcore.AddSync(infoWriter), infoLevel), zapcore.NewCore(encoder, zapcore.AddSync(errorWriter), errorLevel),\t)\treturn zap.New(core, zap.AddCaller(), zap.AddStacktrace(zap.WarnLevel))&#125;func getOneLogger(encoder zapcore.Encoder, logLevel zapcore.Level, fileFormat string) *zap.Logger &#123;\tinfoWriter := getLoggerWriter(&quot;./log/info&quot;, fileFormat)\tinfoLevel := zap.LevelEnablerFunc(func(lvl zapcore.Level) bool &#123; return lvl == zapcore.InfoLevel &amp;&amp; lvl &gt;= logLevel\t&#125;)\tcore := zapcore.NewTee( zapcore.NewCore(encoder, zapcore.AddSync(infoWriter), infoLevel),\t)\treturn zap.New(core, zap.AddCaller(), zap.AddStacktrace(zap.WarnLevel))&#125;func getLoggerWriter(filename, fileFormat string) io.Writer &#123;\t// 生成rotatelogs的Logger 实际生成的文件名 file_YYmmddHH.log\thook, err := rotatelogs.New( filename+fileFormat+&quot;.log&quot;, rotatelogs.WithLinkName(filename), // 保存天数 rotatelogs.WithMaxAge(time.Hour*24*30), // 切割频率24小时 rotatelogs.WithRotationTime(time.Hour*24),\t)\tif err != nil &#123; log.Println(&quot;日志启动异常&quot;) panic(err)\t&#125;\treturn hook&#125;func Debug(format string, v ...interface&#123;&#125;) &#123;\tLogger.Sugar().Debugf(format, v...)&#125;func Info(format string, v ...interface&#123;&#125;) &#123;\tLogger.Sugar().Infof(format, v...)&#125;func Error(format string, v ...interface&#123;&#125;) &#123;\tLogger.Sugar().Errorf(format, v...)&#125; 这里注意init函数，我们直接调用logger其中函数即可，程序加载包的过程中会自动执行init函数。关于init有以下说明： init函数是用于程序执行前做包的初始化的函数，比如初始化包里的变量等 每个包可以拥有多个init函数 包的每个源文件也可以拥有多个init函数 同一个包中多个init函数的执行顺序go语言没有明确的定义(说明) 不同包的init函数按照包导入的依赖关系决定该初始化函数的执行顺序 init函数不能被其他函数调用，而是在main函数执行之前，自动被调用 我们直接使用： logger.Info(&quot;i&#x27;m log123-----Info&quot;)logger.Error(&quot;i&#x27;m log123-----Error&quot;) 平滑重启当程序在线上稳定运行后，我们可能会去更新一些功能，但发布代码的同时，假如有用户正在使用，盲目发布代码可能会造成用户短暂失真，这时候平滑重启就来了。 对于平滑重启，其实有很多方案，这里我们只从自身代码级别来完成，而即便是代码级别，目前也有多种实现方案，比如第三方库endless这种，我这里主要参考了 https://github.com/kuangchanglang/gracefulgithub.com/kuangchanglang/graceful 简单说明下处理步骤： 监听信号（USR2，可自定义其他信号） 收到信号时fork子进程（使用相同的启动命令），将服务监听的socket文件描述符传递给子进程 子进程监听父进程的socket，这个时候父进程和子进程都可以接收请求 子进程启动成功之后，父进程停止接收新的连接，等待旧连接处理完成（或超时） 父进程退出，重启完成 详细分析可看底部参考-Golang服务器热重启、热升级、热更新。 启动检查结合上面的优雅重启，我们在启动时配置上启动健康检查： package main// import 这里我习惯把官方库，开源库，本地module依次分开列出import (\t&quot;fmt&quot;\t&quot;time&quot;\t&quot;errors&quot;\t&quot;net/http&quot; &quot;github.com/spf13/pflag&quot; &quot;github.com/spf13/viper&quot; &quot;github.com/gin-gonic/gin&quot; &quot;local.com/sai0556/demo2-gin-frame/config&quot; &quot;local.com/sai0556/demo2-gin-frame/db&quot; &quot;local.com/sai0556/demo2-gin-frame/router&quot; &quot;local.com/sai0556/demo2-gin-frame/logger&quot; &quot;local.com/sai0556/demo2-gin-frame/graceful&quot;)var ( conf = pflag.StringP(&quot;config&quot;, &quot;c&quot;, &quot;&quot;, &quot;config filepath&quot;))func main() &#123; pflag.Parse() // 初始化配置 if err := config.Run(*conf); err != nil &#123; panic(err)\t&#125;\t// logger.Info(&quot;i&#x27;m log123-----Info&quot;)\t// logger.Error(&quot;i&#x27;m log123-----Error&quot;) // 连接mysql数据库\tDB := db.GetDB()\tdefer db.CloseDB(DB)\t// Redis\tdb.InitRedis()\tgin.SetMode(viper.GetString(&quot;mode&quot;))\tg := gin.New()\tg = router.Load(g)\t// g.Run(viper.GetString(&quot;addr&quot;))\tgo func() &#123; if err := pingServer(); err != nil &#123; fmt.Println(&quot;fail:健康检测失败&quot;, err) &#125; fmt.Println(&quot;success:健康检测成功&quot;)\t&#125;()\tlogger.Info(&quot;启动http服务端口%s &quot;, viper.GetString(&quot;addr&quot;))\tif err := graceful.ListenAndServe(viper.GetString(&quot;addr&quot;), g); err != nil &amp;&amp; err != http.ErrServerClosed &#123; logger.Error(&quot;fail:http服务启动失败: %s &quot;, err)\t&#125;&#125;// 健康检查func pingServer() error &#123;\tfor i := 0; i &lt; viper.GetInt(&quot;max_ping_count&quot;); i++ &#123; url := fmt.Sprintf(&quot;%s%s%s&quot;, &quot;http://127.0.0.1&quot;, viper.GetString(&quot;addr&quot;), viper.GetString(&quot;healthCheck&quot;)) fmt.Println(url) resp, err := http.Get(url) if err == nil &amp;&amp; resp.StatusCode == 200 &#123; return nil &#125; time.Sleep(time.Second)\t&#125;\treturn errors.New(&quot;健康检测404&quot;)&#125; 这里就比较简单，另外启动一个协程，去ping健康检测的url即可。 打包脚本shell #!/bin/bashSERVER=&quot;demo2-gin-frame&quot;function status() &#123;\tif [ &quot;`pgrep $SERVER -u $UID`&quot; != &quot;&quot; ];then echo $SERVER is running\telse echo $SERVER is not running\tfi&#125;function build() &#123;\techo &quot;build...&quot; CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -o ./$SERVER main.go if [ $? -ne &quot;0&quot; ];then echo &quot;built error!!!&quot; return fi echo &quot;built success!&quot;&#125;case &quot;$1&quot; in\t&#x27;status&#x27;)\tstatus\t;; &#x27;build&#x27;)\tbuild\t;; *) echo &quot;unknown, please: $0 &#123;status or build&#125;&quot;\texit 1\t;; esac bat echo &quot;build...&quot;SET CGO_ENABLED=0SET GOOS=linuxgo build -o demo2-gin-frameif %errorlevel% == 0 ( echo &quot;built successfully&quot;) else ( echo &quot;built fail!!!&quot;) 对于程序的重启和保活，建议配合supervisor使用。 好，到这里我们的round 2就结束了。下一轮我们来玩玩钉钉智能机器人。 点击直达完整代码 参考： golang zap 日志库使用（含文件切割、分级别存储和全局使用等） 基于Go语言构建企业级的 RESTful API 服务 golang init函数 - Go语言中文网 - Golang中文社区 Golang服务器热重启、热升级、热更新(safe and graceful hot-restart/reload http server)详解","tags":["goexample"],"categories":["goexample"]},{"title":"防止漏打卡，利用gin和cron来做一个智能提醒","path":"/2021/02/12/goexample3/","content":"目标： 每天10点提醒我打卡 查询杭州天气 使用的库： github.com/robfig/cron 思路round2里面我们做了个框架，我们不妨以此为基础，来完成这个demo。我们通过解析不同时段的提醒任务，规律地存储到Redis的有序集合，10s去查询一次有没有需要提醒的任务，如有发送到钉钉。 (代码额外说明：Redis我更新成了v8版本，命令前需要加上下文，注意一下) 接入钉钉机器人钉钉机器人文档 按照文档在群里新建机器人即可。我开启的是webhook自定义机器人，outgoing提送地址就是项目接收信息地址，比如：http://cron.puresai.com/dingdingPost 建议设置成加签或ip限制，以防被恶意攻击 关键字// util/common.go// 就列了一些常见的，可自行扩展func UpdateKeywords() &#123;\tRedis := model.RedisClient.Pipeline()\tkey := KeyWords\tRedis.HSet(model.Ctx, key, &quot;分钟后&quot;, &quot;1|60&quot;)\tRedis.HSet(model.Ctx, key, &quot;时后&quot;, &quot;1|3600&quot;)\tRedis.HSet(model.Ctx, key, &quot;天后&quot;, &quot;1|86400&quot;)\tRedis.HSet(model.Ctx, key, &quot;每天&quot;, &quot;-1|1&quot;)\tRedis.HSet(model.Ctx, key, &quot;每周一&quot;, &quot;2|0&quot;)\tRedis.HSet(model.Ctx, key, &quot;每周二&quot;, &quot;2|1&quot;)\tRedis.HSet(model.Ctx, key, &quot;每周三&quot;, &quot;2|2&quot;)\tRedis.HSet(model.Ctx, key, &quot;每周四&quot;, &quot;2|3&quot;)\tRedis.HSet(model.Ctx, key, &quot;每周五&quot;, &quot;2|4&quot;)\tRedis.HSet(model.Ctx, key, &quot;每周六&quot;, &quot;2|5&quot;)\tRedis.HSet(model.Ctx, key, &quot;每周日&quot;, &quot;2|6&quot;)\tRedis.HSet(model.Ctx, key, &quot;周一&quot;, &quot;3|0&quot;)\tRedis.HSet(model.Ctx, key, &quot;周二&quot;, &quot;3|1&quot;)\tRedis.HSet(model.Ctx, key, &quot;周三&quot;, &quot;3|2&quot;)\tRedis.HSet(model.Ctx, key, &quot;周四&quot;, &quot;3|3&quot;)\tRedis.HSet(model.Ctx, key, &quot;周五&quot;, &quot;3|4&quot;)\tRedis.HSet(model.Ctx, key, &quot;周六&quot;, &quot;3|5&quot;)\t...\tRedis.HSet(model.Ctx, key, &quot;今天&quot;, &quot;4|0&quot;)\tRedis.HSet(model.Ctx, key, &quot;明天&quot;, &quot;4|1&quot;)\tRedis.HSet(model.Ctx, key, &quot;后天&quot;, &quot;4|2&quot;)\tRedis.HSet(model.Ctx, key, &quot;取消&quot;, &quot;0|0&quot;)\tRedis.Exec(model.Ctx)&#125; 关键字，可以自行扩展，可能会有覆盖的情况，这里需要抉择，是匹配第一个还是匹配字数最多的，我此处选择后者的。 解析内容钉钉文档的outgoing说明不全，或者是藏在哪里我没找到，可以使用@机器人接收信息打印看一下。 //关注senderId发送人id，text发送内容，senderNick发送人昵称即可&#123; &quot;conversationId&quot;:&quot;xxx&quot;, &quot;atUsers&quot;:[ &#123; &quot;dingtalkId&quot;:&quot;xxx&quot; &#125;], &quot;chatbotUserId&quot;:&quot;xxx&quot;, &quot;msgId&quot;:&quot;xxx&quot;, &quot;senderNick&quot;:&quot;sai0556&quot;, &quot;isAdmin&quot;:false, &quot;sessionWebhookExpiredTime&quot;:1594978626787, &quot;createAt&quot;:1594973226742, &quot;conversationType&quot;:&quot;2&quot;, &quot;senderId&quot;:&quot;xxx&quot;, &quot;conversationTitle&quot;:&quot;智能备忘录&quot;, &quot;isInAtList&quot;:true, &quot;sessionWebhook&quot;:&quot;xxx&quot;, &quot;text&quot;:&#123; &quot;content&quot;:&quot; hello gin-frame&quot; &#125;, &quot;msgtype&quot;:&quot;text&quot;&#125; 定义一个struct，接收消息 type DingDingMsgContent struct &#123;\tSenderNick string `json:&quot;senderNick&quot;`\tSenderId string `json:&quot;senderId&quot;`\tText struct &#123; Content string `json:&quot;content&quot;`\t&#125; `json:&quot;text&quot;`&#125;func DingDing(c *gin.Context) &#123;\tdata, _ := ioutil.ReadAll(c.Request.Body)\tform := DingDingMsgContent&#123;&#125;\terr := json.Unmarshal([]byte(data), &amp;form)\t// err := c.ShouldBindJSON(&amp;form)\tif err != nil &#123; fmt.Println(err) return\t&#125;\t....&#125; 解析，注意定义了一些特殊情况，比如绑定手机，取消任务等，做对应的特殊处理，绑定手机是为了@ 某人，否则消息容易被忽略。 func parseContent(form DingDingMsgContent) (err error) &#123;\tstr := form.Text.Content\tRedis := db.RedisClient\tfmt.Println(str)\t// 要先绑定哟，不然无法@到对应的人\tindex := strings.Index(str, &quot;绑定手机&quot;)\tif index &gt; -1 &#123; reg := regexp.MustCompile(&quot;1[0-9]&#123;10&#125;&quot;) res := reg.FindAllString(str, 1) if len(res) &lt; 1 || res[0] == &quot;&quot; &#123; err = errors.New(&quot;手机格式不正确&quot;) return &#125; Redis.HSet(db.Ctx, util.KeyDingDingID, form.SenderId, res[0]) util.SendDD(&quot;绑定成功&quot;) return\t&#125;\thExist := Redis.HExists(db.Ctx, util.KeyDingDingID, form.SenderId)\tif !hExist.Val() &#123; err = errors.New(&quot;绑定手机号才能精确提醒哦，发送--绑定手机 13456567878--@我即可&quot;) return &#125;\tindex = strings.Index(util.StrSub(str, 0, 10), &quot;我的提醒&quot;)\tfmt.Println(index, &quot;---&quot;, util.StrSub(str, 0, 6))\tif index &gt; -1 &#123; www := util.QueryAllQueue(form.SenderId); if len(www) &lt; 1 &#123; err = errors.New(&quot;暂无任务&quot;) return &#125; msg := &quot;&quot; for key,value := range www &#123; fmt.Println(strings.Index(value, &quot;@&quot;)) value := value[0:strings.Index(value, &quot;@&quot;)] fmt.Println(value) msg = util.StrCombine(msg, &quot;任务id：&quot;, key, &quot;，任务内容：&quot;, value, &quot;&#123;br&#125;&quot;) &#125; err = errors.New(msg) return\t&#125;\tindex = strings.Index(util.StrSub(str, 0, 10), &quot;查看任务&quot;)\tfmt.Println(index, &quot;---&quot;, util.StrSub(str, 0, 6))\tif index &gt; -1 &#123; www := util.QueryAllQueue(form.SenderId); if len(www) &lt; 1 &#123; err = errors.New(&quot;暂无任务&quot;) return &#125; msg := &quot;&quot; for key,value := range www &#123; fmt.Println(strings.Index(value, &quot;@&quot;)) value := value[0:strings.Index(value, &quot;@&quot;)] fmt.Println(value) msg = util.StrCombine(msg, &quot;任务id：&quot;, key, &quot;，任务内容：&quot;, value, &quot;&#123;br&#125;&quot;) &#125; err = errors.New(msg) return\t&#125;\tindex = strings.Index(util.StrSub(str, 0, 10), &quot;取消所有任务&quot;)\tfmt.Println(index, &quot;---&quot;, util.StrSub(str, 0, 6))\tif index &gt; -1 &#123; if er := util.CancelAllQueue(form.SenderId); er != nil &#123; err = er return &#125; err = errors.New(&quot;取消成功&quot;) return\t&#125;\tindex = strings.Index(util.StrSub(str, 0, 10), &quot;取消&quot;)\tif index &gt; -1 &#123; reg := regexp.MustCompile(&quot;[a-z0-9]&#123;32&#125;&quot;) res := reg.FindAllString(str, 1) if len(res) &lt; 1 &#123; err = errors.New(&quot;任务id不正确&quot;) return &#125; if er := util.CancelQueue(res[0], form.SenderId); er != nil &#123; err = er return &#125; err = errors.New(&quot;取消成功&quot;) return\t&#125;\treturn&#125;// 提醒内容func tips(form DingDingMsgContent) (err error) &#123;\trd := db.RedisClient\tstr := form.Text.Content\tmobile := rd.HGet(db.Ctx, util.KeyDingDingID, form.SenderId).Val()\tkey := util.KeyWords\tlist, _ := rd.HGetAll(db.Ctx, key).Result()\tnow := time.Now().Unix()\ttipsType := 1\tk := &quot;&quot;\tv := &quot;&quot;\tfmt.Println(&quot;str&quot;, str)\tindex := 0\tfor key, value := range list &#123; index = util.UnicodeIndex(str, key) if index &gt; -1 &amp;&amp; util.StrLen(key) &gt; util.StrLen(k) &#123; fmt.Println(&quot;index&quot;, index, str, key, value) k = key v = value &#125;\t&#125;\tmsg := &quot;&quot;\tvar score int64\tif k != &quot;&quot; &#123; kLen := util.StrLen(k) msg = util.StrSub(str, index+kLen) val := strings.Split(v, &quot;|&quot;) unit := val[1] units,_ := strconv.Atoi(unit) switch val[0] &#123; // 多少时间后 case &quot;1&quot;: reg := regexp.MustCompile(&quot;[0-9]&#123;1,2&#125;&quot;) res := reg.FindAllString(str, 1) minute, _ := strconv.Atoi(res[0]) score = now + int64(units*minute) // 每周 case &quot;2&quot;: reg := regexp.MustCompile(&quot;[0-9]&#123;1,2&#125;&quot;) res := reg.FindAllString(util.StrSub(msg, 0, 7), -1) hour := 9 minute := 0 if len(res) &gt; 0 &#123; hour, _ = strconv.Atoi(res[0]) &#125; if len(res) &gt; 1 &#123; minute, _ = strconv.Atoi(res[1]) &#125; now = util.GetWeekTS(int64(units)) score = now + int64(60*minute + 3600*hour) tipsType = 2 // 下周 case &quot;3&quot;: reg := regexp.MustCompile(&quot;[0-9]&#123;1,2&#125;&quot;) res := reg.FindAllString(util.StrSub(msg, 0, 7), -1) hour := 9 minute := 0 if len(res) &gt; 0 &#123; hour, _ = strconv.Atoi(res[0]) &#125; if len(res) &gt; 1 &#123; minute, _ = strconv.Atoi(res[1]) &#125; now = util.TodayTS() score = now + int64(60*minute + 3600*hour + units*86400) case &quot;4&quot;: reg := regexp.MustCompile(&quot;[0-9]&#123;1,2&#125;&quot;) res := reg.FindAllString(util.StrSub(msg, 0, 7), -1) hour := 9 minute := 0 if len(res) &gt; 0 &#123; hour, _ = strconv.Atoi(res[0]) &#125; if len(res) &gt; 1 &#123; minute, _ = strconv.Atoi(res[1]) &#125; now = util.TodayTS() + 86400*int64(units) score = now + int64(60*minute + 3600*hour) case &quot;-1&quot;: reg := regexp.MustCompile(&quot;[0-9]&#123;1,10&#125;&quot;) res := reg.FindAllString(util.StrSub(msg, 0, 7), -1) fmt.Println(&quot;res&quot;, res) hour := 9 minute := 0 if len(res) &gt; 0 &#123; hour, _ = strconv.Atoi(res[0]) &#125; if len(res) &gt; 1 &#123; minute, _ = strconv.Atoi(res[1]) &#125; now = util.TodayTS() + 86400 score = now + int64(60*minute + 3600*hour) fmt.Println(now, score, minute, hour) tipsType = 3 default: &#125;\t&#125; else &#123; reg := regexp.MustCompile(&quot;(([0-9]&#123;4&#125;)[-|/|年])?([0-9]&#123;1,2&#125;)[-|/|月]([0-9]&#123;1,2&#125;)日?&quot;) pi := reg.FindAllStringSubmatch(str, -1) if (len(pi) &gt; 0 ) &#123; date := pi[0] if date[2] == &quot;&quot; &#123; date[2] = &quot;2020&quot; &#125; location, _ := time.LoadLocation(&quot;Asia/Shanghai&quot;) tm2, _ := time.ParseInLocation(&quot;2006/01/02&quot;, fmt.Sprintf(&quot;%s/%s/%s&quot;, date[2], date[3], date[4]), location) score = util.GetZeroTime(tm2).Unix() msg = reg.ReplaceAllString(str, &quot;&quot;) fmt.Println(msg) &#125; else &#123; msg = str score = util.TodayTS() &#125; reg = regexp.MustCompile(&quot;[0-9]&#123;1,10&#125;&quot;) res := reg.FindAllString(util.StrSub(msg, 0, 7), -1) fmt.Println(&quot;res&quot;, res) hour := 9 minute := 0 if len(res) &gt;= 1 &#123; hour, _ = strconv.Atoi(res[0]) fmt.Println(&quot;hour&quot;, hour, minute) &#125; if len(res) &gt; 1 &#123; minute, _ = strconv.Atoi(res[1]) &#125; score += int64(60*minute + 3600*hour)\t&#125;\tif msg == &quot;&quot; &#123; err = errors.New(&quot;你说啥&quot;) return\t&#125;\tindex = util.UnicodeIndex(msg, &quot;提醒我&quot;)\tindex2 := util.UnicodeIndex(msg, &quot;提醒&quot;)\tif index2 &lt; 0 &#123; err = errors.New(&quot;大哥，要我提醒你干啥呢？请发送--下周一13点提醒我写作业&quot;) return\t&#125;\tif index &lt; 0 &amp;&amp; index2 &gt; -1 &#123; msg = util.StrSub(msg, index2+2)\t&#125; else &#123; msg = util.StrSub(msg, index+3)\t&#125; fmt.Println(msg, mobile)\tmsg = util.StrCombine(msg, &quot;@&quot;, mobile)\tfmt.Println(score, msg, tipsType, err)\tif err != nil &#123; util.SendDD(err.Error()) return\t&#125;\tmember := util.StrCombine(strconv.Itoa(tipsType), msg)\trd.ZAdd(db.Ctx, util.KeyCrontab, &amp;Redis.Z&#123; Score: float64(score), Member: member,\t&#125;)\tuniqueKey := util.Md5(member)\trd.HSet(db.Ctx, util.StrCombine(util.KeyUserCron, form.SenderId), uniqueKey, member)\tutil.SendDD(fmt.Sprintf(&quot;设置成功(取消请回复：取消任务%s)--%s提醒您%s&quot;, uniqueKey, time.Unix(score, 0).Format(&quot;2006/01/02 15:04:05&quot;), msg))\treturn &#125; 发送钉钉消息这里就是对接钉钉接口，解析给需要提醒的人就行，就不做过多说明了。 func SendDD(msg string) &#123; // 打印出来看看是个啥\tfmt.Println(&quot;dingding-----------&quot;)\tfmt.Println(msg)\ttips := make(map[string]interface&#123;&#125;)\tcontent := make(map[string]interface&#123;&#125;)\ttips[&quot;msgtype&quot;] = &quot;markdown&quot; // @ 是用来提醒群里对应的人\tarr := strings.Split(msg, &quot;@&quot;) // [提醒]是机器人关键字，个人建议设置机器人限制ip或使用token，比较靠谱\tcontent[&quot;text&quot;] = fmt.Sprintf(&quot;%s&quot;, strings.Replace(arr[0], &quot;&#123;br&#125;&quot;, &quot; &quot;, -1))\tcontent[&quot;title&quot;] = &quot;鹅鹅鹅&quot;\tif len(arr) &gt; 1 &#123; mobile := make([]string, 0) at := make(map[string]interface&#123;&#125;) mobile = append(mobile, arr[1]) at[&quot;atMobiles&quot;] = mobile tips[&quot;at&quot;] = at content[&quot;text&quot;] = fmt.Sprintf(&quot;%s @%s&quot;, content[&quot;text&quot;], arr[1])\t&#125; tips[&quot;markdown&quot;] = content bytesData, err := json.Marshal(tips) if err != nil &#123; fmt.Println(err.Error() ) return &#125; reader := bytes.NewReader(bytesData) url := viper.GetString(&quot;dingding_url&quot;) request, err := http.NewRequest(&quot;POST&quot;, url, reader) if err != nil &#123; return &#125; request.Header.Set(&quot;Content-Type&quot;, &quot;application/json;charset=UTF-8&quot;) client := http.Client&#123;&#125; _, err = client.Do(request) if err != nil &#123; fmt.Println(err.Error()) return\t&#125;\t// 偷懒不重试了 // respBytes, err := ioutil.ReadAll(resp.Body) // if err != nil &#123; // fmt.Println(err.Error()) // return // &#125; // //byte数组直接转成string，优化内存 // str := (*string)(unsafe.Pointer(&amp;respBytes)) // fmt.Println(*str)&#125; 定时发送与任务取消这就是发送提醒的核心代码了，详细使用说明可以看下： Golang cron 定时任务使用 func Cron() &#123; c := cron.New() spec := &quot;*/10 * * * * ?&quot; c.AddJob(spec, Queue&#123;&#125;) c.Start()&#125;type Queue struct &#123;&#125;func (q Queue) Run() &#123;\tnow := time.Now().Unix()\trd := model.RedisClient\top := &amp;Redis.ZRangeBy&#123; Min: &quot;0&quot;, Max: strconv.FormatInt(now, 10), &#125; ret, err := rd.ZRangeByScoreWithScores(model.Ctx, KeyCrontab, op).Result() if err != nil &#123; fmt.Printf(&quot;zrangebyscore failed, err:%v &quot;, err) return\t&#125; for _, z := range ret &#123; fmt.Println(z.Member.(string), z.Score) QueueDo(z.Member.(string), z.Score) &#125;&#125;func QueueDo(msg string, score float64) &#123;\tmsgType := msg[0:1]\tSendDD(msg[1:])\trd := model.RedisClient\trd.ZRem(model.Ctx, KeyCrontab, msg)\tswitch msgType &#123; case &quot;2&quot;: rd.ZAdd(model.Ctx, KeyCrontab, &amp;Redis.Z&#123; Score: score + 7*86400, Member: msg, &#125;) case &quot;3&quot;: rd.ZAdd(model.Ctx, KeyCrontab, &amp;Redis.Z&#123; Score: score + 86400, Member: msg, &#125;) default: rd.ZRem(model.Ctx, KeyCrontab, msg)\t&#125;&#125;// 取消提醒func CancelQueue(uniqueKey string, SenderId string) (err error) &#123;\trd := model.RedisClient\tmember := rd.HGet(model.Ctx, StrCombine(KeyUserCron, SenderId), uniqueKey).Val()\tif member == &quot;&quot; &#123; fmt.Println(StrCombine(KeyUserCron, SenderId), uniqueKey) err = errors.New(&quot;没有此任务&quot;) return\t&#125;\tfmt.Println(member, &quot;member&quot;)\trd.ZRem(model.Ctx, KeyCrontab, member)\trd.HDel(model.Ctx, StrCombine(KeyUserCron, SenderId), uniqueKey)\terr = errors.New(&quot;取消成功&quot;)\treturn &#125;// 取消所有func CancelAllQueue(SenderId string) (err error) &#123;\trd := model.RedisClient\tlist, _ := rd.HGetAll(model.Ctx, StrCombine(KeyUserCron, SenderId)).Result()\tfor _, value := range list &#123; rd.ZRem(model.Ctx, KeyCrontab, value)\t&#125; rd.Del(model.Ctx, StrCombine(KeyUserCron, SenderId))\terr = errors.New(&quot;已经取消所有提醒任务&quot;)\treturn &#125;func QueryAllQueue(SenderId string) (map[string]string) &#123;\trd := model.RedisClient\tlist, _ := rd.HGetAll(model.Ctx, StrCombine(KeyUserCron, SenderId)).Result()\t// fmt.Println(list)\treturn list&#125; 天气与聊天给你是接了一个免费智能接口，有兴趣可查看github配置文件。 来看看效果 总结这个demo其实主要点就是解析钉钉推送内容做对应的处理，因关键字过多，代码其实有点啰嗦，你可以自行优化，对接智能接口和钉钉接口，还是定时任务其实都是相对简单的，当然，这只是很基础的功能，你可以自行扩展。另外，这次之列出了主要代码，没有做十分详尽的说明，有兴趣可以查看源码。 查看github源码 啰嗦这个demo的起初也是我们几个同事老忘记打卡，有了这个demo，起初只能提醒打卡，后面陆续加入了取消、查看、查询天气等功能，大家学习技术的时候也可以考虑应用到生活场景当中，这样学习起来也比较有有趣，实践中也会发现很多想不到的问题，最后，祝大家工作愉快，不忘打卡。","tags":["goexample"],"categories":["goexample"]},{"title":"gRPC","path":"/2021/02/12/goexample4/","content":"在进行round 4之前呢，说一下go的modules，之前的3个demo中，其实我就直接用到了，没做说明，个人觉得modules的引进算是一个大改进了，让我们可以脱离gopath的束缚，具体说明与配置，可以看我的这一篇文章： go modules 务必设置GOPROXY，会大大提高go get的速度。 gRPC 是可以在任何环境中运行的现代开源高性能 RPC 框架。它可以通过可插拔的支持来有效地连接数据中心内和跨数据中心的服务，以实现负载平衡，跟踪，运行状况检查和身份验证。它也适用于分布式计算的最后一英里，以将设备，移动应用程序和浏览器连接到后端服务。 安装protocol buffer 编译器mac： brew install protobuf 其他系统可以尝试编译安装 protocolbuffers/protobuf 安装gprcgo get -u google.golang.org/grpc 安装protoc-gen-go插件go get -u github.com/golang/protobuf/protoc-gen-go 使用新建hello目录，进入后执行： protoc --proto_path hello/ --go_out=plugins=grpc:hello hello.proto 会看到hello目录下生成了hello.pb.go文件。 当然，其中的 hello.proto 是预先自定义在hello文件夹下的，如： syntax = &quot;proto3&quot;; //语法声明package hello; //包名// 定义服务service Greeter &#123; rpc SayHello (HelloRequest) returns (HelloReply) &#123;&#125;&#125;// 请求数据格式message HelloRequest &#123; string name = 1;&#125;// 响应数据格式message HelloReply &#123; string message = 1;&#125; server新建server目录，golang例子代码来自：https://github.com/grpc/grpc-go/tree/master/examples/helloworld // main.gopackage mainimport ( &quot;context&quot; &quot;log&quot; &quot;net&quot; &quot;google.golang.org/grpc&quot; pb &quot;local.com/sai/game/grpc/hello&quot;)const ( port = &quot;:50051&quot;)// server is used to implement helloworld.GreeterServer.type server struct &#123; pb.UnimplementedGreeterServer&#125;// SayHello implements helloworld.GreeterServerfunc (s *server) SayHello(ctx context.Context, in *pb.HelloRequest) (*pb.HelloReply, error) &#123; log.Printf(&quot;Received: %v&quot;, in.GetName()) return &amp;pb.HelloReply&#123;Message: &quot;Hello &quot; + in.GetName()&#125;, nil&#125;func main() &#123; lis, err := net.Listen(&quot;tcp&quot;, port) if err != nil &#123; log.Fatalf(&quot;failed to listen: %v&quot;, err) &#125; s := grpc.NewServer() pb.RegisterGreeterServer(s, &amp;server&#123;&#125;) if err := s.Serve(lis); err != nil &#123; log.Fatalf(&quot;failed to serve: %v&quot;, err) &#125;&#125; clientgo client// client.gopackage mainimport ( &quot;context&quot; &quot;log&quot; &quot;os&quot; &quot;time&quot; &quot;google.golang.org/grpc&quot; pb &quot;local.com/sai/game/grpc/hello&quot;)const ( address = &quot;127.0.0.1:50051&quot; defaultName = &quot;puresai&quot;)func main() &#123; // Set up a connection to the server. conn, err := grpc.Dial(address, grpc.WithInsecure(), grpc.WithBlock()) if err != nil &#123; log.Fatalf(&quot;did not connect: %v&quot;, err) &#125; defer conn.Close() c := pb.NewGreeterClient(conn) // Contact the server and print out its response. name := defaultName if len(os.Args) &gt; 1 &#123; name = os.Args[1] &#125; ctx, cancel := context.WithTimeout(context.Background(), time.Second) defer cancel() r, err := c.SayHello(ctx, &amp;pb.HelloRequest&#123;Name: name&#125;) if err != nil &#123; log.Fatalf(&quot;could not greet: %v&quot;, err) &#125; log.Printf(&quot;Greeting: %s&quot;, r.GetMessage())&#125;` php client扩展安装 grpc扩展下载 profo 下载安装合适版本的扩展即可，记得别忘记在php.ini中加入： extension=grpc.soextension=protobuf.so 自动生成代码protoc --php_out=client hello/hello.proto 会看到client目录下生成了GPBMetadata和Hello两个目录。 如果你对grpc相对叫熟练，可以直接进行代码编写： &lt;?phprequire __DIR__ . &#x27;/vendor/autoload.php&#x27;;class Client extends \\Grpc\\BaseStub&#123; public function __construct($hostname, $opts, $channel = null) &#123; parent::__construct($hostname, $opts, $channel); &#125; /** * rpc SayHello(HelloRequest) returns (HelloReply) &#123;&#125; * 方法名尽量和 (gprc 定义 Greeter 服务)的方法一样 * 用于请求和响应该服务 */ public function SayHello(\\Hello\\HelloRequest $argument)&#123; // (/hello.Greeter/SayHello) 是请求服务端那个服务和方法，基本和 proto 文件定义一样 return $this-&gt;_simpleRequest(&#x27;/hello.Greeter/SayHello&#x27;, $argument, [&#x27;\\Hello\\HelloReply&#x27;, &#x27;decode&#x27;] ); &#125;&#125;//用于连接 服务端$client = new \\Client(&#x27;127.0.0.1:50051&#x27;, [ &#x27;credentials&#x27; =&gt; Grpc\\ChannelCredentials::createInsecure()]);//实例化 TestRequest 请求类$request = new \\Hello\\HelloRequest();$request-&gt;setName(&quot;fairy&quot;);//调用远程服务$get = $client-&gt;SayHello($request)-&gt;wait();//返回数组//$reply 是 TestReply 对象//$status 是数组list($reply, $status) = $get;echo $reply-&gt;getMessage().PHP_EOL;// print_r($client-&gt;SayHello($request)); 当然，也可以使用grpc_php_plugin插件生成。 grpc-php grpc_php_plugin插件clone太慢可以使用码云 git clone -b $(curl -L https://grpc.io/release) https://github.com/grpc/grpccd grpc#这一步很慢，暂未找到什么好方法git submodule update --initmake grpc_php_plugin 新建php-client，再来自动生成： protoc -I=./hello hello.proto --php_out=./php-client/ --grpc_out=php-client/ --plugin=protoc-gen-grpc=/Users/wangzetao/www/grpc1/bins/opt/grpc_php_plugin 会发现比上面自动生成多了一个GreeterClient.php &lt;?php// client.phprequire __DIR__ . &#x27;/vendor/autoload.php&#x27;;//用于连接 服务端$client = new \\Hello\\GreeterClient(&#x27;127.0.0.1:50051&#x27;, [ &#x27;credentials&#x27; =&gt; Grpc\\ChannelCredentials::createInsecure()]);//实例化 TestRequest 请求类$request = new \\Hello\\HelloRequest();$request-&gt;setName(&quot;world&quot;);//调用远程服务$get = $client-&gt;SayHello($request)-&gt;wait();//返回数组//$status 是数组list($reply, $status) = $get;echo $reply-&gt;getMessage().PHP_EOL;// print_r($client-&gt;SayHello($request)); 运行测试 go run grpc/server/main.go go run grpc/client/main.gogo run grpc/client/client.phpgo run grpc/client/php-client.php grpc初体验完成了，本次只是小小的使用了一下子，后续感兴趣的话可以深入学习一下。文中如有错误，欢迎指出交流。 这篇是之前的文章，代码简单，就不再写一遍了。","tags":["goexample"],"categories":["goexample"]},{"title":"go面向对象","path":"/2021/02/12/goexample5/","content":"面向对象 (Object Oriented,OO) 的思想对软件开发相当重要，它的概念和应用甚至已超越了程序设计和软件开发，扩展到如数据库系统、交互式界面、应用结构、应用平台、分布式系统、网络管理结构、CAD 技术、人工智能等领域。面向对象是一种对现实世界理解和抽象的方法，是计算机编程技术发展到一定阶段后的产物。 严格来说，go不属于面向对象的语言（暂不支持继承），但go允许面向对象的编程风格。今天我们就来实现一个面向对象的demo。 实在没想到好一点的例子，不知道大伙有没有对象，不如以girl friend为例来弄个demo 吧，女同学请new一个boyfrind。当然了，new什么都行，随你喜欢……. 我们定义一个女朋友对象： type GirlFriend struct &#123;\theight int // 身高\tweight int // 体重\tage int // 年龄\tname string // 姓名\tcontent string // 结束语\tgreetings string // 问候语&#125; 我们可以自定义身高，体重，年龄，姓名： func (gf *GirlFriend) SetHeight(v int) &#123;\tgf.height = v&#125;func (gf *GirlFriend) SetWeight(v int) &#123;\tgf.weight = v&#125;func (gf *GirlFriend) SetAge(v int) &#123;\tgf.age = v&#125;func (gf *GirlFriend) SetName(v string) &#123;\tgf.name = v&#125; 喜欢使用链式操作的可以这么来，把女朋友return回去即可： func (gf *GirlFriend) SetContent(v string) *GirlFriend &#123;\tgf.content = v\treturn gf&#125;func (gf *GirlFriend) SetGreeting(v string) *GirlFriend &#123;\tgf.greetings = v\treturn gf&#125; 我们当然还有实现一下，没有女朋友，new一个： func NewOne() *GirlFriend &#123;\treturn &amp;GirlFriend&#123;&#125;&#125; new出来了，当然要秀一下： func (gf *GirlFriend) Show() &#123;\tfmt.Println(gf.greetings + &quot;我是&quot; + gf.name + &quot;,今年&quot; + strconv.Itoa(gf.age) + &quot;岁，身高&quot; + strconv.Itoa(gf.height) + &quot;cm,体重&quot; + strconv.Itoa(gf.weight) + &quot;kg。&quot; + gf.content)&#125; 我们来运行一个： package mainimport (\t&quot;demo5-OOP/oop&quot;)func main() &#123;\tgf := oop.NewOne()\tgf.SetName(&quot;Lily&quot;)\tgf.SetHeight(170)\tgf.SetWeight(50)\tgf.SetGreeting(&quot;hello,&quot;).SetContent(&quot;thanks for your great creavity!&quot;).SetAge(24)\tgf.Show()&#125; 这一篇比较简单，例子呢，仅仅是玩笑，不可当真，女朋友new是不可行的，还是要主动去追的。这里主要是展示一下go的面向对象实现，在使用其他库的过程中应该有注意到一些模块使用了面向对象的实现，希望大家去做一些抽象，在自己的项目合适的地方去实现一下，让自己的代码更优雅、更健壮，也希望大家都能找到对的人，一起new一个baby。 完整代码点击进github","tags":["goexample"],"categories":["goexample"]},{"title":"go-kit","path":"/2021/02/12/goexample6/","content":"何为go-kit Go kit is a programming toolkit for building microservices (or elegant monoliths) in Go. We solve common problems in distributed systems and application architecture so you can focus on delivering business value. go kit是一个用于在Go中构建微服务（或优雅的整体）的编程工具包，解决了分布式系统和应用程序体系结构中的常见问题，以便开发者能够专注于业务交付。 go-kit主要分为三层结构：Transport层，Endpoint层，Service层。 Transport 负责与传输协议HTTP、GRPC等相关的逻辑 Endpoint 负责request/response格式的转换，以及公用拦截器相关的逻辑 Service 业务逻辑。 另外，go-kit提供log日志，metric计数器，tracing请求跟踪，circuitbreaker服务熔断，rate-limiter限流器等模块。简单说，go-kit提供了微服务架构常见的基础模块，可以让开发者省去很多时间。 开始了解还不够，show code。 我们先定义下service，不如就做个简单的计算器，仅仅做演示，有加减功能即可，不整太复杂了。 package service// 接口定义type CalculateService interface &#123;\tAdd(a, b int) int\tReduce(a, b int) int\tMulti(a, b int) int&#125;type calculateService struct&#123;&#125;func NewService() *calculateService &#123;\treturn &amp;calculateService&#123;&#125;&#125;func (s *calculateService) Add(a, b int) int &#123;\treturn a + b&#125;func (s *calculateService) Reduce(a, b int) int &#123;\treturn a - b&#125;func (s *calculateService) Multi(a, b int) int &#123;\treturn a * b&#125; 注意：Go 接口是一组方法的集合，可以理解为抽象的类型。它提供了一种非侵入式的接口。任何类型，只要实现了该接口中方法集，那么就属于这个类型。（这是go中非常常用的特性，切记) endpoint格式化请求，调用service服务，并格式化输出 package endpointimport (\t&quot;context&quot;\t&quot;demo6/service&quot;\t&quot;fmt&quot;\t&quot;github.com/go-kit/kit/endpoint&quot;)type Request struct &#123;\tA int `json:&quot;a&quot; form:&quot;a&quot;`\tB int `json:&quot;b&quot; form:&quot;b&quot;`&#125;type Res struct &#123;\tRes int `json:&quot;res&quot;`\tErr error `json:&quot;err&quot;`&#125;func MakeAddEndpoint(s service.CalculateService) endpoint.Endpoint &#123;\treturn func(_ context.Context, request interface&#123;&#125;) (interface&#123;&#125;, error) &#123; req := request.(Request) return Res&#123;Res: s.Add(req.A, req.B)&#125;, nil\t&#125;&#125;func MakeReduceEndpoint(s service.CalculateService) endpoint.Endpoint &#123;\treturn func(_ context.Context, request interface&#123;&#125;) (interface&#123;&#125;, error) &#123; req := request.(Request) return Res&#123;Res: s.Reduce(req.A, req.B)&#125;, nil\t&#125;&#125;func MakeMultiEndpoint(s service.CalculateService) endpoint.Endpoint &#123;\treturn func(_ context.Context, request interface&#123;&#125;) (interface&#123;&#125;, error) &#123; req := request.(Request) return Res&#123;Res: s.Multi(req.A, req.B)&#125;, nil\t&#125;&#125; 接下来，定义transport定义请求方式（这里我们使用json）： package transportimport (\t&quot;context&quot;\t&quot;demo6/endpoint&quot;\t&quot;encoding/json&quot;\t&quot;errors&quot;\t&quot;net/http&quot;)func DecodeRequest(_ context.Context, r *http.Request) (interface&#123;&#125;, error) &#123;\tvar req endpoint.Request\tif err := json.NewDecoder(r.Body).Decode(&amp;req); err != nil &#123; return nil, errors.New(&quot;params error&quot;)\t&#125;\treturn req, nil&#125;func EncodeResponse(_ context.Context, w http.ResponseWriter, res interface&#123;&#125;) error &#123;\treturn json.NewEncoder(w).Encode(res)&#125; 最后我们将它们endpoint和transport粘合起来，跑起来go～ package mainimport (\t&quot;demo6/endpoint&quot;\t&quot;demo6/service&quot;\t&quot;demo6/transport&quot;\t&quot;net/http&quot;\thttpTransport &quot;github.com/go-kit/kit/transport/http&quot;)func main() &#123;\ts := service.NewService()\tadd := httpTransport.NewServer( endpoint.MakeAddEndpoint(s), transport.DecodeRequest, transport.EncodeResponse,\t)\treduce := httpTransport.NewServer( endpoint.MakeReduceEndpoint(s), transport.DecodeRequest, transport.EncodeResponse,\t)\tmulti := httpTransport.NewServer( endpoint.MakeMultiEndpoint(s), transport.DecodeRequest, transport.EncodeResponse,\t)\thttp.Handle(&quot;/add&quot;, add)\thttp.Handle(&quot;/reduce&quot;, reduce)\thttp.Handle(&quot;/multi&quot;, multi)\thttp.ListenAndServe(&quot;:9009&quot;, nil)&#125; 运行起来： 成功运行！ 详细代码进githubgithub.com/puresai/go-example/tree/main/demo6-go-kit 留一个问题，对于json格式错误的请求，返回的不是json，如何改造，让接口返回json呢？ 最近自己在研究go微服务这块的知识，后续几篇文字应该都会以go-kit为基础展开，有兴趣可继续关注。","tags":["goexample"],"categories":["goexample"]},{"title":"docker-compose整合go-kit和mysql、Redis","path":"/2021/02/12/goexample7/","content":"专栏之前有使用go-kit、gorm、go-Redis，所以部分内容就忽略。 定义model主要实现SelectByEmail（查找）和Save（新建）两个方法： package modelimport &quot;time&quot;type UserEntity struct &#123;\tID int64\tUsername string\tPassword string\tEmail string\tCreatedAt time.Time&#125;func (UserEntity) TableName() string &#123;\treturn &quot;user&quot;&#125;type UserDao interface &#123;\tSelectByEmail(email string) (*UserEntity, error)\tSave(user *UserEntity) error&#125;type UserDaoImpl struct&#123;&#125;func (u *UserDaoImpl) SelectByEmail(email string) (*UserEntity, error) &#123;\tuser := &amp;UserEntity&#123;&#125;\terr := db.Where(&quot;email = ?&quot;, email).First(user).Error\treturn user, err&#125;func (u *UserDaoImpl) Save(user *UserEntity) error &#123;\treturn db.Create(user).Error&#125; 业务servicepackage serviceimport (\t&quot;context&quot;\t&quot;demo7-docker-compose/model&quot;\t&quot;errors&quot;\t&quot;log&quot;\t&quot;time&quot;\t&quot;github.com/jinzhu/gorm&quot;)type UserInfoDTO struct &#123;\tID int64 `json:&quot;id&quot;`\tUsername string `json:&quot;username&quot;`\tEmail string `json:&quot;email&quot;`&#125;var (\tErrUserExisted = errors.New(&quot;user is existed&quot;)\tErrPassword = errors.New(&quot;email and password are not match&quot;)\tErrRegistering = errors.New(&quot;email is registering&quot;))type RegisterUser struct &#123;\tUsername string\tPassword string\tEmail string&#125;type UserService interface &#123;\tLogin(ctx context.Context, email, pass string) (*UserInfoDTO, error)\tRegister(ctx context.Context, user *RegisterUser) (*UserInfoDTO, error)&#125;type UserServiceImpl struct &#123;\tuserDao model.UserDao&#125;func MakeUserServiceImpl(userDao model.UserDao) UserService &#123;\treturn &amp;UserServiceImpl&#123; userDao,\t&#125;&#125;func (userService *UserServiceImpl) Login(ctx context.Context, email, password string) (*UserInfoDTO, error) &#123;\tuser, err := userService.userDao.SelectByEmail(email)\tif err == nil &#123; if user.Password == password &#123; return &amp;UserInfoDTO&#123; ID: user.ID, Username: user.Username, Email: user.Email, &#125;, nil &#125; else &#123; return nil, ErrPassword &#125;\t&#125; else &#123; log.Printf(&quot;err : %s&quot;, err)\t&#125;\treturn nil, err&#125;func (userService UserServiceImpl) Register(ctx context.Context, user *RegisterUser) (*UserInfoDTO, error) &#123;\tret := model.RedisClient.SetNX(user.Email, 1, time.Duration(5)*time.Second)\tif ret.Val() == false &#123; return nil, ErrRegistering\t&#125;\tdefer model.RedisClient.Del(user.Email)\texistUser, err := userService.userDao.SelectByEmail(user.Email)\tif (err == nil &amp;&amp; existUser == nil) || err == gorm.ErrRecordNotFound &#123; newUser := &amp;model.UserEntity&#123; Username: user.Username, Password: user.Password, Email: user.Email, &#125; err = userService.userDao.Save(newUser) if err == nil &#123; return &amp;UserInfoDTO&#123; ID: newUser.ID, Username: newUser.Username, Email: newUser.Email, &#125;, nil &#125;\t&#125;\tif err == nil &#123; err = ErrUserExisted\t&#125;\treturn nil, err&#125; 此处注意分布式锁的实现，利用了Redis的setnx方法，并可以设置过期时间，对应Redis中的 SET key value [EX seconds] [PX milliseconds] [NX|XX] ret := model.RedisClient.SetNX(user.Email, 1, time.Duration(5)*time.Second)if ret.Val() == false &#123;\treturn nil, ErrRegistering&#125;defer model.RedisClient.Del(user.Email) 对于endpoint和transport，就与之前的没有太大差别了，我们这里就暂时略去，有兴趣可点击文章最后的源码查看。 mysql和Redis容器mysql的Dockerfile： FROM mysql:5.7 WORKDIR /docker-entrypoint-initdb.d ENV LANG=C.UTF-8COPY user.sql . 运行mysql-for-user容器 docker run -itd --name mysql-for-user -p 3316:3306 -e MYSQL_ROOT_PASSWORD=111111 mysql-for-user 这里容器启动的时候是可以执行user.sql的。（可通过docker logs mysql-for-user查看容器启动信息） /usr/local/bin/docker-entrypoint.sh: running /docker-entrypoint-initdb.d/user.sql Redis容器的启动简单 docker pull Redis:5.0docker run -itd --name Redis5 -p 6389:6379 Redis:5.0 然后我们可以运行主程序，智能到8089端口： go run main.go -service.port 8089 测试一下。 可以实现登录与注册功能。 打包会员镜像先编译： CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -o user . user的dockerfile FROM alpine:3.12 WORKDIR /COPY ./user /ENTRYPOINT [&quot;./user&quot;] 构建镜像: docker build -t user-alpine . docker-composeversion: &#x27;2.1&#x27;services: user13: image: user-alpine depends_on: - Redis - mysql ports: - &quot;8088:8088&quot; links: - Redis - mysql networks: - user mysql: image: mysql-for-user ports: - &quot;3306:3306&quot; expose: - &quot;3306&quot; environment: - MYSQL_ROOT_PASSWORD=111111 networks: - user restart: always Redis: image: Redis:5.0 ports: - &quot;6379:6379&quot; expose: - &quot;6379&quot; networks: - usernetworks: user: driver: bridge 说明： depends_on 依赖，此处表示user13依赖Redis、mysql，被依赖者会优先构建，但是是可能脚本为运行成功的，所以user13是有可能刚开始连接不上mysql的，docker start即可 links 连接，此处user13连接到Redis、mysql，可以用它们替代连接数据库的host environment 环境变量 expose 对links暴露的端口 运行docker-compose up即可。 可以看见服务运行成功了。wow～ 详细代码点击进github dcoker composer语法可看菜鸟教程： Docker Compose | 菜鸟教程 文中部分知识来自《Go微服务实战38讲》，有兴趣可前往查看：","tags":["goexample"],"categories":["goexample"]},{"title":"goruntine和channel","path":"/2021/02/12/goexample8/","content":"前面几个回合，我们都是实例，但在go中有个很常用的东东，我们代码使用的不多，这一次我们单独拿来讲讲。 goroutine goroutine是go语言特有的并发体，是一种轻量级的线程，由go关键字启动。 goroutine采用的是半抢占市的协作调度，只有当前goroutine发生阻塞时才会导致调度（也就是goroutine的切换）。 那么项目中使用了多个goroutine，如何在不同的goroutine之间通信呢？ 学习go的过程中，想必你应该知道有这么一个经典的句子： Do not communicate by sharing memory; instead, share memory by communicating. goroutine的通信用通道 通道是个啥？ 一个通道相当于一个先进先出（FIFO）的队列，通道中的各个元素是严格地按照发送的顺序排列的，先被发送通道的一定会先被接收。元素的发送和接收都需要用到操作符&lt;-。 这里有一个FIFO简单的例子 package mainimport &quot;fmt&quot;func main() &#123;\tch := make(chan int, 5)\tch &lt;- 1\tch &lt;- 2\tch &lt;- 3\tch &lt;- 4\tch &lt;- 5\tfmt.Println(&quot;1-&quot;, &lt;-ch)\tfmt.Println(&quot;2-&quot;, &lt;-ch)\tch &lt;- 6\tfmt.Println(&quot;3-&quot;, &lt;-ch)\tfmt.Println(&quot;4-&quot;, &lt;-ch)\tfmt.Println(&quot;5-&quot;, &lt;-ch)\tfmt.Println(&quot;6-&quot;, &lt;-ch)\tclose(ch)&#125;/*打印的内容如下：1- 12- 23- 34- 45- 56- 6*/ 我们再来看一下通道的常规操作： 创建通道通道（channel）分两种（容量是否为0）： 缓冲通道 非缓冲通道 // 缓冲通道ch1 := make(chan int, 10)ch2 := make(chan bool, 2)// 非缓冲通道ch3 := make(chan int)ch4 := make(chan bool, 0) 发送通道数据// 创建一个空接口通道，注意定义的通道类型有ch := make(chan interface&#123;&#125;)// 将0放入通道中ch &lt;- 0// 将hello字符串放入通道中ch &lt;- &quot;hello&quot; 接收通道数据1. 阻塞接收数据阻塞模式接收数据时，将接收变量作为&lt;-操作符的左值，格式如下： data := &lt;-ch 执行该语句时将会阻塞，直到接收到数据并赋值给 data 变量。 2. 非阻塞接收数据使用非阻塞方式从通道接收数据时，语句不会发生阻塞，格式如下： data, ok := &lt;-ch// data：表示接收到的数据。未接收到数据时，data 为通道类型的零值// ok：表示是否接收到数据。 非阻塞的通道接收方法可能造成高的 CPU 占用，因此使用非常少。如果需要实现接收超时检测，可以配合 select 和计时器 channel 进行，可以参见后面的内容。 3. 接收任意数据，忽略接收的数据阻塞接收数据后，忽略从通道返回的数据，格式如下： &lt;-ch 4. 循环接收通道的数据接收可以借用 for range 语句进行多个元素的接收操作，格式如下： package mainimport ( &quot;fmt&quot; &quot;time&quot;)func main() &#123; // 构建一个通道 ch := make(chan int) // 开启一个并发匿名函数 go func() &#123; // 从3循环到0 for i := 3; i &gt;= 0; i-- &#123; // 发送3到0之间的数值 ch &lt;- i // 每次发送完时等待 time.Sleep(time.Second) &#125; &#125;() // 遍历接收通道数据 for data := range ch &#123; // 打印通道数据 fmt.Println(data) // 当遇到数据0时, 退出接收循环 if data == 0 &#123; break &#125; &#125;&#125; 关闭通道ch := make(chan string)...close(ch) 通道特性 对于同一个通道，发送操作之间是互斥的，接收操作之间也是互斥的（并发安全） 发送操作和接收操作中对元素值的处理都是不可分割的。 发送操作在完全完成之前会被阻塞，接收操作也是一样。 对于缓冲通道：如果通道已满，那么对它的所有发送操作都会被阻塞，直到通道中有元素值被接收走；如果通道已空，那么对它的所有接收操作都会被阻塞，直到通道中有新的元素值出现。 对于非缓冲通道：无论是发送操作还是接收操作，一开始执行就会被阻塞，直到配对的操作也开始执行，才会继续传递。 注意点： 关闭通道要在发送方关闭，关闭后如果channel内还有元素，并不会对接下来的接收产生影响 单向通道最主要的用途就是约束其他代码的行为 通过函数的参数类型或者返回值类型来限制（Go的语法糖）。 func(ch chan&lt;- int)；传入双向通道，在函数里面调用ch只能发送func() (ch &lt;-chan int)；返回双向通道，在函数外面里面调用ch只能接收 说到这里，我们提一下channel独有的关键字——select。 A “select” statement chooses which of a set of possible send or receive operations will proceed. It looks similar to a “switch” statement but with the cases all referring to communication operations. 一个select语句用来选择哪个case中的发送或接收操作可以被立即执行。它类似于switch语句，但是它的case涉及到channel有关的I/O操作。 说完这些概念性的玩意儿，我们还是来几个实例，感受一下goroutine配合channel使用的快感。 chan配合select实现超时处理func main() &#123;\ttimeout := make(chan bool)\tgo func() &#123; time.Sleep(3e9) timeout &lt;- true\t&#125;()\tch := make(chan int)\tselect &#123;\tcase &lt;-ch:\tcase &lt;-timeout: fmt.Println(&quot;timeout!&quot;)\t&#125;&#125; 非缓冲通道，监听信号量// 来自gin文档的例子func main() &#123;\trouter := gin.Default()\trouter.GET(&quot;/&quot;, func(c *gin.Context) &#123; time.Sleep(5 * time.Second) c.String(http.StatusOK, &quot;Welcome Gin Server&quot;)\t&#125;)\tsrv := &amp;http.Server&#123; Addr: &quot;:8080&quot;, Handler: router,\t&#125;\tgo func() &#123; // 服务连接 if err := srv.ListenAndServe(); err != nil &amp;&amp; err != http.ErrServerClosed &#123; log.Fatalf(&quot;listen: %s &quot;, err) &#125;\t&#125;()\t// 等待中断信号以优雅地关闭服务器（设置 5 秒的超时时间）\tquit := make(chan os.Signal)\tsignal.Notify(quit, os.Interrupt)\t&lt;-quit\tlog.Println(&quot;Shutdown Server ...&quot;)\tctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\tdefer cancel()\tif err := srv.Shutdown(ctx); err != nil &#123; log.Fatal(&quot;Server Shutdown:&quot;, err)\t&#125;\tlog.Println(&quot;Server exiting&quot;)&#125; 当然还有其他应用场景，如消息传递、消息过滤，事件订阅与广播，请求、响应转发，并发控制，同步与异步等，可参考下面的文章： 总结了才知道，原来channel有这么多用法！ 实例代码点击见githubgithub.com/puresai/go-example/tree/main/demo8-goroutine-channel 参考： Go语言通道（chan）——goroutine之间通信的管道 Go语言核心36讲_Golang_Go语言-极客时间","tags":["goexample"],"categories":["goexample"]},{"title":"golang限流器","path":"/2021/02/12/goexample9/","content":"限流应该是我们开发中经常遇到的了，限流器能保证我们不至于在流量过大的时候服务超过负载，能有效地保证服务的可用和稳定。 go自带有限流器rate，它的本质其实就是令牌桶。用起来也十分简单。我们修改下之前的http服务做一些修改： func main() &#123;\t// ServeMux类型是HTTP请求的多路转接器。它会将每一个接收的请求的URL与一个注册模式的列表进行匹配，并调用和URL最匹配的模式的处理器。\tmux := http.NewServeMux()\tmux.HandleFunc(&quot;/&quot;, defaultHttp)\thttp.ListenAndServe(&quot;:8080&quot;, middlewareLimit(mux))&#125;// 限流桶var limiter = rate.NewLimiter(rate.Every(time.Second), 1)func middlewareLimit(next http.Handler) http.Handler &#123;\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) &#123; if limiter.Allow() == false &#123; fmt.Println(&quot;limit&quot;) return &#125; next.ServeHTTP(w, r)\t&#125;)&#125;// 默认http处理func defaultHttp(w http.ResponseWriter, r *http.Request) &#123;\tpath := r.URL.Path\tif path == &quot;/&quot; &#123; w.Write([]byte(&quot;index&quot;)) fmt.Println(&quot;index&quot;) return\t&#125;\t// 自定义404\thttp.Error(w, &quot;you lost???&quot;, http.StatusNotFound)&#125; 这里的 var limiter = rate.NewLimiter(rate.Every(2*time.Second), 1) 就是定义了一个限流器，生成速率是1 个/s，令牌桶的容量是1。也就是每秒最多能通过2个请求。 我们可以用ab或者快速刷新浏览器来看一下效果 是不是有点类似nginx的限流模块： limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s;server &#123; ... location / &#123; #缓存区队列burst=5个,nodelay表示不延期(超过的请求失败)，即每秒最多可处理rate+burst个,同时处理rate个。 limit_req zone=one burst=1 nodelay; &#125;&#125; 上面的代码有两处注意点： middlewareLimit 可看作一个http server的前置中间件，你可以类比去自己处理复杂的http中间件业务。 限流器的初始化务必在中间件前生成，可以尝试修改代码再测试: func middlewareLimit(next http.Handler) http.Handler &#123;\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) &#123; limiter := rate.NewLimiter(rate.Every(2*time.Second), 10) if limiter.Allow() == false &#123; fmt.Println(&quot;limit&quot;) return &#125; next.ServeHTTP(w, r)\t&#125;)&#125; 此外，Limiter 也有其他的方法： SetLimit(Limit) 动态修改放入令牌的速率 SetBurst(int) 动态修改桶大小 Wait/WaitN 当没有可用事件时，将阻塞等待 Reserve/ReserveN 当没有可用事件时，返回 Reservation，和要等待多久才能获得足够的事件 代码点击见githubgithub.com/puresai/go-example/tree/main/demo9-rate","tags":["goexample"],"categories":["goexample"]},{"title":"2020,这一年","path":"/2021/02/11/2020/","content":"大家，过年好啊！ 又到除夕了，大家除夕快乐～ 公众号有半年没更新，一来自己懒了，二来之前找的编辑器实在不好用，知乎和自己博客倒是发了一些文章，想着有这年终总结的习惯，就来总结一下吧。 生活完成了一件人生大事，在对象所在城市买房了，虽然一下子成了百万负翁，但好在两个人心里踏实了一点。 因为疫情的原因，人生大事进度受了影响，都凑到年后了，特殊情况，不急着。 自己也终于决定去医院，治疗自己困扰多年的鼾症，过程痛苦，在ICU躺了一天一夜，好在术后恢复良好，术后也感觉呼吸比之前要舒畅得多。去年治了半年的湿疹，如今也好多了，偶有复发，无甚影响。 偶有不适头晕耳鸣，好在元旦后体检结果，除了要控制下饮食，多运动，没有太大问题。还是要多运动，少油腻，三餐规律，早睡早起。 游泳，自学成才，蛙泳50m一分钟，自由泳50m一分半，只会右侧换气，七八月份早上6点起来游早场，还坚持下来了。给自己点个赞，运动方面的学习能力还是可以的。 工作相比去年要忙得多，不过还能接受，有意识地将学习的知识引入到项目中，做一些架构演进，提高工作效率和可用性。今年也把vue-element-admin也给用得很熟练了，基本做的后台都是这个，快速搭建，贼好用。 来年希望主要语言转到go，具体的就不明确了，看工作需要。 其他关于理财，自己在七月行情中各种瞎操作，亏了，心疼啊，好在后续看好的行业还不错，就当交学费了，来年还是基金吧，没那么多时间看盘，看行业，看长期，看趋势。 新年计划 多尝试自媒体，不局限于公众号、知乎 注意饮食，作息规律 多运动，篮球游泳，注意体重 深入微服务技术栈 媳妇娶回家 最后祝各位除夕快乐，阖家幸福！拜年啦 庚子除夕于扬州","tags":["oneyear"],"categories":["oneyear"]},{"title":"Docker基础与常用命令","path":"/2021/02/10/312/","content":"Docker 是什么？Docker 属于 Linux 容器的一种封装，提供简单易用的容器使用接口。它是目前最流行的 Linux 容器解决方案。 Docker 将应用程序与该程序的依赖，打包在一个文件里面。运行这个文件，就会生成一个虚拟容器。程序在这个虚拟容器里运行，就好像在真实的物理机上运行一样。有了 Docker，就不用担心环境问题。 总体来说，Docker 的接口相当简单，用户可以方便地创建和使用容器，把自己的应用放入容器。容器还可以进行版本管理、复制、分享、修改，就像管理普通的代码一样。 Docker的三个概念 镜像（Image）：类似于虚拟机中的镜像，是一个包含有文件系统的面向Docker引擎的只读模板。任何应用程序运行都需要环境，而镜像就是用来提供这种运行环境的。例如一个Ubuntu镜像就是一个包含Ubuntu操作系统环境的模板，同理在该镜像上装上Apache软件，就可以称为Apache镜像。 容器（Container）：类似于一个轻量级的沙盒，可以将其看作一个极简的Linux系统环境（包括root权限、进程空间、用户空间和网络空间等），以及运行在其中的应用程序。Docker引擎利用容器来运行、隔离各个应用。容器是镜像创建的应用实例，可以创建、启动、停止、删除容器，各个容器之间是是相互隔离的，互不影响。注意：镜像本身是只读的，容器从镜像启动时，Docker在镜像的上层创建一个可写层，镜像本身不变。 仓库（Repository）：类似于代码仓库，这里是镜像仓库，是Docker用来集中存放镜像文件的地方。注意与注册服务器（Registry）的区别：注册服务器是存放仓库的地方，一般会有多个仓库；而仓库是存放镜像的地方，一般每个仓库存放一类镜像，每个镜像利用tag进行区分，比如Ubuntu仓库存放有多个版本（12.04、14.04等）的Ubuntu镜像。 Docker 的用途Docker 的主要用途，目前有三大类。 （1）提供一次性的环境。比如，本地测试他人的软件、持续集成的时候提供单元测试和构建的环境。 （2）提供弹性的云服务。因为 Docker 容器可以随开随关，很适合动态扩容和缩容。 （3）组建微服务架构。通过多个容器，一台机器可以跑多个服务，因此在本机就可以模拟出微服务架构。 Docker的优缺点优点1. 更高效的利用系统资源 docker对系统资源的利用率更高，无论是应用执行速度，内存损耗或者文件存储速度，都要比传统虚拟机技术更高效。因此，相比虚拟机技术，一个相同配置的主机往往可以运行更多数量的应用。 2. 更快速的启动时间 传统的虚拟机技术启动应用服务往往需要数分钟，而docker容器应用，由于直接运行于宿主内核，无需启动完整的操作系统，因此可以做到秒级，甚至毫秒级的启动时间，大大的节约了开发测试，部署的时间。 3. 一致的运行环境 开发过程中常见的一个问题是环境一致问题，由于开发环境，测试环境，生产环境不一致，导致有些bug并未在开发过程中发现。而docker的镜像提供了除内核外完整的运行时环境，确保环境一致性，从而不会在出现“这段代码在我机器上没问题”这类问题。 4. 持续支付和部署 对开发和运维人员来说，最希望就是一次创建和部署，可以在任意的地方运行。（定制应用镜像来实现集成、持续支付、部署。开发人员可以通过dockerfile来进行镜像构建，并结合持续集成系统进行集成测试，而运维人员则可以直接在生产环境中快速部署该镜像，甚至结合持续部署系统进行自动部署）。而且使用dockerfile使镜像构建透明化，不仅仅开发团队可以理解应用运行环境，也方便运维团队理解应用运行所需条件，帮助更好的生产环境中部署该镜像。 5. 更轻松的迁移 由于docker确保了执行环境的一致性，使得应用的迁移更加的容易。docker可以在很多平台上运行，无论是物理机、虚拟机、公有云、私有云、甚至是笔记本、其运行结果是一致的。因此用户可以很轻易的将在一个平台上运行的应用，迁移到另一个平台上，而不用担心运行环境的变化导致应用无法正常运行的情况。 6. 更轻松的维护和拓展 docker使用的分层存储以及镜像的技术，使得应用重复部分的复用更为容易，也使得应用的维护更新更加简单，基于基础镜像进一步扩展镜像也变得十分简单。此外，docker团队同各个开源项目团队一起维护了一大批高质量的官网镜像，既可以直接在生产环境使用，又可以作为基础进一步定制，大大的降低了应用服务的镜像制作成本。 缺点1.隔离性 基于hypervisor的虚拟技术，在隔离性上比容器技术要好，它们的系统硬件资源完全上虚拟化的，当一台虚拟机出现系统级别的问题，往往不会蔓延到同一宿主机上的其它虚拟机上，但是容器就不一样了，容器之间共享同一个操作系统内核及其它组件，所以在受到诸如黑客攻击这种情况的时候，很容易通过底层操作系统影响的其它容器，甚至逐个击破，产生连锁反应，当然，这个问题可以通过部署容器来解决，但随之又会产生新的问题，比如成本增加以及性能问题。 2.性能 不管是虚拟机还是容器，都是运用不同的技术对应用本身进行了一定程度的封装与隔离，在降低应用和应用之间以及应用和环境之间的耦合性上做了很多努力，但是随之而来的，就会产生更过的网络连接转发和数据交互，这在低并发系统上虽然不会很明显，但是当同一虚拟机或者服务器下面的容器需要更高并发量支撑的时候，也就是并发问题成为系统瓶颈的时候，容器会将这个问题放大，所以，并不是所有的场景都适合容器技术。 3.存储方案 容器的诞生并不是为OS抽象服务的，这是它和虚拟机最大的区别，这样的基因意味着容器天生是为应用环境做更多的努力，容器的伸缩也是基于容器的这一特性，而与之相对的，需要持久化存储方案恰恰相反，在数据存储这一点上Docker容器提供的解决方案是利用volume接口(存储卷)形成数据的映射和转移，以实现数据持久化的目的。但是这样同样也会造成一部分资源的浪费和更多的交互，不管是映射到宿主机上还是网络磁盘，都是退而求其次的解决方案。 基础命令 启动 docker start 容器名 删除 docker rm 容器名 停止所有容器 docker stop $(docker ps -a -q) 删除所有容器 docker rm $(docker ps -a -q) 容器构建镜像 Usage:docker build [OPTIONS] PATH | URL | -OPTIONS:-t ，--tag list #构建后的镜像名称-f， --file string #指定Dockerfiile文件位置示例:- 1，docker build .- 2，docker build -t Redis:v1 .- 3，docker build -t Redis:v2 -f /path/Dockerfile /path一般常用第2种方式构建，我们在构建时都会切换到Dockerfile文件的目录下进行构建，所以不需要指定-f参数 进入容器（未必一定是bash命令） docker exec -it 容器名 bash 查看容器详细信息 docker inspect 容器名 查看容器的日志 docker logs 容器名 查看本地镜像 docker images docker 网络 命令 说明 docker network connect 将容器连接到网络。 docker network create 创建新的 Docker 网络。默认情况下，在 Windows 上会采用 NAT 驱动，在 Linux 上会采用 Bridge 驱动。可以使用 -d 参数指定驱动（网络类型）。 docker network disconnect 断开容器的网络。 docker network inspect 提供 Docker 网络的详细配置信息。 docker network ls 用于列出运行在本地 Docker 主机上的全部网络。 docker network prune 删除 Docker 主机上全部未使用的网络。 docker network rm 删除 Docker 主机上指定网络。 镜像的保存 docker save ae513a47849c &gt; nginx-save.tarordocker save -o nginx-save.tar ae513a47849c 镜像的导入 docker load &lt; nginx-save.tarordocker load -i nginx-save.tar 容器的导出 docker export -o mysql-`date +%Y%m%d`.tar 220aee82cfea 容器的导入 docker import my_ubuntu_v3.tar runoob/ubuntu:v4 镜像和容器导出和导入的区别: 1.镜像导入是复制的过程2.容器导入是将当前容器变成一个新的镜像 save 和 export区别： save 保存镜像所有的信息-包含历史 export 只导出当前的信息","tags":["Docker"],"categories":["Docker"]},{"title":"sync.Map","path":"/2021/02/06/syncMap/","content":"sync.Map 是1.9版本才加入的，是线程并发安全的map，类型可以看做map[interface{}]interface{}。 结构Maptype Map struct &#123; mu Mutex //互斥锁，用于锁定dirty map read atomic.Value //优先读map,支持原子操作，源码注释写了readOnly不是说read是只读，而是它的结构体是readOnly dirty map[interface&#123;&#125;]*entry // dirty是一个当前最新的map，允许读写 misses int // 主要记录read读取不到数据加锁读取read map以及dirty map的次数，当misses等于dirty的长度时，会将dirty复制到read&#125; readOnly type readOnly struct &#123; m map[interface&#123;&#125;]*entry amended bool // 如果数据在dirty中但没有在read中，该值为true,作为修改标识&#125; entrytype entry struct &#123; // nil: 表示为被删除，调用Delete()可以将read map中的元素置为nil // expunged: 也是表示被删除，但是该键只在read而没有在dirty中，这种情况出现在将read复制到dirty中，即复制的过程会先将nil标记为expunged，然后不将其复制到dirty // 其他: 表示存着真正的数据 p unsafe.Pointer // *interface&#123;&#125;&#125; Load 查找根据key来查找 value， 函数为 Load()，源码如下： func (m *Map) Load(key interface&#123;&#125;) (value interface&#123;&#125;, ok bool) &#123; // 首先从只读ready的map中查找，这时不需要加锁 read, _ := m.read.Load().(readOnly) e, ok := read.m[key] // 如果没有找到，并且read.amended为true，说明dirty中有新数据，从dirty中查找，开始加锁了 if !ok &amp;&amp; read.amended &#123; m.mu.Lock() // 加锁 // 又在 readonly 中检查一遍，因为在加锁的时候 dirty 的数据可能已经迁移到了read中 read, _ = m.read.Load().(readOnly) e, ok = read.m[key] // read 还没有找到，并且dirty中有数据 if !ok &amp;&amp; read.amended &#123; e, ok = m.dirty[key] //从 dirty 中查找数据 // 不管m.dirty中存不存在，都将misses + 1 // missLocked() 中满足条件后就会把m.dirty中数据迁移到m.read中 m.missLocked() &#125; m.mu.Unlock() &#125; if !ok &#123; return nil, false &#125; return e.load()&#125; 从函数可以看出，如果查询的键值正好在m.read中，不需要加锁，直接返回结果，优化了性能。 即使不在read中，经过几次miss后， m.dirty中的数据也会迁移到m.read中，这时又可以从read中查找。所以对于更新／增加较少，加载存在的key很多的case，性能基本和无锁的map类似。 missLockerd 迁移数据func (m *Map) missLocked() &#123; m.misses++ if m.misses &lt; len(m.dirty) &#123;//misses次数小于 dirty的长度，就不迁移数据，直接返回 return &#125; m.read.Store(readOnly&#123;m: m.dirty&#125;) //开始迁移数据 m.dirty = nil //迁移完dirty就赋值为nil m.misses = 0 //迁移完 misses归0&#125; Store 存储func (m *Map) Store(key, value interface&#123;&#125;) &#123; // 直接在read中查找值，找到了，就尝试 tryStore() 更新值 read, _ := m.read.Load().(readOnly) if e, ok := read.m[key]; ok &amp;&amp; e.tryStore(&amp;value) &#123; return &#125; // m.read 中不存在 m.mu.Lock() read, _ = m.read.Load().(readOnly) if e, ok := read.m[key]; ok &#123; if e.unexpungeLocked() &#123; // 未被标记成删除，前面讲到entry数据结构时，里面的p值有3种。1.nil 2.expunged，这个值含义有点复杂，可以看看前面entry数据结构 3.正常值 m.dirty[key] = e // 加入到dirty里 &#125; e.storeLocked(&amp;value) // 更新值 &#125; else if e, ok := m.dirty[key]; ok &#123; // 存在于 dirty 中，直接更新 e.storeLocked(&amp;value) &#125; else &#123; // 新的值 if !read.amended &#123; // m.dirty 中没有新数据，增加到 m.dirty 中 m.dirtyLocked() // 从 m.read中复制未删除的数据 m.read.Store(readOnly&#123;m: read.m, amended: true&#125;) &#125; m.dirty[key] = newEntry(value) //将这个entry加入到m.dirty中 &#125; m.mu.Unlock()&#125; 操作都是先从m.read开始，不满足条件再加锁，然后操作m.dirty。 Delete 删除func (m *Map) Delete(key interface&#123;&#125;) &#123; // 从 m.read 中开始查找 read, _ := m.read.Load().(readOnly) e, ok := read.m[key] if !ok &amp;&amp; read.amended &#123; // m.read中没有找到，并且可能存在于m.dirty中，加锁查找 m.mu.Lock() // 加锁 read, _ = m.read.Load().(readOnly) // 再在m.read中查找一次 e, ok = read.m[key] if !ok &amp;&amp; read.amended &#123; //m.read中又没找到，amended标志位true，说明在m.dirty中 delete(m.dirty, key) // 删除 &#125; m.mu.Unlock() &#125; if ok &#123; // 在 m.ready 中就直接删除 e.delete() &#125;&#125; 使用package mainimport (\t&quot;fmt&quot;\t&quot;sync&quot;)func main() &#123;\tvar sm sync.Map\tsm.Store(&quot;www&quot;, &quot;2343125&quot;)\tsm.Store(&quot;test&quot;, 111)\tvar v interface&#123;&#125;\tv, _ = sm.Load(&quot;www&quot;)\tfmt.Printf(&quot;%T&quot;, v)\tsm.Delete(&quot;test&quot;)\tv, _ = sm.Load(&quot;test&quot;)\tfmt.Printf(&quot;%T&quot;, v)&#125;// string&lt;nil&gt; 参考 sync.Map源码 sync.Map源码分析 深入理解Go语言(05)：sync.map原理分析","tags":["gosourcecode"],"categories":["gosourcecode"]},{"title":"sync.Once","path":"/2021/02/06/syncOnce/","content":"sync.Once的源码十分简单，而且注释十分清楚，直接来看一下。 源码定义了一个结构体Once type Once struct &#123;\tdone uint32 // 是否执行过，初始值为0\tm Mutex // 锁&#125; 对外提供了一个方法Do，Once.Do可以理解成资源初始化，只会执行一次。 func (o *Once) Do(f func()) &#123; // 这里保证原子性的读取o.done，如果未执行0，调用doSlow\tif atomic.LoadUint32(&amp;o.done) == 0 &#123; // Outlined slow-path to allow inlining of the fast-path. o.doSlow(f)\t&#125;&#125;func (o *Once) doSlow(f func()) &#123;\to.m.Lock() // 锁住\tdefer o.m.Unlock() // 最后释放锁 // 如果未执行过f，就执行f，并修改o.done为1 // 这里已经加锁了，保证了原子性，不需要使用atomic.LoadUint32\tif o.done == 0 &#123; defer atomic.StoreUint32(&amp;o.done, 1) f()\t&#125;&#125; 如果你熟悉atomic，这里你可能会有个疑问，Do方法里面为何不直接使用cas原子操作呢，那多简洁？ if atomic.CompareAndSwapUint32(&amp;o.done, 0, 1) &#123;\tf()&#125; 其实源码注释里已经有了说明，这样的实现并不合理。 当你有2个并发请求调用Do，这样的实现确实能保证只会调用一次f。但是，假如f的执行需要一段时间，比如初始化数据库连接池，当f执行尚未完成，并发中另一个请求因为没有执行原子操作直接返回了，使用f中初始化的连接池就必然会失败，那么这样的实现显然是不可取的。 所以必须确保f执行完成之后，才能将done置为1。 使用var one sync.Oncefun1 := func() &#123;\tfmt.Println(&quot;do one&quot;)&#125;fun2 := func() &#123;\tfmt.Println(&quot;do two&quot;)&#125;one.Do(fun1)one.Do(fun2)output:do one 可以看到只执行了一次，也就是fun1。 其实once很适合应用到单例模式，比如连接数据库， package dbimport (\t&quot;github.com/jinzhu/gorm&quot;\t_ &quot;github.com/jinzhu/gorm/dialects/mysql&quot;\t&quot;github.com/spf13/viper&quot;)var once sync.Oncevar db *gorm.DB// 单例模式获取*gorm.DBfunc GetDB() *gorm.DB &#123;\tonce.Do(func() &#123; db = openPool()\t&#125;)\treturn db&#125;func openPool() *gorm.DB &#123;\t...&#125; 好了，Once是很常用的，也很适合单例模式使用，源码简单明了，以后在项目中多多使用吧！","tags":["gosourcecode"],"categories":["gosourcecode"]},{"title":"vue子组件","path":"/2021/01/26/305/","content":"先来看demo: 父组件： &lt;template&gt; &lt;div class=&quot;app-container calendar-list-container&quot;&gt; &lt;el-tabs v-model=&quot;activeName&quot; type=&quot;card&quot;&gt; &lt;el-tab-pane label=&quot;待审核&quot; name=&quot;first&quot;&gt; &lt;test-page status=&quot;1&quot; @toP=&quot;funct&quot;&gt;&lt;/test-page&gt; &lt;/el-tab-pane&gt; &lt;el-tab-pane label=&quot;全部&quot; name=&quot;second&quot;&gt; &lt;test-page status=&quot;0&quot;&gt;&lt;/test-page&gt; &lt;/el-tab-pane&gt; &lt;/el-tabs&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;import TestPage from &#x27;@/views/components/TestPage&#x27;export default &#123; components: &#123; TestPage &#125;, name: &quot;test&quot;, data() &#123; return &#123; activeName: &#x27;first&#x27;, &#125;; &#125;, methods: &#123; funct(v) &#123; console.warn(v) &#125; &#125;&#125;;&lt;/script&gt; 子组件 &lt;template&gt; &lt;div&gt; &lt;el-table key=&quot;tableList&quot; v-loading=&quot;listLoading&quot; :data=&quot;list&quot; element-loading-text=&quot;给我一点时间&quot; border fit highlight-current-row style=&quot;width: 100%&quot; &gt; &lt;el-table-column align=&quot;center&quot; label=&quot;id&quot; &gt; &lt;template slot-scope=&quot;scope&quot;&gt; &lt;span&gt;&#123;&#123; scope.row.id &#125;&#125;&lt;/span&gt; &lt;/template&gt; &lt;/el-table-column&gt; &lt;el-table-column align=&quot;center&quot; label=&quot;地点&quot; &gt; &lt;template slot-scope=&quot;scope&quot;&gt; &lt;span&gt;&#123;&#123; scope.row.address &#125;&#125;&lt;/span&gt; &lt;/template&gt; &lt;/el-table-column&gt; &lt;el-table-column align=&quot;center&quot; label=&quot;状态&quot; &gt; &lt;template slot-scope=&quot;scope&quot;&gt; &lt;el-tag type=&quot;info&quot; v-if=&quot;scope.row.status == 0&quot;&gt;已拒绝&lt;/el-tag&gt; &lt;el-tag v-if=&quot;scope.row.status == 1&quot;&gt;审核中&lt;/el-tag&gt; &lt;el-tag type=&quot;success&quot; v-if=&quot;scope.row.status == 2&quot;&gt;已通过&lt;/el-tag&gt; &lt;/template&gt; &lt;/el-table-column&gt; &lt;el-table-column align=&quot;center&quot; label=&quot;活动时间&quot; &gt; &lt;template slot-scope=&quot;scope&quot;&gt; &lt;span&gt;&#123;&#123; scope.row.start_date &#125;&#125;&lt;/span&gt;&lt;br&gt;至 &lt;span&gt;&#123;&#123; scope.row.end_date &#125;&#125;&lt;/span&gt; &lt;/template&gt; &lt;/el-table-column&gt; &lt;/el-table&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;...export default &#123; name: &quot;TestPage&quot;, props: [&#x27;status&#x27;], data() &#123; return &#123; list: [], pagination: &quot;&quot;, listQuery: &#123; page: 1, limit: 20, status: 1, type:&#x27;&#x27;, &#125;, typeList: [], dialogFormVisible: false, temp: &#123; image : &#x27;&#x27;, user: &#123; nickname: &#x27;&#x27;, &#125;, college: &#123; name: &quot;&quot;, &#125;, materials: [], &#125;, &#125;; &#125;, created() &#123; this.listQuery.status = this.$props.status; this.getList(); this.$emit(&#x27;toP&#x27;, this.listQuery) &#125;, methods: &#123; ... &#125;&#125;;&lt;/script&gt;&lt;style&gt;.row-container .el-row &#123; margin-bottom: 20px; &amp;:last-child &#123; margin-bottom: 0; &#125; &#125;&lt;/style&gt; 这个demo简单使用了组件引入，及子组件于父组件通信。 引入子组件import TestPage from &#x27;@/views/components/TestPage&#x27;export default &#123; components: &#123; TestPage &#125;, 使用: &lt;test-page&gt;&lt;/test-page&gt; 父组件传递数据到子组件父组件的status就是传递的数据 &lt;test-page status=&quot;0&quot;&gt;&lt;/test-page&gt; 子组件接收： this.$props.status 子组件传递数据到父组件子组件，其实是传递了一个toP事件 this.$emit(&#x27;toP&#x27;, this.listQuery) 父组件 &lt;test-page @toP=&quot;funct&quot;&gt;&lt;/test-page&gt;...methods: &#123; funct(v) &#123; console.warn(v) &#125;&#125; 这里需要稍微注意的就是驼峰命名转**-**，使用相对简单。","tags":["vue"],"categories":["js"]},{"title":"网站不能访问的问题集合","path":"/2021/01/13/302/","content":"https访问不了现象https访问不了，绑定host可访问，网站无报错 排查ping域名对于ip也正常，telnet 443端口失败 处理开启443端口 加了CDN的部分页面突然打不开现象加了cdn的部分页面打不开，http页面访问正常，绑定host访问也正常 打不开的情况nginx有报错如： pwritev() “/usr/local/webserver/nginx_new/fastcgi_temp/1/96/0001214961” failed (28: No space left on device) while reading upstream, client: 61.241.120.188, server:www.puresai.com, request: “GET / HTTP/1.1”, upstream: “fastcgi://127.0.0.1:9000”, host: “www.puresai.com&quot;，后又反馈后台文件上传失败 排查去掉cdn能正常访问，挂载磁盘未满，系统盘满，乍一看是cdn和waf问题 处理系统盘100%，注意No space left on device，挪动大文件到挂载的磁盘，cdn页面也恢复正常 建议上传大文件，下载大文件尽量别放在系统盘","tags":["web"],"categories":["web"]},{"title":"go源码之context","path":"/2021/01/06/context/","content":"定义说明 Package context defines the Context type, which carries deadlines, cancelation signals, and other request-scoped values across API boundaries and between processes.Incoming requests to a server should create a Context, and outgoing calls to servers should accept a Context. The chain of function calls between them must propagate the Context, optionally replacing it with a derived Context created using WithCancel, WithDeadline, WithTimeout, or WithValue. When a Context is canceled, all Contexts derived from it are also canceled. 粗略翻译一下就是： context定义了上下文类型，它携带跨越API边界和进程之间的deadlines、取消信号和其他请求范围的值。对服务器的传入请求应该创建上下文，对服务器的传出调用应该接受上下文。它们之间的函数调用链必须传播上下文，可以选择用使用WithCancel、WithDeadline、WithTimeout或WithValue创建的派生上下文替换它。当一个上下文被取消时，所有从它派生的上下文也被取消。 源码结构 名称 类型 说明 Context interface 定义了 Context 接口的四个方法Deadline、Done、Err、Value emptyCtx int 注意：emptyCtx永远不会取消，没有值，也没有截止日期。这里使用的是类型等价定义，emptyCtx等价于int类型。并且定义上面的四个方法和String方法。 Background func 返回new(emptyCtx) TODO func 返回new(emptyCtx) CancelFunc func CancelFunc告诉操作放弃其工作，不等待工作停止。多个goroutine可以同时调用CancelFunc。在第一个调用之后，对CancelFunc的后续调用将不执行任何操作。 WithCancel func WithCancel返回一个带有新的Done通道的parent副本。当返回的cancel函数被调用时，上下文的Done通道被关闭或者当父上下文的Done通道关闭时，无论哪个先发生。取消此上下文将释放与之相关的资源，代码也应该如此在此上下文中运行的操作一完成，就调用cancel。 newCancelCtx func 返回一个初始化的cancelCtx propagateCancel func propagateCancel在父元素被取消时取消子元素，这里有用到原子锁 parentCancelCtx func 找到第一个可取消的父节点 removeChild func 移除父节点的子节点 canceler interface 取消者，定义了cancel和Done两个方法 init func 初始化方法 cancelCtx struct 一个可以取消的 Context contextName func 返回上下文名称 WithDeadline func 创建一个有 deadline 的 context timerCtx struct timerCtx带有timeout 和deadline 。它将cancelCtx嵌入到实现Done和Err。它通过停止计时器来实现取消，然后委托给cancelCtx.cancel。 WithTimeout func 创建一个有 timeout 的 context WithValue func 创建一个存储 k-v 对的 context valueCtx struct 存储k-v，配合WithValue使用 stringify func 接口类型返回字符串 Contexttype Context interface &#123;\t// 获取设置的截止时间的意思，第一个返回式是截止时间，到了这个时间点，Context会自动发起取消请求；第二个返回值ok==false时表示没有设置截止时间，如果需要取消的话，需要调用取消函数进行取消\tDeadline() (deadline time.Time, ok bool)\t// 返回一个只读的chan，类型为struct&#123;&#125;，我们在goroutine中，如果该方法返回的chan可以读取，则意味着parent context已经发起了取消请求，我们通过Done方法收到这个信号后，就应该做清理操作，然后退出goroutine，释放资源。\tDone() &lt;-chan struct&#123;&#125;\t// 在 channel Done 关闭后，返回 context 取消原因\tErr() error\t// 获取该Context上绑定的值，是一个键值对，所以要通过一个Key才可以获取对应的值，这个值一般是并发安全的\tValue(key interface&#123;&#125;) interface&#123;&#125;&#125; cancelertype canceler interface &#123;\tcancel(removeFromParent bool, err error)\tDone() &lt;-chan struct&#123;&#125;&#125; 实现了上面定义的两个方法的 Context，就表明该 Context 是可取消的。源码中有两个类型实现了 canceler 接口：*cancelCtx 和 *timerCtx。注意是加了 * 号的，是这两个结构体的指针实现了 canceler 接口。 接口设计成这个样子的原因： “取消”操作应该是建议性，而非强制性 “取消”操作应该可传递 emptyCtxtype emptyCtx intfunc (*emptyCtx) Deadline() (deadline time.Time, ok bool) &#123;\treturn&#125;func (*emptyCtx) Done() &lt;-chan struct&#123;&#125; &#123;\treturn nil&#125;func (*emptyCtx) Err() error &#123;\treturn nil&#125;func (*emptyCtx) Value(key interface&#123;&#125;) interface&#123;&#125; &#123;\treturn nil&#125;func (e *emptyCtx) String() string &#123;\tswitch e &#123;\tcase background: return &quot;context.Background&quot;\tcase todo: return &quot;context.TODO&quot;\t&#125;\treturn &quot;unknown empty Context&quot;&#125;// cancelCtxtype cancelCtx struct &#123;\tContext\tmu sync.Mutex // 互斥锁\tdone chan struct&#123;&#125; children map[canceler]struct&#123;&#125; err error &#125; 我们重点看一下 cancel 这个方法 func (c *cancelCtx) cancel(removeFromParent bool, err error) &#123;\tif err == nil &#123; panic(&quot;context: internal error: missing cancel error&quot;)\t&#125;\tc.mu.Lock()\tif c.err != nil &#123; c.mu.Unlock() return // 已经被其他协程取消\t&#125;\t// 给 err 字段赋值\tc.err = err\t// 关闭 channel，通知其他协程\tif c.done == nil &#123; c.done = closedchan\t&#125; else &#123; close(c.done)\t&#125; // 遍历它的所有子节点\tfor child := range c.children &#123; // 递归地取消所有子节点 child.cancel(false, err)\t&#125;\t// 将子节点置空\tc.children = nil\tc.mu.Unlock()\tif removeFromParent &#123; // 从父节点中移除自己 removeChild(c.Context, c)\t&#125;&#125; cancel()方法的功能就是关闭 channel：c.done；递归地取消它的所有子节点；从父节点从删除自己。达到的效果是通过关闭 channel，将取消信号传递给了它的所有子节点。 func WithCancel(parent Context) (ctx Context, cancel CancelFunc)func WithDeadline(parent Context, deadline time.Time) (Context, CancelFunc)func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc)func WithValue(parent Context, key, val interface&#123;&#125;) Context 上面四个可以理解为Context的继承衍生。对于我们日常使用来说，学会Context的继承的4个方法和Background、TODO基本就够了。 Context使用场景 超时请求 package mainimport ( &quot;context&quot; &quot;fmt&quot; &quot;time&quot;)func main() &#123; ctx, cancel := context.WithTimeout(context.Background(), 50*time.Millisecond) defer cancel() select &#123; case &lt;-time.After(1 * time.Second): fmt.Println(&quot;overslept&quot;) case &lt;-ctx.Done(): fmt.Println(ctx.Err()) // prints &quot;context deadline exceeded&quot; &#125;&#125; 共享数据 package mainimport (\t&quot;context&quot;\t&quot;fmt&quot;)func main() &#123;\tctx := context.Background()\tprocess(ctx)\tctx = context.WithValue(ctx, &quot;traceId&quot;, &quot;qcrao-2019&quot;)\tprocess(ctx)&#125;func process(ctx context.Context) &#123;\ttraceId, ok := ctx.Value(&quot;traceId&quot;).(string)\tif ok &#123; fmt.Printf(&quot;process over. trace_id=%s &quot;, traceId)\t&#125; else &#123; fmt.Printf(&quot;process over. no trace_id &quot;)\t&#125;&#125; 这个在web开发中很实用，传递session、token等信息。 防止 goroutine 泄漏package mainimport (\t&quot;time&quot;\t&quot;fmt&quot;)func gen() &lt;-chan int &#123;\tch := make(chan int)\tgo func() &#123; var n int for &#123; ch &lt;- n n++ time.Sleep(time.Second) &#125;\t&#125;()\treturn ch&#125;func main() &#123;\tfor n := range gen() &#123; fmt.Println(n) if n == 5 &#123; break &#125;\t&#125;&#125; 当 n = 5 的时候，直接 break 。但是 gen 的协程就会执行无限循环，永远不会停下来。发生了 goroutine 泄漏。 package mainimport (\t&quot;time&quot;\t&quot;fmt&quot;\t&quot;context&quot;)func gen(ctx context.Context) &lt;-chan int &#123;\tch := make(chan int)\tgo func() &#123; var n int for &#123; select &#123; case &lt;-ctx.Done(): return case ch &lt;- n: n++ time.Sleep(time.Second) &#125; &#125;\t&#125;()\treturn ch&#125;func main() &#123;\tctx, cancel := context.WithCancel(context.Background())\tdefer cancel() // 避免其他地方忘记 cancel，且重复调用不影响\tfor n := range gen(ctx) &#123; fmt.Println(n) if n == 5 &#123; cancel() break &#125;\t&#125;&#125; Context 使用原则最后记住几个主要的使用原则： 不要将 Context 塞到结构体里。直接将 Context 类型作为函数的第一参数，而且一般都命名为 ctx。 不要向函数传入一个 nil 的 context，如果你实在不知道传什么，标准库给你准备好了一个 context：todo。 不要把本应该作为函数参数的类型塞到 context 中，context 存储的应该是一些共同的数据。例如：登陆的 session、cookie 等。 同一个 context 可能会被传递到多个 goroutine，别担心，context 是并发安全的。 参考文章： 深度解密Go语言之context Go语言实战笔记（二十）| Go Context","tags":["gosourcecode"],"categories":["gosourcecode"]},{"title":"x/rate/limit","path":"/2021/01/06/rate/","content":"限流是保证服务可用性和稳定的利器之一。go自带有限流器rate，我们来研读一下源码，源码较少，我们列出主要代码部分，注释说明： // 限定速率type Limit float64// 常量Inf：无速率限制const Inf = Limit(math.MaxFloat64)// 限流器的结构体，本质就是一个令牌桶，type Limiter struct &#123; mu sync.Mutex limit Limit burst int tokens float64 // 记录上次 Limiter 被更新的时间 last time.Time // lastEvent 记录速率受限制的时间 lastEvent time.Time&#125;// new一个新的限流器 *Limiter，r是速率，b是允许突发的令牌数量func NewLimiter(r Limit, b int) *Limiter &#123; return &amp;Limiter&#123; limit: r, burst: b, &#125;&#125;// Reservation 保存了限流器延迟后发生的事件信息type Reservation struct &#123; // 是否满足条件分配了令牌啊 ok bool // 限流器 lim *Limiter // 令牌数量 tokens int // 满足令牌发放的时间 timeToAct time.Time // 令牌发放速率 limit Limit&#125;// 这是一个重要的内部函数，返回一个Reservationfunc (lim *Limiter) reserveN(now time.Time, n int, maxFutureReserve time.Duration) Reservation &#123; // 互斥锁，保证原子性 lim.mu.Lock() // 判断速率是不是最大，是的话无需限流 if lim.limit == Inf &#123; lim.mu.Unlock() return Reservation&#123; ok: true, lim: lim, tokens: n, timeToAct: now, &#125; &#125; // 调用 advance 方法，获取最新的时间、上一次取得令牌的时间、最新的token数量 now, last, tokens := lim.advance(now) // 更新token数量 tokens -= float64(n) // 计算等待时间，数量小于0表示令牌桶中木有可用的令牌了 var waitDuration time.Duration if tokens &lt; 0 &#123; waitDuration = lim.limit.durationFromTokens(-tokens) &#125; // 计算结果 ok := n &lt;= lim.burst &amp;&amp; waitDuration &lt;= maxFutureReserve // 初始化 Reservation r := Reservation&#123; ok: ok, lim: lim, limit: lim.limit, &#125; // 更新令牌桶数量和时间 if ok &#123; r.tokens = n r.timeToAct = now.Add(waitDuration) &#125; // 更新限流器最新取得令牌的时间、数量、事件 if ok &#123; lim.last = now lim.tokens = tokens lim.lastEvent = r.timeToAct &#125; else &#123; lim.last = last &#125; lim.mu.Unlock() return r&#125;// 计算时间变化的 Limiter 的状态变化，得到最新的时间，最后一次取得令牌的时间和 token 令牌数量func (lim *Limiter) advance(now time.Time) (newNow time.Time, newLast time.Time, newTokens float64) &#123; last := lim.last if now.Before(last) &#123; last = now &#125; maxElapsed := lim.limit.durationFromTokens(float64(lim.burst) - lim.tokens) elapsed := now.Sub(last) if elapsed &gt; maxElapsed &#123; elapsed = maxElapsed &#125; delta := lim.limit.tokensFromDuration(elapsed) tokens := lim.tokens + delta if burst := float64(lim.burst); tokens &gt; burst &#123; tokens = burst &#125; return now, last, tokens&#125;// 这里单独放出来，是提醒一下，go也有精度缺失问题，所以复杂计算要注意func (limit Limit) tokensFromDuration(d time.Duration) float64 &#123; sec := float64(d/time.Second) * float64(limit) nsec := float64(d%time.Second) * float64(limit) return sec + nsec/1e9&#125; 使用实例和demo可看： golang 限流器","tags":["gosourcecode"],"categories":["gosourcecode"]},{"title":"MongoDB的简单使用说明","path":"/2020/12/24/301/","content":"安装// 下载，注意下载对应的系统版本，否则安装会报错wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-rhel70-4.4.1.tgz// 解压即可，无需编译安装tar -zxvf mongodb-linux-x86_64-rhel70-4.4.1.tgzmv mongodb-linux-x86_64-rhel70-4.4.1 /usr/local/mongodb 启动服务新建mongodb.conf（版本可能不一样，略有不同） dbpath = /data/mongodb/data #数据文件存放目录 logpath = /data/mongodb/log/mongodb.log #日志文件存放目录 port = 27000 #端口 fork = true #以守护程序的方式启用，即在后台运行 bind_ip=127.0.0.1 cd /usr/local/mongodb/// 启动服务bin/mongod -f ./mongodb.conf 新增用户设置密码 use admin;db.createUser(&#123;user:&quot;root&quot;,pwd:&quot;666888&quot;,roles:[&quot;userAdminAnyDatabase&quot;]&#125;);use test;db.createUser(&#123; user: &quot;test&quot;, pwd: &quot;123456&quot;, roles: [&#123;role: &quot;readWrite&quot;,db: &quot;hotel&quot;&#125;]&#125;)db.createUser( &#123; user: &quot;admin&quot;, pwd: &quot;5176567&quot;, roles: [&#123;role: &quot;userAdminAnyDatabase&quot;, db: &quot;admin&quot;&#125;] &#125;) role的说明 Read：允许用户读取指定数据库readWrite：允许用户读写指定数据库dbAdmin：允许用户在指定数据库中执行管理函数，如索引创建、删除，查看统计或访问system.profileuserAdmin：允许用户向system.users集合写入，可以找指定数据库里创建、删除和管理用户clusterAdmin：只在admin数据库中可用，赋予用户所有分片和复制集相关函数的管理权限。readAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的读权限readWriteAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的读写权限userAdminAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的userAdmin权限dbAdminAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的dbAdmin权限。root：只在admin数据库中可用。超级账号，超级权限 建议出root和admin，各个数据库使用自己独立的账号密码。 auth尝试一下，如果返回1，表示auth验证成功 db.auth(&#x27;root&#x27;, &#x27;666888&#x27;) 常用命令关闭mongo服务 use admindb.shutdownServer() 清空当前数据库 use xxxdb.dropDatabase() 集成到Laravel安装 composer require jenssegers/mongodb 3.6.x 低版本需要在config/app.php加入 Jenssegers\\Mongodb\\MongodbServiceProvider::class, 配置database.php &#x27;mongodb&#x27; =&gt; [ &#x27;driver&#x27; =&gt; &#x27;mongodb&#x27;, &#x27;host&#x27; =&gt; env(&#x27;MONGODB_HOST&#x27;, &#x27;127.0.0.1&#x27;), &#x27;port&#x27; =&gt; env(&#x27;MONGODB_PORT&#x27;, 27017), &#x27;database&#x27; =&gt; env(&#x27;MONGODB_DATABASE&#x27;, &#x27;test&#x27;), &#x27;username&#x27; =&gt; env(&#x27;MONGODB_USERNAME&#x27;, &#x27;test&#x27;), &#x27;password&#x27; =&gt; env(&#x27;MONGODB_PWD&#x27;, &#x27;&#x27;), &#x27;options&#x27; =&gt; [ // here you can pass more settings to the Mongo Driver Manager // see https://www.php.net/manual/en/mongodb-driver-manager.construct.php under &quot;Uri Options&quot; for a list of complete parameters that you can use &#x27;database&#x27; =&gt; env(&#x27;MONGODB_AUTHENTICATION_DATABASE&#x27;, &#x27;hotel&#x27;), // required with Mongo 3+ ], ], Model定义: &lt;?php/** * Author: puresai * Date: 2020/12/22 * Time: 15:08 */namespace App\\Models;use Jenssegers\\Mongodb\\Eloquent\\Model;class Product extends Model&#123; protected $collection = &#x27;products&#x27;; protected $connection = &#x27;mongodb&#x27;; protected $guarded = [&#x27;id&#x27;];&#125; 使用: $users = User::distinct(&#x27;name&#x27;)-&gt;get();$users = User::whereIn(&#x27;age&#x27;, [16, 18, 20])-&gt;get();$total = Product::count();$price = Product::avg(&#x27;price&#x27;); Eloquent ORM常用的命令均支持，用起来毫无违和感，select略有不同，会把_id查询出来。 更多命令点击查看代码仓库 大致也就这些了，赶紧使用起来吧！！！","tags":["MongoDB"],"categories":["db"]},{"title":"go的并发模型","path":"/2020/11/21/283/","content":"介绍并发模型，我们先来说一下并发和并行。 并发和并行并发和并行否是为了充分利用CPU多核计算资源提出来的概念。 并发指的是在同一个时间段内，多条指令在CPU上同时执行 并行值得是在同一时刻，多条指令在CPU上同时执行 并发程序其实并不要求CPU具备多核计算的能力，在同一时间段内，多个线程会被分配一定的执行时间片，在CPU上被快速轮换执行。 CSP并发模型Go语言中实现了两种并发模型，一种是依赖于共享内存实现的线程-锁并发模型，另一种则是CSP。 CSP倡导使用通信来共享内存，它有两个关键点： 并发实体，通常可以理解为执行线程，它们相互独立且可以并发执行 通道，并发实体之间通过通道发送消息，进行通信 CSP 类似于我们常用的同步队列，它关注的消息传输的方式（通道），并不关注消息实体。发送者和接收者可能并不知道对方是谁，耦合度是很低的。 虽然CSP的通道提供了极大的灵活性，但作为独立的对象，它可以被任意并发实体创建、读取、写入、使用，但使用时务必注意，当一个并发实体在读取一个永远没有数据放入的通道或者把数据放入一个永远不会被读取的通道，是会被阻塞，发生死锁的。 MPG线程模型Go语言不但有着独特的并发编程模型，还拥有强大的用于调度goroutine、对接系统级线程的调度器。 这个调度器是Go语言运行时系统的重要组成部分，它主要负责统筹调配Go并发编程模型中的三个主要元素，即：MPG。 模块 说明 Machine 一个Machine对应一个内核线程，相当于内核线程在Go进程中的映射 Processor 一个Processor表示执行Go程序所必须的上下文环境，可以理解为用户代码逻辑的处理器 Goroutine 是对Go语言中代码片段的封装，其实是一个轻量级的用户线程 M和P是一对一绑定的，但由于P的存在，G和M可以呈现出多对多的关系。当一个正在与某个M对接并运行着的G，需要因某个事件（比如等待I/O或锁的解除）而暂停运行的时候，调度器总会及时地发现，并把这个G与那个M分离开，以释放计算资源供那些等待运行的G使用。 可以看图，更直观： 有关P和M的个数问题 P的数量： 由启动时环境变量$GOMAXPROCS或者是由runtime的方法GOMAXPROCS()决定。这意味着在程序执行的任意时刻都只有$GOMAXPROCS个goroutine在同时运行。 M的数量: go语言本身的限制：go程序启动时，会设置M的最大数量，默认10000。但是内核很难支持这么多的线程数，所以这个限制可以忽略。 runtime/debug中的SetMaxThreads函数，设置M的最大数量。 M与P的数量没有绝对关系，一个M阻塞，P就会去创建或者切换另一个M，所以，即使P的默认数量是1，也有可能会创建很多个M出来。 P和M何时会被创建： P何时创建：在确定了P的最大数量n后，运行时系统会根据这个数量创建n个P。 M何时创建：没有足够的M来关联P并运行其中的可运行的G。比如所有的M此时都阻塞住了，而P中还有很多就绪任务，就会去寻找空闲的M，而没有空闲的，就会去创建新的M。 参考： 《Go语言高并发与微服务实战》 《Go语言核心36讲》 Golang调度器GMP原理与调度全分析","tags":["go"],"categories":["go"]},{"title":"MySQL间隙锁","path":"/2020/10/27/MySQL-gaplock/","content":"gap lock 是什么？gap lock，也就是间隙锁，是innodb行级锁的一种，其他的还有record lock, Next-KeyLocks。 行锁（Record Lock）：锁直接加在索引记录上面。 间隙锁（Gap Lock）：锁加在不存在的空闲空间，可以是两个索引记录之间，也可能是第一个索引记录之前或最后一个索引之后的空间。 Next-Key Lock：行锁与间隙锁组合起来用就叫做Next-Key Lock。 什么时候会取得gap lock这和隔离级别有关,只在REPEATABLE READ或以上的隔离级别下的特定操作才会取得gap lock或nextkey lock。locking reads，UPDATE和DELETE时，除了对唯一索引的唯一搜索外都会获取gap锁或next-key锁。即锁住其扫描的范围。 我们来看看实例： CREATE TABLE `sai13` ( `id` int(11) NOT NULL AUTO_INCREMENT, `user_id` int(11) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 插入3条记录， insert into sai13 values(10,1);insert into sai13 values(20,2);insert into sai13 values(30,3); 在REPEATABLE READ下，更新一条记录不提交，然后看看能阻塞另外的会话哪些操作。 SESSION 1: SESSION 1中更新id=20的记录 mysql&gt; begin;Query OK, 0 rows affected (0.00 sec)mysql&gt; update sai13 set user_id=2 where id=20;Query OK, 1 row affected (0.04 sec)Rows matched: 1 Changed: 1 Warnings: 0 SESSION 2: mysql&gt; begin;Query OK, 0 rows affected (0.00 sec)mysql&gt; insert into sai13 values(9,4);Query OK, 1 row affected (0.00 sec)mysql&gt; insert into sai13 values(10,4);ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transactionmysql&gt; insert into sai13 values(19,4);ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transactionmysql&gt; update sai13 set user_id=22 where id=20;ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transactionmysql&gt; insert into sai13 values(20,4);ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transactionmysql&gt; insert into sai13 values(21,4);ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transactionmysql&gt; insert into sai13 values(29,4);ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transactionmysql&gt; insert into sai13 values(30,4);Query OK, 1 row affected (0.01 sec) SESSION 2中，执行插入操作，发现[10,30)范围不能插入数据。 SESSION 1: mysql&gt; begin;mysql&gt; update sai13 set user_id=4 where id=21;Query OK, 0 rows affected (0.00 sec) SESSION 2: mysql&gt; begin;mysql&gt; update sai13 set user_id=22 where id=20;Query OK, 1 row affected (0.01 sec)mysql&gt; insert into sai13 values(20,4);ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transactionmysql&gt; update sai13 set user_id=4 where id=30;Query OK, 0 rows affected (0.00 sec) 这里呢，是去锁住了一条不存在的记录，他会锁住最近的[20,30)区间，然而与前一个例子不同的是，这里update（id = 20）是可以成功的，insert（id = 20）是不可以的。 如果SESSION 1的表扫描没有用到索引，那么gap或next-key锁住的范围是整个表，即任何值都不能插入。 作用间隙锁在InnoDB的唯一作用就是防止其它事务的插入操作，以此来达到防止幻读的发生，所以间隙锁不分什么共享锁与排它锁。 既然知道有gap lock和next key lock，我们开发中就要避免收到其影响，在并发场景下，使用锁尽量走索引，甚至是唯一索引。当然，也可以关闭间隙锁，可以把隔离级别降为读已提交Read Committed，或者开启参数innodb_locks_unsafe_for_binlog。","tags":["mysql"],"categories":["MySQL"]},{"title":"layer关闭的问题","path":"/2020/10/21/277/","content":"layer弹出层应该是我们比较常用的一个组件了。 遇到个问题，就是弹出层加上下一个上一个，其实按理是比较好实现，点击上一个下一个按钮，调用一下layer.close即可，然而无奈的是弹出的是一个iframe，都不在一个页面，如何调用layer.close。 那可怎么办呢？ var index=parent.layer.getFrameIndex(window.name);parent.layer.close(index);parent.layer.open(&#123; type: 2, title: &#x27;详情&#x27;, shadeClose: true, area: [&#x27;1000px&#x27;, &#x27;96%&#x27;], content: &quot;...&quot;&#125;); 如上，我们可以调用parent.layer.close，并通过parent.layer.getFrameIndex获取副页面的layer元素，这样就实现此需求了。","tags":["js"],"categories":["web"]},{"title":"golang的time使用","path":"/2020/09/10/275/","content":"time应该是开发中比较常用的库了，常见方法说明： package mainimport (\t&quot;time&quot;\t&quot;fmt&quot;)func main() &#123;\ta := time.Now().Unix()\tfmt.Println(&quot;时间戳---&quot;, a)\t// 2006-01-02 15:04:05 记住这一刻\tb := time.Now().Format(&quot;2006-01-02 15:04:05&quot;)\tfmt.Println(&quot;格式化时间&quot;, b)\t/**\tfunc (t Time) Add(d Duration) Time\tDuration如下\tconst ( Nanosecond Duration = 1 Microsecond = 1000 * Nanosecond Millisecond = 1000 * Microsecond Second = 1000 * Millisecond Minute = 60 * Second Hour = 60 * Minute\t) */\tc := time.Now().Add(time.Minute * 3)\tfmt.Println(&quot;3分钟后时间&quot;, c.Format(&quot;2006-01-02 15:04:05&quot;))\t/** func (t Time) AddDate(years int, months int, days int) Time\t*/\td := time.Now().AddDate(-1, 1,10)\tfmt.Println(&quot;时间&quot;, d.Format(&quot;2006-01-02 15:04:05&quot;))\t// 返回年月日三个值\tfmt.Println(time.Now().Date())\t// 返回时分秒三个值\tfmt.Println(time.Now().Clock())\tfmt.Println(time.Now().Year(), time.Now().Month(), time.Now().Day())\tfmt.Println(time.Now().Weekday(), time.Now().Hour())\tfmt.Println(time.Now().YearDay())\tfmt.Println(time.Since(d))\t// tring返回采用如下格式字符串的格式化时间。\t// &quot;2006-01-02 15:04:05.999999999 -0700 MST&quot;\tfmt.Println(time.Now().String())\ttime.AfterFunc(2*time.Second, func() &#123; fmt.Println(&quot;hello 2s&quot;)\t&#125;)\tloc, _ := time.LoadLocation(&quot;Asia/Shanghai&quot;)\tconst longForm = &quot;Jan 2, 2006 at 3:04pm (MST)&quot;\tconst shortForm = &quot;2006-Jan-02&quot;\tt, _ := time.ParseInLocation(longForm, &quot;Jul 9, 2012 at 5:02am (CEST)&quot;, loc)\tfmt.Println(t) /**\tfunc ParseInLocation(layout, value string, loc *Location) (Time, error) */\tt, _ = time.ParseInLocation(shortForm, &quot;2022-Jul-09&quot;, loc)\tfmt.Println(t)\t/**\tfunc Parse(layout, value string) (Time, error)\t解析一个格式化的时间字符串并返回它代表的时间\tParseInLocation类似Parse但有两个重要的不同之处。\t第一，当缺少时区信息时，Parse将时间解释为UTC时间，而ParseInLocation将返回值的Location设置为loc；\t第二，当时间字符串提供了时区偏移量信息时，Parse会尝试去匹配本地时区，而ParseInLocation会去匹配loc\t*/\tt, _ = time.Parse(longForm, &quot;Feb 3, 2023 at 7:54pm (PST)&quot;)\tfmt.Println(t) t, _ = time.Parse(shortForm, &quot;2020-Feb-03&quot;)\tfmt.Println(t)\tch := make(chan int)\ttimeout := time.After(time.Second * 2)\ttimer := time.NewTimer(time.Second * 4) var i int\tgo func() &#123; for &#123; // i++ select &#123; case &lt;- ch: fmt.Println(&quot;channel close&quot;) return case &lt;- timer.C: fmt.Println(&quot;4s的NewTimer定时任务&quot;) case &lt;- timeout: fmt.Println(&quot;4s定时输出&quot;) case &lt;- time.After(time.Second * 6): fmt.Println(&quot;6s到了&quot;) // default: // //Sleep 1秒，参数就是上面的Duration // time.Sleep(time.Second * 1) // fmt.Println(&quot;go 1s&quot;) &#125; &#125;\t&#125;()\ttime.Sleep(time.Second * 15)\tfmt.Println(&quot;close----&quot;)\tclose(ch)\ttime.Sleep(time.Second * 2)&#125;","tags":["go"],"categories":["go"]},{"title":"Laravel配合MaatwebsiteExcel实现Excel导出","path":"/2020/08/31/272/","content":"相比导入，项目中导出场景更多，估摸着现在有十多个导出了，之前写了导入，这会才把导出补上。 安装之前说过，这里说一下配置，虽然已有默认配置，但还是有修改配置的场景，所以建议生成配置文件。 配置//生成config/excel.phpphp artisan vendor:publish --provider=&quot;Maatwebsite\\Excel\\ExcelServiceProvider&quot; 配置只提一个，其他注释蛮细的， &#x27;csv&#x27; =&gt; [\t&#x27;delimiter&#x27; =&gt; &#x27;,&#x27;,\t&#x27;enclosure&#x27; =&gt; &#x27;&quot;&#x27;,\t&#x27;line_ending&#x27; =&gt; PHP_EOL,\t// 导出csv中文乱码，把use_bom设为true即可\t&#x27;use_bom&#x27; =&gt; true,\t&#x27;include_separator_line&#x27; =&gt; false,\t&#x27;excel_compatibility&#x27; =&gt; false,], 接下来，来完成一个导出的demo说明下常用的一些点。 DEMOphp artisan make:export MultiExport 生成文件如下： &lt;?phpnamespace App\\Exports;use Maatwebsite\\Excel\\Concerns\\FromCollection;class MultiExport implements FromCollection&#123; /** * @return \\Illuminate\\Support\\Collection */ public function collection() &#123; // &#125;&#125; 自定义sheet，增加 WithTitle 自定义列名，增加WithHeadings 不想使用Collection，替换FromCollection使用FromArray 多个sheet，替换FromCollection使用WithMultipleSheets 经过改造： &lt;?php/** * 多重导出 */namespace App\\Exports;use App\\Exports\\MultiExportA;use App\\Exports\\MultiExportB;use Maatwebsite\\Excel\\Concerns\\WithMultipleSheets;class MultiExport implements WithMultipleSheets&#123; private $date; public function __construct($date) &#123; $this-&gt;date = $date; &#125; public function sheets(): array &#123; $sheets = []; $sheets[] = new MultiExportA($this-&gt;date); $sheets[] = new MultiExportB($this-&gt;date); return $sheets; &#125;&#125;---// MultiExportA，MultiExportB类比即可&lt;?phpnamespace App\\Exports;use Maatwebsite\\Excel\\Concerns\\FromArray;use Maatwebsite\\Excel\\Concerns\\WithHeadings;use Maatwebsite\\Excel\\Concerns\\WithTitle;use App\\Models\\ExportA;class MultiExportA implements FromArray, WithTitle, WithHeadings&#123; private $date; public function __construct($date, $cityId) &#123; $this-&gt;date = $date; &#125; public function headings(): array &#123; return [ &#x27;ID&#x27;, &#x27;名称&#x27;, &#x27;价格&#x27;, &#x27;手机&#x27; ]; &#125; /** * @return array */ public function array() : array &#123; $data = ExportA::where(&#x27;date&#x27;, $this-&gt;date) -&gt;get() -&gt;toArray(); $ret = []; foreach ($data as $val) &#123; // 一段神奇的代码计算出了价格 $price = ...; $ret[] = [ &#x27;id&#x27; =&gt; $val[&#x27;id&#x27;].&quot;\\t&quot;, &#x27;name&#x27; =&gt; $val[&#x27;name&#x27;], &#x27;price&#x27; =&gt; $price, // 转换为文本，编码excel使用了科学计数法 &#x27;mobile&#x27; =&gt; $val[&#x27;mobile&#x27;].&quot;\\t&quot;, ]; &#125; return $ret; &#125; /** * @return string */ public function title(): string &#123; return &#x27;表格A&#x27;; &#125;&#125; 使用 // 保存$obj = new MultiExport($date);Excel::store($obj, &#x27;MultiExport&#x27;.$date.&#x27;.xlsx&#x27;);// 下载csvExcel::download($obj, &#x27;MultiExport&#x27;.$date.&#x27;.csv&#x27;, \\Maatwebsite\\Excel\\Excel::CSV, [&#x27;Content-Type&#x27; =&gt; &#x27;text/csv&#x27;]); 问题思考当数据量过大的时候，导出时很可能会内存溢出了。建议： 使用其他高性能的组件，或者使用原生代码流式输出到浏览器，也可以直接使用其他语言（比如go）编写 文件过大，Excel打开大数据量文件也很鸡肋，容易卡死甚至崩溃，尝试分文件导出，比如1w一个文件 部分导出过程可能有计算，可以提前计算好，导出时直接读表，使用LazyCollection， 使用 Lazy Collections 来提高 Laravel Excel 读取的性能（轻松支持百万数据）","tags":["Laravel"],"categories":["PHP"]},{"title":"Laravel常用代码合集","path":"/2020/08/30/270/","content":"用Laravel也有不短的时间了，也用过不少版本了，以下代码是在日常项目中收集，作为笔记，也分享出来，希望对你有点用处。注：版本没标注，若有不兼容的问题，微调即可。 验证不太习惯单独弄个Request验证类，比较习惯下面的写法： use Illuminate\\Http\\Request;use Illuminate\\Support\\Facades\\Validator;\t$inputData = $request-&gt;only([&#x27;name&#x27;, &#x27;address&#x27;, &#x27;mobile&#x27;, &#x27;draw_id&#x27;]); $messages = [ &#x27;required&#x27;=&gt;&#x27;:attribute为必填项&#x27;, &#x27;int&#x27;=&gt;&#x27;:attribute参数类型错误&#x27;, &#x27;max&#x27;=&gt;&#x27;:attribute长度不得超过 :size&#x27;, ]; $validator = Validator::make($inputData, [ &#x27;draw_id&#x27; =&gt; &#x27;required|int&#x27;, &#x27;name&#x27; =&gt; &#x27;required&#x27;, &#x27;mobile&#x27; =&gt; &#x27;required&#x27;, &#x27;address&#x27; =&gt; &#x27;required&#x27;,\t], $messages,[ &#x27;name&#x27;=&gt;&#x27;收货人姓名&#x27;, &#x27;mobile&#x27;=&gt;&#x27;手机号码&#x27;, &#x27;address&#x27;=&gt;&#x27;收货地址&#x27;,\t]);\tif ($validator-&gt;fails()) &#123; return self::response([], current($validator-&gt;errors()-&gt;all()), 2);\t&#125; ORM关联查询 一对一 // Model定义，关联外键class User extends Model&#123; ... public function userIntegral() &#123; return $this-&gt;hasOne(&#x27;App\\Models\\UserIntegral&#x27;, &#x27;user_id&#x27;, &#x27;id&#x27;); &#125;&#125;// 使用with查询(new User())-&gt;with(&#x27;userIntegral&#x27;)-&gt;orderBy(&#x27;id&#x27;, &#x27;desc&#x27;)-&gt;paginate($limit); 一对多 //Modelnamespace App\\Models;use Illuminate\\Database\\Eloquent\\Model;class Hotel extends Model&#123; public function orders() &#123; return $this-&gt;hasMany(&#x27;App\\Models\\Order&#x27;); &#125;&#125;//使用，比如查询某个Hotel下status=30的Order$hotel = Hotel::with([&#x27;orders&#x27; =&gt; function ($query) &#123; $query-&gt;where(&#x27;status&#x27;, 30); &#125;])-&gt;find(4); 统一异常处理这个可以参见之前的文章Laravel 统一错误处理为 JSON 队列失败队列入库 生成表生成failed_jobs表 php artisan queue:failed-tablephp artisan migrate 单独处理 可以在Job中单独处理失败，Job失败也会写入上面生成的failed_jobs表 /*** 任务失败的处理过程** @param Exception $exception* [@return](https://learnku.com/users/31554) void*/public function failed(Exception $exception)&#123;\t// 处理&#125; 重试队列有时候代码有漏洞可能会有队列执行失败的状况，这时候我们就需要重试。 查看所有失败php artisan queue:failed 重试所有失败php artisan queue:retry all 重试单个失败php artisan queue:retry 13 清空失败（重要的队列数据万不可这么操作）php artisan queue:flush 另外，手动去操作确实不太方便，你可以设置个cron，定时重试所有失败，但务必要注意消息提醒，以免队列一直重试一直失败，往复运行，影响了正常的队列性能。 其他常用代码文件上传OSS&lt;?phpnamespace App\\Http\\Controllers;use Illuminate\\Http\\Request;use Controller;use Illuminate\\Support\\Facades\\Storage;use Illuminate\\Support\\Facades\\Validator;use OSS\\OssClient;use OSS\\Core\\OssException;class UploadController extends Controller&#123; public function index(Request $request) &#123; $file = $request-&gt;file(&#x27;file&#x27;); if ($file-&gt;isValid()) &#123; $ext = $file-&gt;getClientOriginalExtension(); $realPath = $file-&gt;getRealPath(); $filepath = config(&#x27;app.env&#x27;).&#x27;/&#x27; . md5(uniqid(&#x27;&#x27;, true)); $result = $this-&gt;uploadOss($realPath, $filepath.&quot;.&quot;.$ext); if ($result[&#x27;code&#x27;]) &#123; return response([&#x27;code&#x27; =&gt; 2, &#x27;msg&#x27; =&gt; $result[&#x27;msg&#x27;]]); &#125; else &#123; return response([&#x27;code&#x27; =&gt; 0, &#x27;msg&#x27; =&gt; &#x27;上传成功&#x27;, &#x27;data&#x27; =&gt; [ &#x27;filepath&#x27; =&gt; $result[&#x27;data&#x27;][&#x27;url&#x27;], &#x27;data&#x27; =&gt; $request-&gt;all() ]]); &#125; &#125; &#125; /** * 上传oss * @param $filePath 当前路径 * @param $object 预定义文件名，可含文件夹 * [@return](https://learnku.com/users/31554) array */ public function uploadOss($filePath, $object) &#123; $accessKeyId = config(&#x27;filesystems.disks&#x27;)[config(&#x27;filesystems.default&#x27;)][&#x27;access_key&#x27;]; $accessKeySecret = config(&#x27;filesystems.disks&#x27;)[config(&#x27;filesystems.default&#x27;)][&#x27;secret_key&#x27;]; $endpoint = config(&#x27;filesystems.disks&#x27;)[config(&#x27;filesystems.default&#x27;)][&#x27;endpoint&#x27;]; $bucket= config(&#x27;filesystems.disks&#x27;)[config(&#x27;filesystems.default&#x27;)][&#x27;bucket&#x27;]; $url = config(&#x27;filesystems.disks&#x27;)[config(&#x27;filesystems.default&#x27;)][&#x27;host&#x27;]; try&#123; $ossClient = new OssClient($accessKeyId, $accessKeySecret, $endpoint); $ossClient-&gt;uploadFile($bucket, $object, $filePath); return [ &#x27;code&#x27; =&gt; 0, &#x27;data&#x27; =&gt; [ &#x27;url&#x27; =&gt; $url.&#x27;/&#x27;.$object ] ]; &#125; catch(OssException $e) &#123; return [ &#x27;code&#x27; =&gt; 1, &#x27;msg&#x27; =&gt; $e-&gt;getMessage() ]; &#125; &#125;&#125;// -------// 配置&#x27;oss&#x27; =&gt; [ &#x27;driver&#x27; =&gt; &#x27;oss&#x27;, &#x27;root&#x27; =&gt; &#x27;&#x27;, &#x27;access_key&#x27; =&gt; env(&#x27;OSS_ACCESS_KEY&#x27;), &#x27;secret_key&#x27; =&gt; env(&#x27;OSS_SECRET_KEY&#x27;), &#x27;endpoint&#x27; =&gt; env(&#x27;OSS_ENDPOINT&#x27;), // 使用 ssl 这里设置如: https://oss-cn-beijing.aliyuncs.com &#x27;bucket&#x27; =&gt; env(&#x27;OSS_BUCKET&#x27;), &#x27;isCName&#x27; =&gt; env(&#x27;OSS_IS_CNAME&#x27;, false), // 如果 isCname 为 false，endpoint 应配置 oss 提供的域名如：`oss-cn-beijing.aliyuncs.com`，否则为自定义域名，，cname 或 cdn 请自行到阿里 oss 后台配置并绑定 bucket &#x27;host&#x27; =&gt; env(&#x27;OSS_HOST&#x27;, &#x27;&#x27;)], json输出protected static $code = 0;protected static $msg = &#x27;ok&#x27;;public function response($data = [], $msg = &#x27;&#x27;, $code = 0)&#123; if (is_null($data)) &#123; $data = new \\stdClass(); &#125; return response()-&gt;json([ &#x27;code&#x27; =&gt; $code? $code : self::$code, &#x27;msg&#x27; =&gt; $msg? $msg : self::$msg, &#x27;data&#x27; =&gt; $data, ], 200);&#125; 进程锁 普通版本 // $autoDel字段删除，$ttl 过期时间，秒public function processLock($key, $autoDel = true, $ttl = 60)&#123; $key = &#x27;processLock:&#x27;.$key;\t// 不同版本或Redis扩展，会有略微不同，自行调整下代码即可 if (Redis::Command(&#x27;set&#x27;, [$key, 1, &#x27;EX&#x27;, $ttl, &#x27;NX&#x27;])) &#123; if ($autoDel) &#123; register_shutdown_function(function () use ($key) &#123; Redis::del($key); &#125;); &#125; return true; &#125; return false;&#125; lua版本 public function getScript() &#123; return &lt;&lt;&lt;LUA local ret = Redis.call(&quot;setnx&quot;, KEYS[1], ARGV[1]) if ret == 1 then return Redis.call(&quot;expire&quot;, KEYS[1], ARGV[2]) else return 0 endLUA; &#125; public function processLock($key, $autoDel = true, $ttl = 60) &#123; if (Redis::eval($this-&gt;getScript(), 1, $key, 1, $ttl)) &#123; if ($autoDel) &#123; register_shutdown_function(function () use ($key) &#123; Redis::del($key); &#125;); &#125; &#125; return false;\t&#125; 说明：Redis::eval行第一个1表示key的数量，是为了区分KEYS和ARGV。 JWTLaravel 配合 jwt 使用 系统通知到钉钉我们可以使用队列，把一些重要的通知投到钉钉，主要代码如下： &lt;?phpnamespace App\\Jobs;use Illuminate\\Bus\\Queueable;use Illuminate\\Contracts\\Queue\\ShouldQueue;use Illuminate\\Foundation\\Bus\\Dispatchable;use Illuminate\\Queue\\InteractsWithQueue;use Illuminate\\Queue\\SerializesModels;use Illuminate\\Support\\Facades\\Log;use GuzzleHttp\\Client;class SystemNotify implements ShouldQueue&#123; use Dispatchable, InteractsWithQueue, Queueable, SerializesModels; private $title; private $content; private $type; private $robot; const DD_URL = &#x27;https://oapi.dingtalk.com&#x27;; /** * Create a new job instance. * * @param $title * @param string $content * @param string $type text, markdown * @param int $robot */ public function __construct($title, $content = &#x27;&#x27;, $type = &#x27;markdown&#x27;, $robot = 1) &#123; // 单独使用SystemNotify队列 $this-&gt;queue = &#x27;SystemNotify&#x27;; $this-&gt;title = $title; $this-&gt;content = $content; $this-&gt;type = $type; $this-&gt;robot = $robot; &#125; /** * Execute the job. * * @return void */ public function handle() &#123; // 可以不使用关键字，建议钉钉机器人使用IP段设置，更为安全 switch ($this-&gt;type)&#123; case &#x27;markdown&#x27;: $params = [ &#x27;msgtype&#x27; =&gt; $this-&gt;type, $this-&gt;type =&gt; [ &#x27;title&#x27; =&gt; $this-&gt;title.&#x27;[关键字]&#x27;, &#x27;text&#x27; =&gt; $this-&gt;content ] ]; break; default: $params = [ &#x27;msgtype&#x27; =&gt; $this-&gt;type, $this-&gt;type =&gt; [ &#x27;content&#x27; =&gt; $this-&gt;content.&#x27;[关键字]&#x27;, ] ]; break; &#125; $params = json_encode($params, JSON_UNESCAPED_UNICODE); $uri = self::URL_MAPPING[$this-&gt;robot]; $this-&gt;getClient()-&gt;request(&#x27;POST&#x27;, $uri, [ &#x27;headers&#x27; =&gt; [ &#x27;Content-Type&#x27; =&gt; &#x27;application/json;charset=utf-8&#x27; ], &#x27;body&#x27; =&gt; $params ]); &#125; // 对应不同的钉钉群通知，修改access_token参数即可 const URL_MAPPING = [ 1 =&gt; &#x27;/robot/send?access_token=@1&#x27;, 2 =&gt; &#x27;/robot/send?access_token=@2&#x27; ]; public function getClient() &#123; return new Client([ &#x27;base_uri&#x27; =&gt; &#x27;https://oapi.dingtalk.com&#x27;, &#x27;timeout&#x27; =&gt; 30, &#x27;verify&#x27; =&gt; false ]); &#125;&#125; 说明：通知内容可以自定义，添加智能机器人操作比较简单就不赘述了 钉钉文档 后台操作日志利用 Laravel 中间件给后台加个操作日志 ExcelLaravel6 配合 Maatwebsite\\Excel 实现 Excel 导入 Laravel6 配合 Maatwebsite\\Excel 实现 Excel 导出 陆续补充中…","tags":["Laravel"],"categories":["PHP"]},{"title":"最近使用gin的总结","path":"/2020/07/20/261/","content":"最近有新项目是利用gin开发的，过程中遇到一些问题，总结一下，作为笔记，也希望能帮助到你。 跨域问题中间件： func Cors() gin.HandlerFunc &#123;\treturn func(c *gin.Context) &#123; // 这里可以用*，也可以用你指定的域名 c.Header(&quot;Access-Control-Allow-Origin&quot;, &quot;*&quot;) // 允许头部参数 c.Header(&quot;Access-Control-Allow-Headers&quot;, &quot;Content-Type,AccessToken,X-CSRF-Token, Authorization, Token&quot;) // 允许的方法 c.Header(&quot;Access-Control-Allow-Methods&quot;, &quot;POST, GET, OPTIONS&quot;) c.Header(&quot;Access-Control-Expose-Headers&quot;, &quot;Content-Length, Access-Control-Allow-Origin, Access-Control-Allow-Headers, Content-Type&quot;) c.Header(&quot;Access-Control-Allow-Credentials&quot;, &quot;true&quot;) method := c.Request.Method //放行OPTIONS方法 if method == &quot;OPTIONS&quot; &#123; c.AbortWithStatus(http.StatusOK) &#125; // 处理请求 c.Next()\t&#125;&#125; 然后在路由中加入： // g : *gin.Engineg.Use(Cors()) 当然也可以在Nginx层配置，可自行查阅，我就不展开了。 使用多个中间件// g : *gin.Engineg.Use(Cors())g.Use(Session()) 中间件终止请求func Auth() gin.HandlerFunc &#123; return func(c *gin.Context) &#123; uid := c.MustGet(&quot;uid&quot;).(int) if uid == 0 &#123; c.Abort() controller.SendResponse(c, 401, &quot;未登录&quot;, nil) // return可忽略 return &#125; else &#123; c.Next() &#125; &#125;&#125; session使用package utilimport (\t&quot;github.com/gin-gonic/gin&quot;\t&quot;github.com/gin-contrib/sessions&quot;\t&quot;github.com/gin-contrib/sessions/Redis&quot;\tRedisGo &quot;github.com/gomodule/redigo/Redis&quot;\t&quot;github.com/spf13/viper&quot;)// 启动sessionfunc SessionStart(g *gin.Engine, RedisClient *RedisGo.Pool, key ...[]byte) &#123;\tstore, _ := Redis.NewStoreWithPool(RedisClient, []byte(viper.GetString(&quot;name&quot;)))\tRedis.SetKeyPrefix(store, &quot;session_&quot;)\tg.Use(sessions.Sessions(viper.GetString(&quot;name&quot;), store))&#125;// 使用sessionsession := sessions.Default(c)session.Set(&quot;uid&quot;, uid)uid := session.Get(&quot;uid&quot;) 上传ossimport (\t&quot;os&quot; &quot;github.com/aliyun/aliyun-oss-go-sdk/oss&quot;\t&quot;github.com/spf13/viper&quot;)func upload(localPath string, iType int, Name string) (path string) &#123;\tclient, err := oss.New(viper.GetString(&quot;oss.end_point&quot;), viper.GetString(&quot;oss.access_key_id&quot;), viper.GetString(&quot;oss.access_key_secret&quot;)) if err != nil &#123; return &#125; // 获取存储空间。 bucket, err := client.Bucket(viper.GetString(&quot;oss.bucket&quot;)) if err != nil &#123; return &#125; // 上传本地文件。\tossPath := fmt.Sprintf(&quot;%s/%s&quot;, &quot;qiling&quot;, Name) err = bucket.PutObjectFromFile(ossPath, localPath) if err != nil &#123; return &#125; path = fmt.Sprintf(&quot;%s/%s&quot;, viper.GetString(&quot;oss.hosts&quot;), ossPath)\tos.Remove(localPath)\treturn&#125; 几个实用的方法import (\t&quot;fmt&quot;\t&quot;crypto/md5&quot;\t&quot;bytes&quot;\t&quot;regexp&quot;)// md5func Md5(str string) string &#123;\treturn fmt.Sprintf(&quot;%x&quot;, md5.Sum([]byte(str)));&#125;// 判断是不是真实手机号码func IsMobile(mobile string) bool &#123; result, _ := regexp.MatchString(`^(1\\d&#123;10&#125;)$`, mobile) if result &#123; return true &#125; else &#123; return false &#125;&#125;// 合并字符串func StrCombine(str ...string) string &#123;\tvar bt bytes.Buffer\tfor _, arg := range str &#123; bt.WriteString(arg) &#125;\t//获得拼接后的字符串\treturn bt.String()&#125; 大概就这些了，后面有可以分析的再补充。","tags":["gin"],"categories":["go"]},{"title":"使用vue-element-admin的一些总结","path":"/2020/07/14/262/","content":"最近开发的项目后台基于vue-element-admin开发，在逐步完善的过程中遇到了一些问题，特此总结，希望能对你有所帮助。 先上链接，真的很好用，安利一下，链接如下： A magical vue admin 基本上常用的不常用的功能都有，就不多说了，有兴趣链接直达，正式开始正文。 修改菜单图标为elementUI图标官方的svg图标确实比较少，添加我也觉得繁琐，另外，既然集成了elementUI，直接用elementUI图标就好了。 改： 修改菜单icon为elementUI图标：// 文件地址：src\\layout\\components\\Sidebar\\Item.vue// if (icon) &#123;// vnodes.push(&lt;svg-icon icon-class=&#123;icon&#125;/&gt;)// &#125;if (icon) &#123; vnodes.push(&lt;i class=&#123;icon&#125;&gt;&lt;/i&gt;)&#125; 关闭eslint官网已有答案 // vue.config.jslintOnSave: false but，如果你使用的是git管理代码，会发现commit的时候依旧会触发eslint。 // package.json &quot;lint-staged&quot;: &#123; &quot;src/**/*.&#123;js,vue&#125;&quot;: [ &quot;eslint --fix&quot;, // 删除这一行 &quot;git add&quot; ] &#125;, 增加本地环境变量// package.json &quot;scripts&quot;: &#123; &quot;local&quot;: &quot;vue-cli-service serve --mode local&quot;, ... &#125;, 复制.env.production为.env.local，自定义配置后，运行： yarn run local 缓存页面想缓存的页面： &lt;script&gt;export default &#123; name: &quot;cacheIndex&quot;, 加入cachedViews // src\\store\\modules\\tagsView.jsconst state = &#123; visitedViews: [], cachedViews: [ &#x27;cacheIndex&#x27; ]&#125; 最近开发的项目后台基于vue-element-admin开发，在逐步完善的过程中遇到了一些问题，特此总结，希望能对你有所帮助。 先上链接，真的很好用，安利一下，链接如下： A magical vue admin 基本上常用的不常用的功能都有，就不多说了，有兴趣链接直达，正式开始正文。 修改菜单图标为elementUI图标官方的svg图标确实比较少，添加我也觉得繁琐，另外，既然集成了elementUI，直接用elementUI图标就好了。 改： 修改菜单icon为elementUI图标：// 文件地址：src\\layout\\components\\Sidebar\\Item.vue// if (icon) &#123;// vnodes.push(&lt;svg-icon icon-class=&#123;icon&#125;/&gt;)// &#125;if (icon) &#123; vnodes.push(&lt;i class=&#123;icon&#125;&gt;&lt;/i&gt;)&#125; 关闭eslint官网已有答案 // vue.config.jslintOnSave: false but，如果你使用的是git管理代码，会发现commit的时候依旧会触发eslint。 // package.json &quot;lint-staged&quot;: &#123; &quot;src/**/*.&#123;js,vue&#125;&quot;: [ &quot;eslint --fix&quot;, // 删除这一行 &quot;git add&quot; ] &#125;, 增加本地环境变量// package.json &quot;scripts&quot;: &#123; &quot;local&quot;: &quot;vue-cli-service serve --mode local&quot;, ... &#125;, 复制.env.production为.env.local，自定义配置后，运行： yarn run local 缓存页面想缓存的页面： &lt;script&gt;export default &#123; name: &quot;cacheIndex&quot;, 加入cachedViews // src\\store\\modules\\tagsView.jsconst state = &#123; visitedViews: [], cachedViews: [ &#x27;cacheIndex&#x27; ]&#125;","tags":["ElementUI"],"categories":["vue"]},{"title":"利用ElementUI的table和calendar制作一个价格日历","path":"/2020/05/04/250/","content":"项目中需要做一个价格日历，便于展示和修改日期价格，我们先看下最终效果，然后利用ElementUI的table 和 calendar 实现一下。 来看看主要代码（代码仅保留了主要代码和属性，并不完整，可以自行根据实际情况修改）： &lt;template&gt; &lt;div class=&quot;calendar-list-container&quot;&gt; &lt;!--expand-row-keys设置了row-key也要设置，\texpand-change\t当用户对某一行展开或者关闭的时候会触发该事件（展开行时，回调的第二个参数为 expandedRows；树形表格时第二参数为 expanded）\trow, (expandedRows | expanded)--&gt; &lt;el-table ref=&quot;table&quot; key=&quot;id&quot; v-loading=&quot;listLoading&quot; :data=&quot;list&quot; element-loading-text=&quot;loading&quot; row-key=&quot;id&quot; :expand-row-keys=&quot;expands&quot; @expand-change=&quot;expandChange&quot; &gt; &lt;el-table-column align=&quot;center&quot; type=&quot;expand&quot; &gt; &lt;template slot-scope=&quot;scope&quot;&gt; &lt;!--价格日历渲染 --&gt; &lt;el-calendar v-loading=&quot;calendarLoad&quot; element-loading-text=&quot;loading&quot; &gt; &lt;template slot=&quot;dateCell&quot; slot-scope=&quot;&#123;date, data&#125;&quot; &gt; &lt;!--今日及之后的价格可设置setPrice --&gt; &lt;div :class=&quot;nowDay &lt;= data.day.replace(/-/g, &#x27;&#x27;)? &#x27;calendar-div&#x27; : &#x27;calendar-div calendar-prev&#x27;&quot; @click=&quot;nowDay &lt;= data.day.replace(/-/g, &#x27;&#x27;) &amp;&amp; setPrice(data, date)&quot; &gt; &lt;div&gt;&#123;&#123; data.day.slice(-2) &#125;&#125;&lt;/div&gt; &lt;div v-if=&quot;data.type == &#x27;current-month&#x27; &amp;&amp; refreshPrice(data)&quot; class=&quot;price &quot; &gt; 预订价：&#123;&#123; priceList[data.day.slice(-2) -1] &#125;&#125;元 &lt;/div&gt; &lt;/div&gt; &lt;/template&gt; &lt;/el-calendar&gt; &lt;/template&gt; &lt;/el-table-column&gt; &lt;el-table-column align=&quot;center&quot; label=&quot;名称&quot; class-name=&quot;overflow-on&quot; &gt; &lt;template slot-scope=&quot;scope&quot;&gt; &#123;&#123; scope.row.name &#125;&#125; &lt;/template&gt; &lt;/el-table-column&gt; &lt;el-table-column align=&quot;center&quot; label=&quot;图片&quot; width=&quot;210&quot; &gt; &lt;template slot-scope=&quot;scope&quot;&gt; &lt;img :src=&quot;scope.row.imageList[0]&quot; style=&quot;width:150px&quot; &gt; &lt;/template&gt; &lt;/el-table-column&gt; &lt;el-table-column align=&quot;center&quot; label=&quot;今日价格&quot; max-width=&quot;200&quot; &gt; &lt;template slot-scope=&quot;scope&quot;&gt; &lt;span&gt;&#123;&#123; scope.row.price &#125;&#125;&lt;/span&gt; &lt;/template&gt; &lt;/el-table-column&gt; &lt;el-table-column align=&quot;center&quot; label=&quot;原价&quot; max-width=&quot;200&quot; &gt; &lt;template slot-scope=&quot;scope&quot;&gt; &lt;span&gt;&#123;&#123; scope.row.original_price &#125;&#125;&lt;/span&gt; &lt;/template&gt; &lt;/el-table-column&gt; &lt;el-table-column align=&quot;center&quot; label=&quot;操作&quot; &gt; &lt;template slot-scope=&quot;scope&quot;&gt; &lt;el-button type=&quot;primary&quot; @click=&quot;handleCheck(scope.row)&quot; &gt; 价格设置 &lt;/el-button&gt; &lt;/template&gt; &lt;/el-table-column&gt; &lt;/el-table&gt; &lt;el-dialog title=&quot;设置价格&quot; :visible.sync=&quot;dialogPriceVisible&quot; &gt; &lt;el-form class=&quot;small-space&quot; :model=&quot;temp&quot; label-position=&quot;left&quot; label-width=&quot;100px&quot; style=&quot;width: 500px; margin-left:50px;&quot; &gt; &lt;el-form-item label=&quot;名称&quot;&gt; &lt;el-input v-model=&quot;temp.name&quot; disabled /&gt; &lt;/el-form-item&gt; &lt;el-form-item label=&quot;时间段&quot;&gt; &lt;el-date-picker v-model=&quot;temp.date&quot; type=&quot;daterange&quot; range-separator=&quot;至&quot; start-placeholder=&quot;开始日期&quot; end-placeholder=&quot;结束日期&quot; :picker-options=&quot;pickerBeginDateBefore&quot; /&gt; &lt;/el-form-item&gt; &lt;el-form-item label=&quot;分时计价&quot; prop=&quot;is_part&quot; required &gt; &lt;el-radio v-model=&quot;temp.is_part&quot; :label=&quot;0&quot; &gt; 不分平时周末 &lt;/el-radio&gt; &lt;el-radio v-model=&quot;temp.is_part&quot; :label=&quot;1&quot; &gt; 区分周末 &lt;/el-radio&gt; &lt;/el-form-item&gt; &lt;el-form-item label=&quot;平时价&quot;&gt; &lt;el-input v-model=&quot;temp.normal_price&quot; /&gt; &lt;/el-form-item&gt; &lt;el-form-item v-if=&quot;temp.is_part == 1&quot; label=&quot;周末价&quot; &gt; &lt;el-input v-model=&quot;temp.week_price&quot; /&gt; &lt;/el-form-item&gt; &lt;/el-form&gt; &lt;div slot=&quot;footer&quot; class=&quot;dialog-footer&quot; &gt; &lt;el-button @click=&quot;dialogPriceVisible = false&quot;&gt; 取 消 &lt;/el-button&gt; &lt;el-button type=&quot;primary&quot; @click=&quot;putPrice&quot; &gt; 确 定 &lt;/el-button&gt; &lt;/div&gt; &lt;/el-dialog&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;import &#123; fetchList, setRoomPrice, getRoomPrice &#125; from &quot;@/api&quot;;import moment from &#x27;moment&#x27;;export default &#123; name: &quot;room&quot;, data() &#123; return &#123; pickerBeginDateBefore:&#123; disabledDate(time) &#123; return time.getTime() &lt; Date.now() - 86400*1000; &#125; &#125;, schedule: [], list: [], dialogPriceVisible: false, dialogFormVisible: false, priceDate: &#x27;2020-01-01&#x27;, nowDate: 1, nowMonth: 1, nowDay: 0, nowYear: 2020, calendarMonth: 1, priceList: [], expands: [],//只展开一行放入当前行id room: &#123;&#125;, listLoading:false, calendarLoad: false, &#125;; &#125;, created() &#123; this.priceDate = new Date(); this.nowDate = this.priceDate.getDate(); this.nowMonth = this.priceDate.getMonth(); this.calendarMonth = this.nowMonth; this.nowYear = this.priceDate.getFullYear(); this.nowDay = this.priceDate.getFullYear()*10000+ (1+this.priceDate.getMonth())*100+ this.priceDate.getDate(); &#125;, methods: &#123; refreshPrice (data) &#123; // console.log(data); if (!data.isSelected) &#123; return true; &#125; if (data.day.slice(5, 7) == this.calendarMonth + 1) &#123; return true; &#125; this.calendarMonth = data.day.slice(5, 7) - 1; var that = this; getRoomPrice(that.room.id, &#123;&#x27;date&#x27;: data.day&#125;).then(response =&gt; &#123; var arr = []; response.data.priceList.forEach((item,index,array)=&gt;&#123; arr[index] = item? item : that.room.price; &#125;) that.priceList = arr &#125;); that.$forceUpdate() &#125;, getRowKeys(row) &#123; // console.log(row.id) return row.id //这里看这一行中需要根据哪个属性值是id &#125;, selectDate(type) &#123; // consoloe.log(type) &#125;, expandChange(row, expandedRows) &#123; // console.log(this.expands) var that = this; that.room = row; // 每次只展开一行 if (expandedRows.length) &#123; that.calendarLoad = true; getRoomPrice(row.id, &#123;&#x27;date&#x27;: this.priceDate&#125;).then(response =&gt; &#123; that.calendarLoad = false; var arr = []; response.data.priceList.forEach((item,index,array)=&gt;&#123; arr[index] = item? item : row.price; &#125;) that.priceList = arr that.expands = [row.id] &#125;); &#125; else &#123; // 收起价格日历 that.expands = [] &#125; &#125;, setPrice(data, date) &#123; if (this.nowDay &gt; data.day.replace(/-/g, &#x27;&#x27;)) &#123; return false; &#125; var that = this; this.temp = &#123; name: that.room.name, date: [date, date], is_part: 0, &#125;; this.dialogPriceVisible = true; &#125;, putPrice() &#123; this.dialogPriceVisible = true; setRoomPrice(this.room.id, this.temp).then(res =&gt; &#123; if (res.code == 0) &#123; this.$message.success(&quot;编辑成功&quot;); this.dialogPriceVisible = !this.dialogPriceVisible; var that = this; getRoomPrice(that.room.id, &#123;&#x27;date&#x27;: this.temp.date[0]&#125;).then(response =&gt; &#123; var arr = []; response.data.priceList.forEach((item,index,array)=&gt;&#123; arr[index] = item? item : that.room.price; &#125;) that.priceList = arr &#125;); fetchList(that.params).then(response =&gt; &#123; that.list = response.data; &#125;); that.resetTemp(); that.$forceUpdate() &#125; else &#123; this.$message.error(res.msg); &#125; &#125;); &#125;,\t// 用于可展开表格与树形表格，切换某一行的展开状态，如果使用了第二个参数，则是设置这一行展开与否（expanded 为 true 则展开） handleCheck(row) &#123; const $table = this.$refs.table $table.toggleRowExpansion(row) &#125; &#125;&#125;;&lt;/script&gt; 价格日历返回数据格式： &#123;\t&quot;status&quot;: &quot;success&quot;,\t&quot;code&quot;: 0,\t&quot;msg&quot;: &quot;操作成功&quot;,\t&quot;data&quot;: &#123; &quot;room&quot;: &#123; &quot;name&quot;: &quot;大床房&quot;, &quot;price&quot;: 299, &quot;original_price&quot;: 289 &#125;, &quot;priceList&quot;: [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, 209, 219, false, false, false, false, false],\t&#125;&#125; priceList是本月价格，false表示未设置。 table的功能比较强大，部分属性函数并不常用，可以自行打印出来看看，研究一下即可。calendar是2.8版本新增的组件，如果版本过低，可以尝试升级到新版本。","tags":["ElementUI"],"categories":["vue"]},{"title":"利用Laravel中间件给后台加个操作日志","path":"/2020/04/29/248/","content":"项目后台角色及人员变多，需要加下日志，方便查询，不妨利用中间件实现下。 方案： 中间件判断是否需要记录，写入队列 队列写入数据库 表设计 CREATE TABLE `admin_log` ( `id` int(10) unsigned NOT NULL AUTO_INCREMENT, `user_id` int(11) NOT NULL, `path` varchar(255) COLLATE utf8mb4_unicode_ci NOT NULL, `method` varchar(10) COLLATE utf8mb4_unicode_ci NOT NULL, `ip` varchar(255) COLLATE utf8mb4_unicode_ci NOT NULL, `input` text COLLATE utf8mb4_unicode_ci NOT NULL, `created_at` timestamp NULL DEFAULT CURRENT_TIMESTAMP, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci ROW_FORMAT=DYNAMIC; 新建中间件AdminLogMiddleware，在后台路由中加入此中间件即可， &lt;?php/** * Author: sai * Date: 2020/4/1 * Time: 16:19 */namespace App\\Http\\Middleware;use App\\Jobs\\OperationLogJob;use Closure;use Auth;class AdminLogMiddleware&#123; /** * 处理传入的参数 * * @param \\Illuminate\\Http\\Request $request * @param \\Closure $next * @param string $role * @return mixed */ public function handle($request, Closure $next, $role) &#123; // 剔除GET，OPTIONS请求 if (!in_array($method = $request-&gt;getMethod(), [&#x27;GET&#x27;, &#x27;OPTIONS&#x27;])) &#123; $data = [ &#x27;user_id&#x27; =&gt; Auth::guard(&#x27;admin&#x27;)-&gt;id(), &#x27;path&#x27; =&gt; $request-&gt;getPathInfo(), &#x27;method&#x27; =&gt; $method, &#x27;ip&#x27; =&gt; $request-&gt;getClientIp(), &#x27;input&#x27; =&gt; \\json_encode($request-&gt;all(), JSON_HEX_TAG | JSON_HEX_APOS | JSON_HEX_QUOT | JSON_HEX_AMP | JSON_UNESCAPED_UNICODE), ]; // 异步写入，提高操作流畅性 $job = (new OperationLogJob($data)); dispatch($job); &#125; return $next($request); &#125;&#125; &lt;?phpnamespace App\\Jobs;use App\\Models\\AdminLog;use Illuminate\\Bus\\Queueable;use Illuminate\\Contracts\\Queue\\ShouldQueue;use Illuminate\\Foundation\\Bus\\Dispatchable;use Illuminate\\Queue\\InteractsWithQueue;use Illuminate\\Queue\\SerializesModels;class OperationLogJob implements ShouldQueue&#123; use Dispatchable, InteractsWithQueue, Queueable, SerializesModels; /** * Create a new job instance. * * @return void */ public function __construct($data) &#123; // $this-&gt;queue = &#x27;adminLog&#x27;; $this-&gt;data = $data; &#125; private $data; /** * Execute the job. * * @return void */ public function handle() &#123; // AdminLog::create($this-&gt;data); &#125;&#125; 执行队列： php artisan queue:work --queue=adminLog 当然，也可以不写入数据库，写在log文件里，这里就不展开了。 另外，为了方便，也可以给后台统一加入AdminLogMiddleware中间件，把不需要做记录的路由加入配置文件，在中间件加入判断，省去在路由配置去区分是否需要记录。","tags":["Laravel"],"categories":["PHP"]},{"title":"ElementUI中table表格自定义表头Tooltip文字提示","path":"/2020/04/29/247/","content":"table表格需要增加提示文案说明，没有现成的属性添加，我们可以通过render-header来渲染表头。 代码如下： &lt;el-table-column align=&quot;center&quot; label=&quot;价格&quot; :render-header=&quot;renderTipsHeader&quot; &gt; &lt;template slot-scope=&quot;scope&quot;&gt; &#123;&#123; scope.row.amount &#125;&#125; &lt;/template&gt;&lt;/el-table-column&gt; renderTipsHeader： renderTipsHeader (h,&#123;column&#125;) &#123; return h( &#x27;div&#x27;,[ h(&#x27;span&#x27;, column.label), h(&#x27;el-tooltip&#x27;,&#123; props:&#123; effect:&#x27;dark&#x27;, content:&#x27;提示文案&#x27;, placement:&#x27;top&#x27; &#125;, &#125;,[ h(&#x27;i&#x27;, &#123; class:&#x27;el-icon-question&#x27;, style:&#x27;color:#409EFF;margin-left:5px;&#x27; &#125;) ]) ] ); &#125; 效果如图： render-header 列标题 Label 区域渲染使用的 Function Function(h, &#123; column, $index &#125;) 感兴趣可以打印出来看看，这里还有更复杂的应用–https://github.com/Darkerxi/ElementUI-Table-column_render-header 参考文章：element-ui自定义table表头，修改标题样式、添加tooltip及 :render-header使用简介","tags":["ElementUI"],"categories":["vue"]},{"title":"分享按日执行的脚本","path":"/2020/04/25/246/","content":"项目中要做一些按日进行的统计，之前的任务都没跑，写个脚本执行下。 plus.sh #!/bin/bashSTART_DATE=$1END_DATE=$2EXEC_COMMAND=$3echo &#x27;start_date: &#x27;$START_DATEecho &#x27;end_date: &#x27;$END_DATEi=$START_DATEwhile [[ $i &lt; `date -d &quot;+1 day $END_DATE&quot; +%Y%m%d` ]] do echo $i $EXEC_COMMAND $i i=`date -d &quot;+1 day $i&quot; +%Y%m%d`done 执行 ./plus.sh 2020-03-01 2020-04-24 ‘php artisan command:test’","tags":["shell"],"categories":["shell"]},{"title":"Laravel配合MaatwebsiteExcel实现Excel导入","path":"/2020/04/05/245/","content":"前一段需要项目中需要通过Excel导入用户，之前用过phpexcel，总感觉太过繁琐，印象中phpexcel也很久没更新，看到项目中有使用Maatwebsite\\Excel，便尝试使用一下。 安装composer require maatwebsite/excel 导入生成导入类php artisan make:import AdminsImport --model=Admin 会看到app下面生成了Imports文件夹。 完善业务逻辑&lt;?phpnamespace App\\Imports;use App\\Models\\Admin;use function EasyWeChat\\Kernel\\Support\\str_random;use Maatwebsite\\Excel\\Concerns\\ToModel;class AdminsImport implements ToModel&#123; /** * @param array $row * * @return \\Illuminate\\Database\\Eloquent\\Model|null */ public function model(array $row) &#123; //过滤表头和空行，我这边表头的第一个单元格是id，具体自行调整 if (empty($row[0]) || $row[0] == &#x27;id&#x27;) &#123; return null; &#125; return new Admin([ &#x27;username&#x27; =&gt; $row[2], &#x27;password&#x27; =&gt; bcrypt($row[3]), &#x27;api_token&#x27; =&gt; str_random(60), ]); &#125;&#125; 导入任务&lt;?phpnamespace App\\Console\\Commands;use App\\Imports\\AdminsImport;use Illuminate\\Console\\Command;use Maatwebsite\\Excel\\Facades\\Excel;class ImportAdmin extends Command&#123; /** * The name and signature of the console command. * * @var string */ protected $signature = &#x27;importAdmin&#x27;; /** * The console command description. * * @var string */ protected $description = &#x27;导入admin&#x27;; /** * Create a new command instance. * * @return void */ public function __construct() &#123; parent::__construct(); &#125; /** * Execute the console command. * * @return mixed */ public function handle() &#123; Excel::import(new AdminsImport(), storage_path(&#x27;files/export.xlsx&#x27;)); $this-&gt;info($this-&gt;description.&#x27;完成&#x27;);\t&#125;&#125; 其他逻辑当然，可能业务必不仅仅是写入数据，可能有一些设计具体业务的操作，那么你可以这样操作。 &lt;?phpnamespace App\\Imports;use App\\Models\\Admin;use function EasyWeChat\\Kernel\\Support\\str_random;use Maatwebsite\\Excel\\Concerns\\ToCollection;use Illuminate\\Support\\Collection;class AdminsImport implements ToCollection&#123; public function collection(Collection $rows) &#123; //如果需要去除表头 unset($rows[0]); //$rows 是数组格式 return $this-&gt;createData($rows); &#125; public function createData($rows) &#123; $success = 0; foreach ($rows as $row) &#123; $row[0] = (int) $row[0]; if (empty($row[0])) &#123; continue; &#125; (new Admin())-&gt;create( [ &#x27;username&#x27; =&gt; $row[2], &#x27;name&#x27; =&gt; $row[2], &#x27;password&#x27; =&gt; bcrypt($row[3]), &#x27;api_token&#x27; =&gt; str_random(60), ] ); // 其他业务代码 $success++; &#125; return $success.&#x27;-&#x27;.count($rows); &#125;&#125; 执行php7.2 artisan importAdmin 总的来说，使用起来还是简单明了的。 more具体导入实现可以搜索Maatwebsite\\Excel\\Excel查看，里面还有导出、以队列方式导入等，支持的格式也是多种多样，具体代码如下，功能还是很强大的，足够应付日常需求了。 &lt;?phpnamespace Maatwebsite\\Excel;use Illuminate\\Support\\Collection;use Maatwebsite\\Excel\\Files\\Filesystem;use Maatwebsite\\Excel\\Files\\TemporaryFile;use Illuminate\\Contracts\\Queue\\ShouldQueue;use Illuminate\\Foundation\\Bus\\PendingDispatch;use Maatwebsite\\Excel\\Helpers\\FileTypeDetector;class Excel implements Exporter, Importer&#123; use RegistersCustomConcerns; const XLSX = &#x27;Xlsx&#x27;; const CSV = &#x27;Csv&#x27;; const TSV = &#x27;Csv&#x27;; const ODS = &#x27;Ods&#x27;; const XLS = &#x27;Xls&#x27;; const SLK = &#x27;Slk&#x27;; const XML = &#x27;Xml&#x27;; const GNUMERIC = &#x27;Gnumeric&#x27;; const HTML = &#x27;Html&#x27;; const MPDF = &#x27;Mpdf&#x27;; const DOMPDF = &#x27;Dompdf&#x27;; const TCPDF = &#x27;Tcpdf&#x27;; /** * @var Writer */ protected $writer; /** * @var QueuedWriter */ protected $queuedWriter; /** * @var Filesystem */ protected $filesystem; /** * @var Reader */ private $reader; /** * @param Writer $writer * @param QueuedWriter $queuedWriter * @param Reader $reader * @param Filesystem $filesystem */ public function __construct( Writer $writer, QueuedWriter $queuedWriter, Reader $reader, Filesystem $filesystem ) &#123; $this-&gt;writer = $writer; $this-&gt;reader = $reader; $this-&gt;filesystem = $filesystem; $this-&gt;queuedWriter = $queuedWriter; &#125; /** * &#123;@inheritdoc&#125; */ public function download($export, string $fileName, string $writerType = null, array $headers = []) &#123; return response()-&gt;download( $this-&gt;export($export, $fileName, $writerType)-&gt;getLocalPath(), $fileName, $headers )-&gt;deleteFileAfterSend(true); &#125; /** * &#123;@inheritdoc&#125; */ public function store($export, string $filePath, string $diskName = null, string $writerType = null, $diskOptions = []) &#123; if ($export instanceof ShouldQueue) &#123; return $this-&gt;queue($export, $filePath, $diskName, $writerType, $diskOptions); &#125; $temporaryFile = $this-&gt;export($export, $filePath, $writerType); $exported = $this-&gt;filesystem-&gt;disk($diskName, $diskOptions)-&gt;copy( $temporaryFile, $filePath ); $temporaryFile-&gt;delete(); return $exported; &#125; /** * &#123;@inheritdoc&#125; */ public function queue($export, string $filePath, string $disk = null, string $writerType = null, $diskOptions = []) &#123; $writerType = FileTypeDetector::detectStrict($filePath, $writerType); return $this-&gt;queuedWriter-&gt;store( $export, $filePath, $disk, $writerType, $diskOptions ); &#125; /** * &#123;@inheritdoc&#125; */ public function raw($export, string $writerType) &#123; $temporaryFile = $this-&gt;writer-&gt;export($export, $writerType); $contents = $temporaryFile-&gt;contents(); $temporaryFile-&gt;delete(); return $contents; &#125; /** * &#123;@inheritdoc&#125; */ public function import($import, $filePath, string $disk = null, string $readerType = null) &#123; $readerType = FileTypeDetector::detect($filePath, $readerType); $response = $this-&gt;reader-&gt;read($import, $filePath, $readerType, $disk); if ($response instanceof PendingDispatch) &#123; return $response; &#125; return $this; &#125; /** * &#123;@inheritdoc&#125; */ public function toArray($import, $filePath, string $disk = null, string $readerType = null): array &#123; $readerType = FileTypeDetector::detect($filePath, $readerType); return $this-&gt;reader-&gt;toArray($import, $filePath, $readerType, $disk); &#125; /** * &#123;@inheritdoc&#125; */ public function toCollection($import, $filePath, string $disk = null, string $readerType = null): Collection &#123; $readerType = FileTypeDetector::detect($filePath, $readerType); return $this-&gt;reader-&gt;toCollection($import, $filePath, $readerType, $disk); &#125; /** * &#123;@inheritdoc&#125; */ public function queueImport(ShouldQueue $import, $filePath, string $disk = null, string $readerType = null) &#123; return $this-&gt;import($import, $filePath, $disk, $readerType); &#125; /** * @param object $export * @param string|null $fileName * @param string $writerType * * @throws \\PhpOffice\\PhpSpreadsheet\\Exception * @return TemporaryFile */ protected function export($export, string $fileName, string $writerType = null): TemporaryFile &#123; $writerType = FileTypeDetector::detectStrict($fileName, $writerType); return $this-&gt;writer-&gt;export($export, $writerType); &#125;&#125; 最后，感谢下面这一篇站内文章让我快速上手。 maatwebsite/Excel 3.1 使用教程 （导入篇） 最后，附上Laravel Excel 文档： Laravel Excel","tags":["Laravel"],"categories":["PHP"]},{"title":"go的类型转换","path":"/2020/03/29/243/","content":"类型转换是经常使用到的，汇总了一些比较常见的用法，分享给你～ package main/**\t变量类型转换*/import (\t&quot;fmt&quot;\t&quot;reflect&quot;\t&quot;strconv&quot;)func main() &#123; v := &quot;hello world&quot; fmt.Println(typeofFmt(v))\tfmt.Println(typeofReflect(v))\tstr := &quot;1245&quot;\tfmt.Println(stringToInt(str))\tfmt.Println(stringToInt64(str))\ta := 3545;\tvar b int64;\tb = 98;\tfmt.Println(int64ToString(b))\tfmt.Println(intToString(a))\tvar f float64\tf = 3.45\tfmt.Println(floatToString(f))\tstr = &quot;1.24&quot;\tfmt.Println(stringToFloat(str))\t//int到int64\tfmt.Println(int64(1234))\t//int 转化为 float\tscore := 100\tfmt.Println(float64(score))&#125;// 利用fmtfunc typeofFmt(v interface&#123;&#125;) string &#123; return fmt.Sprintf(&quot;%T&quot;, v)&#125;// 利用reflectfunc typeofReflect(v interface&#123;&#125;) string &#123; return reflect.TypeOf(v).String()&#125;// string转intfunc stringToInt(a string) int &#123;\td,_ := strconv.Atoi(a)\treturn d&#125;//Atoi是ParseInt(s, 10, 0)的简写。// string转int64func stringToInt64(a string) int64 &#123;\td, _ := strconv.ParseInt(a, 10, 64) return d&#125;/**func ParseInt(s string, base int, bitSize int) (i int64, err error)返回字符串表示的整数值，接受正负号。base指定进制（2到36），如果base为0，则会从字符串前置判断，&quot;0x&quot;是16进制，&quot;0&quot;是8进制，否则是10进制；bitSize指定结果必须能无溢出赋值的整数类型，0、8、16、32、64 分别代表 int、int8、int16、int32、int64；返回的err是*NumErr类型的，如果语法有误，err.Error = ErrSyntax；如果结果超出类型范围err.Error = ErrRange。*/// int转stringfunc intToString(a int) string &#123;\tstr := strconv.Itoa(a) return str&#125;// int64转stringfunc int64ToString(a int64) string &#123;\tstr := strconv.FormatInt(a,10)\treturn str&#125;/**func FormatInt(i int64, base int) string返回i的base进制的字符串表示。base 必须在2到36之间，结果中会使用小写字母&#x27;a&#x27;到&#x27;z&#x27;表示大于10的数字。*/// float转stringfunc floatToString (f float64) string &#123;\treturn strconv.FormatFloat(f,&#x27;f&#x27;,-1,32)&#125;/**func FormatFloat(f float64, fmt byte, prec, bitSize int) stringbitSize表示f的来源类型（32：float32、64：float64），会据此进行舍入。fmt表示格式：&#x27;f&#x27;（-ddd.dddd）、&#x27;b&#x27;（-ddddp±ddd，指数为二进制）、&#x27;e&#x27;（-d.dddde±dd，十进制指数）、&#x27;E&#x27;（-d.ddddE±dd，十进制指数）、&#x27;g&#x27;（指数很大时用&#x27;e&#x27;格式，否则&#x27;f&#x27;格式）、&#x27;G&#x27;（指数很大时用&#x27;E&#x27;格式，否则&#x27;f&#x27;格式）。prec控制精度（排除指数部分）：对&#x27;f&#x27;、&#x27;e&#x27;、&#x27;E&#x27;，它表示小数点后的数字个数；对&#x27;g&#x27;、&#x27;G&#x27;，它控制总的数字个数。如果prec 为-1，则代表使用最少数量的、但又必需的数字来表示f。*/// string转floatfunc stringToFloat(s string) float64 &#123;\tf,_ := strconv.ParseFloat(s,64)\treturn f&#125;/**func ParseFloat(s string, bitSize int) (f float64, err error)解析一个表示浮点数的字符串并返回其值。如果s合乎语法规则，函数会返回最为接近s表示值的一个浮点数（使用IEEE754规范舍入）。bitSize指定了期望的接收类型，32是float32（返回值可以不改变精确值的赋值给float32），64是float64；返回值err是*NumErr类型的，语法有误的，err.Error=ErrSyntax；结果超出表示范围的，返回值f为±Inf，err.Error= ErrRange。*/ 更多类型转换相关可查看标准库：- strconv 技术文章也发布在自己的公众号【爱好历史的程序员】，欢迎扫码关注，谢谢！","tags":["go"],"categories":["go"]},{"title":"Redis常用类型及应用场景","path":"/2020/03/22/230/","content":"主要类型 字符串（strings，bitmaps） 散列（hashes） 列表（lists） 集合（sets） 有序集合（sorted sets） hyperloglogs 发布订阅（pub/sub） 地理空间（geospatial） Stream（5.0版本新增） 关于命令我推荐看这两个： http://doc.Redisfans.com/ http://www.Redis.cn/commands.html 应用场景strings 缓存 分布式锁（setnx） 签到统计（setbit） 计数（incr） hashes 缓存 用户标签 lists 队列 sets 交集并集 数据去重 zset 排行榜 延时任务 限流 hyperloglogs uv统计（ip统计） pub/sub 发布订阅（不是特别可靠） geospatial 附近的人 Stream 队列 发布订阅 其他利用事务实现秒杀以php代码为例： WATCH命令可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行。监控一直持续到EXEC命令（事务中的命令是在EXEC之后才执行的，所以在MULTI命令后可以修改WATCH监控的键值） // 库存为5//实例化Redis$Redis = new Redis();//连接$Redis-&gt;connect(&#x27;127.0.0.1&#x27;, 6379);$key = &#x27;sale&#x27;;$Redis-&gt;setnx($key, 0); // 此项不预定义亦可，保证key唯一就行$Redis-&gt;watch($key); //监视一个(或多个) key ，如果在事务执行之前这个(或这些) key 被其他命令所改动，那么事务将被打断。$sale_num = $Redis-&gt;get($key);if ($sale_num &gt; 4) &#123;\texit();&#125;$Redis-&gt;multi(); //标记事务$Redis-&gt;incr($key); //销量+1sleep(1); //模拟真实环境$ret = $Redis-&gt;exec(); // 事务块内所有命令的返回值，按命令执行的先后顺序排列。if ($ret) &#123; // 自定义的一个基于medoo的dbclass\tinclude &#x27;db.php&#x27;;\t$db = new db([ &#x27;database_type&#x27; =&gt; &#x27;mysql&#x27;, &#x27;database_name&#x27; =&gt; &#x27;test&#x27;, &#x27;server&#x27; =&gt; &#x27;puresai&#x27;, &#x27;username&#x27; =&gt; &#x27;puresai&#x27;, &#x27;password&#x27; =&gt; &#x27;*&#x27;, &#x27;charset&#x27; =&gt; &#x27;utf8&#x27;\t]);\t$db-&gt;update(&#x27;goods&#x27;, [&quot;stock_num[-]&quot; =&gt; 1], [&#x27;id&#x27; =&gt; 1]);&#125; 布隆过滤器 布隆过滤器（Bloom Filter）是1970年由布隆提出的。它实际上是一个很长的二进制向量和一系列随机映射函数。布隆过滤器可以用于检索一个元素是否在一个集合中。 php实现推荐看看这篇文章： https://github.oscome.cn/2019/05/21/188/ 当然，Redis自己也有第三方模块： https://github.com/RedisBloom/RedisBloom git clone https://github.com/RedisBloom/RedisBloom.gitcd Redisbloommake/path/to/Redis-server --loadmodule ./Redisbloom.so Bloom：向过滤器添加新项,如果尚不存在，则会为您创建一个新的过滤器 127.0.0.1:6379&gt; BF.ADD newFilter foo(integer) 1 Bloom：检查过滤器中是否存在项 127.0.0.1:6379&gt; BF.EXISTS newFilter foo(integer) 1127.0.0.1:6379&gt; BF.EXISTS newFilter notpresent(integer) 0 限流Redis-cell// 提前安装rust哟git clone https://github.com/brandur/Redis-cell.gitcd Redis-cellcargo build --releasecp target/release/libRedis_cell.dylib /path/to/modules/Redis-server --loadmodule /path/to/modules/libRedis_cell.so 该模块只有1条指令cl.throttle，它的参数和返回值都略显复杂，接下来让我们来看看这个指令具体该如何使用。 &gt; cl.throttle limitThrot 15 30 60 1 ▲ ▲ ▲ ▲ ▲ | | | | └───── need 1 quota (可选参数，默认值也是1) | | └──┴─────── 30 operations / 60 seconds 这是漏水速率 | └───────────── 15 capacity 这是漏斗容量&gt; └─────────────────── key 上面这个指令的意思是允许频率为每 60s 最多 30 次(漏水速率)，漏斗的初始容量为 15，也就是说一开始可以取 15 个，然后才开始受漏水速率的影响。我们看到这个指令中漏水速率变成了 2 个参数，替代了之前的单个浮点数。用两个参数相除的结果来表达漏水速率相对单个浮点数要更加直观一些。 &gt; cl.throttle limitThrot 15 30 60 11) (integer) 0 # 0 表示允许，1表示拒绝2) (integer) 15 # 漏斗容量capacity3) (integer) 14 # 漏斗剩余空间left_quota4) (integer) -1 # 如果拒绝了，需要多长时间后再试(漏斗有空间了，单位秒)5) (integer) 2 # 多长时间后，漏斗完全空出来(left_quota==capacity，单位秒) 基本上常见的场景就是这些了，各位周末愉快！","tags":["Redis"],"categories":["Redis"]},{"title":"MySQL是如何做到不丢数据","path":"/2020/03/18/MySQL-data/","content":"本文为极客时间专栏《MySQL实战45讲》笔记，文中部分图文来自该专栏。附上专栏链接，有兴趣可点击订阅：https://time.geekbang.org/column/intro/139 MySQL是如何做到数据不丢失呢？ 我们先来介绍下WAL。 WAL(Write-Ahead Loggin)机制WAL 是预写式日志, 关键点在于先写日志再写磁盘. MySQL在对数据页进行修改时, 通过将”修改了什么”这个操作记录在日志中, 而不必马上将更改内容刷新到磁盘上, 从而将随机写转换为顺序写, 提高了性能。 这种机制一方面提高了MySQL的吞吐量，另一方面也实现了数据的高可靠性。 binlog的写入机制事务执行过程中，先把日志写到binlog cache，事务提交的时候，再把binlog cache写到binlog文件中。 一个事务的binlog是不能被拆开的，因此不论这个事务多大，也要确保一次性写入。这就涉及到了binlog cache的保存问题。 系统给binlog cache分配了一片内存，每个线程一个，参数 binlog_cache_size用于控制单个线程内binlog cache所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。 事务提交的时候，执行器把binlog cache里的完整事务写入到binlog中，并清空binlog cache。 可以看到，每个线程有自己binlog cache，但是共用同一份binlog文件。 图中的write，指的就是指把日志写入到文件系统的page cache，并没有把数据持久化到磁盘，所以速度比较快。 图中的fsync，才是将数据持久化到磁盘的操作。 write 和fsync的时机，是由参数sync_binlog控制的： sync_binlog=0的时候，表示每次提交事务都只write，不fsync； sync_binlog=1的时候，表示每次提交事务都会执行fsync； sync_binlog=N(N&gt;1)的时候，表示每次提交事务都write，但累积N个事务后才fsync。 因此，在出现IO瓶颈的场景里，将sync_binlog设置成一个比较大的值，可以提升性能。在实际的业务场景中，考虑到丢失日志量的可控性，一般不建议将这个参数设成0，比较常见的是将其设置为100~1000中的某个数值。 但是，将sync_binlog设置为N，对应的风险是：如果主机发生异常重启，会丢失最近N个事务的binlog日志。 redo log先说说说redo log的三种状态： 红色：存在redo log buffer中，物理上是在MySQL进程内存中 黄色：写到磁盘(write)，但是没有持久化（fsync)，物理上是在文件系统的page cache里面 绿色：持久化到磁盘，对应的是hard disk 为了控制 redo log 的写入策略，InnoDB 提供了 innodb_flush_log_at_trx_commit 参 数，它有三种可能取值: 0，表示每次事务提交时都只是把 redo log 留在 redo log buffer 中 ; 1，表示每次事务提交时都将 redo log 直接持久化到磁盘; 2 ，表示每次事务提交时都只是把 redo log 写到 page cache。 InnoDB 有一个后台线程，每隔 1 秒，就会把 redo log buffer 中的日志，调用 write 写 到文件系统的 page cache，然后调用 fsync 持久化到磁盘。 实际上，除了后台线程每秒一次的轮询操作外，还有两种场景会让一个没有提交的事务的 redo log 写入到磁盘中。 1. redo log buffer 占用的空间即将达到 innodb_log_buffer_size 一半的时 候，后台线程会主动写盘。注意，由于这个事务并没有提交，所以这个写盘动作只是 write，而没有调用 fsync，也就是只留在了文件系统的 page cache。2. 并行的事务提交的时候，顺带将这个事务的 redo log buffer 持久化到磁 盘。假设一个事务 A 执行到一半，已经写了一些 redo log 到 buffer 中，这时候有另 外一个线程的事务 B 提交，如果 innodb_flush_log_at_trx_commit 设置的是 1，那么 按照这个参数的逻辑，事务 B 要把 redo log buffer 里的日志全部持久化到磁盘。这时 候，就会带上事务 A 在 redo log buffer 里的日志一起持久化到磁盘。 既然MySQL能保证redo log和binlog能可靠性写入磁盘，那么在他们两者直接如何保证可靠转换的呢？ 两阶段提交redo log 先 prepare，再写 binlog，最后再把 redo log commit。利用这个两阶段提交机制，MySQL保证了redo log和binlog的可靠传输。 最后我们来看下整体简图： 配置建议 innodb_flush_log_at_trx_commit=1。表示每次事务的redolog都直接持久化到磁盘，保证mysql重启后数据不丢失。 sync_binlog=1。表示每次事务的binlog都直接持久化到磁盘，保证mysql重启后binlog记录是完整的。","tags":["mysql"],"categories":["MySQL"]},{"title":"MySQL主从","path":"/2020/03/17/MySQL-master-slave/","content":"本文为极客时间专栏《MySQL实战45讲》笔记，文中部分图文来自该专栏。附上专栏链接，有兴趣可点击订阅：https://time.geekbang.org/column/intro/139 昨天的文章我们操作了主从复制，那么你有仔细想一想工作原理吗？ 主从同步复制原理复制简单分成三步： master将改变记录到二进制日志(binary log)中（这些记录叫做二进制日志事件，binary log events）； slave将master的binary log events拷贝到它的中继日志(relay log)； slave重做中继日志中的事件，将改变反映它自己的数据。 当然，其中的细节是很复杂的，我们可以看下极客时间《MySQL实战45讲》专栏的图： 主库接收到客户端的更新请求后，执行内部事务的更新逻辑，同时写binlog。 而备库B跟主库A之间维持了一个长连接。主库A内部有一个线程，专门用于服务备库B的这个长连接。一个事务日志同步的完整过程是这样的： 在备库B上通过change master命令，设置主库A的IP、端口、用户名、密码，以及要从哪个位置开始请求binlog，这个位置包含文件名和日志偏移量。 在备库B上执行start slave命令，这时候备库会启动两个线程，就是图中的io_thread和sql_thread。其中io_thread负责与主库建立连接。 主库A校验完用户名、密码后，开始按照备库B传过来的位置，从本地读取binlog，发给B。 备库B拿到binlog后，写到本地文件，称为中转日志（relay log）。 sql_thread读取中转日志，解析出日志里的命令，并执行。 binlog里记录的是什么？那么介绍了工作原理，之前也有文章介绍过binlog，那么binlog里到底记录的是什么呢？ binlog根据配置记录的内容是不一样的，我们看表格： format 定义 优点 缺点 statement 记录的是修改SQL语句 日志文件小，节约IO，提高性能 准确性差，对一些系统函数不能准确复制或不能复制，如now()、uuid()等 row 记录的是每行实际数据的变更 准确性强，能准确复制数据的变更 日志文件大，较大的网络IO和磁盘IO mixed statement和row模式的混合 准确性强，文件大小适中 有可能发生主从不一致问题 推荐使用的是row模式，准确性高，虽然说文件大，但是现在有SSD和万兆光纤网络，这些磁盘IO和网络IO都是可以接受的。 mixed格式的意思是，MySQL自己会判断这条SQL语句是否可能引起主备不一致，如果有可能，就用row格式，否则就用statement格式。也就是说，mixed格式可以利用statment格式的优点，同时又避免了数据不一致的风险。那么，为什么不推荐使用mixed模式，我们可以举例说明（数据恢复）： 我们就分别从delete、insert和update这三种SQL语句的角度，来看看数据恢复的问题。 即使执行的是delete语句，row格式的binlog也会把被删掉的行的整行信息保存起来。所以，如果你在执行完一条delete语句以后，发现删错数据了，可以直接把binlog中记录的delete语句转成insert，把被错删的数据插入回去就可以恢复了。 如果你是执行错了insert语句呢？那就更直接了。row格式下，insert语句的binlog里会记录所有的字段信息，这些信息可以用来精确定位刚刚被插入的那一行。这时，你直接把insert语句转成delete语句，删除掉这被误插入的一行数据就可以了。 如果执行的是update语句的话，binlog里面会记录修改前整行的数据和修改后的整行数据。所以，如果你误执行了update语句的话，只需要把这个event前后的两行信息对调一下，再去数据库里面执行，就能恢复这个更新操作了。 其实，由delete、insert或者update语句导致的数据操作错误，需要恢复到操作之前状态的情况，也时有发生。 查看binlogbinlog本身是一类二进制文件。二进制文件更省空间，写入速度更快，是无法直接打开来查看的。因此mysql提供了命令mysqlbinlog进行查看。一般的statement格式的二进制文件，用下面命令就可以 mysqlbinlog mysql-bin.000001 如果是row格式，加上-v或者-vv参数就行，如 mysqlbinlog -vv mysql-bin.000001 配置参数 参数名 含义 log_bin = {on | off | base_name} 指定是否启用记录二进制日志或者指定一个日志路径 sql_log_bin ={ on | off } 指定是否启用记录二进制日志 expire_logs_days 指定自动删除二进制日志的时间，即日志过期时间 log_bin_index 指定mysql-bin.index文件的路径 binlog_format = { mixed | row | statement } 指定二进制日志基于什么模式记录 max_binlog_size 指定二进制日志文件最大值 binlog_cache_size 指定事务日志缓存区大小 max_binlog_cache_size 指定二进制日志缓存最大大小 sync_binlog = { 0 | n } 指定写缓冲多少次，刷一次盘 之前是介绍一些概念的东西，今天我们来换换口味，实际操作一下啊，操作内容是搭建我们经常用到的MySQL主从。 前提已经安装好了主数据库和从数据库，并新建database为test，假如一些数据。（因为是测试，单机器上开两个MySQL示例也可以） masterGRANT REPLICATION SLAVE, REPLICATION CLIENT ON . TO repl@&#x27;127.0.0.1&#x27; IDENTIFIED BY &#x27;111111&#x27;; //分配账号 grant all on . to repl@&#x27;127.0.0.1&#x27;; //授权 查看状态 SHOW MASTER STATUS;//记住这里的file和position。 修改配置 [mysqld] log-bin=mysql-bin server-id=1 重启 slave修改配置，注意server_id要与主库，其他从库不一样，可以设置成ip [mysqld] log_bin = mysql-bin server_id = 2 relay_log = mysql-relay-bin log_slave_updates = 1 read_only = 1 重启后，建议先进行重置操作。 reset slave 连接master CHANGE MASTER TO MASTER_HOST=&#x27;127.0.0.1&#x27;,MASTER_USER=&#x27;repl&#x27;, MASTER_PASSWORD=&#x27;111111&#x27;, MASTER_LOG_FILE=&#x27;mysql-bin.000051&#x27;,master_log_pos=8694; master_log_file和master_log_pos就是上面记住的file和position，具体自行修改。 开启并查看状态 start slave show slave status 如果Slave_IO_Running和Slave_SQL_Running都显示Yes，一般就成功了。 失败一般就是master_log_pos，master_log_file配置有问题，重新配置下就行了。 可以在master插入修改数据，测试slave是否相应变化。 注意如果master已有数据，可以锁定master（flush tables with read lock），然后导出同步到slave，配置完成后释放master（unlock tables）。 参考文章 【原创】研发应该懂的binlog知识(上) https://www.cnblogs.com/rjzheng/p/9721765.html","tags":["mysql"],"categories":["MySQL"]},{"title":"MySQL的count","path":"/2020/03/15/MySQL-count/","content":"本文为极客时间专栏《MySQL实战45讲》笔记，文中部分图文来自该专栏。 count(*)语句应该是我们开发中很经常用到的,n那么你有仔细研究过吗？ 实现方式 MyISAM引擎把一个表的总行数存在了磁盘上，因此执行count()的时候会直接返回这个数，效率很高；如果加了where 条件的话，MyISAM表也是不能返回得这么快的。而InnoDB引擎就麻烦了，它执行count()的时候，需要把数据一行一行地从引擎里面读出来，然后判断not null累积计数。 那你就问了，为什么InnoDB不跟MyISAM一样，也把数字存起来呢？ 这是因为即使是在同一个时刻的多个查询，由于多版本并发控制（MVCC）的原因，InnoDB表“应该返回多少行”也是不确定的。 假设表t中现在有10000条记录，我们设计了三个用户并行的会话。 会话A先启动事务并查询一次表的总行数； 会话B启动事务，插入一行后记录后，查询表的总行数； 会话C先启动一个单独的语句，插入一行记录后，查询表的总行数。 我们假设从上到下是按照时间顺序执行的，同一行语句是在同一时刻执行的。 你会看到，在最后一个时刻，三个会话A、B、C会同时查询表t的总行数，但拿到的结果却不同。 这和InnoDB的事务设计有关系，可重复读是它默认的隔离级别，在代码上就是通过多版本并发控制来实现的。每一行记录都要判断自己是否对这个会话可见，因此对于count(*)请求来说，InnoDB只好把数据一行一行地读出依次判断，可见的行才能够用于计算“基于这个查询”的表的总行数。 当然，现在这个看上去笨笨的MySQL，在执行count(*)操作的时候还是做了优化的。 InnoDB支持的是索引组织表，主键索引树的叶子节点是数据，而普通索引树的叶子节点是主键值。所以，普通索引树比主键索引树小很多。对于count(*)这样的操作，遍历哪个索引树得到的结果逻辑上都是一样的。因此，MySQL优化器会找到最小的那棵树来遍历。 在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一。 如果你用过show table status 命令的话，就会发现这个命令的输出结果里面也有一个TABLE_ROWS用于显示这个表当前有多少行，这个命令执行挺快的，那这个TABLE_ROWS能代替count(*)吗？ 而索引统计的值是通过采样来估算的，实际上，TABLE_ROWS就是从这个采样估算得来的，因此它也不是很准。有多不准呢，官方文档说误差可能达到40%到50%。所以，show table status命令显示的行数也不能直接使用。 MyISAM表虽然count(*)很快，但是不支持事务；show table status命令虽然返回很快，但是不准确；InnoDB表直接count(*)会遍历全表，虽然结果准确，但会导致性能问题。 那么，如果你现在有一个页面经常要显示记录总数，到底应该怎么办呢？ 有时候，我们未必就只能纠结于count，我们可以自己额外计数。 计数方法缓存计数对于更新很频繁的库来说，你可能会第一时间想到，用缓存系统来支持，比如Redis。 我们可以用一个Redis服务来保存这个表的总行数，读和更新操作都很快。 当然，使用Redis存储计数是有一些问题的。 首先，无法保证Redis完全可用，假如异常挂掉，我们无法保证MySQL和Redis数据的一致性。 其次，即使Redis正常可用，计数也并不精确，因为MySQL和Redis存储必然有先后之分，在高并发场景下，多个会话从Redis和MySQL读到的数据很可能是不一致的，我们可以看看图片，就不展开说明了。 当然了，在某些场景下，我们可以这么做，因为业务并不要保证数据每时每刻都是精确的，那就无需考虑这些问题，Redis异常后我们可以从计算表行数去更新。 数据库计数我们也可以用MySQl新建一张表去计数。那么针对缓存计数的两个问题，我们来分析下： 首先，这解决了崩溃丢失的问题，InnoDB是支持崩溃恢复不丢数据的。 然后，我们再看看能不能解决计数不精确的问题。当然，我们有“事务”这个大杀器，可以保证数据一致性。 不同的count用法对比 count(主键id)：InnoDB引擎会遍历整张表，把每一行的id值都取出来，返回给server层。server层拿到id后，判断是不可能为null，就按行累加。 count(1)：InnoDB引擎遍历整张表，但不取值。server层对于返回的每一行，放一个数字“1”进去，判断是不可能为null，按行累加，显然这比上面的效率要高一些。 count(字段)：如果这个“字段”是定义为not null的话，一行行地从记录里面读出这个字段，判断不能为null，按行累加；如果这个“字段”定义允许为null，那么执行的时候，判断到有可能是null，还要把值取出来再判断一下，不是null才累加。 count()：是例外，并不会把全部字段取出来，而是专门做了优化，不取值。count()肯定不是null，按行累加。 按照效率排序的话，count(字段)&lt;count(主键id)&lt;count(1)≈count(*)，所以我建议你，尽量使用count(*)。","tags":["mysql"],"categories":["MySQL"]},{"title":"MySQL的锁","path":"/2020/03/14/MySQL-lock/","content":"本文为极客时间专栏《MySQL实战45讲》笔记，文中部分图文来自该专栏。 锁是MySQL中经常用到的，根据加锁的范围，MySQL里面的锁大致可以分成全局锁、表级锁和行锁三类。 全局锁顾名思义，全局锁就是对整个数据库实例加锁。 MySQL提供了一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL)。 当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。 典型使用场景是，做全库逻辑备份。 官方自带的逻辑备份工具是mysqldump。当mysqldump使用参数–single-transaction的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于MVCC的支持，这个过程中数据是可以正常更新的。 表锁MySQL里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。 表锁的语法是 lock tables … read/write。 与FTWRL类似，可以用unlock tables主动释放锁，也可以在客户端断开的时候自动释放。需要注意，lock tables语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。 举个例子, 如果在某个线程A中执行 lock tables t1 read, t2 write 这个语句，则其他线程写t1、读写t2的语句都会被阻塞。同时，线程A在执行unlock tables之前，也只能执行读t1、读写t2的操作。连写t1都不允许，自然也不能访问其他表。 在还没有出现更细粒度的锁的时候，表锁是最常用的处理并发的方式。而对于InnoDB这种支持行锁的引擎，一般不使用lock tables命令来控制并发，毕竟锁住整个表的影响面还是太大。 另一类表级的锁是MDL（metadata lock)。 MDL不需要显式使用，在访问一个表的时候会被自动加上。 MDL的作用是，保证读写的正确性。你可以想象一下，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。 因此，在MySQL 5.5版本中引入了MDL，当对一个表做增删改查操作的时候，加MDL读锁；当要对表做结构变更操作的时候，加MDL写锁。 读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。 虽然MDL锁是系统默认会加的，但却是你不能忽略的一个机制。比如下面这个例子，我经常看到有人掉到这个坑里：给一个小表加个字段，导致整个库挂了。 行锁MySQL的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，比如MyISAM引擎就不支持行锁。不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。InnoDB是支持行锁的，这也是MyISAM被InnoDB替代的重要原因之一。 在InnoDB事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。 死锁 所谓死锁: 是指两个或两个以上的进程在执行过程中,因争夺资源而造成的一种互相等待的现象,若无外力作用,它们都将无法推进下去.此时称系统处于死锁状态或系统产生了死锁,这些永远在互相等竺的进程称为死锁进程.表级锁不会产生死锁.所以解决死锁主要还是针对于最常用的InnoDB. 当出现死锁以后，有两种策略： 一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数innodb_lock_wait_timeout来设置。另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数innodb_deadlock_detect设置为on，表示开启这个逻辑。 加锁规则加锁规则里面，包含了两个“原则”、两个“优化”和一个“bug”。 原则1：加锁的基本单位是next-key lock，lock是前开后闭区间。 原则2：查找过程中访问到的对象才会加锁。 优化1：索引上的等值查询，给唯一索引加锁的时候，next-key lock退化为行锁。 优化2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock退化为间隙锁。 一个bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。","tags":["mysql"],"categories":["MySQL"]},{"title":"MySQL事务隔离","path":"/2020/03/13/MySQL-Isolation/","content":"本文为极客时间专栏《MySQL实战45讲》笔记，文中部分图文来自该专栏。 提到事务，你肯定会想到ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性），今天我们就来说说其中I，也就是“隔离性”。 SQL标准的事务隔离级别包括：读未提交（read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（serializable ）。 读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。 读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。 可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。 串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。 我们来看看在不同的隔离级别下，事务A会有哪些不同的返回结果，也就是图里面V1、V2、V3的返回值分别是什么。若隔离级别是“读未提交”， 则V1的值就是2。这时候事务B虽然还没有提交，但是结果已经被A看到了。因此，V2、V3也都是2。若隔离级别是“读提交”，则V1是1，V2的值是2。事务B的更新在提交后才能被A看到。所以， V3的值也是2。若隔离级别是“可重复读”，则V1、V2是1，V3是2。之所以V2还是1，遵循的就是这个要求：事务在执行期间看到的数据前后必须是一致的。若隔离级别是“串行化”，则在事务B执行“将1改成2”的时候，会被锁住。直到事务A提交后，事务B才可以继续执行。所以从A的角度看， V1、V2值是1，V3的值是2。 查看隔离级别： show variables like ‘transaction_isolation’; 事务启动 显式启动事务语句， begin 或 start transaction。配套的提交语句是commit，回滚语句是rollback。 建议你总是使用set autocommit=1, 通过显式语句的方式来启动事务。 事务隔离的实现理解了事务的隔离级别，我们再来看看事务隔离具体是怎么实现的。这里我们展开说明“可重复读”。 在MySQL中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。 假设一个值从1被按顺序改成了2、3、4，在回滚日志里面就会有类似下面的记录。 当前值是4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的read-view。如图中看到的，在视图A、B、C里面，这一个记录的值分别是1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。对于read-view A，要得到1，就必须将当前值依次执行图中所有的回滚操作得到。 同时你会发现，即使现在有另外一个事务正在将4改成5，这个事务跟read-view A、B、C对应的事务是不会冲突的。 你一定会问，回滚日志总不能一直保留吧，什么时候删除呢？答案是，在不需要的时候才删除。也就是说，系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除。 什么时候才不需要了呢？就是当系统里没有比这个回滚日志更早的read-view的时候。 基于上面的说明，我们来讨论一下为什么建议你尽量不要使用长事务。 长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。 在MySQL 5.5及以前的版本，回滚日志是跟数据字典一起放在ibdata文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小。我见过数据只有20GB，而回滚段有200GB的库。最终只好为了清理回滚段，重建整个库。 除了对回滚段的影响，长事务还占用锁资源，也可能拖垮整个库，这事需要注意的。 相关语法START TRANSACTION [transaction_characteristic [, transaction_characteristic] ...]transaction_characteristic: &#123; WITH CONSISTENT SNAPSHOT | READ WRITE | READ ONLY&#125;BEGIN [WORK]COMMIT [WORK] [AND [NO] CHAIN] [[NO] RELEASE]ROLLBACK [WORK] [AND [NO] CHAIN] [[NO] RELEASE]SET autocommit = &#123;0 | 1&#125; 这些语句提供对事务使用的控制 ： START TRANSACTION或 BEGIN开始新交易。 COMMIT 提交当前事务，使其更改永久生效。 ROLLBACK 回滚当前事务，取消其更改。 SET autocommit 禁用或启用当前会话的默认自动提交模式。","tags":["mysql"],"categories":["MySQL"]},{"title":"MySQL中几个重要的日志","path":"/2020/03/12/MySQL-log/","content":"本文为极客时间专栏《MySQL实战45讲》笔记，文中部分图文来自该专栏。 几个日志的作用 重做日志（redo log）：确保事务的持久性。防止在发生故障的时间点，尚有脏页未写入磁盘，在重启mysql服务的时候，根据redo log进行重做，从而达到事务的持久性这一特性。 回滚日志（undo log）：保存了事务发生之前的数据的一个版本，可以用于回滚，同时可以提供多版本并发控制下的读（MVCC），即非锁定读 二进制日志（binlog）：用于复制和备份，在主从复制中，从库利用主库上的binlog进行重播，实现主从同步。 也可基于时间点做数据库的的还原。 redo log在MySQL里，如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程IO成本、查找成本都很高。为了解决这个问题，MySQL的设计者就用了WAL技术，WAL的全称是Write-Ahead Logging，它的关键点就是先写日志，再写磁盘。 具体来说，当有一条记录需要更新的时候，InnoDB引擎就会先把记录写到redo log里面，并更新内存，这个时候更新就算完成了。同时，InnoDB引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。 另外，InnoDB的redo log是固定大小的，比如可以配置为一组4个文件，每个文件的大小是1GB，那么这块“粉板”总共就可以记录4GB的操作。从头开始写，写到末尾就又回到开头循环写，如下面这个图所示。 write pos是当前记录的位置，一边写一边后移，写到第3号文件末尾后就回到0号文件开头。checkpoint是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。 write pos和checkpoint之间的是空着的部分，可以用来记录新的操作。如果write pos追上checkpoint，表示满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把checkpoint推进一下。 有了redo log，InnoDB就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为crash-safe。 undo log在数据修改的时候，不仅记录了redo log，还记录了相对应的undo log，如果因为某些原因导致事务失败或回滚了，可以借助undo log进行回滚。 undo log和redo log记录物理日志不一样，它是逻辑日志。可以认为当delete一条记录时，undo log中会记录一条对应的insert记录，反之亦然，当update一条记录时，它记录一条对应相反的update记录。 当执行rollback时，就可以从undo log中的逻辑记录读取到相应的内容并进行回滚。有时候应用到行版本控制的时候，也是通过undo log来实现的：当读取的某一行被其他事务锁定时，它可以从undo log中分析出该行记录以前的数据是什么，从而提供该行版本信息，让用户实现非锁定一致性读取。 undo log是采用段(segment)的方式来记录的，每个undo操作在记录的时候占用一个undo log segment。 另外，undo log也会产生redo log，因为undo log也要实现持久性保护。 binlogMySQL整体来看，其实就有两块：一块是Server层，它主要做的是MySQL功能层面的事情；还有一块是引擎层，负责存储相关的具体事宜。上面我们聊到的redo log是InnoDB引擎特有的日志，而Server层也有自己的日志，称为binlog（归档日志）。 我想你肯定会问，为什么会有两份日志呢？ 因为最开始MySQL里并没有InnoDB引擎。MySQL自带的引擎是MyISAM，但是MyISAM没有crash-safe的能力，binlog日志只能用于归档。而InnoDB是另一个公司以插件形式引入MySQL的，既然只依靠binlog是没有crash-safe能力的，所以InnoDB使用另外一套日志系统——也就是redo log来实现crash-safe能力。 这两种日志有以下三点不同。 redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。 redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ”。 redo log是循环写的，空间固定会用完；binlog是可以追加写入的。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。 有了对这两个日志的概念性理解，我们再来看执行器和InnoDB引擎在执行这个简单的update语句时的内部流程。 执行器先找引擎取ID=2这一行。ID是主键，引擎直接用树搜索找到这一行。如果ID=2这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。 执行器拿到引擎给的行数据，把这个值加上1，比如原来是N，现在就是N+1，得到新的一行数据，再调用引擎接口写入这行新数据。 引擎将这行新数据更新到内存中，同时将这个更新操作记录到redo log里面，此时redo log处于prepare状态。然后告知执行器执行完成了，随时可以提交事务。 执行器生成这个操作的binlog，并把binlog写入磁盘。 执行器调用引擎的提交事务接口，引擎把刚刚写入的redo log改成提交（commit）状态，更新完成。 这里我给出这个update语句的执行流程图，图中浅色框表示是在InnoDB内部执行的，深色框表示是在执行器中执行的。 参考文章：详细分析MySQL事务日志(redo log和undo log)-https://www.cnblogs.com/f-ck-need-u/archive/2018/05/08/9010872.html#auto_id_14","tags":["mysql"],"categories":["MySQL"]},{"title":"MySQL执行流程说明","path":"/2020/03/11/MySQL-workon/","content":"MySQL的执行流程示意图： 大体来说，MySQL可以分为Server层和存储引擎层两部分。 Server层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖MySQL的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。 而存储引擎层负责数据的存储和提取，常见的有InnoDB、MyISAM、Memory等多个存储引擎。现在最常用的存储引擎是InnoDB，从MySQL 5.5.5版本开始它成为了默认存储引擎。 从图中不难看出，不同的存储引擎共用一个Server层，也就是从连接器到执行器的部分。 我们依次看下每个组件的作用。 连接器连接器负责跟客户端建立连接、获取权限、维持和管理连接。连接命令一般是这么写的： mysql -h $ip -P $port -u $user -p 输完命令之后，你就需要在交互对话里面输入密码。 连接完成后，如果你没有后续的动作，这个连接就处于空闲状态，你可以在show processlist命令中看到它。 如果用户名或密码不对，你就会收到一个”Access denied for user”的错误，然后客户端程序结束执行。如果用户名密码认证通过，连接器会到权限表里面查出你拥有的权限。之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。 这就意味着，一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置。 客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数wait_timeout控制的，默认值是8小时。 如果在连接被断开之后，客户端再次发送请求的话，就会收到一个错误提醒： Lost connection to MySQL server during query。这时候如果你要继续，就需要进行重连操作，然后再执行请求。 连接注意点： 长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。 短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。 建立连接的过程通常是比较复杂的，所以我建议你在使用中要尽量减少建立连接的动作，也就是尽量使用长连接。 但是全部使用长连接后，你可能会发现，有些时候MySQL占用内存涨得特别快，这是因为MySQL在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是MySQL异常重启了。 怎么解决这个问题呢？你可以考虑以下两种方案。 定期主动断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。 如果你用的是MySQL 5.7或更新版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。 查询缓存连接建立完成后，你就可以执行select语句了。执行逻辑就会来到第二步：查询缓存。 MySQL拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以key-value对的形式，被直接缓存在内存中。key是查询的语句，value是查询的结果。如果你的查询能够直接在这个缓存中找到key，那么这个value就会被直接返回给客户端。 如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会被存入查询缓存中。你可以看到，如果查询命中缓存，MySQL不需要执行后面的复杂操作，就可以直接返回结果，这个效率会很高。 但是大多数情况下我会建议你不要使用查询缓存，为什么呢？因为查询缓存往往弊大于利。 查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了。对于更新压力大的数据库来说，查询缓存的命中率会非常低。除非你的业务就是有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。 好在MySQL也提供了这种“按需使用”的方式。你可以将参数query_cache_type设置成DEMAND，这样对于默认的SQL语句都不使用查询缓存。而对于你确定要使用查询缓存的语句，可以用SQL_CACHE显式指定，像下面这个语句一样： mysql&gt; select SQL_CACHE * from T where ID=10； 需要注意的是，MySQL 8.0版本直接将查询缓存的整块功能删掉了，也就是说8.0开始彻底没有这个功能了。 分析器如果没有命中查询缓存，就要开始真正执行语句了。首先，MySQL需要知道你要做什么，因此需要对SQL语句做解析。 分析器先会做“词法分析”。你输入的是由多个字符串和空格组成的一条SQL语句，MySQL需要识别出里面的字符串分别是什么，代表什么。 MySQL从你输入的”select”这个关键字识别出来，这是一个查询语句。它也要把字符串“T”识别成“表名T”，把字符串“ID”识别成“列ID”。 做完了这些识别以后，就要做“语法分析”。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个SQL语句是否满足MySQL语法。 如果你的语句不对，就会收到“You have an error in your SQL syntax”的错误提醒，比如下面这个语句select少打了开头的字母“s”。 mysql&gt; elect * from t where id=1;ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near &#x27;elect * from t where ID=1&#x27; at line 1 一般语法错误会提示第一个出现错误的位置，所以你要关注的是紧接“use near”的内容。 优化器经过了分析器，MySQL就知道你要做什么了。在开始执行之前，还要先经过优化器的处理。 优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。 优化器阶段完成后，这个语句的执行方案就确定下来了，然后进入执行器阶段。如果你还有一些疑问，比如优化器是怎么选择索引的，有没有可能选择错等等，没关系，我会在后面的文章中单独展开说明优化器的内容。 执行器MySQL通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。 开始执行的时候，要先判断一下你对这个表T有没有执行查询的权限，如果没有，就会返回没有权限的错误，如下所示(在工程实现上，如果命中查询缓存，会在查询缓存返回结果的时候，做权限验证。查询也会在优化器之前调用precheck验证权限)。 mysql&gt; select * from T where ID=10;ERROR 1142 (42000): SELECT command denied to user &#x27;b&#x27;@&#x27;localhost&#x27; for table &#x27;T&#x27; 如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。 比如我们这个例子中的表T中，ID字段没有索引，那么执行器的执行流程是这样的： 调用InnoDB引擎接口取这个表的第一行，判断ID值是不是10，如果不是则跳过，如果是则将这行存在结果集中； 调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。 执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。 至此，这个语句就执行完成了。 对于有索引的表，执行的逻辑也差不多。第一次调用的是“取满足条件的第一行”这个接口，之后循环取“满足条件的下一行”这个接口，这些接口都是引擎中已经定义好的。","tags":["mysql"],"categories":["MySQL"]},{"title":"ElementUI多图拖拽","path":"/2020/02/27/228/","content":"准备 yarn add vuedraggableornpm i -S vuedraggable 代码示例&lt;template&gt; &lt;div&gt; &lt;el-row style=&quot;margin-top: 20px;&quot;&gt; &lt;el-col :span=&quot;20&quot; :offset=&quot;2&quot;&gt; &lt;el-form-item label=&quot;预览&quot; prop=&quot;desc&quot;&gt; &lt;div class=&quot;image-list&quot;&gt; &lt;draggable v-model=&quot;showImgList&quot; @change=&quot;dragChange&quot;&gt; &lt;div v-for=&quot;(image, index) in showImgList&quot; :key=&quot;index&quot; class=&quot;image-wrap&quot;&gt; &lt;img :src=&quot;image&quot; :style=&quot;imgStyle&quot; /&gt; &lt;div class=&quot;icon-wrap&quot; @click.stop=&quot;removeFile(index)&quot;&gt; &lt;i class=&quot;el-icon-delete&quot;&gt;&lt;/i&gt; &lt;/div&gt; &lt;/div&gt; &lt;el-upload ref=&quot;imageListUpload&quot; :action=&quot;$uploadPicUrl&quot; :headers=&quot;header&quot; :before-upload=&quot;beforeUpload&quot; :on-success=&quot;uploadSuccess&quot; class=&quot;image-uploader&quot; :on-error=&quot;onError&quot; multiple :show-file-list=&quot;false&quot; accept=&quot;image/*&quot;&gt; &lt;i :class=&quot;loading ? &#x27;el-icon-loading&#x27; : &#x27;el-icon-plus&#x27;&quot; :style=&quot;imgStyle&quot;&gt;&lt;/i&gt; &lt;/el-upload&gt; &lt;/draggable&gt; &lt;/div&gt; &lt;/el-form-item&gt; &lt;/el-col&gt; &lt;/el-row&gt; &lt;/div&gt;&lt;/template&gt;&lt;style&gt;.ql-container .ql-editor&#123; height:400px;&#125;.avatar-uploader .el-upload &#123; height: 180px; width: 180px; overflow: hidden;&#125;.avatar-uploader img &#123; height: 180px; width: 180px;&#125;.avatar-uploader .avatar-uploader-icon &#123; border: 1px dashed #d9d9d9; border-radius: 6px; cursor: pointer; font-size: 28px; color: #8c939d; width: 178px; height: 178px; line-height: 178px; text-align: center;&#125;#video .video &#123; max-width: 300px; max-height: 200px;&#125;.avatar &#123; width: 178px; height: 178px; display: block;&#125;.avatar-uploader img &#123; height: 180px; width: 180px;&#125;.ql-editor&#123; height:400px;&#125;.ql-snow .ql-picker &#123; height: auto;&#125;.image-list,.image-item &#123; display: flex;&#125;.image-list .image-wrap,.image-item .image-wrap &#123; position: relative; display: inline-block; box-sizing: content-box; margin: 0 8px 8px 0; vertical-align: top;&#125;.image-list .image-wrap:hover .icon-wrap,.image-item .image-wrap:hover .icon-wrap &#123; opacity: 1;&#125;.image-list .image-wrap .icon-wrap,.image-item .image-wrap .icon-wrap &#123; position: absolute; left: 0; bottom: 0; width: 100%; height: 30px; cursor: default; text-align: center; color: #fff; opacity: 0; font-size: 20px; background-color: rgba(0, 0, 0, 0.7); transition: opacity .3s;&#125;.image-list .image-wrap .icon-wrap .el-icon-zoom-in,.image-item .image-wrap .icon-wrap .el-icon-zoom-in &#123; cursor: pointer; margin-right: 8px;&#125;.image-list .image-wrap .icon-wrap .el-icon-delete,.image-item .image-wrap .icon-wrap .el-icon-delete &#123; cursor: pointer;&#125;.image-item &#123; display: inline-flex;&#125;.image-uploader &#123; display: inline-block;&#125;.image-uploader .el-upload &#123; border: 1px dashed #d9d9d9; border-radius: 6px; cursor: pointer; position: relative; overflow: hidden;&#125;.image-uploader .el-upload [class^=&quot;el-icon&quot;] &#123; font-size: 28px; color: #8c939d; text-align: center;&#125;.image-uploader .el-upload:hover &#123; border-color: #409EFF;&#125;&lt;/style&gt;&lt;script&gt;import draggable from &#x27;vuedraggable&#x27;export default &#123; components: &#123; draggable, &#125;, data() &#123; return &#123; showImgList: [], loading: false, &#125; &#125;, created() &#123; if (this.$route.params.id &gt; 0) &#123; this.getInfo(this.$route.params.id) this.goodsForm.id = this.$route.params.id; &#125; else &#123; this.responseVisible = false; &#125; &#125;, computed: &#123; imgStyle() &#123; return &#123; width: &#x27;180px&#x27;, height: &#x27;180px&#x27;, lineHeight: &#x27;180px&#x27;, &#125; &#125; &#125;, mounted() &#123; // 为图片ICON绑定事件 getModule 为编辑器的内部属性 // this.$refs.myQuillEditor.quill.getModule(&#x27;toolbar&#x27;).addHandler(&#x27;image&#x27;, this.imgHandler) // this.$refs.myQuillEditor.quill.getModule(&#x27;toolbar&#x27;).addHandler(&#x27;video&#x27;, this.insertVideo) // 为视频ICON绑定事件 &#125;, methods: &#123; beforeUpload(file) &#123; if (file.type.split(&#x27;/&#x27;)[0] === &#x27;image&#x27;) &#123; let tempSize = file.size / 1024 / 1024 / 2; if (tempSize &gt; 1) &#123; this.$message.error(&#x27;图片尺寸不得大于2M！&#x27;); return false; &#125; &#125; else &#123; this.$message.error(&#x27;请上传图片格式（jpg、png、gif）&#x27;); return false; &#125; &#125;, getInfo(id) &#123; var _self = this; projectInfo(id).then(function(res)&#123; _self.goodsForm = res.data.data; _self.goodsForm.start_time = timestampToDate(_self.goodsForm.start_time); _self.goodsForm.over_time = timestampToDate(_self.goodsForm.over_time); _self.showImgList = _self.goodsForm.desc.split(&quot;|&quot;); _self.responseVisible = false; &#125;).catch(function(error)&#123; console.log(error); &#125;) &#125;, handleRemove(file, fileList) &#123; console.log(file, fileList); &#125;, uploadSuccess(response, file, fileList) &#123; try &#123; for (let fileInfo of fileList) &#123; if (this.type === &#x27;image&#x27;) &#123; this.imgUrl = response.key this.$emit(&#x27;update:data&#x27;, response.key) &#125; else &#123; if (this.showImgList.length &gt;= this.limit) &#123; // 限制图片张数 this.showImgList.length = this.limit throw(new Error(`最多上传 $&#123;this.limit&#125; 张图片`)) &#125; this.showImgList.push(response.data.filepath) this.$emit(&#x27;update:data&#x27;, this.showImgList) &#125; &#125; &#125; catch (error) &#123; this.$message.error(error.message) &#125; finally &#123; this.loading = false this.$refs.imageListUpload &amp;&amp; this.$refs.imageListUpload.clearFiles() this.$refs.imageUpload &amp;&amp; this.$refs.imageUpload.clearFiles() &#125; &#125;, removeFile(index) &#123; this.$confirm(&#x27;确定删除该图片吗?&#x27;, &#x27;提示&#x27;, &#123; confirmButtonText: &#x27;确定&#x27;, cancelButtonText: &#x27;取消&#x27;, type: &#x27;warning&#x27; &#125;).then(() =&gt; &#123; if (this.type === &#x27;image&#x27;) &#123; this.$emit(&#x27;update:data&#x27;, typeof this.data === &#x27;object&#x27; ? &#123;&#125; : &#x27;&#x27;) &#125; else &#123; this.showImgList.splice(index, 1) this.$emit(&#x27;update:data&#x27;, this.showImgList) &#125; &#125;) &#125;, onError() &#123; this.$message.error(&#x27;上传文件失败&#x27;) &#125;, dragChange(ele) &#123; console(ele.moved) &#125;, handleRemove(file, fileList) &#123; let imgList = fileList.map(item =&gt; &#123; return item.response.key &#125;) this.$emit(&#x27;update:data&#x27;, imgList) &#125;, &#125;&#125;&lt;/script&gt; 注意务必注册引入组件 import draggable from &#x27;vuedraggable&#x27;export default &#123; ... components: &#123; draggable, &#125;, ...","tags":["ElementUI"],"categories":["vue"]},{"title":"应用篇：2.延时任务","path":"/2020/02/22/phpframe14/","content":"PHP DIY系列–一起手写一个api框架 延时任务有别于定时任务，定时任务往往是固定周期的，有明确的触发时间。而延时任务一般没有固定的开始时间，它常常是由一个事件触发的，而在这个事件触发之后的一段时间内触发另一个事件。 我们不妨来设定一个实际的场景，电商系统下单成功之后如果15分钟未支付成功，就系统自动取消订单。 我们先来实现代码，然后再来详细说明： // 我们定义一个abstract，定义两个方法，startAfter和startAt&lt;?phpabstract class DelayTask&#123; const DELAY_TASK = &#x27;delayTask&#x27;; /** * 延时时间，在触发时间后多久执行 * @param $pushDelayTime */ public function startAfter(int $pushDelayTime) &#123; RedisManager::getRedis()-&gt;zAdd(self::DELAY_TASK, time() + $pushDelayTime, serialize($this)); &#125; /** * 定时时间，在未来某时刻执行 * @param $pushDelayAt */ public function startAt(int $pushDelayAt) &#123; RedisManager::getRedis()-&gt;zAdd(self::DELAY_TASK, $pushDelayAt, serialize($this)); &#125; abstract function run();&#125;class TestDelayTask extends DelayTask&#123; public function __construct($id) &#123; $this-&gt;id = $id; &#125; public function run() &#123; $file = &#x27;text.txt&#x27;;//要写入文件的文件名（可以是任意文件名），如果文件不存在，将会创建一个 $content = &quot;写入的内容&quot;.time().&quot; &quot;; if($f = file_put_contents($file, $content,FILE_APPEND))&#123;// 这个函数支持版本(PHP 5) echo &quot;写入成功。&lt;br /&gt;&quot;; &#125; &#125;&#125; RedisManager是封装的一个单例模式实现的Redis类，我们也贴出代码，然后再对上面的代码做一些说明。 &lt;?phpclass RedisManager&#123; private static $instance = null; private function __construct() &#123; self::$instance = new \\Redis(); $config = require &#x27;Redis.config.php&#x27;; self::$instance-&gt;connect($config[&#x27;host&#x27;], $config[&#x27;port&#x27;], $config[&#x27;timeout&#x27;]); if (isset($config[&#x27;password&#x27;])) &#123; self::$instance-&gt;auth($config[&#x27;password&#x27;]); &#125; &#125; /** * 获取静态实例 */ public static function getRedis() &#123; if (!self::$instance) &#123; new self; &#125; return self::$instance; &#125; /** * 禁止clone */ private function __clone() &#123; &#125;&#125; 有序集合Redis 127.0.0.1:6379&gt; ZADD saif 1 Redis(integer) 1Redis 127.0.0.1:6379&gt; ZADD saif 2 mongodb(integer) 1Redis 127.0.0.1:6379&gt; ZADD saif 4 mysql(integer) 0Redis 127.0.0.1:6379&gt; ZRANGE saif 0 10 WITHSCORES1) &quot;Redis&quot;2) &quot;1&quot;3) &quot;mongodb&quot;4) &quot;2&quot;5) &quot;mysql&quot;6) &quot;4&quot; 如果你有Redis可视化工具，你会发现有序集合存储的结构是这样： row value score 1 Redis 1 2 mongodb 2 3 mysql 4 我们再来看一下代码，我们使用时间戳作为分值，使用对象作为值，存储到Redis有序集合。 file_put_contents ( string $filename , mixed $data [, int $flags = 0 [, resource $context ]] ) : int — 将一个字符串写入文件 执行我们先尝试写入任务：(new TestDelayTask(4))-&gt;startAfter(900);(new TestDelayTask(4))-&gt;startAfter(120);(new TestDelayTask(4))-&gt;startAfter(600);(new TestDelayTask(3))-&gt;startAt(158120384);(new TestDelayTask(3))-&gt;startAt(158420380);(new TestDelayTask(3))-&gt;startAt(158120900); 执行代码： class DelayTaskTask&#123; const QueneName = &#x27;delayTask&#x27;; private $currentTime; private $once = 5; public function run() &#123; $this-&gt;currentTime = time(); error_reporting(error_reporting() &amp; ~E_WARNING); while (true) &#123; // 每次取出5条 $list = RedisManager::getRedis()-&gt;zRange(self::QueneName, 0, $this-&gt;once, true); if (!empty($list)) &#123; foreach ($list as $val=&gt;$score) &#123; if ($score &lt; $this-&gt;currentTime) &#123; unserialize($val)-&gt;run(); RedisManager::getRedis()-&gt;zDelete(self::QueneName, $val); &#125; else &#123; break 2; &#125; &#125; &#125; else &#123; break; &#125; &#125; &#125;&#125;(new DelayTaskTask())-&gt;run(); 我们可以设置一个定时任务，每分钟执行一次上述代码。 我们执行之后，会发现一旦过了我们设定的时间，text.txt就不断有文字写入了。 代码比较杂，我有一个demo代码，大家可以查看。 DelayTask-基于Redis的延时任务 这样，我们就利用Redis有序集合，完成了一个很基础的延时任务。 问题 加入run方法代码执行时间过长，一分钟执行一次有什么问题吗？ 每分钟执行一次，间隔有点长，能不能优化呢？","tags":["phpframe"],"categories":["phpframe"]},{"title":"应用篇：1.分布式锁","path":"/2020/02/22/phpframe13/","content":"PHP DIY系列–一起手写一个api框架 含义 为了防止分布式系统中的多个进程之间相互干扰，我们需要一种分布式协调技术来对这些进程进行调度。而这个分布式协调技术的核心就是来实现这个分布式锁。 分析 在分布式系统环境下，一个方法在同一时间只能被一个机器的一个线程执行 高可用的获取锁与释放锁 高性能的获取锁与释放锁 具备可重入特性（可理解为重新进入，由多于一个任务并发使用，而不必担心数据错误） 具备锁失效机制，防止死锁 具备非阻塞锁特性，即没有获取到锁将直接返回获取锁失败 实现方式常见的有： 基于Redis 基于mysql 基于Zookeeper 具体实现考虑到我们使用的PHP语言，简单结合Redis来实现一下分布式锁。 我们来画个简单的原理图： 原理十分简单，那么我们如何实现呢？ 这里我们用到两个知识点： Redis的setnx方法 php的register function processLock($Redis, $key, $ttl = 5)&#123; $ret = $Redis-&gt;setnx($key, 1); if ($ret) &#123; $Redis-&gt;expire($key, $ttl); register_shutdown_function(function () use ($Redis, $key)&#123; $Redis-&gt;del($key); &#125;); &#125; return $ret;&#125; demo里的$Redis是一个Redis实例，我们在前面已经实现过，不多说明。 加锁我们使用的setnx命令，senx表示“SET if Not eXists”，如果key不存在，则set，如果存在，则不set Redis&gt; SETNX mykey &quot;Hello&quot;(integer) 1Redis&gt; SETNX mykey &quot;World&quot;(integer) 0Redis&gt; GET mykey&quot;Hello&quot; 解锁使用的是del，即删除这个key。这里结合了 register_shutdown_function — 注册一个会在php中止时执行的函数，设置了之后我们就可以不必手动去解锁 锁超时这里给锁加了一个expire过期时间5秒，目的是防止使用这个方法之后的执行了“神奇”代码抛出了语法错误，导致register_shutdown_function里的代码没有执行，虽然请求结束，但是加锁后，没有解锁，影响了后续请求。 问题 加入setnx之后expire之前程序异常了怎么办？","tags":["phpframe"],"categories":["phpframe"]},{"title":"Redis持久化aof和rdb","path":"/2020/02/16/aof/","content":"Redis持久持久化的功能:Redis是内存数据库，数据都是存储在内存中，为了避免进程退出导致数据的永久丢失，需要定期将Redis中的数据以某种形式(数据或命令) 从内存保存到硬盘。 当下次Redis重启时，利用持久化文件实现数据恢复。除此之外，为了进行灾难备份，可以将持久化文件拷贝到一个远程位置。 Redis持久化分为RDB持久化和AOF持久化，前者将当前数据保存到硬盘，后者则是将每次执行的写命令保存到硬盘。 RDB RDB是一种快照存储持久化方式，具体就是将Redis某一时刻的内存数据保存到硬盘的文件当中，默认保存的文件名为dump.rdb，而在Redis服务器启动时，会重新加载dump.rdb文件的数据到内存当中恢复数据。 ，触发 RDB 持久化过程分为手动触发和自动触发。 触发机制save 命令:阻塞当前 Redis 服务器，直到 RDB 过程完成为止，对于内存比较大的实例会造成长时间阻塞，线上环境不建议使用。 bgsave 命令:Redis 进程执行 fork 操作创建子进程，RDB 持久化过程由子进程负责，完成后自动结束。阻塞只发生在 fork 阶段，一般时间很短。 显然 bgsave 命令是针对 save阻塞问题做的优化。因此 Redis 内部所有的涉及 RDB 的操作都采用 bgsave 的方式。 除了执行命令手动触发之外，Redis 内部还存在自动触发 RDB 的持久化机制，例如以下场景: 使用 save 相关配置，如“save m n”。表示 m 秒内数据集存在 n 次修改时，自动触发 bgsave。 如果从节点执行全量复制操作，主节点自动执行 bgsave 生成 RDB 文件并发送给从节点。 执行 debug reload 命令重新加载 Redis 时，也会自动触发 save 操作。 默认情况下执行 shutdown 命令时，如果没有开启 AOF 持久化功能则自动执行 bgsave。 bgsave流程 执行 bgsave 命令，Redis 父进程判断当前是否存在正在执行的子进程，如 RDB/AOF 子进程，如果存在 bgsave 命令直接返回。 父进程执行 fork 操作创建子进程，fork操作过程中父进程会阻塞。 父进程 fork 完成后，bgsave 命令返回“Background saving started”信息并不再阻塞父进程，可以继续响应其他命令。 子进程会共享一部分主进程的数据空间，并且把共享的数据置为read-only的状态，子进程创建 RDB 文件，根据父进程内存生成临时快照文件，完成后对原有文件进行原子替换。在持久化的过程中是避免不了有新的数据写入的，因为我们有一部分的数据是共享的，两个进程同时拥有一块数据，肯定会导致数据不一致的问题， 但是依赖于操作系统的fork机制，在修改的时候一定是修改部分内存页的数据，这个时候会触发对应内存页的copyonwrite的操作 进程发送信号给父进程表示完成，父进程更新统计信息。 配置文件（流程类似bgsave）# 900s内至少达到一条写命令 save 900 1# 300s内至少达至10条写命令 save 300 10# 60s内至少达到10000条写命令 save 60 10000 RDB 文件的处理1. 保存:RDB 文件保存在 dir 配置指定的目录下，文件名通过 dbfilename 配置指定。可以通过执行 config set dir{newDir}和 config setdbfilename{newFileName}运行期动态执行，当下次运行时 RDB 文件会保存到新目录。当遇到坏盘或磁盘写满等情况时，可以通过 config set dir{newDir}在线修改文件路径到可用的磁盘路径，之后执行 bgsave 进行磁盘切换，同样适用于 AOF 持久化文件。 2. 压缩:Redis 默认采用 LZF 算法对生成的 RDB 文件做压缩处理，压缩后的文件远远小于内存大小，默认开启，可以通过参数 config set rdbcompression{yes|no}动态修改。虽然压缩 RDB 会消耗 CPU，但可大幅降低文件的体积，方便保存到硬盘或通过网络发送给从节点，因此线上建议开启。 RDB方式的优点 RDB 是一个非常紧凑的文件，它保存了 Redis 在某个时间点上的数据集。这种文件非常适合用于进行备份: 比如说，你可以在最近的 24小时内，每小时备份一次 RDB文件，并且在每个月的每一天，也备份一个 RDB 文件。 这样的话，即使遇上问题，也可以随时将数据集还原到不同的版本。 RDB 可以最大化 Redis 的性能:父进程在保存 RDB 文件时唯一要做的就是 fork 出一个子进程，然后这个子进程就会处理接下来的所有保存 工作，父进程无须执行任何磁盘 I/O 操作。 RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。 RDB方式的缺点 RDB 方式数据没办法做到实时持久化/秒级持久化。 如果服务器宕机的话，采用RDB的方式会造成某个时段内数据的丢失，比如我们设置10分钟同步一次或5分钟达到1000次写入就同步一次，那么如果还没达到触发条件服务器就死机了，那么这个时间段的数据会丢失。 使用bgsave命令在forks子进程时，如果数据量太大，forks的过程也会发生阻塞，另外，forks子进程会耗费内存。 AOF AOF(append only file)持久化:与RDB存储某个时刻的快照不同，AOF持久化方式会记录客户端对服务器的每一次写操作命令到日志当中，并将这些写操作以Redis协议追加保存到以后缀为aof文件末尾 配置Redis.conf appendonly yes #启用aof持久化方式 appendfsync always/no/everysec设置为always时，会极大消弱Redis的性能，因为这种模式下每次write后都会调用fsync（Linux为调用fdatasync）。如果设置为no，则write后不会有fsync调用，由操作系统自动调度刷磁盘，性能是最好的。everysec为最多每秒调用一次fsync，这种模式性能并不是很糟糕，一般也不会产生毛刺，这归功于Redis引入了BIO线程，所有fsync操作都异步交给了BIO线程。 流程 所有的写入命令会追加到 aof_buf(缓冲区)中。（Redis使用单线程响应命令，如果每次AOF文件命令都追加到磁盘，会极大的影响处理性能） AOF 缓冲区根据对应的策略向硬盘做同步操作。 随着 AOF 文件越来越大，需要定期对 AOF 文件进行重写，达到压缩的目的。 当 Redis 服务器重启时，可以加载 AOF 文件进行数据恢复。 重写机制 AOF将客户端的每一个写操作都追加到aof文件末尾，随着命令不断写入 AOF，文件会越来越大，为了解决这个问题，Redis 引入了AOF 重写机制压缩文件体积。AOF 文件重写是把 Redis 进程内的数据转化为写命令同步到新 AOF 文件的过程。 比如:多条写命令可以合并为一个，如:lpush list a、lpush list b、lpush list c 可以转化为:lpush list a b c。 AOF 重写降低了文件占用空间，除此之外，另一个目的是:更小的 AOF 文件可以更快地被 Redis 加载。 重写流程 执行 AOF 重写请求。 如果当前进程正在执行 AOF 重写，请求不执行并返回如下响应: ERR Background append only file rewriting already in progress 父进程执行 fork 创建子进程，并拿到fork时的AOF文件数据写到一个临时AOF文件中。 主进程 fork 操作完成后，继续响应其他命令。所有修改命令依然写入 AOF 缓冲区并根据 appendfsync 策略同步到硬盘，保证原有 AOF 机制正确 性。 由于 fork 操作运用写时复制技术，子进程只能共享 fork 操作时的内存数据。由于父进程依然响应命令，Redis 使用“AOF 重写缓冲区”保存这部分新数据，防止新 AOF 文件生成期间丢失这部分数据。 子进程根据内存快照，按照命令合并规则写入到新的 AOF 文件。每次批量写入硬盘数据量由配置 aof-rewrite-incremental-fsync 控制，默认为 32MB，防止单 次刷盘数据过多造成硬盘阻塞。 5.1) 新 AOF 文件写入完成后，子进程发送信号给父进程，父进程更新统计信息。5.2) 父进程把 AOF 重写缓冲区的数据写入到新的 AOF 文件。5.3) 使用新 AOF 文件替换老文件，完成 AOF 重写。 触发重写 手动触发:直接调用 bgrewriteaof 命令。 自动触发:根据 auto-aof-rewrite-min-size和auto-aof-rewrite-percentage 参数确定自动触发时机。 auto-aof-rewrite-min-size:表示运行 AOF 重写时文件最小体积，默认为 64MB。auto-aof-rewrite-percentage:代表当前 AOF 文件空间(aof_current_size)和上一次重写后 AOF 文件空间(aof_base_size)的比值。示例:auto-aof-rewrite-percentage:100 auto-aof-rewrite-min-size:64mb默认配置是当AOF文件大小是上次rewrite后大小的一倍且文件大于64M时触发 异常处理AOF文件损坏在写入aof日志文件时，如果Redis服务器宕机，则aof日志文件文件会出格式错误，在重启Redis服务器时，Redis服务器会拒绝载入这个aof文件， 可以通过命令修复aof并恢复数据 Redis-check-aof -fix file.aof AOF的优点 AOF可以设置 完全不同步、每秒同步、每次操作同，默认是每秒同步。因为AOF是操作指令的追加，所以可以频繁的大量的同步。 AOF文件是一个值追加日志的文件，即使服务宕机为写入完整的命令，也可以通过Redis-check-aof工具修复这些问题。 如果AOF文件过大，Redis会在后台自动地重写AOF文件。重写后会使AOF文件压缩到最小所需的指令集。 AOF文件是有序保存数据库的所有写入操作，易读，易分析。即使如果不小心误操作数据库，也很容易找出错误指令，恢复到某个数据节点。例如不小心FLUSHALL，可以非常容易恢复到执行命令之前。 AOF的缺点 相同数据量下，AOF的文件通常体积会比RDB大。因为AOF是存指令的，而RDB是所有指令的结果快照。但AOF在日志重写后会压缩一些空间。 在大量写入和载入的时候，AOF的效率会比RDB低。因为大量写入，AOF会执行更多的保存命令，载入的时候也需要大量的重执行命令来得到最后的结果。RDB对此更有优势。 配置汇总save 60 1000:60s内至少达到1000条写命令appendonly no:是否开启AOFappendfilename &quot;appendonly.aof&quot;:AOF文件名dir ./:RDB文件和AOF文件所在目录appendfsync everysec:fsync持久化策略no-appendfsync-on-rewrite no:AOF重写期间是否禁止fsync;如果开启该选项，可以减轻文件重写时CPU和硬盘的负载(尤其是硬盘)，但是可能会丢 失AOF重写期间的数据;需要在负载和安全性之间进行平衡auto-aof-rewrite-percentage 100:文件重写触发条件之一auto-aof-rewrite-min-size 64mb:文件重写触发提交之一aof-load-truncated yes:如果AOF文件结尾损坏，Redis启动时是否仍载入AOF文件","tags":["Redis"],"categories":["Redis"]},{"title":"框架篇：9.设计模式","path":"/2020/02/16/phpframe12/","content":"PHP DIY系列–一起手写一个api框架 框架的开发基本结束了，这一节我们来探讨一下设计模式。 谈设计模式，首先要来简单聊聊面向对象。 面向对象 面向对象程序设计（Object-Oriented Programming, OOP）是一种程序设计范型，同时也是一种程序开发方法。它将对象作为程序的基本单元，将程序和数据封装其中，以提高软件的重用性、灵活性和可扩展性。它和面向过程、函数式编程被称为编程语言中的三大范式。 概念知识 面向对象的核心思想是对象、封装、可重用性、可扩展性。 面向对象三要素：封装、继承和多态。 面向对象设计的五大原则：单一职责原则、接口隔离原则、开放封闭原则、替换原则、依赖倒置原则。 关于这些概念的更详细解释，我推荐大家阅读《PHP核心技术与最佳实践》这本书关于关于面向对象的部分。 设计模式上述所述的面向对象知识，尤其是面向对象设计的五大原则，是诸多设计模式的基础。 设计模式有很多，我们可以简单列出来： 有强调实例化过程的创建型设计模式 抽象工厂 生成器 工厂方法 原型 单例 又有组合对象和类构成更大结构的结构型设计模式 适配器模式 桥接模式 组合模式 装饰器模式 外观模式 享元模式 代理模式 还有行为型设计模式 职责链模式 命令模式 解释器模式 迭代器模式 中介者模式 备忘录模式 观察者模式 状态模式 策略模式 模板授权模式 访问者模式 说到这里你有没有蒙圈？ 其实我们无需一下子去了解那么多设计模式，在实际开发过程中我们可能也是混合使用设计模式的。我们不妨可以就框架里用到的几个典型的设计模式做一些分析。 单例模式是否还记得我们使用Redis代替Session那一节，我们就用到了单例模式。 我们来简化一下代码： class RedisSession&#123; private $Redis; private function getRedisInstance() &#123; if (empty($this-&gt;Redis)) &#123; $Redis = new \\Redis(); $Redis-&gt;connect($this-&gt;_config[&#x27;host&#x27;], $this-&gt;_config[&#x27;port&#x27;], $this-&gt;_config[&#x27;timeout&#x27;]); if (!$this-&gt;_config[&#x27;auth&#x27;]) &#123; $Redis-&gt;auth($this-&gt;_config[&#x27;auth&#x27;]); &#125; $this-&gt;Redis = $Redis; &#125; return $this-&gt;Redis; &#125;&#125; 一般我们还会在类里面加入一个魔术方法__clone，防止实例创建后被clone 单例模式有显而易见的优点：提高可重用性，减少开销。框架里使用Redis时都可以使用此方法来获取Redis，也减少Redis的连接数和多次连接时间。 策略模式还记得依赖注入那一节么，我们举例的那个Travel就是一个很好的策略模式Demo： interface Travel&#123; public function travelAlgorithm();&#125;/** *具体策略类(ConcreteStrategy) *1：乘坐飞机 */class AirPlanelStrategy implements Travel&#123; public function travelAlgorithm() &#123; echo&quot;travelbyAirPlain\\r &quot;; &#125;&#125;/** *具体策略类(ConcreteStrategy) *2：乘坐火车 */class TrainStrategy implements Travel&#123; public function travelAlgorithm() &#123; echo&quot;travelbyTrain\\r &quot;; &#125;&#125;/** * *环境类(Context): *用一个ConcreteStrategy对象来配置。 *维护一个对Travel对象的引用。可定义一个接口来让Strategy访问它的数据。 *算法解决类，以提供客户选择使用何种解决方案： */class PersonContext&#123; private $strategy = null; public function __construct(Travel $travel) &#123; $this-&gt;strategy=$travel; &#125; /** *旅行 */ public function travel() &#123; return$this-&gt;strategy-&gt;travelAlgorithm(); &#125;&#125;// 乘坐火车旅行$person = new PersonContext(new TrainStrategy());$person-&gt;travel();// 改乘飞机$person =PersonContext(new AirPlanelStrategy());$person-&gt;travel(); 策略模式降低了代码耦合度，可以使得我们下层代码依赖上层，替换下层代码即可简单实现功能的替换。 工厂方法我们在路由解析创建控制器那里使用了工厂方法，只不过与路由解析代码糅合在一起，我们简化一下： class Factory&#123; public function createController($controllerName) &#123; $controllerName = rtrim($controllerName,&#x27;\\\\&#x27;).&#x27;Controller&#x27;; if (!class_exists($controllerName)) &#123; throw new NotFoundException(&quot;未找到控制器&quot;); &#125; return new $controllerName; &#125; ···&#125; 工厂方法是很常见的一种设计模式，像Model经常能用到。","tags":["phpframe"],"categories":["phpframe"]},{"title":"框架篇：8.依赖注入与控制反转","path":"/2020/02/15/phpframe11/","content":"PHP DIY系列–一起手写一个api框架 依赖倒置原则（Dependence Inversion Principle）DIP是面向对象设计原则之一。传统软件设计中，上层代码依赖于下层代码，当下层出现变动时， 上层代码也要相应变化，维护成本较高。而DIP的核心思想是上层定义接口，下层实现这个接口， 从而使得下层依赖于上层，降低耦合度，提高整个系统的弹性。这是一种经实践证明的有效策略。 控制反转（Inversion of Control）IoC则是DIP的一种具体思路，DIP只是一种理念、思想，而IoC是一种实现DIP的方法。 IoC的核心是将类（上层）所依赖的单元（下层）的实例化过程交由第三方来实现。 当调用者需要被调用者的协助时，在传统的程序设计过程中，通常由调用者来创建被调用者的实例，但在这里，创建被调用者的工作不再由调用者来完成，而是将被调用者的创建移到调用者的外部，从而反转被调用者的创建，消除了调用者对被调用者创建的控制，因此称为控制反转。 依赖注入（Dependence Injection）DI是IoC的一种设计模式，按照DI的模式，就可以实现IoC。 DI的实质就是把一个类不可能更换的部分和可更换的部分分离开来，通过注入的方式来使用，从而达到解耦的目的。 这里我们举个例子（旅行的接口）说明一下： interface Travel&#123; public function travelAlgorithm();&#125;/** *乘坐飞机 */class AirPlanelStrategy implements Travel&#123; public function travelAlgorithm() &#123; echo&quot;travelbyAirPlain\\r &quot;; &#125;&#125;/** *乘坐火车 */class TrainStrategy implements Travel&#123; public function travelAlgorithm() &#123; echo&quot;travelbyTrain\\r &quot;; &#125;&#125;/** * *算法解决类，以提供客户选择使用何种解决方案： */class PersonContext&#123; private $strategy = null; public function __construct(Travel $travel) &#123; $this-&gt;strategy=$travel; &#125; /** *旅行 */ public function travel() &#123; return$this-&gt;strategy-&gt;travelAlgorithm(); &#125;&#125;// 乘坐火车旅行$person = new PersonContext(new TrainStrategy());$person-&gt;travel();// 改乘飞机$person =PersonContext(new AirPlanelStrategy());$person-&gt;travel(); 当我们更换交通工具时，只需要去增加Travel接口的实现，修改下实现的代码接口，无需去改动核心代码。 控制反转容器（IoC Container）当项目比较大时，依赖关系可能会十分复杂。 而IoC Container提供了动态地创建、注入依赖单元，映射依赖关系等功能，方便开发者使用，并大大缩减了许多代码量。 因为我们的框架比较简单，我们不妨实现下Ioc容器(主要参考了Yii的di容器)。 代码实现用到了PHP的反射Api，有疑问的不妨先看看手册： PHP反射 还记得PSR吗？PSR11是关于依赖注入容器接口规范： 然后我们利用composer执行 composer require psr/container 我们在library/Components新建Container实现ContainerInterface，在library/Exceptions下新建ContainerException实现Psr\\Container\\ContainerExceptionInterface，新建ContainerNotFoundException实现Psr\\Container\\NotFoundExceptionInterface。 我们主要来实现一下Container代码，我们预先定义三个属性，用以保存对象、依赖及依赖的定义信息。 &lt;?phpnamespace Library\\Components;use Library\\Exceptions\\ContainerException;use Library\\Exceptions\\ContainerNotFoundException;use Psr\\Container\\ContainerInterface;use ReflectionClass;class Container implements ContainerInterface&#123; // 用于保存依赖的定义，以对象名称为键 private $definitions = []; // 用于缓存ReflectionClass对象，以对象名称为键 private $reflections = []; // 用于缓存依赖信息，以对象名称为键 private $dependencies = []; public function has($class) &#123; return isset($this-&gt;definitions[$class]); &#125; public function get($class) &#123; ... &#125;&#125; 我们先添加一个set方法，用以定义， public function set($class, $definition = [])&#123; $this-&gt;definitions[$class] = $this-&gt;normalizeDefinition($class, $definition); return $this;&#125;protected function normalizeDefinition($class, $definition)&#123; // $definition 是空的转换成 [&#x27;class&#x27; =&gt; $class] 形式 if (empty($definition)) &#123; return [&#x27;class&#x27; =&gt; $class]; // $definition 是字符串，转换成 [&#x27;class&#x27; =&gt; $definition] 形式 &#125; elseif (is_string($definition)) &#123; return [&#x27;class&#x27; =&gt; $definition]; // $definition 是对象，则直接将其作为依赖的定义 &#125; elseif (is_object($definition)) &#123; return $definition; // $definition 是数组则确保该数组定义了 class 元素 &#125; elseif (is_array($definition)) &#123; if (!isset($definition[&#x27;class&#x27;])) &#123; $definition[&#x27;class&#x27;] = $class; &#125; return $definition; // 这也不是，那也不是，那就抛出异常算了 &#125; else &#123; throw new ContainerException( &quot;不支持的类型： \\&quot;$class\\&quot;: &quot; . gettype($definition)); &#125;&#125; 知识点： gettype — 获取变量的类型 然后我们重点实现get方法： public function get($class)&#123; // 加入未作set操作，我们依旧可以构建 if (!isset($this-&gt;definitions[$class])) &#123; return $this-&gt;build($class); &#125; $definition = $this-&gt;definitions[$class]; if (is_array($definition)) &#123; $concrete = $definition[&#x27;class&#x27;]; unset($definition[&#x27;class&#x27;]); if ($concrete === $class) &#123; $object = $this-&gt;build($class, $definition); &#125; else &#123; $object = $this-&gt;get($concrete); &#125; &#125; elseif (is_object($definition)) &#123; return $this-&gt;_singletons[$class] = $definition; &#125; else &#123; throw new ContainerNotFoundException(&#x27;不能识别的对象类型: &#x27; . gettype($definition)); &#125; return $object;&#125; build方法如下，主要是构建出对象并实现注入， public function build($class, $params = [])&#123; try &#123; // 通过反射api获取对象 $reflector = $this-&gt;getReflectionClass($class); // 获取依赖关系数组 $dependencies = $this-&gt;getDependencies($class, $reflector); // 创建一个类的新实例,给出的参数将传递到类的构造函数. $reflector = $reflector-&gt;newInstanceArgs($dependencies); return $reflector; &#125; catch (\\Throwable $t) &#123; throw new ContainerException(&#x27;反射出错&#x27;); &#125;&#125; 获取对象： public function getReflectionClass($class)&#123; if (isset($this-&gt;reflections[$class])) &#123; return $this-&gt;reflections[$class]; &#125; $reflector = new ReflectionClass($class); if (!$reflector-&gt;isInstantiable()) &#123; throw new ContainerException(&quot;不能实例化&quot;.$class); &#125; return $this-&gt;reflections[$class] = $reflector;&#125; 获取依赖关系： public function getDependencies($class, $reflector)&#123; // 判断是否有缓存依赖关系 if (isset($this-&gt;dependencies[$class])) &#123; return $this-&gt;dependencies[$class]; &#125; $constructor = $reflector-&gt;getConstructor(); #如果没有构造函数， 直接实例化并返回 if (is_null($constructor)) &#123; return $this-&gt;dependencies[$class] = []; &#125; $parameters = $constructor-&gt;getParameters(); $dependencies = []; foreach ($parameters as $className) &#123; $dependency = $className-&gt;getClass(); if (is_null($dependency)) &#123; $dependencies[] = $this-&gt;resolveNoneClass($className); &#125; else &#123; // 先取出容器中绑定的类 否则自动绑定 $dependencies[] = $this-&gt;get($dependency-&gt;getName()); &#125; &#125; $this-&gt;dependencies[$class] = $dependencies; return $dependencies;&#125;public function resolveNoneClass($class)&#123; // 有默认值则返回默认值 if ($class-&gt;isDefaultValueAvailable()) &#123; return $class-&gt;getDefaultValue(); &#125; throw new ContainerException(&#x27;不能解析参数&#x27;);&#125; 到这里，我们基本就完成了一个完整的IOC Container的代码。 我们来写一个demo： &lt;?phpnamespace App\\Https\\Controllers;class C&#123;&#125; &lt;?phpnamespace App\\Https\\Controllers;class B&#123; public function __construct(C $c) &#123; $this-&gt;ccc = $c; &#125;&#125; &lt;?phpnamespace App\\Https\\Controllers;class A&#123; public function __construct(B $b, C $c) &#123; $this-&gt;bbb = $b; $this-&gt;ccc = $c; &#125;&#125; &lt;?phpnamespace App\\Https\\Controllers;use Library\\Components\\Container;use Library\\Https\\Controller;class IndexController extends Controller&#123; public function index() &#123; $contain = new Container(); $contain-&gt;set(&#x27;App\\\\Https\\\\Controllers\\\\A&#x27;); p($contain-&gt;get(&#x27;App\\\\Https\\\\Controllers\\\\A&#x27;)); &#125;&#125; 我们可以看到的结果： 是不是代码简洁很多了，不愿因为需要创建一个A对象，而先去实例化B和C，这些都是由我们完成的IOC Container去实现了。 总结这一节我们实现了IOC容器，然而你如果仔细去想，我们会发现我们可以让容器更加强大，比如单例对象的实现，比如依赖的扩展（兼容对象参数注入，数组参数注入等）。这些你可以自行实现，我也在源代码做了简单的扩展，大家可以思考试着实现一下，当然也可以看看开源框架Laravel、Yii的服务容器的实现。","tags":["phpframe"],"categories":["phpframe"]},{"title":"框架篇：7.使用Redis加速session读写","path":"/2020/02/15/phpframe10/","content":"PHP DIY系列–一起手写一个api框架 大家都知道，默认的session是存储在文件里的，一般情况下这是没什么问题的，然而一旦访问很多，session的使用就会频繁读写文件，必然会影响应用的性能。另外，假如是多机部署，session的共享也是个问题。 既然我们知道有Redis这个利器，而PHP也是支持session自定义的，那么为何不要性能更好又能实现共享session的Redis呢？ Redis是什么？Redis 是完全开源免费的，遵守 BSD 协议，是一个高性能的 key - value 数据库 Redis数据结构 string hash set sorted set pub/sub list 另外还有HyperLogLog，geo…. Redis的优势 性能极佳，官网显示QPS能达到100k/s 数据结构丰富，不止于字符串，hash 稳定性不错，持久化 支持集群 社区不错，使用率高，对于PHP程序员，除了LNMP/LAMP，然后应该就是Redis了 Redis应用 缓存 分布式锁 计数器 队列 geo …… Redis命令 点击查看Redis命令 使用Redis存储session我介绍两种方法给大家： session_start带参 session_set_save_handler托管session 下面我们里一一说明： session_startsession_start ([ array $options = array() ] ) : bool —— 启动新会话或者重用现有会话（点击查看更多参数） 来看demo： session_start([ &#x27;save_path&#x27; =&gt; &#x27;tcp://127.0.0.1:6379&#x27;, &#x27;save_handler&#x27; =&gt; &#x27;Redis&#x27;,]);$_SESSION[&#x27;user_id&#x27;] = 10001;$_SESSION[&#x27;userInfo&#x27;] = [&#x27;name&#x27; =&gt; &#x27;sai&#x27;];p($_SESSION[&#x27;user_id&#x27;]);p($_SESSION[&#x27;userInfo&#x27;]); 输出如下： 10001 Array ( [name] => sai ) 我们可以使用Redis-cli连接查看： Redis-cli -h 127.0.0.1 -p 6379// 如设置密码再输入（auth 你设置的密码）即可 我们可以看到Redis里有了PHPREDIS_SESSION:nmo65igogqnq8ur2gia94jt15u，里面存储了我们的session信息。 session_set_save_handler建议session.serialize_handler = php_serialize，默认php写入和读取略微繁琐。 这里说明我们成功了将session信息通过Redis进行了读写。下面我们使用session_set_save_handler来实现： &lt;?phpnamespace Library\\Sessions;use SessionHandler;class RedisSession extends SessionHandler&#123; private $Redis; private $lifeTime = 7200; private $config; private $prefix = &#x27;PHPREDIS_SESSION:&#x27;; public function __construct($config) &#123; $this-&gt;config = $config; &#125; private function getRedisInstance() &#123; if (empty($this-&gt;Redis)) &#123; $Redis = new \\Redis(); $Redis-&gt;connect($this-&gt;config[&#x27;host&#x27;], $this-&gt;config[&#x27;port&#x27;], $this-&gt;config[&#x27;timeout&#x27;]); if (!$this-&gt;config[&#x27;auth&#x27;]) &#123; $Redis-&gt;auth($this-&gt;config[&#x27;auth&#x27;]); &#125; $this-&gt;Redis = $Redis; &#125; return $this-&gt;Redis; &#125; public function read($id) &#123; return $this-&gt;getRedisInstance()-&gt;get($this-&gt;prefix.$id); &#125; public function write($id, $data) &#123; if ($this-&gt;getRedisInstance()-&gt;setex($this-&gt;prefix.$id, $this-&gt;lifeTime, $data)) &#123; return true; &#125; return false; &#125; public function destroy($id) &#123; if($this-&gt;getRedisInstance()-&gt;delete($id))&#123;//删除Redis中的指定记录 return true; &#125; return false; &#125; public function gc($maxlifetime) &#123; return true; &#125; public function __destruct() &#123; session_write_close(); &#125;&#125;$handler = new RedisSession([ &#x27;host&#x27; =&gt; &#x27;127.0.0.1&#x27;, &#x27;port&#x27; =&gt; 6379, &#x27;auth&#x27; =&gt; null, &#x27;timeout&#x27; =&gt; 5, ]);session_set_save_handler($handler, true);session_start();$_SESSION[&#x27;user_id&#x27;] = 10001;$_SESSION[&#x27;userInfo&#x27;] = [&#x27;name&#x27; =&gt; &#x27;sai&#x27;];p($_SESSION[&#x27;user_id&#x27;]);p($_SESSION[&#x27;userInfo&#x27;]); 知识点： 这里需要注意下read方法，里面需要加一下serialize，以便于我们存储复杂的session结构。如果不加会报错（Warning: session_start(): Failed to read session data: user (path: )）这是因为Redis无法直接存储array结构，需要转化为string类型存储。 我们也来看看Redis客户端存储情况： 通用我们也看到Redis存储了session，与前面略有不同的只是存储的key不一样。但是我们可以定义一个私有属性： private $prefix = ‘PHPREDIS_SESSION:’; 然后做一下调整即可： public function read($id)&#123; return serialize($this-&gt;getRedisInstance()-&gt;get($this-&gt;prefix.$id));&#125;public function write($id,$data)&#123; if ($this-&gt;getRedisInstance()-&gt;setex($this-&gt;prefix.$id, $this-&gt;lifeTime, $data)) &#123; return true; &#125; return false;&#125; 运行后会发现把之前第一种设置的session覆盖掉。 当然我比较建议使用第二种方法，便于我们定制化编码。 总结总的来说，两种方法配置都比较简单，个人建议使用第二种方式实现，这样也比较适合集成到框架，后期我们可以在进行扩展。","tags":["phpframe"],"categories":["phpframe"]},{"title":"框架篇：6.简单测试","path":"/2020/02/13/phpframe09/","content":"PHP DIY系列–一起手写一个api框架 虽然框架基本完成，但我们还没有测试过。 我们使用postman作为接口测试工具（http://saif.com/test）。 // 自定义路由return [ &#x27;debug&#x27; =&gt; false, &#x27;route&#x27; =&gt; [ &#x27;&#x27; =&gt; &#x27;demo/welcome&#x27;, &#x27;test&#x27; =&gt; &#x27;demo/test&#x27;, ],];class DemoController extends Controller&#123; public function welcome($params) &#123; return $this-&gt;response-&gt;json([&#x27;hello&#x27; =&gt; &#x27;welcome&#x27;]); &#125; public function test($params) &#123; return $this-&gt;response-&gt;json($params); &#125;&#125; 我们测试下： 我们发现能正常获取获取GET参数，但没有获取到POST参数。 debug： 我们发现Content-Type输出是： multipart/form-data; boundary=--------------------------498010462598077868347660 我们优化一下代码： public function getBodyParams()&#123; $contentType = strtolower($this-&gt;getHeader(&#x27;Content-Type&#x27;)); // p($contentType); if (strpos($contentType, &#x27;multipart/form-data&#x27;) === false) &#123; $this-&gt;_bodyParams = \\json_decode(file_get_contents(&quot;php://input&quot;), true); &#125; else &#123; $this-&gt;_bodyParams = $_POST; &#125; return $this-&gt;_bodyParams?? [];&#125; 另外我们发现getHeader方法有点问题： public function getHeader($name, $defaultValue = null)&#123; $name = ucfirst($name); if (function_exists(&#x27;apache_request_headers&#x27;)) &#123; $headers = apache_request_headers(); p($headers); return $headers[$name]?? $defaultValue; &#125; // $_SERVER使用下划线 $name = strtoupper(str_replace(&#x27;-&#x27;, &#x27;_&#x27;, $name)); // 部分自定义参数需要加上HTTP_ return $_SERVER[$name]?? ($_SERVER[&#x27;HTTP_&#x27;.$name] ?? $defaultValue);&#125; 测试正常。 另外，做一下说明，我们可以使用public function test($params)，是源于我们Request，将参数注入到方法里。 public function runAction($route)&#123; ... 省略代码 return $controller-&gt;$action(array_merge($this-&gt;getQueryParams(), $this-&gt;getBodyParams()));&#125; 性能测试 我们使用的是wrk压测 wrk &gt; git clone https://github.com/wg/wrk&gt; cd wrk &gt; make&gt; ln -s ./wrk /usr/bin/wrk wrk参数：-c, --connections（连接数）: total number of HTTP connections to keep open with each thread handling N = connections/threads-d, --duration（测试持续时间）: duration of the test, e.g. 2s, 2m, 2h-t, --threads（线程）: total number of threads to use-s, --script（脚本）: LuaJIT script, see SCRIPTING-H, --header（头信息）: HTTP header to add to request, e.g. &quot;User-Agent: wrk&quot; --latency（响应信息）: print detailed latency statistics --timeout（超时时间）: record a timeout if a response is not received within this amount of time.-v, --version（版本信息） Print version details 我们仅仅在控制返回空信息，然后对比yii2（返回字符串“yii2”），laravel5.5（返回字符串“laravel5.5”）。 因为我们的框架没有中间件、组件之类的，所以性能对比yii2、laravel，QPS要高很多。","tags":["phpframe"],"categories":["phpframe"]},{"title":"框架篇：5.自定义配置与路由","path":"/2020/02/09/phpframe08/","content":"PHP DIY系列–一起手写一个api框架 我们已经开发完成，但我们还需要更多。比如自定义配置和路由。 app文件夹下新建Config.php &lt;?php/** *自定义配置 */return [ &#x27;debug&#x27; =&gt; false, &#x27;route&#x27; =&gt; [ &#x27;&#x27; =&gt; &#x27;demo/welcome&#x27;, &#x27;test&#x27; =&gt; &#x27;demo/test&#x27;, ],]; 新建DemoController（app/Https/Controllers目录下） &lt;?php/** * Demo控制器 */namespace App\\Https\\Controllers;use Library\\Https\\Controller;class DemoController extends Controller&#123; public function welcome($params) &#123; return $this-&gt;response-&gt;json([&#x27;hello&#x27; =&gt; &#x27;welcome&#x27;]); &#125; public function test($params) &#123; return $this-&gt;response-&gt;json($params); &#125;&#125; 修改入口文件index.php,加入加载配置代码： ... 省略代码// 加载配置$config = require SF_LIBRARY_PATH.&#x27;Config.php&#x27;;$appConfig = file_exists($appConfigPath = SF_APP_PATH.&#x27;Config.php&#x27;) ? require $appConfigPath : [];$config = array_merge($config, $appConfig);$config[&#x27;debug&#x27;] = ($config[&#x27;debug&#x27;]?? SF_DEBUG);...省略代码 解析路由部分也加入自定义路由处理： // Application...省略代码public function handleRequest(Request $request)&#123; $route = $request-&gt;resolve($this-&gt;_config[&#x27;route&#x27;]??[]); $response = $request-&gt;runAction($route); /** * 执行结果赋值给$response-&gt;data，并返回给response对象 */ if ($response instanceof Response) &#123; return $response; &#125; throw new SaiException(&#x27;Content format error&#x27;);&#125;...省略代码// Request...省略代码public function runAction($route)&#123; if (array_key_exists($route, $this-&gt;_route)) &#123; $route = $this-&gt;_route[$route]; &#125; $match = explode(&#x27;/&#x27;, $route); $match = array_filter($match); ...省略代码 保存后打开浏览器看看效果： 这里虽然有自定义路由，但是我们有时候需要禁止默认路由，所以我们不妨增加配置参数defaultRoute，用来控制是否开启默认路由。 我们修改一下路由解析的代码： //Application...省略代码public function handleRequest(Request $request)&#123; $route = $request-&gt;resolve($this-&gt;_config[&#x27;route&#x27;]??[]); $response = $request-&gt;runAction($route, $this-&gt;_config[&#x27;defaultRoute&#x27;]??true); /** * 执行结果赋值给$response-&gt;data，并返回给response对象 */ if ($response instanceof Response) &#123; return $response; &#125; throw new SaiException(&#x27;Content format error&#x27;);&#125;...省略代码 ...省略代码public function runAction($route, $defaultRoute)&#123; if (array_key_exists($route, $this-&gt;_route)) &#123; $route = $this-&gt;_route[$route]; &#125; elseif (!$defaultRoute) &#123; throw new NotFoundException(&quot;route not found:&quot;.$route); &#125; ...省略代码 我们在app下面的Config，加入： return [ &#x27;debug&#x27; =&gt; false, &#x27;route&#x27; =&gt; [ &#x27;&#x27; =&gt; &#x27;demo/welcome&#x27;, &#x27;test&#x27; =&gt; &#x27;demo/test&#x27;, ], &#x27;defaultRoute&#x27; =&gt; false,]; 我们打开浏览器输入http://saif.com/login 报错如下： Array ( [line] =&gt; 137 [msg] =&gt; route not found:login [code] =&gt; 404 [file] =&gt; library/Https/Request.php )","tags":["phpframe"],"categories":["phpframe"]},{"title":"框架篇：4.入口文件","path":"/2020/02/08/phpframe07/","content":"PHP DIY系列–一起手写一个api框架 回顾上一节我们完成了从路由解析到数据输出的过程，并且之前已经完成了Request的编写，这一节我们写完入口文件，真正的将我们的web应用跑起来了。 入口文件里需要做些什么呢？ 还记得那个流程图吗？ 我们需要加载配置，实例化Application并运行，并且引入后面可能遇到的一些常量。 &lt;?phprequire __DIR__.DIRECTORY_SEPARATOR.&#x27;..&#x27;.DIRECTORY_SEPARATOR.&#x27;library&#x27;.DIRECTORY_SEPARATOR.&#x27;System.php&#x27;;// 加载配置$config = require SF_LIBRARY_PATH.&#x27;Config.php&#x27;;$config[&#x27;debug&#x27;] = ($config[&#x27;debug&#x27;]?? SF_DEBUG);if ($config[&#x27;debug&#x27;]) &#123; ini_set(&quot;display_errors&quot;, &quot;On&quot;); error_reporting(E_ALL);&#125;// composer自动加载require __DIR__ . &#x27;/../vendor/autoload.php&#x27;;// 实例化应用并运行$app = new Library\\Application(new Library\\Https\\Request() ,$config);$app-&gt;run(); 知识点： __DIR__是PHP的一个魔术常量，可以理解成当前文件所在路径。DIRECTORY_SEPARATOR是一个显示系统分隔符的命令，DIRECTORY_SEPARATOR是PHP的内部常量，不需要任何定义与包含即可直接使用。 ini_set — 为一个配置选项设置值 error_reporting — 设置应该报告何种 PHP 错误 &lt;?php// Turn off all error reportingerror_reporting(0);// Report simple running errorserror_reporting(E_ERROR | E_WARNING | E_PARSE);// Reporting E_NOTICE can be good too (to report uninitialized// variables or catch variable name misspellings ...)error_reporting(E_ERROR | E_WARNING | E_PARSE | E_NOTICE);// Report all errors except E_NOTICEerror_reporting(E_ALL &amp; ~E_NOTICE);// Report all PHP errors (see changelog)error_reporting(E_ALL);// Report all PHP errorserror_reporting(-1);// Same as error_reporting(E_ALL);ini_set(&#x27;error_reporting&#x27;, E_ALL);?&gt; System.php&lt;?php// debug默认开启defined(&#x27;SF_DEBUG&#x27;) or define(&#x27;SF_DEBUG&#x27;, true);// 框架开始运行时间defined(&#x27;SF_START_TIME&#x27;) or define(&#x27;SF_START_TIME&#x27;, microtime(true));// 核心文件目录defined(&#x27;SF_LIBRARY_PATH&#x27;) or define(&#x27;SF_LIBRARY_PATH&#x27;, __DIR__.DIRECTORY_SEPARATOR);// 应用目录defined(&#x27;SF_APP_PATH&#x27;) or define(&#x27;SF_APP_PATH&#x27;, __DIR__.DIRECTORY_SEPARATOR.&#x27;..&#x27;.DIRECTORY_SEPARATOR.&#x27;app&#x27;.DIRECTORY_SEPARATOR);// 入口目录defined(&#x27;SF_PUBLIC_PATH&#x27;) or define(&#x27;SF_PUBLIC_PATH&#x27;, __DIR__.DIRECTORY_SEPARATOR.&#x27;..&#x27;.DIRECTORY_SEPARATOR.&#x27;public&#x27;.DIRECTORY_SEPARATOR); Config.php&lt;?php/** * 系统配置 */return [ &#x27;debug&#x27; =&gt; true, // 建议开发过程中开启]; 到这里，我们的框架已经可以运行起来了。 运行应用配置Nginx server &#123; listen 80; server_name saif.com; # 框架根目录 root /Users/sai/Work/www/saif/public; location / &#123; index index.html index.htm index.php; try_files $uri $uri/ /index.php?$query_string; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125; location ~ \\.php$ &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; &#125;&#125; 浏览器输入http://saif.com。 你会看到返回的json数组： 备注：前面3行请忽略，是我浏览器的插件自动加入的。 到这里，我们已经完成了基础API框架的开发。","tags":["phpframe"],"categories":["phpframe"]},{"title":"框架篇：3.路由解析","path":"/2020/02/08/phpframe06/","content":"PHP DIY系列–一起手写一个api框架 回顾上一节我们介绍了编写了如何处理请求与输出数据，这一节我们开始编写路由模块。 正文还记得我们之前建立的Application在哪里吗？ 我们先思考一下Application应该具备哪些功能？ 首先很重要的，我们要让应用运行起来，姑且就先定义run方法。另外我们需要处理请求并且输出数据，我们再定义一个handleRequest方法。当然，我们的应用是有一些配置信息（config）的。 因为，我们不难编写出以下代码： &lt;?phpnamespace Library;use Library\\Exceptions\\SaiException;use Library\\Https\\Request;use Library\\Https\\Response;class Application&#123; private $config; private $request; public function __construct(Request $request, $config = []) &#123; $this-&gt;config = $config; $this-&gt;request = $request; &#125; /** * 运行应用并输出数据 * @return bool */ public function run() &#123; try &#123; $response = $this-&gt;handleRequest($this-&gt;request); $response-&gt;send(); return $response-&gt;exitStatus; &#125; catch (SaiException $e) &#123; $e-&gt;response($e-&gt;getCode(), [ &#x27;line&#x27; =&gt; $e-&gt;getLine(), &#x27;msg&#x27; =&gt; $e-&gt;getMessage(), &#x27;code&#x27; =&gt; $e-&gt;getCode(), &#x27;file&#x27; =&gt; $e-&gt;getFile(), ]); return false; &#125; &#125; /** * 处理请求 * @param Request $request * @return mixed * @throws SaiException */ public function handleRequest(Request $request) &#123; // todo // 返回Response对象 return $response; &#125;&#125; 这里我们看到handleRequest方法还有一部分代码为完成，回想以下流程图，这里就是我们比较核心的部分，路由处理模块。 路由解析路由解析我们使用非常简单而常见的处理方式，不妨看几个url例子来理解一下： route controller method http://blog.puresai.com/ IndexController index http://blog.puresai.com/admin AdminController index http://blog.puresai.com/admin/test AdminController test http://blog.puresai.com/admin/index/test Admin\\IndexController test 有没有看出规律，我们会以斜杠/分割路由为几个部分，最后两部分分别是对应的控制器名称和方法名称，少于两部分默认用index，多余两部分的作为控制器的命名空间。然后我们要根据路由找到控制器构建出控制器。 /** * 控制器处理 * @param $route * @return mixed * @throws NotFoundException */public function runAction($route)&#123; $match = explode(&#x27;/&#x27;, $route); $match = array_filter($match); // 处理$route=/ if (empty($match)) &#123; $match = [&#x27;index&#x27;]; $controller = $this-&gt;createController($match); $action = &#x27;index&#x27;; // 处理$route=index &#125; elseif (count($match) &lt; 2) &#123; $controller = $this-&gt;createController($match); $action = &#x27;index&#x27;; &#125; else &#123; $action = array_pop($match); $controller = $this-&gt;createController($match); if (!method_exists($controller, $action)) &#123; throw new NotFoundException(&quot;method not found:&quot;.$action); &#125; &#125; // 将get和post注入控制器方法中 return $controller-&gt;$action(array_merge($this-&gt;getQueryParams(), $this-&gt;getBodyParams()));&#125;// app应用控制器命名空间private $controllerNameSpace = &#x27;App\\\\Https\\\\Controllers\\\\&#x27;;// 之前定义的基类控制器private $baseController = &#x27;Library\\\\Https\\\\Controller&#x27;;public function createController($match)&#123; $controllerName = $this-&gt;controllerNameSpace; foreach ($match as $namespace) &#123; $controllerName .= ucfirst($namespace).&#x27;\\\\&#x27;; &#125; $controllerName = rtrim($controllerName,&#x27;\\\\&#x27;).&#x27;Controller&#x27;; if (!class_exists($controllerName)) &#123; if ($controllerName == $this-&gt;controllerNameSpace.&#x27;IndexController&#x27;) &#123; return new $this-&gt;baseController; &#125; throw new NotFoundException(&quot;controller not found:&quot;.$controllerName); &#125; return new $controllerName;&#125; 上面是寻找控制器和方法的过程，但我们需要提前获得页面地址以解析路由。 知识点： 反斜杠：反斜线有多种用法。首先，如果紧接着是一个非字母数字字符，表明取消 该字符所代表的特殊涵义。这种将反斜线作为转义字符的用法在字符类 内部和外部都可用。 array_filter ( array $array [, callable $callback [, int $flag = 0 ]] ) : array——依次将 array 数组中的每个值传递到 callback 函数。如果 callback 函数返回 true，则 array 数组的当前值会被包含在返回的结果数组中。数组的键名保留不变。代码中是过滤value为空的单元。 获取页面地址/** * 返回不含参数的REQUEST_URI地址 */public function resolve()&#123; return $this-&gt;getPathUrl();&#125;private $pathUrl;/** * 获取请求地址 * @return bool|mixed|string */public function getPathUrl()&#123; if (is_null($this-&gt;pathUrl)) &#123; $url = trim($_SERVER[&#x27;REQUEST_URI&#x27;], &#x27;/&#x27;); $index = strpos($url, &#x27;?&#x27;); $this-&gt;pathUrl = ($index &gt; -1) ? substr($url, 0, $index) : $url; &#125; return $this-&gt;pathUrl;&#125; 我们尽量让Application变得简洁，而路由解析又和Request关联度较高，因此我们不妨把这些方法抛出到Request对象。 知识点： strpos ( string $haystack , mixed $needle [, int $offset = 0 ] ) : int——返回 needle 在 haystack 中首次出现的数字位置，如果没找到 needle，将返回 FALSE。 上面已经解析好路由并且找到了控制器和方法。这样我们就可以完善Application的代码了。 处理请求public function handleRequest(Request $request)&#123; $route = $request-&gt;resolve(); $response = $request-&gt;runAction($route); /** * 执行结果赋值给$response-&gt;data，并返回给response对象 */ if ($response instanceof Response) &#123; return $response; &#125; throw new SaiException(&#x27;输出的内容格式错误&#x27;);&#125; 再次需要说明的是，我们在这里仅做了json格式输出，如果有兴趣，你可以自己动手拓展一下。 另：NotFoundException继承自SaiException，代码： &lt;?phpnamespace Library\\Exceptions;class NotFoundException extends SaiException&#123; protected $code = 404;&#125;","tags":["phpframe"],"categories":["phpframe"]},{"title":"框架篇：2.请求与输出","path":"/2020/02/04/phpframe05/","content":"PHP DIY系列–一起手写一个api框架 我们在library\\Https目录下新建Request、Response，开始编写请求和输出的代码。 Request我们实现几个常用的方法，get、post、method等，这里主要用$_SERVER实现，为了复用我们定义了三个私有属性存储get参数、post参数和method。 &lt;?php/** * 处理请求 */namespace Library\\Https;use Library\\Components\\Base;class Request extends Base&#123; /** * 获取请求方法 * @return string */ public function getMethod() &#123; if (isset($_SERVER[&#x27;REQUEST_METHOD&#x27;])) &#123; return strtoupper($_SERVER[&#x27;REQUEST_METHOD&#x27;]); &#125; return &#x27;GET&#x27;; &#125; /** * 请求头 * @param $name * @param null $defaultValue * @return mixed|null */ public function getHeader($name, $defaultValue = null) &#123; $name = ucfirst($name); if (function_exists(&#x27;apache_request_headers&#x27;)) &#123; $headers = apache_request_headers(); return $headers[$name]?? $defaultValue; &#125; $name = strtoupper($name); return $_SERVER[$name]?? $defaultValue; &#125; /** * 获取get参数 * @param null $name * @param null $defaultValue * @return |null */ public function get($name = null, $defaultValue = null) &#123; if ($name === null) &#123; return $this-&gt;getQueryParams(); &#125; return $this-&gt;getQueryParam($name, $defaultValue); &#125; public function getQueryParam($name, $defaultValue = null) &#123; $params = $this-&gt;getQueryParams(); return isset($params[$name]) ? $params[$name] : $defaultValue; &#125; public function getQueryParams() &#123; if (empty($this-&gt;queryParams)) &#123; return $this-&gt;queryParams = $_GET; &#125; return $this-&gt;queryParams; &#125; /** * 获取post参数 * @param null $name * @param null $defaultValue * @return array|mixed|null */ public function post($name = null, $defaultValue = null) &#123; if ($name === null) &#123; return $this-&gt;getBodyParams(); &#125; return $this-&gt;getBodyParam($name, $defaultValue); &#125; public function getBodyParam($name, $defaultValue = null) &#123; $params = $this-&gt;getBodyParams(); if (is_object($params)) &#123; try &#123; return $params-&gt;&#123;$name&#125;; &#125; catch (\\Exception $e) &#123; return $defaultValue; &#125; &#125; return isset($params[$name]) ? $params[$name] : $defaultValue; &#125; public function getBodyParams() &#123; $contentType = strtolower($this-&gt;getHeader(&#x27;Content-Type&#x27;)); if ($contentType == &#x27;multipart/form-data&#x27;) &#123; $this-&gt;bodyParams = $_POST; &#125; else &#123; $this-&gt;bodyParams = \\json_decode(file_get_contents(&quot;php://input&quot;), true); &#125; return $this-&gt;bodyParams?? []; &#125; /** * get参数数组 */ private $queryParams = []; /** * post参数数组 */ private $bodyParams = []; private $method;&#125; 知识点： 获取请求头部信息的方式nginx和apache不同 apache可以使用apache_request_headers nginx使用$_SERVER，并且需要注意的是的是自定义信息等参数会在前面自动加上http_，并且会转换为大写 post参数获取的方式 当Content-Type是application/x-www-data-urlencoded或multipart/form-data时，数据会放进$_POST中； 除了Coentent-Type为multipart/form-data的情况，数据都可以通过file_get_contents(“php://input”)取到； 不建议使用$GLOBALS[‘HTTP_RAW_POST_DATA’] ResponseResponse默认以使用广泛的json输出，暂时也只考虑json格式输出的情况。 &lt;?php/** * 数据输出 */namespace Library\\Https;use Library\\Components\\Base;class Response extends Base&#123; public $code = 0; public $result = []; public $msg = &quot;success&quot;; public function send() &#123; header(&#x27;Content-Type:application/json; charset=utf-8&#x27;); echo \\json_encode([ &#x27;data&#x27; =&gt; $this-&gt;result, &#x27;msg&#x27; =&gt; $this-&gt;msg, &#x27;code&#x27; =&gt; $this-&gt;code, &#x27;timestamp&#x27; =&gt; time() ]); &#125; public function json($data = []) &#123; $this-&gt;result = array_merge($this-&gt;result, $data); return $this; &#125;&#125; 知识点： header() 用于发送原生的 HTTP 头。 json_encode ( mixed $value [, int $options = 0 [, int $depth = 512 ]] ) : string — 对变量进行 JSON 编码，options可以预定义常量，如 JSON_UNESCAPED_UNICODE，JSON_UNESCAPED_SLASHES。 Controller结合输出对象，我们在创建一个基类控制器，也放在相同的Https目录，我们控制创建一个构造函数，实例化一个Response，并实现一个通用的json： &lt;?php/** * 基类控制器 * 预定义json方法，便于其他控制器使用 * 返回格式 &#123; &quot;data&quot;: [], &quot;msg&quot;: &quot;success&quot;, &quot;code&quot;: 0, &quot;timestamp&quot;: 1572231957&#125; */namespace Library\\Https;class Controller&#123; protected $response; protected $code = 200; public function __construct() &#123; $this-&gt;response = new Response(); &#125; public function json($data = []) &#123; return $this-&gt;response-&gt;json($data); &#125; public function index($params) &#123; return $this-&gt;response-&gt;json([&#x27;hello&#x27; =&gt; &#x27;saif&#x27;]); &#125;&#125; app应用里的控制器都必须继承这个基类控制器。","tags":["phpframe"],"categories":["phpframe"]},{"title":"框架篇：1.框架目录与辅助","path":"/2020/02/02/phpframe04/","content":"PHP DIY系列–一起手写一个api框架 那么就利用composer来开始我们的项目吧。 新建目录并进入目录，输入命令： composer init 命令行会跟你确认以下信息（以下信息可以自行DIY） # 1. 输入项目命名空间# 注意&lt;vendor&gt;/&lt;name&gt; 必须要符合 [a-z0-9_.-]+/[a-z0-9_.-]+Package name (&lt;vendor&gt;/&lt;name&gt;) yourname/projectname# 2. 项目描述Description []:这是一个测试composer init 项目# 3. 输入作者信息Author [puresai &lt;sai0556@qq.com&gt;, n to skip]:# 4. 输入最低稳定版本，stable, RC, beta, alpha, devMinimum Stability []:dev# 5. 输入项目类型Package Type (e.g. library, project, metapackage, composer-plugin) []:project# 6. 输入授权类型License []:MITDefine your dependencies.# 7. 输入依赖信息Would you like to define your dependencies (require) interactively [yes]?# 7.1. 如果需要依赖，则输入要安装的依赖Search for a package:php# 7.2. 输入版本号Enter the version constraint to require (or leave blank to use the latest version): &gt;=5.4.0# 如需多个依赖，则重复以上两个步骤(7.1/7.2)Search for a package:# 8. 是否需要require-dev，Would you like to define your dev dependencies (require-dev) interactively [yes]?&#123; &quot;name&quot;: &quot;sai/saif&quot;, &quot;description&quot;: &quot;php framework&quot;, &quot;type&quot;: &quot;project&quot;, &quot;require&quot;: &#123; &#125;, &quot;license&quot;: &quot;MIT&quot;, &quot;authors&quot;: [ &#123; &quot;name&quot;: &quot;puresai&quot;, &quot;email&quot;: &quot;sai0556@qq.com&quot; &#125; ], &quot;minimum-stability&quot;: &quot;dev&quot;&#125;# 9. 是否生成composer.jsonDo you confirm generation [yes]?# 现在安装依赖项吗Would you like to install dependencies now [yes]? 我们的目录下会生成composer.json。 然后我们来思考一个问题： 你觉得一个基础的API框架需要什么模块呢？ 下面是我的思考结果： 路由 请求 数据响应 异常处理 日志系统… 当然，你可能觉得还应该有： 配置 session 缓存 验证 模型 服务层 文件上传… 也许你想到更多： 任务调度 队列 用户验证 锁 … 那么这么些我们如何取舍呢？手心手背都是肉啊。 这里需要做一下说明，我们所做的框架无需考虑太多的功能，是做一个简单可用的API接口框架，我们接受get/post请求，返回json数据，并且路由好用，这是我们的初衷，其他的暂且就“断舍离”吧。 我们先画一个极简的流程图。 我们一切从简，所以我们定义以下几个模块： 路由 控制器 请求 数据响应 配置 异常处理 … 基于这些，我们新建目录，app和library，public app web应用 library 核心代码 public 入口目录 出于简单安全考虑，我们的入口单独放在public目录，并在目录下新建index.php作为我们的入口文件。 library下面新建几个目录和文件 Components 常用组件 Exceptions 异常模块 Https http应用模块 Sessions session模块 Application.php 应用文件 Config.php 配置文件 Functions.php 常用函数 System.php 框架自定义常量 对应的我们在composer.json中加入一些autoload配置，用以自动加载，省去我们实现自动加载。 &quot;autoload&quot;: &#123; &quot;psr-4&quot;: &#123; &quot;Library\\\\&quot;: &quot;library/&quot;, &quot;App\\\\&quot;: &quot;app/&quot; &#125;, &quot;files&quot;: [ &quot;library/Functions.php&quot; ]&#125; 执行一下，composer install或者composer dump-autoload即可。 这里简单说明一下autoload的四种方式： autoload的四种方式 PSR-4 在psr-4键下，定义了相对于包根目录从名称空间到路径的映射。当自动加载一个类（如foo\\bar\\baz）时，指向src/目录的名称空间前缀foo\\，意味着自动加载程序将查找一个名为src/bar/baz.php的文件，并包括它（如果存在）。注意，与旧的psr-0样式相反，前缀（foo\\）不在文件路径中。 命名空间前缀必须以“\\”结尾，以避免类似前缀之间的冲突。例如，foo将匹配foobar名称空间中的类，因此后面的反斜杠可以解决问题：foo\\，foobar\\。 该数组可以在生成的文件vendor/composer/autoload_psr4.php中找到。 PSR-0 在 psr-0 key 下你定义了一个命名空间到实际路径的映射（相对于包的根目录）。注意，这里同样支持 PEAR-style 方式的约定（与命名空间不同，PEAR 类库在类名上采用了下划线分隔）。 请注意，命名空间的申明应该以 \\ 结束，以确保 autoloader 能够准确响应。例： Foo 将会与 FooBar 匹配，然而以反斜杠结束就可以解决这样的问题， Foo\\ 和 FooBar\\ 将会被区分开来。 PSR-0 引用都将被结合为一个单一的键值对数组，存储至 vendor/composer/autoload_namespaces.php 文件中。 classmap 你可以用 classmap 生成支持支持自定义加载的不遵循 PSR-0/4 规范的类库。要配置它指向需要的目录，以便能够准确搜索到类文件。 classmap 引用的所有组合会存储到 vendor/composer/autoload_classmap.php 文件中。这个 map 是经过扫描指定目录（同样支持直接精确到文件）中所有的 .php 和 .inc 文件里内置的类而得到的。 files 如果你想要明确的指定，在每次请求时都要载入某些文件，那么你可以使用 ‘files’ autoloading。通常作为函数库的载入方式（而非类库）。files 引用的文件会存储到 vendor/composer/autoload_files.php 文件中 点击查看autoload说明与实例 我们先不着急进行核心代码编写，不妨先做一下辅助工作，常用方法，异常处理等。 常用函数Functions编写常用函数 &lt;?php/** * 常用函数 */ if (!function_exists(&quot;p&quot;)) &#123; function p($var) &#123; if (is_bool($var)) &#123; var_dump($var); &#125; elseif (is_null($var)) &#123; var_dump(null); &#125; else &#123; die(&quot;&lt;meta charset=&#x27;utf-8&#x27;/&gt;&lt;pre style=&#x27;position:relative;z-index:999;padding:10px;border-radius:5px;background:#f5f5f5;border:1px solid #aaa;font-size:14px;line-height:18px;opacity:0.8;&#x27;&gt;&quot;.print_r($var, true).&quot;&lt;/pre&gt;&quot;); &#125; &#125;&#125;······ 异常处理在Exceptions目录下，定义一个最基础的异常SaiException： &lt;?phpnamespace Library\\Exceptions;class SaiException extends \\Exception&#123; const CODE_MAPPING = [ 100 =&gt; &#x27;Continue&#x27;, 101 =&gt; &#x27;Switching Protocols&#x27;, 102 =&gt; &#x27;Processing&#x27;, 200 =&gt; &#x27;OK&#x27;, 201 =&gt; &#x27;Created&#x27;, 202 =&gt; &#x27;Accepted&#x27;, 203 =&gt; &#x27;Non-Authoritative Information&#x27;, 204 =&gt; &#x27;No Content&#x27;, 205 =&gt; &#x27;Reset Content&#x27;, 206 =&gt; &#x27;Partial Content&#x27;, 207 =&gt; &#x27;Multi-Status&#x27;, 226 =&gt; &#x27;IM Used&#x27;, 300 =&gt; &#x27;Multiple Choices&#x27;, 301 =&gt; &#x27;Moved Permanently&#x27;, 302 =&gt; &#x27;Found&#x27;, 303 =&gt; &#x27;See Other&#x27;, 304 =&gt; &#x27;Not Modified&#x27;, 305 =&gt; &#x27;Use Proxy&#x27;, 306 =&gt; &#x27;Reserved&#x27;, 307 =&gt; &#x27;Temporary Redirect&#x27;, 400 =&gt; &#x27;Bad Request&#x27;, 401 =&gt; &#x27;Unauthorized&#x27;, 402 =&gt; &#x27;Payment Required&#x27;, 403 =&gt; &#x27;Forbidden&#x27;, 404 =&gt; &#x27;Not Found&#x27;, 405 =&gt; &#x27;Method Not Allowed&#x27;, 406 =&gt; &#x27;Not Acceptable&#x27;, 407 =&gt; &#x27;Proxy Authentication Required&#x27;, 408 =&gt; &#x27;Request Timeout&#x27;, 409 =&gt; &#x27;Conflict&#x27;, 410 =&gt; &#x27;Gone&#x27;, 411 =&gt; &#x27;Length Required&#x27;, 412 =&gt; &#x27;Precondition Failed&#x27;, 413 =&gt; &#x27;Request Entity Too Large&#x27;, 414 =&gt; &#x27;Request-URI Too Long&#x27;, 415 =&gt; &#x27;Unsupported Media Type&#x27;, 416 =&gt; &#x27;Requested Range Not Satisfiable&#x27;, 417 =&gt; &#x27;Expectation Failed&#x27;, 422 =&gt; &#x27;Unprocessable Entity&#x27;, 423 =&gt; &#x27;Locked&#x27;, 424 =&gt; &#x27;Failed Dependency&#x27;, 426 =&gt; &#x27;Upgrade Required&#x27;, 429 =&gt; &#x27;Too Many Request&#x27;, 500 =&gt; &#x27;Internal Server Error&#x27;, 501 =&gt; &#x27;Not Implemented&#x27;, 502 =&gt; &#x27;Bad Gateway&#x27;, 503 =&gt; &#x27;Service Unavailable&#x27;, 504 =&gt; &#x27;Gateway Timeout&#x27;, 505 =&gt; &#x27;HTTP Version Not Supported&#x27;, 506 =&gt; &#x27;Variant Also Negotiates&#x27;, 507 =&gt; &#x27;Insufficient Storage&#x27;, 510 =&gt; &#x27;Not Extended&#x27;, 1001 =&gt; &#x27;LACK PARAMS&#x27;, 1002 =&gt; &#x27;RETRY TOO MANY&#x27;, ]; /** * 输出指定HTTP状态码的响应头信息 * @param int $code * @param $data * @return void */ public function response($code, $data)&#123; $code = array_key_exists($code, self::CODE_MAPPING)? $code : 500; $desc = self::CODE_MAPPING[$code]; $protocol = $_SERVER[&#x27;SERVER_PROTOCOL&#x27;]; if ( &#x27;HTTP/1.1&#x27; != $protocol &amp;&amp; &#x27;HTTP/1.0&#x27; != $protocol ) $protocol = &#x27;HTTP/1.0&#x27;; $header = &quot;$protocol $code $desc&quot;; header($header); p($data); &#125;&#125; 几乎后面所有Exception的类都会继承这个异常类。 在Components目录下新建基础的类Base： &lt;?phpnamespace Library\\Components;class Base implements \\ArrayAccess&#123; private $_container; public function __get($name) &#123; if (method_exists($this, $method = &#x27;get&#x27;.ucfirst($name))) &#123; return $this-&gt;$method($name); &#125; return null; &#125; public function __set($name, $value) &#123; if (method_exists($this, $method = &#x27;set&#x27;.ucfirst($name))) &#123; return $this-&gt;$method($name, $value); &#125; &#125; public function offsetSet($offset, $value) &#123; if (is_null($offset)) &#123; $this-&gt;_container[] = $value; &#125; else &#123; $this-&gt;_container[$offset] = $value; &#125; &#125; public function offsetExists($offset) &#123; return isset($this-&gt;_container[$offset]); &#125; public function offsetUnset($offset) &#123; unset($this-&gt;_container[$offset]); &#125; public function offsetGet($offset) &#123; return isset($this-&gt;_container[$offset]) ? $this-&gt;_container[$offset] : null; &#125;&#125; 这里有两个知识点： ArrayAccess数组式访问接口（提供像访问数组一样访问对象的能力的接口。） 魔术方法__set和__get（在给不可访问属性赋值时__set() 会被调用;读取不可访问属性的值时__get() 会被调用。） 如果想了解更多，可看官方文档： ArrayAccess接口 魔术方法","tags":["phpframe"],"categories":["phpframe"]},{"title":"基础篇：3.反射","path":"/2020/02/01/phpframe03/","content":"PHP DIY系列–一起手写一个api框架 反射，直观理解就是根据到达地找到出发地和来源。 反射指在PHP运行状态中，扩展分析PHP程序，导出或提出关于类、方法、属性、参数等的详细信息，包括注释。这种动态获取信息以及动态调用对象方法的功能称为反射API。 不妨先来看一个demo： &lt;?php/** * Author: sai * Date: 2019/10/21 * Time: 10:59 */function p($msg, $var)&#123; echo(&quot;&lt;pre style=&#x27;position:relative;z-index:999;padding:10px;border-radius:5px;background:#f5f5f5;border:1px solid #aaa;font-size:14px;line-height:18px;opacity:0.8;&#x27;&gt;&quot;.$msg.&quot;:&quot;.print_r($var, true).&quot;&lt;/pre&gt;&quot;);&#125;class Demo&#123; private $id; protected $name; public $skills = []; public function __construct($id, $name, $skills = []) &#123; $this-&gt;id = $id; $this-&gt;name = $name; $this-&gt;skills = $skills; &#125; public function getName() &#123; return $this-&gt;name; &#125; public function getSkill() &#123; p(&#x27;skill&#x27;, $this-&gt;skills); &#125;&#125;$ref = new ReflectionClass(&#x27;Demo&#x27;);if ($ref-&gt;isInstantiable()) &#123; p(&#x27;检查类是否可实例化isInstantiable&#x27;, null );&#125;$constructor = $ref-&gt;getConstructor();p(&#x27;获取构造函数getConstructor&#x27;, $constructor);$parameters = $constructor-&gt;getParameters();foreach ($parameters as $param) &#123; p(&#x27;获取参数getParameters&#x27;, $param);&#125;if ($ref-&gt;hasProperty(&#x27;name&#x27;)) &#123; $attr = $ref-&gt;getProperty(&#x27;name&#x27;); p(&#x27;获取属性getProperty&#x27;, $attr);&#125;$attributes = $ref-&gt;getProperties();foreach ($attributes as $row) &#123; p(&#x27;获取属性列表getProperties&#x27;, $row-&gt;getName() );&#125;if ($ref-&gt;hasMethod(&#x27;getSkill&#x27;)) &#123; $method = $ref-&gt;getMethod(&#x27;getSkill&#x27;); p(&#x27;获取方法getMethod&#x27;, $method);&#125;$methods = $ref-&gt;getMethods();foreach ($methods as $row) &#123; p(&#x27;获取方法列表getMethods&#x27;, $row-&gt;getName());&#125;$instance = $ref-&gt;newInstanceArgs([1, &#x27;sai&#x27;, [&#x27;php&#x27;, &#x27;js&#x27;]]);p(&#x27;newInstanceArgs&#x27;, $instance); 输出： 检查类是否可实例化isInstantiable: 获取构造函数getConstructor:ReflectionMethod Object ( [name] => __construct [class] => Demo ) 获取参数getParameters:ReflectionParameter Object( [name] => id)获取参数getParameters:ReflectionParameter Object( [name] => name)获取参数getParameters:ReflectionParameter Object( [name] => skills)获取属性getProperty:ReflectionProperty Object( [name] => name [class] => Demo)获取属性列表getProperties:id获取属性列表getProperties:name获取属性列表getProperties:skills获取方法getMethod:ReflectionMethod Object( [name] => getSkill [class] => Demo)获取方法列表getMethods:__construct获取方法列表getMethods:getName获取方法列表getMethods:getSkillnewInstanceArgs:Demo Object( [id:Demo:private] => 1 [name:protected] => sai [skills] => Array ( [0] => php [1] => js ) ) demo里面就有使用了ReflectionClass类，当然ReflectionClass类不止于这些方法。 更多方法ReflectionClass类还有更多方法： 方法 说明 ReflectionClass::__construct 初始化 ReflectionClass 类 ReflectionClass::export 导出一个类 ReflectionClass::getConstant 获取定义过的一个常量 ReflectionClass::getConstants 获取一组常量 ReflectionClass::getConstructor 获取类的构造函数 ReflectionClass::getDefaultProperties 获取默认属性 ReflectionClass::getDocComment 获取文档注释 ReflectionClass::getEndLine 获取最后一行的行数 ReflectionClass::getExtension 根据已定义的类获取所在扩展的 ReflectionExtension 对象 ReflectionClass::getExtensionName 获取定义的类所在的扩展的名称 ReflectionClass::getFileName 获取定义类的文件名 ReflectionClass::getInterfaceNames 获取接口（interface）名称 ReflectionClass::getInterfaces 获取接口 ReflectionClass::getMethod 获取一个类方法的 ReflectionMethod。 ReflectionClass::getMethods 获取方法的数组 ReflectionClass::getModifiers 获取类的修饰符 ReflectionClass::getName 获取类名 ReflectionClass::getNamespaceName 获取命名空间的名称 ReflectionClass::getParentClass 获取父类 ReflectionClass::getProperties 获取一组属性 ReflectionClass::getProperty 获取类的一个属性的 ReflectionProperty ReflectionClass::getReflectionConstant Gets a ReflectionClassConstant for a class’s constant ReflectionClass::getReflectionConstants Gets class constants ReflectionClass::getShortName 获取短名 ReflectionClass::getStartLine 获取起始行号 ReflectionClass::getStaticProperties 获取静态（static）属性 ReflectionClass::getStaticPropertyValue 获取静态（static）属性的值 ReflectionClass::getTraitAliases 返回 trait 别名的一个数组 ReflectionClass::getTraitNames 返回这个类所使用 traits 的名称的数组 ReflectionClass::getTraits 返回这个类所使用的 traits 数组 ReflectionClass::hasConstant 检查常量是否已经定义 ReflectionClass::hasMethod 检查方法是否已定义 ReflectionClass::hasProperty 检查属性是否已定义 ReflectionClass::implementsInterface 接口的实现 ReflectionClass::inNamespace 检查是否位于命名空间中 ReflectionClass::isAbstract 检查类是否是抽象类（abstract） ReflectionClass::isAnonymous 检查类是否是匿名类 ReflectionClass::isCloneable 返回了一个类是否可复制 ReflectionClass::isFinal 检查类是否声明为 final ReflectionClass::isInstance 检查类的实例 ReflectionClass::isInstantiable 检查类是否可实例化 ReflectionClass::isInterface 检查类是否是一个接口（interface） ReflectionClass::isInternal 检查类是否由扩展或核心在内部定义 ReflectionClass::isIterable Check whether this class is iterable ReflectionClass::isIterateable 检查是否可迭代（iterateable） ReflectionClass::isSubclassOf 检查是否为一个子类 ReflectionClass::isTrait 返回了是否为一个 trait ReflectionClass::isUserDefined 检查是否由用户定义的 ReflectionClass::newInstance 从指定的参数创建一个新的类实例 ReflectionClass::newInstanceArgs 从给出的参数创建一个新的类实例。 ReflectionClass::newInstanceWithoutConstructor 创建一个新的类实例而不调用它的构造函数 ReflectionClass::setStaticPropertyValue 设置静态属性的值 ReflectionClass::__toString 返回 ReflectionClass 对象字符串的表示形式。 除去强大的ReflectionClass，还有Reflection、ReflectionClassConstant 、ReflectionMethod 、ReflectionFunctionAbstract等等。建议查看手册： PHP反射 反射的实际应用 反射可以用于文档、文件生成。可以用它对文件里的类进行扫描，逐个生成描述文档; 既然反射可以探知类的内部结构，那么可以用它做hook实现插件功能； 可以用于做动态代理，在未知或者不确定类名的情况下，动态生成和实例化一些类和执行方法； 依赖注入。对于多次继承的类，我们可以通过多次反射探索到基类的结构，或者采用递归的形式反射，实现实例化所有继承类，这也是PHP依赖注入的原理。 反射的优点 支持反射的语言提供了一些在低级语言中难以实现的运行时特性。 可以在一定程度上避免硬编码，提供灵活性和通用性。 可以作为一个第一类对象发现并修改源代码的结构（如代码块、类、方法、协议等）。 可以在运行时像对待源代码语句一样计算符号语法的字符串（类似JavaScript的eval()函数），进而可将跟class或function匹配的字符串转换成class或function的调用或引用。 可以创建一个新的语言字节码解释器来给编程结构一个新的意义或用途。 反射的缺点 学习成本高。面向反射的编程需要较多的高级知识，包括框架、关系映射和对象交互，以利用更通用的代码执行 同样因为反射的概念和语法都比较抽象，过多地滥用反射技术会使得代码难以被其他人读懂，不利于合作与交流 反射在提高了代码灵活性的同时，牺牲了一点点运行效率，有一定的消耗 反射也会破坏类的封装性，把本不该暴露的方法或属性暴露了出来 在平时的开发中，我们用到反射其实不多，为什么把它拿到这里来说呢？一来是我们后面会使用到反射去实现Ioc容器，二来反射也是PHP核心功能之一，在我们流行的框架中十分常见，理解它是很有必要的。","tags":["phpframe"],"categories":["phpframe"]},{"title":"基础篇：2.composer","path":"/2020/02/01/phpframe02/","content":"PHP DIY系列–一起手写一个api框架 上一节我们介绍了我们需要遵循的规范，这一节我们来介绍一下我们的项目中需要用到的一个依赖管理工具——Composer。 Composer 是 PHP 的一个依赖管理工具。它允许你申明项目所依赖的代码库，它会在你的项目中为你安装他们。 如果你是前端工程师，你应该用过npm；如果你是pyhton开发者，你应该用过pip，简单说你可以这样理解composer。 composer在小册中可能经常会被提及，我们来学习一下安装和常用命令。 安装 Linux composer的安装比较简单，不建议使用yum等管理包直接install，因为有可能会修改你的默认php版本。我们可以跳过以下方式安装： curl -sS https://getcomposer.org/installer | php mv composer.phar /usr/local/bin/composer Windows 下载并且运行 Composer-Setup.exe，它将安装最新版本的 Composer ，建议加入系统的环境变量，这样你就可以在任何目录下直接使用 composer 命令。 修改镜像源默认镜像源国内下载比较慢，建议更换镜像源 composer config -g repo.packagist composer https://packagist.phpcomposer.com 也可以使用阿里的镜像源(推荐) composer config -g repo.packagist composer https://mirrors.aliyun.com/composer/ config -g/–global 表示全局配置 composer常用命令init初始化参数：--name: 包的名称。--description: 包的描述。--author: 包的作者。--homepage: 包的主页。--require: 需要依赖的其它包，必须要有一个版本约束。并且应该遵循 foo/bar:1.0.0 这样的格式。--require-dev: 开发版的依赖包，内容格式与 --require 相同。--stability (-s): minimum-stability 字段的值。 require增加require 命令增加新的依赖包到当前目录的 composer.json 文件中，并可以指定版本。 composer require vendor/package:2.* vendor/package2:dev-master install安装install 命令从当前目录读取 composer.json 文件，处理了依赖关系，并把其安装到 vendor 目录下。 如果当前目录下存在 composer.lock 文件，它会从此文件读取依赖版本，而不是根据 composer.json 文件去获取依赖。这确保了该库的每个使用者都能得到相同的依赖版本。 如果没有 composer.lock 文件，composer 将在处理完依赖关系后创建它。 你可以简单把composer.lock理解为扩展库的缓存。 update更新为了获取依赖的最新版本，并且更新 composer.lock 文件，你应该使用 update 命令。 composer update 这将解决项目的所有依赖，并将确切的版本号写入 composer.lock。 如果你只是想更新几个包，你可以像这样分别列出它们： composer update vendor/package vendor/package2 ==注意==：update命令会更新composer.json里限定版本的最新依赖。比如你写的是”monolog/monolog”: “1.*”,update命令可能会把1.0更新为1.2版本，但不会将1.0更新为2.0。所以使用时需要注意。 searchsearch 命令允许你为当前项目搜索依赖包，通常它只搜索 packagist.org 上的包，你可以简单的输入你的搜索条件。 show列出所有可用的软件包，你可以使用 show 命令。 也可以点击查看更多composer包 dump-autoload打印自动加载索引，某些情况下你需要更新 autoloader，例如在你的包中加入了一个新的类。你可以使用 dump-autoload 来完成，而不必执行 install 或 update 命令。 此外，它可以打印一个优化过的，符合 PSR-0/4 规范的类的索引，这也是出于对性能的可考虑。在大型的应用中会有许多类文件，而 autoloader 会占用每个请求的很大一部分时间，使用 classmaps 或许在开发时不太方便，但它在保证性能的前提下，仍然可以获得 PSR-0/4 规范带来的便利。 更composer多命令请点击查看 好了，这一节我们介绍了composer的安装和常用命令。我们后面可以将框架集成到一个composer包，分享给其他开发同学使用。","tags":["phpframe"],"categories":["phpframe"]},{"title":"基础篇：1.PSR","path":"/2020/02/01/phpframe01/","content":"PHP DIY系列–一起手写一个api框架 创作初衷 有没有用烦了CURD？ 各种框架是不是有点头大？ 有没有尝试自己设计一个框架？ 学了PHP语法，没有项目去实战，夯实基础 希望能帮助能让你快速地搭建一个自己的框架，能给你的工作或者学习中带来一定的帮助与启发。 你能学到什么 PSR规范 composer的使用 快速搭建一个API接口框架 Redis各种数据类型的应用 缓存应用分析 在开发框架之前，我来介绍框架开发遵循的规范。 大多数编程语言都有自己的一套编码规范，作为“世界上最好的语言”，PHP当然也有自己的编码规范。这个规范就是PHP Standard Recommendation（简称PSR）。 当然，从我自己的工作中，我发现很多PHP程序员尤其是初级程序员，是不知道PHP是有这么一个规范的，我认为这是不科学的。 什么是PSR？介绍PSR之前需要介绍一下制定此规范的组织—–PHP-FIG，全称是PHP Framework Interoperability。 组织成员制定规范，并且落实在自己的项目中，虽然不是官方组织，但也代表了大部分PHP社区项目，如CakePHP，Composer，Drupal，PEAR，Slim，Yii framework，Zend Framework等。并且有越来越多的项目加入并遵循此标准。 PSR项目的目的在于：通过框架作者或者框架的代表之间讨论，以最低程度的限制，制定一个协作标准，各个框架遵循统一的编码规范，让工程师一起更好协同工作。 截止目前，已经官网已有20条列出，除去起草中和舍弃的，有以下13条。 我们不妨来看看这些规范： PSR-1 基础编码规范 PHP 代码文件必须以 &lt;?php 或 &lt;?= 标签开始 PHP 代码文件必须以不带BOM的UTF-8编码 PHP 代码中 应该 只定义类、函数、常量等声明，或其他会产生 副作用 的操作（如：生成文件输出以及修改 .ini 配置文件等），二者只能选其一 命名空间以及类必须符合 PSR 的自动加载规范PSR-4 类的命名必须遵循 StudlyCaps 式大写开头的驼峰命名规范 类中的常量所有字母都必须 大写，单词间用下划线分隔 方法名称必须符合 camelCase 式的小写开头驼峰命名规范 PSR-12 代码风格规范PSR-12的规范很细致，包含了声明、命名空间、类及继承以及控制结构等说明。 我们先来看一个demo： &lt;?phpdeclare(strict_types=1);namespace Vendor\\Package;use Vendor\\Package\\&#123;ClassA as A, ClassB, ClassC as C&#125;;use Vendor\\Package\\SomeNamespace\\ClassD as D;use function Vendor\\Package\\&#123;functionA, functionB, functionC&#125;;use const Vendor\\Package\\&#123;ConstantA, ConstantB, ConstantC&#125;;class Foo extends Bar implements FooInterface&#123; public function sampleFunction(int $a, int $b = null): array &#123; if ($a === $b) &#123; bar(); &#125; elseif ($a &gt; $b) &#123; $foo-&gt;bar($arg1); &#125; else &#123; BazClass::bar($arg2, $arg3); &#125; &#125; final public static function bar() &#123; // method body &#125;&#125; 代码 必须 遵循 [PSR-1] 中的编码规范 所有PHP文件必须使用Unix LF (linefeed)作为行的结束符； 所有PHP文件必须以一个空白行作为结束； 纯PHP代码文件必须省略最后的 ?&gt; 结束标签 每行的字符数 应该软性保持在 80 个之内，理论上 一定不可 多于 120 个，但一定不可有硬性限制；非空行后一定不能有多余的空格符； 空行可以使得阅读代码更加方便以及有助于代码的分块。 每行一定不能存在多于一条语句 代码必须使用4个空格符的缩进，一定不能用 tab键 PHP所有关键字必须全部小写 控制结构的基本规范如下：控制结构关键词后必须有一个空格。左括号 ( 后一定不能有空格。右括号 ) 前也一定不能有空格。右括号 ) 与开始花括号 &#123; 间一定有一个空格。结构体主体一定要有一次缩进。结束花括号 &#125; 一定在结构体主体后单独成行。 代码风格规范内容很多，这里就不一一说明了，大家可自行阅读 PSR-4 自动加载关于由文件路径 自动载入 对应类的相关规范， 本规范是可互操作的，可以作为任一自动载入规范的补充，其中包括 PSR-0，此外， 本 PSR 还包括自动载入的类对应的文件存放路径规范。 此处的“类”泛指所有的class类、接口、traits可复用代码块以及其它类似结构。 一个完整的类名需具有以下结构: \\&lt;命名空间&gt;(\\&lt;子命名空间&gt;)*\\&lt;类名&gt; 完整的类名必须要有一个顶级命名空间，被称为 “vendor namespace”； 完整的类名可以有一个或多个子命名空间； 完整的类名必须有一个最终的类名； 完整的类名中任意一部分中的下划线都是没有特殊含义的； 完整的类名可以由任意大小写字母组成； 所有类名都必须是大小写敏感的。 当根据完整的类名载入相应的文件…… 完整的类名中，去掉最前面的命名空间分隔符，前面连续的一个或多个命名空间和子命名空间，作为“命名空间前缀”，其必须与至少一个“文件基目录”相对应； 紧接命名空间前缀后的子命名空间必须与相应的”文件基目录“相匹配，其中的命名空间分隔符将作为目录分隔符。 末尾的类名必须与对应的以 .php 为后缀的文件同名。 自动加载器（autoloader）的实现一定不能抛出异常、一定不能触发任一级别的错误信息以及不应该有返回值。 例子下表展示了符合规范完整类名、命名空间前缀和文件基目录所对应的文件路径。 完整类名 命名空间前缀 文件基目录 文件路径 \\Acme\\Log\\Writer\\File_Writer Acme\\Log\\Writer ./acme-log-writer/lib/ ./acme-log-writer/lib/File_Writer.php \\Aura\\Web\\Response\\Status Aura\\Web /path/to/aura-web/src/ /path/to/aura-web/src/Response/Status.php \\Symfony\\Core\\Request Symfony\\Core ./vendor/Symfony/Core/ ./vendor/Symfony/Core/Request.php \\Zend\\Acl Zend /usr/includes/Zend/ /usr/includes/Zend/Acl.php 暂且只介绍这比较常用的三个规范。 更多最新规范建议点击查看 本节主要介绍了PHP的编码规范PSR，建议大家在开发中尽量遵循此规范，特别是团队开发的时候，我们不应该各自有着各自的编码风格，应该尽可能统一风格。正如PHP-FIG组织的初衷所说，他们建立的规范不是限制大家的编码自由，只是寻找共性，为了我们一起更好的协同工作。","tags":["phpframe"],"categories":["phpframe"]},{"title":"Redis使用scan替换keys","path":"/2020/01/26/225/","content":"我们都知道查找Redis的键时，可以使用keys pattern，但当key太多时，keys命令的效率就很低，如果在线上直接使用，甚至可能发生生产事故，这时候，我们不妨使用scan命令。 SCAN 命令是一个基于游标的迭代器（cursor based iterator）： SCAN 命令每次被调用之后， 都会向用户返回一个新的游标， 用户在下次迭代时需要使用这个新游标作为 SCAN 命令的游标参数， 以此来延续之前的迭代过程。当 SCAN 命令的游标参数被设置为 0 时， 服务器将开始一次新的迭代， 而当服务器向用户返回值为 0 的游标时， 表示迭代已结束。 生成key&lt;?php// 生成1000个$Redis = new \\Redis();$Redis-&gt;connect(&#x27;127.0.0.1&#x27;, 6379, 10);$Redis-&gt;select(2);$arr = [ &#x27;rwer&#x27;, &#x27;24erw&#x27;, &#x27;rterq4&#x27;, &#x27;sdgfd5&#x27;, &#x27;dgsdg&#x27;, &#x27;sfst&#x27;,];for ($i=0; $i&lt;1000; $i++) &#123; $Redis-&gt;set(md5($i.$arr[$i%6]), md5($arr[$i%6].&#x27;sdfsd&#x27;));&#125;echo &quot;OK&quot;.PHP_EOL; keys查看个数keys c* scan遍历&lt;?php$Redis = new \\Redis();$Redis-&gt;connect(&#x27;127.0.0.1&#x27;, 6379, 10);$Redis-&gt;select(2);$iterator = null;// 遍历前缀$pattern = &#x27;c*&#x27;;$count = 100;// 务必设置，如果没扫描到，继续扫描，而不是返回空，否则while直接退出，遍历就会不准确$Redis-&gt;setOption(\\Redis::OPT_SCAN, \\Redis::SCAN_RETRY);$total = [];$i = 0;// $count可以不设置，非必需参数while($arr = $Redis-&gt;scan($iterator, $pattern, $count)) &#123; $arrVal = $Redis-&gt;mget($arr); $ret = array_combine($arr, $arrVal); $total = array_merge($total, $ret); $i++;&#125;// var_dump($total);var_dump($i);echo count($total).PHP_EOL; 当然你也可以不使用\\Redis::OPT_SCAN, \\Redis::SCAN_RETRY这两个参数，自行循环，判断返回值是不是false，也能遍历成功。","tags":["Redis"],"categories":["Redis"]},{"title":"2019,这一年","path":"/2020/01/24/2019/","content":"大家，过年好啊！ 一直想写来着，被留到了最后，辞年回来，时间尚早，来说说这一年吧！ 工作与学习工作上能说的似乎不是太多。三月份跳槽，来到一家游戏公司，相比之前待过的创业型公司，感觉有点不一样。 工作没有那么重，有更多的时间去学习去思考，并能应用到工作中，这些都是我非常满意的。相对的，也感觉到自己的不足，增加突破性是来年工作的重点之一。 工作之余的学习，走了一些弯路，从java到go，再到swoole，再又到go，最后到基础知识，没有完整地去深入探索，而是因为跳来跳去，浪费了一些时间。 比较满意自己写了两个技术小专栏，关于Nginx和PHP的，这也算是业余输出吧！（有兴趣的可以点击菜单查看） 平时做业务的比较多，容易陷于重复劳动的误区，试着阶段性总结，减少重复劳动，并试图引入新的技术，倒是也算忙得不亦乐乎，自我成长还是满意的，即便学习似乎与年初计划不太相符。建议程序员朋友，经常能输出笔记博客，归档起来，方便自己，也方便分享他人。 2020，不想去规划太多，更多的是深入与基础的巩固吧，也在工作中寻找一些突破，有余力再去拓展自己的技术栈。 万事皆变，工作与学习的相辅相成不变。 生活体重变化的不多，生活其实变化的很多。相比之前，可能过得更粗糙了点，抛弃了一些东西，但也更加懂得了责任的意义。有时候对生活上会有一丝无力感，没有以前那么理想化了，会去想很多事，似乎也会刻意去逃避一些东西，但一直保有对美好未来的憧憬与希望。 不知道怎么地，下半年突发过敏，不知道是治疗不当还是自己没有正视，最终引发全身湿疹，折磨了自己三个月。时间久了，反倒心态越来越平和了，即便现在还没好，但我不为这个发愁了。也许，身体只是提醒我早睡早起，注意饮食与个人卫生。 很开心的事是遇见了一个姑娘，主观客观地变化了很多，潜移默化的，很幸运，感谢（此处略过2020字）～ 新年计划 确定人生大事 增加自己的软实力（不止于技术） 减轻3kg体重，瘦瘦肚子 注意饮食，早睡早起 最后祝各位新年快乐，身体健康，远离疾病，2020开心快乐！ 2020/01/24己亥除夕记at 安庆岳西","tags":["oneyear"],"categories":["oneyear"]},{"title":"Laravel配合JWT","path":"/2020/01/20/224/","content":"测试使用的是Laravel5.5版本。 安装composer require tymon/jwt-auth=1.0.0-rc.5 配置生成配置php artisan vendor:publish --provider=&quot;Tymon\\JWTAuth\\Providers\\LaravelServiceProvider&quot;php artisan jwt:secret auth配置&lt;?phpreturn [\t... &#x27;defaults&#x27; =&gt; [ &#x27;guard&#x27; =&gt; &#x27;web&#x27;, &#x27;passwords&#x27; =&gt; &#x27;users&#x27;, ], &#x27;guards&#x27; =&gt; [ &#x27;web&#x27; =&gt; [ &#x27;driver&#x27; =&gt; &#x27;session&#x27;, &#x27;provider&#x27; =&gt; &#x27;users&#x27;, ], // 使用jwt &#x27;api&#x27; =&gt; [ &#x27;driver&#x27; =&gt; &#x27;jwt&#x27;, &#x27;provider&#x27; =&gt; &#x27;apiUser&#x27;, ], ], &#x27;providers&#x27; =&gt; [ ... // 指定model &#x27;apiUser&#x27; =&gt; [ &#x27;driver&#x27; =&gt; &#x27;eloquent&#x27;, &#x27;model&#x27; =&gt; App\\ApiUser::class, ], ],]; 编码控制器： &lt;?phpnamespace App\\Http\\Controllers\\Api;use App\\ApiUser;use App\\Http\\Controllers\\Controller;use Illuminate\\Http\\Request;use Tymon\\JWTAuth\\Facades\\JWTAuth;class AuthController extends Controller&#123; /** * 中间件去除login和refresh * * @return void */ public function __construct() &#123; $this-&gt;middleware(&#x27;auth:api&#x27;, [&#x27;except&#x27; =&gt; [&#x27;login&#x27;,&#x27;refresh&#x27;]]); &#125; /** * Get a JWT via given credentials. * * @return \\Illuminate\\Http\\JsonResponse */ public function login(Request $request) &#123; $credentials = $request-&gt;only(&#x27;phone&#x27;, &#x27;password&#x27;); if (count($credentials) &lt; 2) &#123; return response()-&gt;json([&#x27;error&#x27; =&gt; &#x27;Unauthorized&#x27;], 401); &#125; $user = ApiUser::where(&#x27;phone&#x27;, $credentials[&#x27;phone&#x27;]) -&gt;where(&#x27;password&#x27;, md5($credentials[&#x27;password&#x27;])) -&gt;first(); if (empty($user) || !$token = JWTAuth::fromUser($user)) &#123; return response()-&gt;json([&#x27;error&#x27; =&gt; &#x27;Unauthorized&#x27;], 401); &#125; // dd($token); return $this-&gt;respondWithToken($token); &#125; /** * Get the authenticated User. * * @return \\Illuminate\\Http\\JsonResponse */ public function me() &#123; return response()-&gt;json(auth(&#x27;api&#x27;)-&gt;user()); &#125; /** * Log the user out (Invalidate the token). * * @return \\Illuminate\\Http\\JsonResponse */ public function logout() &#123; auth()-&gt;logout(); return response()-&gt;json([&#x27;message&#x27; =&gt; &#x27;Successfully logged out&#x27;]); &#125; /** * Refresh a token. * * @return \\Illuminate\\Http\\JsonResponse */ public function refresh() &#123; return $this-&gt;respondWithToken(auth(&#x27;api&#x27;)-&gt;refresh()); &#125; /** * Get the token array structure. * * @param string $token * * @return \\Illuminate\\Http\\JsonResponse */ protected function respondWithToken($token) &#123; return response()-&gt;json([ &#x27;access_token&#x27; =&gt; $token, &#x27;token_type&#x27; =&gt; &#x27;bearer&#x27;, &#x27;expires_in&#x27; =&gt; auth(&#x27;api&#x27;)-&gt;factory()-&gt;getTTL() * 60 ]); &#125;&#125; 路由： 此处注意，我为了方便测试，使用了get方法，生产环境不建议使用get。 // routes/api.phpRoute::middleware(&#x27;api&#x27;)-&gt;prefix(&#x27;auth&#x27;)-&gt;namespace(&#x27;Api&#x27;)-&gt;group(function () &#123;\tRoute::get(&#x27;login&#x27;, &#x27;AuthController@login&#x27;);\tRoute::post(&#x27;logout&#x27;, &#x27;AuthController@logout&#x27;);\tRoute::get(&#x27;refresh&#x27;, &#x27;AuthController@refresh&#x27;);\tRoute::get(&#x27;me&#x27;, &#x27;AuthController@me&#x27;);&#125;); 测试一下: unauthenticated处理这里需要注意下，unauthenticated处理一下比较好，否则会默认跳转login登录页面。 &lt;?phpnamespace App\\Exceptions;use Exception;use Illuminate\\Foundation\\Exceptions\\Handler as ExceptionHandler;use Illuminate\\Auth\\AuthenticationException;class Handler extends ExceptionHandler&#123; ... protected function unauthenticated($request, AuthenticationException $exception) &#123; return response()-&gt;json([&#x27;message&#x27; =&gt; &#x27;Unauthenticated.&#x27;], 401); /*非api可以这么处理 return $request-&gt;expectsJson() ? response()-&gt;json([&#x27;message&#x27; =&gt; &#x27;Unauthenticated.&#x27;], 401) : redirect()-&gt;guest(route(&#x27;login&#x27;)); */ &#125;&#125; 加入token refresh加入中间件代码： &lt;?phpnamespace App\\Http\\Middleware; use Closure;use Tymon\\JWTAuth\\Facades\\JWTAuth;use Tymon\\JWTAuth\\Exceptions\\JWTException;use Illuminate\\Auth\\AuthenticationException;use Tymon\\JWTAuth\\Exceptions\\TokenExpiredException;use Illuminate\\Http\\Exceptions\\HttpResponseException;use Tymon\\JWTAuth\\Http\\Middleware\\BaseMiddleware;class RefreshToken extends BaseMiddleware&#123; /** * Handle an incoming request. * * @param \\Illuminate\\Http\\Request $request * @param \\Closure $next * @return mixed */ public function handle($request, Closure $next) &#123; try&#123; //检查请求中是否带有token 如果没有token值则抛出异常 $this-&gt;checkForToken($request); if ($request-&gt;user = JWTAuth::parseToken()-&gt;authenticate()) &#123; return $next($request); &#125; throw new AuthenticationException(&#x27;Unauthorized&#x27;, []); &#125;catch (TokenExpiredException $exception)&#123; //返回特殊的code throw new HttpResponseException(response()-&gt;json([ &#x27;message&#x27; =&gt; &#x27;token expired&#x27; ])); &#125; catch (\\Exception $exception) &#123; throw new AuthenticationException(&#x27;Unauthorized&#x27;, []); &#125; &#125;&#125; 注册： &lt;?phpnamespace App\\Http;use Illuminate\\Foundation\\Http\\Kernel as HttpKernel;class Kernel extends HttpKernel&#123; ... protected $routeMiddleware = [ &#x27;token.refresh&#x27; =&gt; \\App\\Http\\Middleware\\RefreshToken::class, &#x27;auth.basic&#x27; =&gt; \\Illuminate\\Auth\\Middleware\\AuthenticateWithBasicAuth::class, &#x27;bindings&#x27; =&gt; \\Illuminate\\Routing\\Middleware\\SubstituteBindings::class, &#x27;can&#x27; =&gt; \\Illuminate\\Auth\\Middleware\\Authorize::class, &#x27;guest&#x27; =&gt; \\App\\Http\\Middleware\\RedirectIfAuthenticated::class, &#x27;throttle&#x27; =&gt; \\Illuminate\\Routing\\Middleware\\ThrottleRequests::class, ];&#125; 相应的控制器构造函数修改： public function __construct()&#123; $this-&gt;middleware(&#x27;token.refresh&#x27;, [&#x27;except&#x27; =&gt; [&#x27;login&#x27;,&#x27;refresh&#x27;]]);&#125; 把token时间设置成1分钟，测试一下。 可以根据api返回，去调用刷新接口。 简单使用就是这样啦。更多使用可以看下站内其他文章：JWT 完整使用详解jwt-auth文档","tags":["Laravel","jwt"],"categories":["PHP"]},{"title":"Laravel统一错误处理","path":"/2020/01/20/223/","content":"Laravel中的App\\Exceptions\\Handler 类负责记录应用程序触发的所有异常，这在我们开发过程中十分方便，总是try…catch使代码太过繁琐且可读性大大降低，那么怎么使用它处理异常为json呢？ 我们可以新建一个class，用来处理异常返回。 &lt;?php/** * Author: sai * Date: 2020/1/15 * Time: 14:31 */namespace App\\Exceptions;class ApiException extends \\Exception&#123; const ERROR_CODE = 1001; const ERROR_MSG = &#x27;ApiException&#x27;; private $data = []; /** * BusinessException constructor. * * @param string $message * @param string $code * @param array $data */ public function __construct(string $message, string $code, $data = []) &#123; $this-&gt;code = $code ? : self::ERROR_CODE; $this-&gt;message = $message ? : self::ERROR_MSG; $this-&gt;data = $data; &#125; /** * @return array */ public function getData() &#123; return $this-&gt;data; &#125;\t/** * 异常输出 */ public function render($request) &#123; return response()-&gt;json([ &#x27;data&#x27; =&gt; $this-&gt;getData(), &#x27;code&#x27; =&gt; $this-&gt;getCode(), &#x27;messgae&#x27; =&gt; $this-&gt;getMessage(), ], 200); &#125;&#125; 然后我们在Handler加入，加入$dontReport，便不会使用自带的错误处理，而使用自定义的处理。 &lt;?phpnamespace App\\Exceptions;use Exception;use Illuminate\\Foundation\\Exceptions\\Handler as ExceptionHandler;class Handler extends ExceptionHandler&#123; /** * 一些不需管或不需要抛出的异常 */ protected $dontReport = [ ApiException::class, ]; ...&#125; 我们测试一下： &lt;?phpnamespace App\\Http\\Controllers;use App\\Exceptions\\ApiException;use Illuminate\\Http\\Request;class HomeController extends Controller&#123; public function index(Request $request) &#123; throw new ApiException(&#x27;error&#x27;, 10001, [&#x27;oh&#x27; =&gt; &#x27;no&#x27;]); return 1; &#125;&#125; 查看输出： 测试ok，我们可以愉快的使用啦。当然，其他形式的错误输出可以自行扩展。","tags":["Laravel"],"categories":["PHP"]},{"title":"ElementUI整合编辑器vue-quill-editor","path":"/2020/01/08/222/","content":"直接上代码： main.js import VueQuillEditor from &#x27;vue-quill-editor&#x27;import &#x27;quill/dist/quill.core.css&#x27;import &#x27;quill/dist/quill.snow.css&#x27;import &#x27;quill/dist/quill.bubble.css&#x27;Vue.use(VueQuillEditor) template: ...&lt;el-form-item label=&quot;详情&quot; prop=&quot;content&quot;&gt; &lt;quill-editor v-model=&quot;form.remark&quot; ref=&quot;myQuillEditor&quot; :options=&quot;editorOption&quot; @blur=&quot;onEditorBlur($event)&quot; @focus=&quot;onEditorFocus($event)&quot; @change=&quot;onEditorChange($event)&quot;&gt; &lt;/quill-editor&gt;&lt;/el-form-item&gt;&lt;div style=&quot;display:none;&quot;&gt; &lt;el-upload class=&quot;edit-uploader&quot; :action=&quot;uploadPicUrl&quot; :show-file-list=&quot;false&quot; :headers=&quot;header&quot; :on-success=&quot;editorUploadSuccess&quot; :on-error=&quot;editorUploadError&quot; :before-upload=&quot;beforeEditorUpload&quot; &gt; &lt;i class=&quot;el-icon-plus avatar-uploader-icon&quot; ref=&quot;aUpload&quot;&gt;&lt;/i&gt; &lt;/el-upload&gt;&lt;/div&gt;... &lt;script&gt;export default &#123; data() &#123; return &#123; editorOption: &#123; modules: &#123; toolbar: &#123;container:[ [&#x27;bold&#x27;, &#x27;italic&#x27;, &#x27;underline&#x27;, &#x27;strike&#x27;], [&#x27;blockquote&#x27;, &#x27;code-block&#x27;], [&#123; &#x27;header&#x27;: 1 &#125;, &#123; &#x27;header&#x27;: 2 &#125;], [&#123; &#x27;list&#x27;: &#x27;ordered&#x27; &#125;, &#123; &#x27;list&#x27;: &#x27;bullet&#x27; &#125;], [&#123; &#x27;script&#x27;: &#x27;sub&#x27; &#125;, &#123; &#x27;script&#x27;: &#x27;super&#x27; &#125;], [&#123; &#x27;indent&#x27;: &#x27;-1&#x27; &#125;, &#123; &#x27;indent&#x27;: &#x27;+1&#x27; &#125;], [&#123; &#x27;direction&#x27;: &#x27;rtl&#x27; &#125;], [&#123; &#x27;size&#x27;: [&#x27;small&#x27;, false, &#x27;large&#x27;, &#x27;huge&#x27;] &#125;], [&#123; &#x27;header&#x27;: [1, 2, 3, 4, 5, 6, false] &#125;], [&#123; &#x27;font&#x27;: [] &#125;], [&#123; &#x27;color&#x27;: [] &#125;, &#123; &#x27;background&#x27;: [] &#125;], [&#123; &#x27;align&#x27;: [] &#125;], [&#x27;clean&#x27;], [&#x27;link&#x27;, &#x27;image&#x27;] ], handlers: &#123; &#x27;image&#x27;: function(value) &#123; if (value) &#123; document.querySelector(&#x27;.edit-uploader input&#x27;).click() &#125; else &#123; this.quill.format(&#x27;image&#x27;, false); &#125; // this.$refs.aUpload.click() //自定义图片上传回调 &#125; &#125; &#125;, syntax: &#123; highlight: text =&gt; hljs.highlightAuto(text).value &#125; &#125;, &#125; &#125; &#125;, methods: &#123; onEditorReady(editor) &#123; // 准备编辑器 &#125;, onEditorBlur()&#123;&#125;, // 失去焦点事件 onEditorFocus()&#123;&#125;, // 获得焦点事件 onEditorChange()&#123;&#125;, // 内容改变事件 beforeEditorUpload() &#123; // 显示loading动画 this.quillUpdateImg = true &#125;, editorUploadSuccess(res, file) &#123; // 获取富文本组件实例 let quill = this.$refs.myQuillEditor.quill // 如果上传成功 if (res.code === 0) &#123; // 获取光标所在位置 let length = quill.getSelection().index; // 插入图片 res.info为服务器返回的图片地址 quill.insertEmbed(length, &#x27;image&#x27;, res.data.filepath) // 调整光标到最后 quill.setSelection(length + 1) &#125; else &#123; this.$message.error(&#x27;图片插入失败&#x27;) &#125; // loading动画消失 this.quillUpdateImg = false &#125;, // 富文本图片上传失败 editorUploadError() &#123; // loading动画消失 this.quillUpdateImg = false this.$message.error(&#x27;图片插入失败&#x27;) &#125; &#125;&#125;&lt;/script&gt; 这里需要注意的是，编辑器默认使用base64上传，我们使用elementui的上传组件替换掉原来的图片上传。","tags":["ElementUI"],"categories":["vue"]},{"title":"javascript签名直传OSS","path":"/2020/01/08/221/","content":"最近在写后台代码，使用的是VUE+ElementUI，踩了一些坑分享一下。 原理：从服务端获取签名，js直接上传阿里云OSS服务器。 elementui主要代码 template:&lt;el-form-item label=&quot;上传图片&quot; prop=&quot;video&quot;&gt; &lt;el-upload id=&quot;video&quot; action :data=&quot;aliyunOssToken&quot; :http-request=&quot;uploadVideo&quot; :headers=&quot;header&quot;&gt; &lt;img v-if=&quot;form.cover&quot; :src=&quot;form.cover&quot;&gt; &lt;el-button class=&quot;avatar-uploader-icon&quot; type=&quot;primary&quot;&gt;上传&lt;/el-button&gt; &lt;/el-upload&gt;&lt;/el-form-item&gt;script：upload(file)&#123; var _self = this; let imgType = file.file.type.split(&quot;/&quot;)[1].toLowerCase(); if (imgType != &#x27;jpg&#x27; &amp;&amp; imgType != &#x27;png&#x27;) &#123; this.$message.error(&#x27;请上传图片类型&#x27;); return; &#125; getOSSToken().then(function(res)&#123; _self.aliyunOssToken = res.data; var ossData = &#123;&#125;; //key就代表文件层级和阿里云上的文件名 let imgType = file.file.type.split(&quot;/&quot;)[1]; let filename = file.file.name + file.file.size; //md5对图片名称进行加密 let keyValue = &quot;images/&quot; + md5(new Date() + filename) + &quot;.&quot; + imgType; // 组装formdata let formdata = new FormData(); formdata.append(&#x27;name&#x27;, file.file.name) formdata.append(&#x27;key&#x27;, keyValue) formdata.append(&#x27;policy&#x27;, _self.aliyunOssToken.policy) formdata.append(&#x27;OSSAccessKeyId&#x27;, _self.aliyunOssToken.accessid) formdata.append(&#x27;success_action_status&#x27;, 200) formdata.append(&#x27;signature&#x27;, _self.aliyunOssToken.signature) formdata.append(&#x27;file&#x27;, file.file) _self.uploadOSS(formdata, _self.aliyunOssToken.host).then(function(res)&#123; _self.form.cover = _self.aliyunOssToken.host + &#x27;/&#x27; + keyValue; _self.$message.success(&#x27;上传成功&#x27;); &#125;).catch(function(error)&#123; _self.$message.error(&#x27;上传失败&#x27;); console.log(error); &#125;) &#125;).catch(function(error)&#123; console.log(error); &#125;)&#125;,uploadOSS(formData, url) &#123; const config = &#123; headers: &#123; &quot;Content-Type&quot;: &quot;multipart/form-data;boundary=&quot;+new Date().getTime() &#125; &#125;; return axios.post(url,formData,config);&#125; 其中：务必使用表单提交方式，aliyunOssToken格式如下 &#123;\t&quot;accessid&quot;: &quot;LToofXWKudxfoAlI&quot;,\t&quot;host&quot;: &quot;https:\\/\\/xxx.oss-cn-hangzhou.aliyuncs.com&quot;,\t&quot;policy&quot;: &quot;eyJleHBpcmF0eretaW9uIjoiQxODowNzowMFoiLCJjb25kaXRpb25zIjpbWyJjb250ZW50LWxlbmd0aC17ewreMDQ4NTc2MDAwXSxbInN0YXJ0cy13aXRoIiwiJGtleSIsInZpZGVvXC8iXV19&quot;,\t&quot;signature&quot;: &quot;HRFJ4345VIvRhrsMa44546=&quot;,\t&quot;expire&quot;: 1578478020,\t&quot;dir&quot;: &quot;images\\/&quot;&#125; 记得设置阿里云OSS跨域规则： 文档： javascript签名直传","tags":["js"],"categories":["web"]},{"title":"wrk压测使用","path":"/2019/12/30/220/","content":"最近有需要做一些压力测试，之前一直用ab，用起来不是很舒服，最近有使用wrk，轻量好用。 安装git clone https://github.com/wg/wrk.git wrkcd wrkmake# move the executable to somewhere in your PATHsudo cp wrk /somewhere/in/your/PATH 默认情况下wrk会使用自带的LuaJIT和OpenSSL，如果你想使用系统已安装的版本，可以使用WITH_LUAJIT和WITH_OPENSSL这两个选项来指定它们的路径。比如： make WITH_LUAJIT=/usr WITH_OPENSSL=/usr 使用说明wrk &lt;选项&gt; &lt;被测HTTP服务的URL&gt; Options: -c, --connections &lt;N&gt; 跟服务器建立并保持的TCP连接数量 -d, --duration &lt;T&gt; 压测时间 -t, --threads &lt;N&gt; 使用多少个线程进行压测 -s, --script &lt;S&gt; 指定Lua脚本路径 -H, --header &lt;H&gt; 为每一个HTTP请求添加HTTP头 --latency 在压测结束后，打印延迟统计信息 --timeout &lt;T&gt; 超时时间 -v, --version 打印正在使用的wrk的详细版本信息 &lt;N&gt;代表数字参数，支持国际单位 (1k, 1M, 1G) &lt;T&gt;代表时间参数，支持时间单位 (2s, 2m, 2h) 测试wrk -t8 -c200 -d30s --latency &quot;http://www.bing.com&quot;输出：Running 30s test @ http://www.bing.com 8 threads and 200 connections Thread Stats Avg Stdev Max +/- Stdev Latency 46.67ms 215.38ms 1.67s 95.59% Req/Sec 7.91k 1.15k 10.26k 70.77% Latency Distribution 50% 2.93ms 75% 3.78ms 90% 4.73ms 99% 1.35s 1790465 requests in 30.01s, 684.08MB readRequests/sec: 59658.29Running 30s test @ http://www.bing.com （压测时间30s） 8 threads and 200 connections （共8个测试线程，200个连接） Thread Stats Avg Stdev Max +/- Stdev （平均值） （标准差）（最大值）（正负一个标准差所占比例） Latency 46.67ms 215.38ms 1.67s 95.59% （延迟） Req/Sec 7.91k 1.15k 10.26k 70.77% （处理中的请求数） Latency Distribution （延迟分布） 50% 2.93ms 75% 3.78ms 90% 4.73ms 99% 1.35s （99分位的延迟） 1790465 requests in 30.01s, 684.08MB read （30.01秒内共处理完成了1790465个请求，读取了684.08MB数据）Requests/sec: 59658.29 （平均每秒处理完成59658.29个请求）Transfer/sec: 22.79MB （平均每秒读取数据22.79MB） lua脚本使用--data.lualocal data= &quot;&#123;.count.:1&#125;&quot;wrk.headers[&quot;Content-Type&quot;] = &quot;application/jason&quot;wrk.method = &quot;POST&quot;function request()\treturn wrk.format(&#x27;POST&#x27;, nil, nil, data)end 测试： wrk -t500 -c1000 -d1s --script=data.lua --latency https://github.oscome.cn/ 个人用了几次，感觉比ab好用，推荐一下。 参考：Http压测工具wrk使用指南wrk","tags":["wrk"],"categories":["test"]},{"title":"gomodules","path":"/2019/12/27/219/","content":"Modules 是 Go 管理依赖关系的工具，在 1.11 版本中加入，并在 1.13中对模块进行了重大改进和更改。相比前面的 dep，vendor，glide 等包管理方案，更易于上手。如果你现在开始一个 go 项目，最好了解一下。 Modules 的使用非常简单，我们不妨尝试一下： 开启（1.13版本及以后无需这一步)1.13版本前请需手动开启模块（1.13 版本开始已经是默认模式） export GO111MODULE=auto 初始化进入项目目录，执行以下命令： go mod init github.com/puresai/gomodules output: go: creating new go.mod: module github.com/puresai/gomodules 可以看到会生成go.mod，文件内容如下【go 1.19表示当前版本】 module github.com/puresai/gomodulesgo 1.19 使用 go get每次 go get 后，modules也会将你的安装的package加入go.mod go get github.com/puresai/gohelper module github.com/puresai/gomodulesgo 1.19require github.com/puresai/gohelper v0.0.1 // indirect 当然，如果你没有翻墙，也没有使用国内镜像，很多包可能都下载失败。可以参考https://goproxy.cn/设置。 本地文件夹相互调用新建 pkg 目录，新建 str.go package pkgimport &quot;github.com/puresai/gohelper/str&quot;func MD(s string) string &#123;\treturn str.Md5(s)&#125; 简单写一下 main.go package mainimport &quot;github.com/puresai/gomodules/pkg&quot; // 引入刚刚新建的 pkgfunc main() &#123;\tprint(pkg.MD(&quot;puresai&quot;))&#125; 然后执行： go run main.gopkg/str.go:3:8: no required module provides package github.com/puresai/gohelper/str; to add it: go get github.com/puresai/gohelper/str 这里可以执行根据提示执行 go get github.com/puresai/gohelper/str 或者可以使用 go mod tidy 这个命令可以拉取缺少的 package，移除不用的 package。 这个命令很有用，我习惯每次完成一个阶段代码都执行一次，可以去除很多冗余的 package。 其他命令go mod download//下载依赖包到本地缓存go mod graph //打印现有依赖结构go mod verify //校验依赖go mod why //解释为什么需要此模块go mod vendor //下载依赖的package到本地vendor目录，学习中可使用 相关代码可参考:https://github.com/puresai/blog-code/tree/master/gomodules 参考 Modules的wiki","tags":["go"],"categories":["go"]},{"title":"Nginx负载均衡","path":"/2019/12/21/Nginx2/","content":"负载均衡策略1.轮询(默认)：每一个来自网络中的请求，轮流分配给内部的服务器，从1到N然后重新开始。此种负载均衡算法适合服务器组内部的服务器都具有相同的配置并且平均服务请求 相对均衡的情况。2.加权轮询（weight）：根据服务器的不同处理能力，给每个服务器分配不同的权值，使其能够接受相应权值数的服务请求。例如:服务器A的权值被设计成1，B的权值是3，C的权值是6，则服务器A、B、C将分别接受到10%、30%、60%的服务请求。此种均衡算法能确保高性能的服务器得到更多的使用率，避免低性能的服务器负载过重。3.ip-hash（ip_hash）：nginx将会根据相应的hash函数，对每个请求的ip作为关键字，得到的hash值将会决定将请求分发给相应Server进行处理。4.最少连接数（least_conn）：nginx会判断后端集群服务器中哪个Server当前的 Active Connection 数是最少的，对于每个新进来的请求，nginx将该其分发给对应的Server。 语法语法: upstream name &#123; ... &#125; 默认值: —上下文: httpupstream 指令当中包含server指令语法: server address [parameters]; 上下文: upstream demo: upstream backend &#123; server backend1.example.com:8081 weight=4 max_fails=2 fail_timeout=30s; server backend2.example.com:8080 weight=1;&#125;server &#123; location / &#123; proxy_pass http://backend; &#125;&#125; 参数说明: weight=number 设定服务器的权重，默认是1，权重越大被访问机会越大，可以根据机器的配置情况来配置。 max_fails=number 设定Nginx与服务器通信的尝试失败的次数。在fail_timeout参数定义的时间段内，如果失败的次数达到此值，Nginx就认为服务器不 可用。在下一个fail_timeout时间段，服务器不会再被尝试。 失败的尝试次数默认是1。默认配置时，http_404状态不被认为是失败的尝试。 可以通过指令proxy_next_upstream 和 memcached_next_upstream 来配置什么是失败的尝试。 fail_timeout=time,统计失败尝试次数的时间段。在这段时间中，服务器失败次数达到指定的尝试次数，服务器就被认为不可用。默认情况下，该超时时间是10秒。 backup,标记为备用服务器。当主服务器不可用以后，请求会被传给这些服务器，配置这个指令可以实现故障转移。 down,标记服务器永久不可用，可以跟ip_hash指令一起使用。 proxy_next_upstream 指令在nginx的配置文件中， proxy_next_upstream 项定义了什么情况下进行重试 语法: proxy_next_upstream error | timeout | invalid_header | http_500 | http_502 | http_503 | http_504 | http_403 | http_404 | http_429 | non_idempotent | off ...; 默认值: proxy_next_upstream error timeout;上下文: http, server, location 参数说明: error 表示和后端服务器建立连接时，或者向后端服务器发送请求时，或者从后端服务器接收响应头时，出现错误。 timeout 表示和后端服务器建立连接时，或者向后端服务器发送请求时，或者从后端服务器接收响应头时，出现超时。 invalid_header 表示后端服务器返回空响应或者非法响应头 http_500 表示后端服务器返回的响应状态码为500 non_idempotent 通常，如果请求已发送到上游服务器，则具有非等幂方法（POST、LOCK、PATCH）的请求不会传递到下一个服务器；启用此选项可显式允许重试此类请求； off 表示停止将请求发送给下一台后端服务器 PS: non_idempotent参数，proxy_next_upstream配置默认转发get请求，但对于post等请求并无效果，建议配置这一项。 相关 proxy_next_upstream_tries:设置重试次数，默认0表示不限制，注意此重试次数指的是所有请求次数(包括第一次和之后的重试次数之和)。 proxy_next_upstream_timeout: 设置重试最大超时时间，默认0表示不限制。即在 proxy_next_upstream_timeout 时间内允许 proxy_next_upstream_tries 次重试。如果超过了其中一个设置，则 Nginx 也会结束重试并返回客户端响应(可能是错误码)。 proxy_send_timeout:后端服务器数据回传时间(代理发送超时时间) proxy_read_timeout:连接成功后，后端服务器响应时间(代理接收超时时间) proxy_connect_timeout:nginx连接后端的超时时间，一般不超过75s demo: location / &#123; proxy_pass http://app-proxy; proxy_next_upstream error timeout http_500 http_502 http_503 http_504; proxy_next_upstream_tries 3; proxy_connect_timeout 60s; proxy_read_timeout 60s; proxy_send_timeout 60s; proxy_pass_request_headers on; proxy_set_header Host $host:$server_port; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;&#125; 建议自己动手使用这些参数，试验一下，加深印象和理解。","tags":["Nginx"],"categories":["Nginx"]},{"title":"Nginx工作模式和进程模型","path":"/2019/12/20/Nginx3/","content":"工作模式 Nginx启动后，会产生一个master主进程，主进程执行一系列的工作后会产生一个或者多个工作进程worker 在客户端请求动态站点的过程中，Nginx服务器还涉及和后端服务器的通信。Nginx将接收到的Web请求通过代理转发到后端服务器，由后端服务器进行数据处理和组织; Nginx为了提高对请求的响应效率，降低网络压力，采用了缓存机制，将历史应答数据缓存到本地。保障对缓存文件的快速访问 进程模型nginx的进程模型，可以由下图来表示： master进程主要用来管理 worker 进程，master进程会接收来自外界发来的信号，再根据信号做不同的事情。所以我们要控制nginx，只需要通过kill向master进程发送信号就行了。 具体包括以下主要功能: 接收来自外界的信号 向各worker进程发送信号 监控worker进程的运行状态，当worker进程退出后(异常情况下)，会自动重新启动新的worker进程 重启说明（示例）比如kill -HUP pid，则是告诉nginx，重启nginx，早期版本可以用这个信号来重启nginx，因为是从容地重启，因此服务是不中断的。（现在一般使用nginx -s reload） master进程在接收到HUP信号后，会先重新加载配置文件，然后再启动新的worker进程，并向所有老的worker进程发送信号，告诉他们可以光荣退休了。新的worker在启动后，就开始接收新的请求，而老的worker在收到来自master的信号后，就不再接收新的请求，并且在当前进程中的所有未处理完的请求处理完成后，再退出。 （master不需要处理网络事件，不负责业务的执行） worker进程主要任务是完成具体的任务逻辑。其主要关注点是与客户端或后端真实服务器(此时 worker 作为中间代理)之间的数据可读/可写等I/O交互事件。具体包括以下主要功能: 接收客户端请求; 将请求一次送入各个功能模块进行过滤处理; 与后端服务器通信，接收后端服务器处理结果; 数据缓存proxy_cache模块 响应客户端请求 （一个请求，完全由worker进程来处理，而且只在一个worker进程中处理。） worker进程是如何处理请求的？首先，worker进程之间是平等的，每个worker进程都是从master进程fork过来，在master进程里面，先建立好需要listen的socket（listenfd）之后，然后再fork出多个worker进程。每个worker进程，处理请求的机会也是一样的。当一个连接请求过来，每个进程都有可能处理这个连接，怎么做的呢？ 所有worker进程的listenfd会在新连接到来时变得可读，为保证只有一个进程处理该连接，所有worker进程在注册listenfd读事件前抢accept_mutex，抢到互斥锁的那个worker进程注册listenfd读事件，在读事件里调用accept接受该连接。 当一个worker进程在accept这个连接之后，就开始读取请求，解析请求，处理请求，产生数据后，再返回给客户端，最后断开连接，这样就是一个完整的请求就是这样的了。 我们可以了解到一个请求，完全由worker进程来处理，且只在一个worker进程中处理。 Nginx采用的IO多路复用模型 IO多路复用是指内核一旦发现进程指定的一个或者多个IO条件准备读取，它就通知该进程，目前支持I/O多路复用的系统调用有 select ， poll ， epoll ，I/O多路复用就是通过一种机制，一个进程可以监视多个描述符(socket)，一旦某个描述符就绪(一般是读就绪或者写就绪)，能够通知程序进行相应的读 写操作。 select基本原理select 函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds。调用后select函数会阻塞，直到有描述符就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以通过遍历fdset，来找到就绪的描述符。 优点 目前几乎在所有的平台上支持 缺点 select本质上是通过设置或者检查存放fd标志位的数据结构来进行下一步处理。这样所带来的缺点是： select最大的缺陷就是单个进程所打开的FD是有一定限制的，它由FD_SETSIZE设置，默认值是1024。（一般来说这个数目和系统内存关系很大，具体数目可以cat /proc/sys/fs/file-max查看。32位机默认是1024个。64位机默认是2048） 对socket进行扫描时是线性扫描，即采用轮询的方法，效率较低。（当套接字比较多的时候，每次select()都要通过遍历FD_SETSIZE个Socket来完成调度，不管哪个Socket是活跃的，都遍历一遍。这会浪费很多CPU时间。如果能给套接字注册某个回调函数，当他们活跃时，自动完成相关操作，那就避免了轮询，这正是epoll与kqueue做的） 需要维护一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大。 poll基本原理poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历完所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历fd。这个过程经历了多次无谓的遍历。 优点 它没有最大连接数的限制，原因是它是基于链表来存储的。 缺点 大量的fd的数组被整体复制于用户态和内核地址空间之间，而不管这样的复制是不是有意义。 poll还有一个特点是“水平触发”，如果报告了fd后，没有被处理，那么下次poll时会再次报告该fd。 注意：从上面看，select和poll都需要在返回后，通过遍历文件描述符来获取已经就绪的socket。事实上，同时连接的大量客户端在一时刻可能只有很少的处于就绪状态，因此随着监视的描述符数量的增长，其效率也会线性下降。 epollepoll是在2.6内核中提出的，是之前的select和poll的增强版本。相对于select和poll来说，epoll更加灵活，没有描述符限制。epoll使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次。 基本原理epoll支持水平触发和边缘触发，最大的特点在于边缘触发，它只告诉进程哪些fd刚刚变为就绪态，并且只会通知一次。还有一个特点是，epoll使用“事件”的就绪通知方式，通过epoll_ctl注册fd，一旦该fd就绪，内核就会采用类似callback的回调机制来激活该fd，epoll_wait便可以收到通知。 epoll对文件描述符的操作有两种模式LT（level trigger）和ET（edge trigger）。LT模式是默认模式，两者区别如下： LT模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用epoll_wait时，会再次响应应用程序并通知此事件。 ET模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。 优点 没有最大并发连接的限制，能打开的FD的上限远大于1024（1G的内存上能监听约10万个端口）。 效率提升，不是轮询的方式，不会随着FD数目的增加效率下降。 只有活跃可用的FD才会调用callback函数；即Epoll最大的优点就在于它只管你“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中，Epoll的效率就会远远高于select和poll。 内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递；即epoll使用mmap减少复制开销。 kqueuekqueue与epoll非常相似，最初是2000年Jonathan Lemon在FreeBSD系统上开发的一个高性能的事件通知接口。注册一批socket描述符到 kqueue 以后，当其中的描述符状态发生变化时，kqueue 将一次性通知应用程序哪些描述符可读、可写或出错了。只是适应平台不多。 参考： 网络通信 –&gt; IO多路复用之select、poll、epoll详解 nginx平台初探 这应该是Nginx系列最后一篇文章了，如果你有疑问，欢迎交流，水平有限，错误欢迎指正。 技术文章也发布在自己的公众号【爱好历史的程序员】，欢迎扫码关注，谢谢！","tags":["Nginx"],"categories":["Nginx"]},{"title":"gRPC初体验","path":"/2019/12/20/215/","content":"gRPC是可以在任何环境中运行的现代开源高性能RPC框架。它可以通过可插拔的支持来有效地连接数据中心内和跨数据中心的服务，以实现负载平衡，跟踪，运行状况检查和身份验证。它也适用于分布式计算的最后一英里，以将设备，移动应用程序和浏览器连接到后端服务。 安装protocol buffer 编译器mac： brew install protobuf 其他系统可以尝试编译安装 protocolbuffers/protobuf 安装gprcgo get -u google.golang.org/grpc 安装protoc-gen-go插件go get -u github.com/golang/protobuf/protoc-gen-go 使用新建hello目录，进入后执行： protoc --proto_path hello/ --go_out=plugins=grpc:hello hello.proto 会看到hello目录下生成了hello.pb.go文件。 当然，其中的 hello.proto 是预先自定义在hello文件夹下的，如： syntax = &quot;proto3&quot;; //语法声明package hello; //包名// 定义服务service Greeter &#123; rpc SayHello (HelloRequest) returns (HelloReply) &#123;&#125;&#125;// 请求数据格式message HelloRequest &#123; string name = 1;&#125;// 响应数据格式message HelloReply &#123; string message = 1;&#125; server新建server目录，golang例子代码来自：https://github.com/grpc/grpc-go/tree/master/examples/helloworld // main.gopackage mainimport (\t&quot;context&quot;\t&quot;log&quot;\t&quot;net&quot;\t&quot;google.golang.org/grpc&quot;\tpb &quot;local.com/sai/game/grpc/hello&quot;)const (\tport = &quot;:50051&quot;)// server is used to implement helloworld.GreeterServer.type server struct &#123;\tpb.UnimplementedGreeterServer&#125;// SayHello implements helloworld.GreeterServerfunc (s *server) SayHello(ctx context.Context, in *pb.HelloRequest) (*pb.HelloReply, error) &#123;\tlog.Printf(&quot;Received: %v&quot;, in.GetName())\treturn &amp;pb.HelloReply&#123;Message: &quot;Hello &quot; + in.GetName()&#125;, nil&#125;func main() &#123;\tlis, err := net.Listen(&quot;tcp&quot;, port)\tif err != nil &#123; log.Fatalf(&quot;failed to listen: %v&quot;, err)\t&#125;\ts := grpc.NewServer()\tpb.RegisterGreeterServer(s, &amp;server&#123;&#125;)\tif err := s.Serve(lis); err != nil &#123; log.Fatalf(&quot;failed to serve: %v&quot;, err)\t&#125;&#125; clientgo client// client.gopackage mainimport (\t&quot;context&quot;\t&quot;log&quot;\t&quot;os&quot;\t&quot;time&quot;\t&quot;google.golang.org/grpc&quot;\tpb &quot;local.com/sai/game/grpc/hello&quot;)const (\taddress = &quot;127.0.0.1:50051&quot;\tdefaultName = &quot;puresai&quot;)func main() &#123;\t// Set up a connection to the server.\tconn, err := grpc.Dial(address, grpc.WithInsecure(), grpc.WithBlock())\tif err != nil &#123; log.Fatalf(&quot;did not connect: %v&quot;, err)\t&#125;\tdefer conn.Close()\tc := pb.NewGreeterClient(conn)\t// Contact the server and print out its response.\tname := defaultName\tif len(os.Args) &gt; 1 &#123; name = os.Args[1]\t&#125;\tctx, cancel := context.WithTimeout(context.Background(), time.Second)\tdefer cancel()\tr, err := c.SayHello(ctx, &amp;pb.HelloRequest&#123;Name: name&#125;)\tif err != nil &#123; log.Fatalf(&quot;could not greet: %v&quot;, err)\t&#125;\tlog.Printf(&quot;Greeting: %s&quot;, r.GetMessage())&#125;` php client扩展安装 grpc扩展下载 profo 下载安装合适版本的扩展即可，记得别忘记在php.ini中加入： extension=grpc.soextension=protobuf.so 自动生成代码protoc --php_out=client hello/hello.proto 会看到client目录下生成了GPBMetadata和Hello两个目录。 如果你对grpc相对较熟练，可以直接进行代码编写： &lt;?phprequire __DIR__ . &#x27;/vendor/autoload.php&#x27;;class Client extends \\Grpc\\BaseStub&#123; public function __construct($hostname, $opts, $channel = null) &#123; parent::__construct($hostname, $opts, $channel); &#125; /** * rpc SayHello(HelloRequest) returns (HelloReply) &#123;&#125; * 方法名尽量和 (gprc 定义 Greeter 服务)的方法一样 * 用于请求和响应该服务 */ public function SayHello(\\Hello\\HelloRequest $argument)&#123; // (/hello.Greeter/SayHello) 是请求服务端那个服务和方法，基本和 proto 文件定义一样 return $this-&gt;_simpleRequest(&#x27;/hello.Greeter/SayHello&#x27;, $argument, [&#x27;\\Hello\\HelloReply&#x27;, &#x27;decode&#x27;] ); &#125;&#125;//用于连接 服务端$client = new \\Client(&#x27;127.0.0.1:50051&#x27;, [ &#x27;credentials&#x27; =&gt; Grpc\\ChannelCredentials::createInsecure()]);//实例化 TestRequest 请求类$request = new \\Hello\\HelloRequest();$request-&gt;setName(&quot;fairy&quot;);//调用远程服务$get = $client-&gt;SayHello($request)-&gt;wait();//返回数组//$reply 是 TestReply 对象//$status 是数组list($reply, $status) = $get;echo $reply-&gt;getMessage().PHP_EOL;// print_r($client-&gt;SayHello($request)); 当然，也可以使用grpc_php_plugin插件生成。 grpc-php grpc_php_plugin插件clone太慢可以使用码云 git clone -b $(curl -L https://grpc.io/release) https://github.com/grpc/grpccd grpc#这一步很慢，暂未找到什么好方法git submodule update --initmake grpc_php_plugin 新建php-client，再来自动生成： protoc -I=./hello hello.proto --php_out=./php-client/ --grpc_out=php-client/ --plugin=protoc-gen-grpc=/Users/wangzetao/www/grpc1/bins/opt/grpc_php_plugin 会发现比上面自动生成多了一个GreeterClient.php &lt;?php// client.phprequire __DIR__ . &#x27;/vendor/autoload.php&#x27;;//用于连接 服务端$client = new \\Hello\\GreeterClient(&#x27;127.0.0.1:50051&#x27;, [ &#x27;credentials&#x27; =&gt; Grpc\\ChannelCredentials::createInsecure()]);//实例化 TestRequest 请求类$request = new \\Hello\\HelloRequest();$request-&gt;setName(&quot;world&quot;);//调用远程服务$get = $client-&gt;SayHello($request)-&gt;wait();//返回数组//$status 是数组list($reply, $status) = $get;echo $reply-&gt;getMessage().PHP_EOL;// print_r($client-&gt;SayHello($request)); 运行测试 go run grpc/server/main.go go run grpc/client/main.go go run grpc/client/client.php go run grpc/client/php-client.php grpc初体验完成了，本次只是小小的使用了一下子，后续感兴趣的话可以深入学习一下。文中如有错误，欢迎指出交流。 技术文章也发布在自己的公众号【爱好历史的程序员】，欢迎扫码关注，谢谢！","tags":["gRPC"],"categories":["go"]},{"title":"docker安装gogs","path":"/2019/12/08/214/","content":"docker pull gogs/gogs docker run -itd –name=gogs1 -p 10022:22 -p 10023:3000 gogs/gogs 浏览器输入http://127.0.0.1:10023/ 主要修改的参数是 应用 URL 数据库用户密码 管理员信息 如果你有其他修改，自行修改即可。 点击立即安装按钮，按理说会跳到3000端口地址，你换成10023就好了。 然后你就可以自行创建，开始gogs之旅了。 另外，配置文件在容器的/data/gogs/conf/app.ini。 详细配置文件手册（来自github）概览 名称 描述 APP_NAME 应用名称，可以改成您的组织或公司名称 RUN_USER 运行应用的用户名称，我们建议您使用 git，但如果您在个人计算机上运行 Gogs，请修改为您的系统用户名称。如果没有正确设置这个值，很可能导致您的应用崩溃 RUN_MODE 鉴于性能和其它考虑，建议在部署环境下修改为 prod 模式。在您完成安装操作时，该值也会被设置为 prod 服务器 (server) 名称 描述 PROTOCOL http 或 https DOMAIN 服务器域名 ROOT_URL 公开的完整 URL 路径 HTTP_ADDR 应用 HTTP 监听地址 HTTP_PORT 应用 HTTP 监听端口号 UNIX_SOCKET_PERMISSION Unix 套接字文件的权限 LOCAL_ROOT_URL 用于 Gogs 工作进程（如：SSH）回访应用的本地（DMZ）URL，一般情况下请保持默认值，除非您的 SSH 服务器节点与 HTTP 并不是同一个节点入口 DISABLE_SSH 当 SSH 功能不可用时可以禁用 START_SSH_SERVER 启用该选项来启动内置 SSH 服务器 SSH_DOMAIN 允许公用网络访问 SSH 的域名 SSH_PORT SSH 端口号，如果不为 22 的话可以在此修改 SSH_LISTEN_HOST 内置 SSH 服务器监听的地址 SSH_LISTEN_PORT 内置 SSH 服务器监听的端口 SSH_ROOT_PATH SSH 根目录，一般为 ~/.ssh，但必须填写为 /home/git/.ssh REWRITE_AUTHORIZED_KEYS_AT_START 激活该选项以在应用启动时自动重写 authorized_keys 文件，该选项在使用内置 SSH 服务器时将会被自动禁用 SSH_KEY_TEST_PATH 用于测试 SSH 公钥的临时目录 SSH_KEYGEN_PATH ssh-keygen 程序的路径，默认为 ssh-keygen 即通过系统路径查找 MINIMUM_KEY_SIZE_CHECK 指定不同类型的公钥的最小密钥大小 OFFLINE_MODE 激活该选项来禁止从 CDN 获取静态资源，同时 Gravatar 服务也将被自动禁用 DISABLE_ROUTER_LOG 激活该选项来禁止打印路由日志 CERT_FILE HTTPS 授权文件路径 KEY_FILE HTTPS 的密钥文件路径 STATIC_ROOT_PATH 模板文件和静态文件的上级目录，默认为应用二进制所在的位置 APP_DATA_PATH 应用内部数据的存放目录 ENABLE_GZIP 激活该选项来启用应用级别 GZIP 支持 LANDING_PAGE 未登录用户的默认首页，可以是 home 或 explore（探索页） 仓库 (repository) 名称 描述 ROOT 用户仓库存储根目录，必须为绝对路径，默认为 ~/&lt;user name&gt;/gogs-repositories SCRIPT_TYPE 系统脚本类型，一般情况下均为 bash，但有些用户反应只能使用 sh ANSI_CHARSET 当遇到无法识别的字符集时使用的默认字符集 FORCE_PRIVATE 强制要求所有新建的仓库都是私有的 MAX_CREATION_LIMIT 全局默认的每个用户可创建创建仓库上限，-1 表示无限制 PREFERRED_LICENSES 建议用户首选的授权类型 DISABLE_HTTP_GIT 激活该选项来禁止用户通过 HTTP 对 Git 仓库进行交互操作，即用户只能通过 SSH 操作 ENABLE_LOCAL_PATH_MIGRATION 激活该选项来启用本地路径迁移仓库功能。启动后默认只有管理员可以使用，普通用户必须经由管理员授权 ENABLE_RAW_FILE_RENDER_MODE 激活该选项来启用在查看原始数据时对页面进行真实渲染，例如渲染实际的 HTML 页面，有潜在安全隐患 仓库 - 编辑器 (repository.editor) 名称 描述 LINE_WRAP_EXTENSIONS 需要显示为行包装的文件名后缀，通过逗号分隔。如果是无后缀名的文件，则单独放置一个逗号，例如：.txt, 仓库 - 文件上传 (repository.upload) 名称 描述 ENABLED 激活该选项来启用仓库文件上传功能 TEMP_PATH 文件上传的临时存放目录 ALLOWED_TYPES 允许上传的文件类型（例如：”image/jpeg|image/png”），留空表示允许上传任意类型的文件 FILE_MAX_SIZE 单个上传的文件的最大体积，以 MB 为单位 MAX_FILES 单次同时上传的最多文件个数 版本发布 - 附件 (release.attachment) 名称 描述 ENABLED 激活该选项来启用版本发布附件功能 PATH 存放附件的路径 ALLOWED_TYPES 允许上传的 MIME 类型，例如 “image/jpeg|image/png”，使用 */* 允许所有类型的文件 MAX_SIZE 最大允许上传的附件体积，单位为 MB，例如 32 MAX_FILES 最大允许一次性上传的附件个数，例如 10 Markdown (markdown) 名称 描述 ENABLE_HARD_LINE_BREAK 指示是否启用硬性换行扩展 CUSTOM_URL_SCHEMES 允许被解析为链接的自定义 URL 方案，例如 git（用于 git://）和magnet（用于 magnet://） FILE_EXTENSIONS 需要被渲染为 Markdown 格式的文件名后缀，通过逗号分隔。如果是无后缀名的文件，则单独放置一个逗号，例如：.markdown, Smartypants (smartypants) 名称 描述 ENABLED 指示是否启用 Smartypants 扩展 HTTP (http) 名称 描述 ACCESS_CONTROL_ALLOW_ORIGIN 头信息 Access-Control-Allow-Origin 的自定义值，默认为空，即不响应此头信息 数据库 (database) 名称 描述 DB_TYPE 数据库类型，可以是 mysql、postgres、mssql 或 sqlite3 HOST 数据库主机地址与端口 NAME 数据库名称 USER 数据库用户名 PASSWD 数据库用户密码 SSL_MODE 仅限 PostgreSQL 使用 PATH 仅限 SQLite3 使用，数据库文件路径 应用管理 (admin) 名称 描述 DISABLE_REGULAR_ORG_CREATION 激活该选项来禁止普通用户（非管理员）创建组织 安全 (security) 名称 描述 INSTALL_LOCK 用于指示是否允许访问安装页面（该页面可以设置管理员帐号，因此该选项非常重要） SECRET_KEY 全局的加密密钥，务必修改该值以确保您的服务器安全（会在每次安装时自动生成随机字符串） LOGIN_REMEMBER_DAYS 记住登录的天数 COOKIE_USERNAME 记录用户名的 Cookie 名称 COOKIE_REMEMBER_NAME 记录用户自动登录信息的 Cookie 名称 REVERSE_PROXY_AUTHENTICATION_USER 反向代理认证用户的 Header 字段名 服务 (service) 名称 描述 ACTIVE_CODE_LIVE_MINUTES 激活码的有效期，单位为分钟 RESET_PASSWD_CODE_LIVE_MINUTES 重置密码的有效期，单位为分钟 REGISTER_EMAIL_CONFIRM 激活该选项来要求注册用户必须验证邮箱，要求已启用 Mailer DISABLE_REGISTRATION 激活该选项来禁止用户注册功能，只能由管理员创建帐号 SHOW_REGISTRATION_BUTTON 用于指示是否显示注册按钮 REQUIRE_SIGNIN_VIEW 激活该选项来要求用户必须登录才能浏览任何页面 ENABLE_CACHE_AVATAR 激活该选项来缓存 Gravatar 的头像 ENABLE_NOTIFY_MAIL 激活该选项来发送通知邮件给关注者，例如创建 issue 时，要求已启用 Mailer ENABLE_REVERSE_PROXY_AUTHENTICATION 激活该选项来开启反向代理用户认证，请从 #165 了解更多信息 ENABLE_REVERSE_PROXY_AUTO_REGISTRATION 激活该选项来开启反向代理用户认证的自动注册功能 DISABLE_MINIMUM_KEY_SIZE_CHECK 激活该选项来禁止检查响应类型的密钥最小长度 ENABLE_CAPTCHA 激活该选项以在用户注册时要求输入验证码 Web 钩子 (webhook) 名称 描述 TYPES 启动的 Web 钩子类型，可以是 gogs、slack、discord或dingtalk QUEUE_LENGTH Web钩子队列长度，如果发现部分Webhook未能成功触发，可考虑增加该值 DELIVER_TIMEOUT 发送通知的超时时间，以秒为单位 SKIP_TLS_VERIFY 指示是否允许向具有非信任证书的地址发送通知 PAGING_NUM Web 钩子历史页面每页显示记录条数 邮件 (mailer) 名称 描述 ENABLED 启用该选项以激活邮件服务 SUBJECT_PREFIX 邮件标题的前缀 HOST SMTP 主机地址与端口 DISABLE_HELO 禁用 HELO 操作 HELO_HOSTNAME HELO 操作的自定义主机名 SKIP_VERIFY 不验证自签发证书的有效性 FROM 邮箱的来自地址，遵循 RFC 5322规范，可以是一个单纯的邮箱地址或者 &quot;名字&quot; &lt;email@example.com&gt; 的形式 USER 邮箱用户名 PASSWD 邮箱密码 USE_PLAIN_TEXT 使用 text/plain 作为邮件内容格式 备注：Gogs 仅支持使用 STARTTLS 的 SMTP 协议 缓存 (cache) 名称 描述 ADAPTER 缓存引擎适配器，可以为 memory、Redis 或 memcache。如果您使用 Redis 或 memcache，请确保使用 -tags 选项重新构建所有依赖，例如：go build -tags=&#39;Redis&#39; INTERVAL 仅限内存缓存使用，GC 周期，单位为秒 HOST 仅限 Redis 和 memcache 使用，主机地址和端口号 - Redis：network=tcp,addr=127.0.0.1:6379,password=macaron,db=0,pool_size=100,idle_timeout=180 - Memache：127.0.0.1:9090;127.0.0.1:9091 会话 (session) 名称 描述 PROVIDER Session 引擎提供者，可以是 memory、file、Redis 或 mysql PROVIDER_CONFIG 如果提供者为 file，则为文件根目录；如果为其它提供者，则为主机地址和端口号 COOKIE_SECURE 激活该选项以要求所有 session 操作均通过 HTTPS GC_INTERVAL_TIME GC 周期，单位为秒 图片 (picture) 名称 描述 AVATAR_UPLOAD_PATH 存放用户上传头像的目录 GRAVATAR_SOURCE 可以是 gravatar、duoshuo 或任何 URL，例如：http://cn.gravatar.com/avatar/ DISABLE_GRAVATAR 激活该选项来仅使用本地头像 ENABLE_FEDERATED_AVATAR 激活该选项来启用 Federated 头像服务（http://www.libravatar.org），当 Gravatar 被禁用时此选项无法生效 附件 (attachment) 名称 描述 ENABLED 激活该选项以允许用户上传附件 PATH 存放附件的路径 ALLOWED_TYPES 允许上传的 MIME 类型，例如 “image/jpeg|image/png”，使用 */* 允许所有类型的文件 MAX_SIZE 最大允许上传的附件体积，单位为 MB，例如 4 MAX_FILES 最大允许一次性上传的附件个数，例如 5 时间 (time) 名称 描述 FORMAT 指定日期的输出格式，默认为 RFC1123，其它可选的格式为 ANSIC、UnixDate、RubyDate、RFC822、RFC822Z、RFC850、RFC1123、RFC1123Z、RFC3339、RFC3339Nano、Kitchen、Stamp、StampMilli、StampMicro 和 StampNano。访问 http://golang.org/pkg/time/#pkg-constants 查看详情 日志 (log) 名称 描述 ROOT_PATH 日志文件的根目录 MODE 日志记录模式，默认为 console。如果想要开启多模式，请使用逗号分割，例如：&quot;console, file&quot; LEVEL 基本日志级别，默认为 Trace 日志 - 控制台 (log.console) 名称 描述 LEVEL 控制台日志级别，留空则继承父值 日志 - 文件 (log.file) 名称 描述 LEVEL 文件日志级别，留空则继承父值 LOG_ROTATE 激活该选项以启用日志文件自转 DAILY_ROTATE 激活该选项以进行日常自转 MAX_SIZE_SHIFT 自转需要达到的最大文件体积，使用位左移，默认为 28 即 1 &lt;&lt; 28，表示 256MB MAX_LINES 自转需要达到的最大文件行数，默认为 1000000 MAX_DAYS 保留自转文件的最长期限，默认为 7 天后删除 日志 - Slack (log.slack) 名称 描述 LEVEL Slack 日志级别，留空则继承父值 URL Slack Web 钩子 URL 日志 - Discord (log.discord) 名称 描述 LEVEL Discord 日志级别，留空则继承父值 URL Discord Web 钩子 URL USERNAME 在 Web 钩子中显示的用户名 Cron (cron) 名称 描述 ENABLED 激活该选项以允许周期性运行 Cron 任务 RUN_AT_START 激活该选项以允许在启动时执行 Cron 任务 Cron - 更新镜像 (cron.update_mirrors) 名称 描述 SCHEDULE 定时更新仓库镜像的 Cron 语法，例如：@every 1h Cron - 仓库健康检查 (cron.repo_health_check) 名称 描述 SCHEDULE 定时进行仓库健康检查的 Cron 语法，例如：@every 24h TIMEOUT 仓库健康检查超时的定义语法，例如：60s ARGS git fsck 命令的参数，例如：--unreachable --tags Cron - 仓库统计检查 (cron.check_repo_stats) 名称 描述 RUN_AT_START 激活该选项以在启动时执行仓库统计检查 SCHEDULE 定时进行仓库统计检查的 Cron 语法，例如：@every 24h Cron - 仓库归档清理 (cron.repo_archive_cleanup) 名称 描述 RUN_AT_START 激活该选项以在启动时执行仓库归档清理 SCHEDULE 定时进行仓库归档清理的 Cron 语法，例如：@every 24h OLDER_THAN 仓库归档的文件有效期，过期的归档将被清理，例如：24h Git (git) 名称 描述 DISABLE_DIFF_HIGHLIGHT 激活该选项以禁用行内差异高亮 MAX_GIT_DIFF_LINES 差异对比页面单个文件显示的最大行数 MAX_GIT_DIFF_LINE_CHARACTERS 差异对比页面单行显示的最大字符数 MAX_GIT_DIFF_FILES 差异对比页面文件显示的最多个数 GC_ARGS git gc 命令的参数，例如：--aggressive --auto Git - 超时 (git.timeout) 名称 描述 MIGRATE 仓库迁移操作超时，默认为 600 秒 MIRROR 仓库镜像同步操作超时，默认为 300 秒 CLONE 仓库克隆操作超时，默认为 300 秒 PULL 仓库拉取操作超时，默认为 300 秒 GC 仓库垃圾回收操作超时，默认为 60 秒 UI (ui) 名称 描述 EXPLORE_PAGING_NUM 探索页面每页显示仓库的数量 ISSUE_PAGING_NUM 每页显示工单（Issue）的数量（应用到所有以列表形式显示工单的页面） FEED_MAX_COMMIT_NUM 一条最新活动中显示代码提交（Commit）的最大数量 THEME_COLOR_META_TAG 被用于 Android &gt;= 5.0 版本 “theme-color” 标记的值，无效的值将被忽略并使用默认值（查看详情） MAX_DISPLAY_FILE_SIZE 显示到页面的最大文件体积（Byte） UI - Admin (ui.admin) 名称 描述 USER_PAGING_NUM 用户管理页面每页显示记录条数 REPO_PAGING_NUM 仓库管理页面每页显示记录条数 NOTICE_PAGING_NUM 系统提示管理页面每页显示记录条数 ORG_PAGING_NUM 组织管理页面每页显示记录条数 Prometheus (prometheus) 名称 描述 ENABLED 激活该选项以启用 Prometheus 监控信息，默认为 true ENABLE_BASIC_AUTH 激活该选项以启用 HTTP 基本认证保护监控信息数据，默认为 false BASIC_AUTH_USERNAME HTTP 基本认证的用户名 BASIC_AUTH_PASSWORD HTTP 基本认证的密码 其他 (other) 名称 描述 SHOW_FOOTER_BRANDING 激活该选项以在页脚显示 Gogs 推广信息 SHOW_FOOTER_VERSION 激活该选项以在页脚显示 Gogs 版本信息 SHOW_FOOTER_TEMPLATE_LOAD_TIME 激活该选项以在页脚显示 Gogs 模板加载时间","tags":["Docker","CI","gogs"],"categories":["CI"]},{"title":"利用consul+nginx-upsync实现动态负载","path":"/2019/12/01/212/","content":"当 Nginx 遇到大流量和高负载，修改配置文件重启略显繁琐，因为恢复Nginx并重载配置会进一步增加系统负载，并很可能短暂降低性能，而一个个修改配置文件也是很容易出错和费时间的操作，这时候不妨试试consul+nginx-upsync-module实现Nginx的动态负载。 nginx-upsync-modulenginx-upsync-module 提供了动态的负载均衡，它可以从consul或etcd同步upstreams，动态修改后端服务器属性，而不需要重新加载nginx。这样我们通过它实现平滑伸缩，而不严重地影响性能。 利用docker安装我已经基于centos7构建了一个镜像 puresai/nginx-lua-upsync ，你可以使用下面的命令启动一个容器 docker run -itd –name=nginx-upsync -p 8008:80 -p 9501:9501 -p 9502:9502 -p 9503:9503 -p 8500:8500 puresai/nginx-lua-upsync 当然，你也可以不使用docker自行搭建，添加nginx-upsync-module模块可以参考nginx模块lua模块。 nginx-upsync-module的git地址 进入容器配置 docker exec -it nginx-upsync /bin/bash cd /usr/local/nginx/conf echo “server host.docker.internal:9501 weight=1 fail_timeout=10 max_fails=3;” &gt;&gt; servers.conf vi nginx.conf #nginx.conf 主要配置...upstream puresai&#123; upsync 192.168.65.2:8500/v1/kv/upstreams/test-server upsync_timeout=6m upsync_interval=500ms upsync_type=consul strong_dependency=off; upsync_dump_path /usr/local/nginx/conf/servers.conf; include /usr/local/nginx/conf/servers.conf;&#125;server &#123; listen 80; location / &#123; proxy_pass http://puresai; &#125; ... &#125; 相关语法说明 upsync 定义从consul/etcd拉取最新的upstream信息并存到本地的操作 upsync_timeout 定义从consul/etcd拉取配置的超时时间，默认 6m upsync_interval 定义从consul/etc拉取配置的间隔时间，默认 5s upsync_type 定义使用配置服务类型 consul/etcd strong_dependency 启动时是否强制依赖配置服务器，如果配置为on,则拉取失败，nginx同样会启用失败 upsync_dump_path 定义从consul/etcd拉取配置后持久化到的本地的文件路径，这样即使 consul/etcd出问题了，本地同样会有备份文件 注意 upsync_dump_path 指定这个文件必须要有，否则Nginx启动会报错。文件路径和名称可以自定义，nginx-upsync-module会将负载信息缓存到此文件 #servers.conf，192.168.x.xxx是我的宿主机ipserver 192.168.x.xxx:9501 weight=20 max_fails=1 fail_timeout=5s; 重启nginx /usr/local/nginx/sbin/nginx -t /usr/local/nginx/sbin/nginx -s reload 这里虽然我们还未启动consul，但没有什么影响，upsync会去拉取，也必然会失败，servers.conf 就不会更新，Nginx的 error 日志会有信息。 利用swoole启动3个http服务// 可启动3个server，端口分别为9501，9502，9503，输出也做对应修改$http = new Swoole\\Http\\Server(&quot;127.0.0.1&quot;, 9501);$http-&gt;on(&#x27;request&#x27;, function ($request, $response) &#123; $response-&gt;end(&quot;9501&quot;);&#125;); consul安装 这里consul只做一个kv存储，我自己也是第一次用，就不去做过多介绍了。 下载地址 解压到你需要的目录，主要也就是一个consul可执行文件。（这里我装在我的电脑，而不是刚才的docker容器） 命令可看文档：Consul 简介和快速入门 启动： nohup ./consul agent -dev &amp; 为了方便，我们也没有启动集群，生产环境建议使用consul集群。 UI查看 http://127.0.0.1:8500/ 查看节点 ./consul members curl 127.0.0.1:8500/v1/catalog/nodes 查看kv值 curl -v http://127.0.0.1:8500/v1/kv/\\?recurse 添加 curl -X PUT -d ‘{“weight”:20,”max_fails”:2,”fail_timeout”:5}’ http://127.0.0.1:8500/v1/kv/upstreams/test-server/192.168.x.xxx:9502 此处192.168.x.xxx是因为我创建的docker容器的宿主机ip。 删除 curl -X DELETE http://127.0.0.1:8500/v1/kv/upstreams/test-server/192.168.x.xxx:9502 我们可以通过添加和删除来测试，查看 http://127.0.0.1:8008/ 来查看输出，也可以看看Nginx里的配置文件servers.conf，你会看到你操作consul，会动态改变Nginx的upstream，这样就实现了Nginx的动态扩容，相比一个个改配置要轻松一点。","tags":["consul","SLB"],"categories":["Nginx"]},{"title":"Nginx配置常用参数","path":"/2019/11/22/Nginx6/","content":"最近在全面学习Nginx，当作笔记了，如有错误，欢迎指出或深入交流。 主模块# 配置用户或者组，默认为nobody nobody。#user www www; #Nginx开启的worker进程数，建议为CPU的核数#worker_processes 2; #指定nginx进程运行文件存放地址#pid /nginx/pid/nginx.pid;#指定日志路径，级别。这个设置可以放入全局块、http块、server块，级别以此为：debug|info|notice|warn|error|crit|alert|emergerror_log log/error.log debug; #可以在任意地方使用include指令实现配置文件的包含，类似于apache中的include方法，可减少主配置文件长度。include vhosts/*.conf; 事件模块events &#123; #设置网路连接序列化，防止惊群现象发生，默认为on accept_mutex on; #默认: 500ms 如果一个进程没有互斥锁，它将延迟至少多长时间。默认情况下，延迟是500ms 。 accept_mutex_delay 100ms; #设置一个进程是否同时接受多个网络连接，默认为off multi_accept on; #事件驱动模型，select|poll|kqueue|epoll|resig|/dev/poll|eventport，不建议设置，nginx会自行选择 #use epoll; #最大连接数，默认为512 worker_connections 1024;&#125; http部分http &#123; #文件扩展名与文件类型映射表 include mime.types; # 默认文件类型，默认为text/plain default_type application/octet-stream; #取消服务日志 #access_log off; #允许sendfile方式传输文件，默认为off，可以在http块，server块，location块。 sendfile on; #每个进程每次调用传输数量不能大于设定的值，默认为0，即不设上限。 sendfile_max_chunk 100k; #连接超时时间，默认为75s，可以在http，server，location块。 keepalive_timeout 65; #开启gzip资源压缩 gzip on; # 负载均衡，详细可看了一篇文章：https://learnku.com/articles/36737 upstream blog &#123; server 192.167.20.19:8081; server 192.168.10.121:8080 weight=5; &#125; #设定请求缓冲 client_header_buffer_size 128k; large_client_header_buffers 4 128k; #上传文件的大小限制 默认1m client_max_body_size 8m; server &#123; #单连接请求上限次数。 keepalive_requests 120; #监听端口 listen 80; #监听地址 server_name blog.puresai.com; #设定日志格式 log_format main &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27; &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27; &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;; access_log /data/logs/access.log main; # 根目录 root /www/web/public; # 定义错误提示页面 error_page 500 502 503 504 /50x.html; location /static/ &#123; #root与alias主要区别在于nginx如何解释location后面的uri，这会使两者分别以不同的方式将请求映射到服务器文件上。 #root的处理结果是：root路径＋location路径 #alias的处理结果是：使用alias路径替换location路径 alias /www/static/; #过期30天，静态文件不怎么更新，过期可以设大一点,如果频繁更新，则可以设置得小一点。 expires 30d; &#125; # 处理php请求到fpm端口 location ~ \\.php$ &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; &#125; location / &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_pass http://blog; #请求转向blog 定义的服务器列表 &#125; #禁止访问文件 location ~ /.git &#123; deny all; allow 127.0.0.1; #允许的ip &#125; &#125;&#125; 部分参数详细说明server_name1.首先选择所有字符串完全匹配的server_name，如 blog.puresai.com 。2.其次选择通配符在前面的server_name，如 *.puresai.com。3.再次选择通配符在后面的server_name，如www.puresai.* 。 4.最后选择使用正则表达式才匹配的server_name，如 ~^\\.sai\\.com$如果都不匹配1、优先选择listen配置项后有default或default_server的 2、找到匹配listen端口的第一个server块 locationlocation语法: location[=|~|~*|^~|@]/uri/&#123;...&#125;配置块: server location会尝试根据用户请求中的URI来匹配上面的/uri表达式，如果可以匹配，就选择 location&#123;&#125;块中的配置来处理用户请求。 location表达式类型 ~ 表示执行一个正则匹配，区分大小写;~* 表示执行一个正则匹配，不区分大小写;^~ 表示普通字符匹配。使用前缀匹配。如果匹配成功，则不再匹配其他location; = 进行普通字符精确匹配。也就是完全匹配;@ 它定义一个命名的 location，使用在内部定向时，例如 error_page, try_files 优先级: 等号类型(=)的优先级最高。一旦匹配成功，则不再查找其他匹配项 前缀普通匹配(^~)优先级次之。不支持正则表达式。使用前缀匹配，如果有多个location匹配的话，则使用表达式最长的那个 正则表达式类型(~ ~*)的优先级次之。一旦匹配成功，则不再查找其他匹配项 常规字符串匹配，如果有多个location匹配的话，则使用表达式最长的那个 (location =) &gt; (location 完整路径) &gt; (location ^~ 路径) &gt; (location ,* 正则顺序) &gt; (location 部分起始路径) return语法:return code [text] return code URL;return URL;配置块:server，location，if该指令用于结束规则的执行并返回状态吗给客户端。状态码包括:204(No Content)、400(Bad Request)、402(Payment Required)、403(Forbidden) 404(Not Found)、405(Method Not Allowed)、406(Not Acceptable)、 408(Request Timeout)、410(Gone)、411(Length Required)、413(Request Entity Too Large)、416(Requested Range Not Satisfiable)、 500(Internal Server Error)、501(Not Implemented)、502(Bad Gateway)、 503(Service Unavailable)504(Gateway Timeout)。例如，示例，如果访问的URL以.sh .bash 结尾，返回状态码403 location ~ .*\\.(sh|bash)?$ &#123;\treturn 403;&#125; rewrite执行顺序：1. 执行server块的rewrite指令(这里的块指的是server关键字后&#123;&#125;包围的区域，其它xx块类似)2. 执行location匹配3. 执行选定的location中的rewrite指令如果其中某步URI被重写，则重新循环执行1-3，直到找到真实存在的文件如果循环超过10次，则返回500 Internal Server Error错误语法:rewrite regex replacement [flag]; 默认值:—配置块:server, location, ifrewrite是实现URL重写的关键指令，根据regex(正则表达式)部分内容，重定向到replacement，结尾是flag标记。 正则:perl兼容正则表达式语句进行规则匹配替代内容:将正则匹配的内容替换成replacementflag标记:rewrite支持的flag标记 if指令语法：if(condition)&#123;...&#125;默认值：无配置块：server,location对给定的条件condition进行判断。如果为真，大括号内的rewrite指令将被执行。if条件(conditon)可以是如下任何内容:一个变量名；false如果这个变量是空字符串或者以0开始的字符串；使用= ,!= 比较的一个变量和字符串是用~， ~*与正则表达式匹配的变量，如果这个正则表达式中包含&#125;，;则整个表达式需要用&quot; 或&#x27; 包围使用-f ，!-f 检查一个文件是否存在使用-d, !-d 检查一个目录是否存在使用-e ，!-e 检查一个文件、目录、符号链接是否存在使用-x ， !-x 检查一个文件是否可执行 if实例if ($http_user_agent~*(mobile|nokia|iphone|ipad|android|samsung|htc|blackberry)) &#123; rewrite ^.+ /mobile last; ＃跳转到手机站&#125;if ($request_method = POST) &#123; return 405;&#125;if ($slow) &#123; limit_rate 10k;&#125;if ($invalid_referer) &#123; return 403;&#125; last &amp; break（1）last 和 break 当出现在location 之外时，两者的作用是一致的没有任何差异。注意一点就是，他们会跳过所有的在他们之后的rewrite 模块中的指令，去选择自己匹配的location（2）last 和 break 当出现在location 内部时，两者就存在了差异-- last: 使用了last 指令，rewrite 后会跳出location 作用域，重新开始再走一次刚刚的行为-- break: 使用了break 指令，rewrite后不会跳出location 作用域。它的生命也在这个location中终结。解释通俗易懂：last： 重新将rewrite后的地址在server标签中执行break： 将rewrite后的地址在当前location标签中执行 permanent &amp; redirect:permanent: 永久性重定向。请求日志中的状态码为301redirect:临时重定向。请求日志中的状态码为302 从实现功能的角度上去看，permanent 和 redirect 是一样的。不存在好坏。也不存在什么性能上的问题。但是对seo会有影响，这里要根据需要做出选择在 permanent 和 redirect 中提到了 状态码 301 和 302。 记住：last 和 break 想对于的访问日志的请求状态码为200 当你打开一个网页，同时打开debug 模式时，会发现301 和 302 时的行为是这样的。 第一个请求301 或者 302 后，浏览器重新获取了一个新的URL ，然后会对这个新的URL 重新进行访问。所以当你配置的是permanent 和 redirect ,你对一个URL 的访问请求，落到服务器上至少为2次；而当你配置了last 或者是break 时，你最终的URL 确定下来后，不会将这个URL返回给浏览器，而是将其扔给了fastcgi_pass或者是proxy_pass指令去处理。请求一个URL ，落到服务器上的次数就为1次。 注意：配置last 在跨域的时候效果和redirect一致，都是返回302状态码，请求地址也发生改变 应用估算并发nginx作为http服务器的时候： max_clients = worker_processes * worker_connections/2 nginx作为反向代理服务器的时候： max_clients = worker_processes * worker_connections/4 限制每个IP的并发连接数demo:定义一个叫“two”的记录区，总容量为 10M（超过大小将请求失败，以变量 $binary_remote_addr 作为会话的判断基准（即一个地址一个会话）。 限制 /download/ 目录下，一个会话只能进行一个连接。 简单点，就是限制 /download/ 目录下，一个IP只能发起一个连接，多过一个，一律503。 http &#123; ... limit_conn_zone $binary_remote_addr zone=two:10m; server &#123; ... location /download &#123; limit_conn two 1; &#125; &#125;&#125; 限流demo:定义一个叫“one”的记录区，占用空间大小为10m（超过大小将请求失败），平均处理的请求频率不能超过每秒一次，也可以设置分钟速率 http &#123; ... limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s; server &#123; ... location / &#123; #缓存区队列burst=5个,nodelay表示不延期(超过的请求失败)，即每秒最多可处理rate+burst个,同时处理rate个。 limit_req zone=one burst=5 nodelay; &#125; &#125;&#125; 白名单http&#123; ... #判断客户端的ip地址是否在白名单列表当中,如果返回为0,则在白名单列表当中,否则返回为1 geo $whiteIpList &#123; default 1; 118.24.109.254 0; 47.98.147.0/24 1; #可以引入一些白名单配置 include &#x27;whiteIP.conf&#x27; &#125; #如果不在白名单之内,返回客户端的二进制的ip地址 map $whiteIpList $limit &#123; default &quot;&quot;; 1 $binary_remote_addr; 0 &quot;&quot;; &#125; #如果返回的是空字符串那么速率限制会失效 limit_req_zone $limit zone=test:2m rate=1r/m; ...&#125; 防盗链http &#123; ... server &#123; ... location ~* \\.(gif|jpg|png|swf|flv)$ &#123; valid_referers none blocked *.puresai.com; if ($invalid_referer) &#123; rewrite ^/ blog.puresai.com &#125; &#125; &#125;&#125;","tags":["Nginx"],"categories":["Nginx"]},{"title":"Nginx代理缓存","path":"/2019/11/22/Nginx1/","content":"Nginx的缓存可以简单分成web缓存和代理缓存，本篇文章主要介绍代理缓存。 web缓存Nginx提供了expires、etag、if-modified-since指令来实现浏览器缓存控制。 这个配置比较简单，一般可以缓存一些js、css等静态文件。 对于这几个不想做过多说明，大家可以看两张图，简单理解下。 代理缓存代理缓存主要用到proxy模块中的proxy_cache。我们来看一个demo。 upstream puresai&#123; server 127.0.0.1:9501 weight=10;&#125;#自定义缓存目录,缓存文件大小proxy_cache_path /usr/local/etc/nginx/cache levels=1:2 keys_zone=sai_cache:10m max_size=200m inactive=10m use_temp_path=off;server &#123; listen 80; server_name nginx-t.com; location / &#123; proxy_next_upstream error http_503; proxy_pass http://puresai; #启用缓存sai_cache proxy_cache sai_cache; #定义如何生成缓存的键 proxy_cache_key $scheme$proxy_host$uri$is_args$args; #针对多种请求方法缓存，默认GET HEAD proxy_cache_methods GET HEAD POST; #为不同的响应状态码设置不同的缓存时间。 proxy_cache_valid 200 302 10m; proxy_cache_valid 404 1m; #设置响应被缓存的最小请求次数,最少2次才会缓存 proxy_cache_min_uses 1; #开启此功能时，对于相同的请求，同时只允许一个请求发往后端 proxy_cache_lock on; #为proxy_cache_lock指令设置锁的超时5s proxy_cache_lock_timeout 5s; #忽略服务器不缓存的要求 proxy_ignore_headers Cache-Control; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125;&#125; 测试效果// server1.php&lt;?php$http = new Swoole\\Http\\Server(&quot;127.0.0.1&quot;, 9501);$http-&gt;on(&#x27;request&#x27;, function ($request, $response) &#123; echo &quot;no cache&quot;.PHP_EOL; $response-&gt;end(&quot;&lt;h1&gt;9501&lt;/h1&gt;&quot;);&#125;);$http-&gt;start(); php server1.php #查看控制台输出 发送get和post请求 ab -n10 -c10 http://nginx-t.com/v\\=get ab -p ‘data.json’ -n10 -c10 http://nginx-t.com/v\\=post 重复提交几次put请求 curl -X PUT http://nginx-t.com/v\\=put 下面是我的测试结果截图（为了方便查看，我在get和post请求之前敲了几个空行） 下面说明几个参数： proxy_cache_path语法:\tproxy_cache_path path [levels=levels] keys_zone=name:size [inactive=time] [max_size=size] [loader_files=number] [loader_sleep=time] [loader_threshold=time];默认值:\t—上下文:\thttp path：缓存数据是保存在文件中的，缓存的键和文件名都是在代理URL上执行MD5的结果。 levels：定义了缓存的层次结构 #当levels=1:2时，表示是两级目录，1和2表示用1位和2位16进制来命名目录名称。在此例中，第一级目录用1位16进制命名，如b；第二级目录用2位16进制命名，如2c。所以此例中一级目录有16个，二级目录有16*16=256个：cache/b/2c/c75ad5e343f042f52e875343425e51b key_zone:在共享内存中设置一块存储区域来存放缓存的key和metadata(类似使用次数)，这样nginx可以快速判断一个request是否命中或者未命中缓 存，1m可以存储8000个key，10m可以存储80000个key。 max_size:最大cache空间，如果不指定，会使用掉所有disk space，如果超过max_size参数设置的最大值，使用LRU算法移除缓存数据 inactive:未被访问文件在缓存中保留时间，默认是10分钟。指定时间内未被访问的缓存文件将被删除。 loader_files:每次最多加载的数量 loader_sleeps:每次加载的延时 loader_threshold:指定每次加载执行的时间 proxy_cache_lock开启此功能时，对于相同的请求，同时只允许一个请求发往后端，并根据proxy_cache_key指令的设置在缓存中植入一个新条目。其他请求相同条目的请求将一直等待，直到缓存中出现相应的内容，或者锁在proxy_cache_lock_timeout指令设置的超时后被释放。 proxy_cache_valid如果仅仅指定了time， proxy_cache_valid 5m; 那么只有状态码为200、300和302的响应会被缓存。 如果使用了any参数，那么就可以缓存任何响应： proxy_cache_valid any 1m; proxy_ignore_headers语法:\tproxy_ignore_headers field ...;默认值:\t—上下文:\thttp, server, location 不处理后端服务器返回的指定响应头。下面的响应头可以被设置： “X-Accel-Redirect”，“X-Accel-Expires”，“X-Accel-Limit-Rate” ，“X-Accel-Buffering” ， “X-Accel-Charset”，“Expires”，“Cache-Control”，和“Set-Cookie” 。 此参数不建议设置，原则上这些缓存应当后端代码处理。 proxy_cache_use_stale语法:\tproxy_cache_use_stale error | timeout | invalid_header | updating | http_500 | http_502 | http_503 | http_504 | http_404 | off ...;默认值:\tproxy_cache_use_stale off;上下文:\thttp, server, location 如果后端服务器出现状况，nginx是可以使用过期的响应缓存的。这条指令就是定义何种条件下允许开启此机制。这条指令的参数与proxy_next_upstream指令的参数相同。 proxy_cache_bypass与proxy_no_cache语法:\tproxy_cache_bypass string ...;默认值:\t—上下文:\thttp, server, location 定义nginx不从缓存取响应的条件。如果至少一个字符串条件非空而且非“0”，nginx就不会从缓存中去取响应： proxy_cache_bypass $cookie_nocache $arg_nocache$arg_comment;proxy_cache_bypass $http_pragma $http_authorization; 本指令可和与proxy_no_cache一起使用。 语法:\tproxy_no_cache string ...;默认值:\t—上下文:\thttp, server, location 定义nginx不将响应写入缓存的条件。如果至少一个字符串条件非空而且非“0”，nginx就不将响应存入缓存： proxy_no_cache $cookie_nocache $arg_nocache$arg_comment;proxy_no_cache $http_pragma $http_authorization; proxy_cache_methods该指令用于设置缓存哪些HTTP方法,默认缓存HTTP GET/HEAD方法,不缓存HTTP POST 方法。 有了代理缓存，那么清除缓存如何操作呢？ 清除缓存 删除缓存目录的文件 使用ngx_cache_purge模块，可查看这篇文章Nginx缓存配置及nginx ngx_cache_purge模块的使用 推荐第二种方法。","tags":["Nginx"],"categories":["Nginx"]},{"title":"Nginx内嵌变量","path":"/2019/11/22/Nginx5/","content":"Nginx内嵌变量是非常常用的，记录下备查。 Nginx内嵌变量由 ngx_http_core_module 模块支持，变量名与Apache服务器对应，这些变量可以表示客户端的请求头字段，诸如$http_user_agent、$http_cookie等等。 nginx也支持其他变量： 参数名称 说明 $arg_name 请求中的的参数名，即“?”后面的arg_name=arg_value形式的arg_name，如/index.php?www=www.puresai.com，可以用$arg_www就是www.puresai.com $args 请求中的参数值 $binary_remote_addr 客户端地址的二进制形式, 固定长度为4个字节 $body_bytes_sent 传输给客户端的字节数，响应头不计算在内；这个变量和Apache的mod_log_config模块中的“%B”参数保持兼容 $bytes_sent 传输给客户端的字节数 $connection TCP连接的序列号 $connection_requests TCP连接当前的请求数量 $content_length “Content-Length” 请求头字段 $content_type “Content-Type” 请求头字段 $cookie_name cookie名称 $document_root 当前请求的文档根目录或别名 $document_uri 同 $uri $host 优先级如下：HTTP请求行的主机名&gt;”HOST”请求头字段&gt;符合请求的服务器名 $hostname 主机名 $http_name 匹配任意请求头字段； 变量名中的后半部分“name”可以替换成任意请求头字段，如在配置文件中需要获取http请求头：“Accept-Language”，那么将“－”替换为下划线，大写字母替换为小写，形如：$http_accept_language即可。 $https 如果开启了SSL安全模式，值为“on”，否则为空字符串。 $is_args 如果请求中有参数，值为“?”，否则为空字符串。 $limit_rate 用于设置响应的速度限制，详见 limit_rate。 $msec 当前的Unix时间戳 (1.3.9, 1.2.6) $nginx_version nginx版本 $pid 工作进程的PID $pipe 如果请求来自管道通信，值为“p”，否则为“.” (1.3.12, 1.2.7) $proxy_protocol_addr 获取代理访问服务器的客户端地址，如果是直接访问，该值为空字符串。(1.5.12) $query_string 同 $args，然而 $query_string是只读的不会改变 $realpath_root 当前请求的文档根目录或别名的真实路径，会将所有符号连接转换为真实路径。 $remote_addr 客户端地址 $remote_port 客户端端口 $remote_user 用于HTTP基础认证服务的用户名 $request 代表客户端的请求地址 $request_body 客户端的请求主体,此变量可在location中使用，将请求主体通过proxy_pass, fastcgi_pass, uwsgi_pass, 和 scgi_pass传递给下一级的代理服务器。 $request_body_file 请求正文的临时文件名。处理完成时，临时文件将被删除。 如果希望总是将请求正文写入文件，需要开启client_body_in_file_only。 如果在被代理的请求或FastCGI请求中传递临时文件名，就应该禁止传递请求正文本身。 使用proxy_pass_request_body off指令 和fastcgi_pass_request_body off指令 分别禁止在代理和FastCGI中传递请求正文。 $request_completion 如果请求成功，值为”OK”，如果请求未完成或者请求不是一个范围请求的最后一部分，则为空。 $request_filename 当前连接请求的文件路径，由root或alias指令与URI请求生成。 $request_length 请求的长度 (包括请求的地址, http请求头和请求主体) $request_method HTTP请求方法，通常为“GET”或“POST” $request_time 处理客户端请求使用的时间; 从读取客户端的第一个字节开始计时。 $request_uri 这个变量等于包含一些客户端请求参数的原始URI，它无法修改，请查看$uri更改或重写URI，不包含主机名，例如：”/sai/test.php?arg=www”。 $scheme 请求使用的Web协议, “http” 或 “https” $sent_http_name 可以设置任意http响应头字段； 变量名中的后半部分“name”可以替换成任意响应头字段，如需要设置响应头Content-length，那么将“－”替换为下划线，大写字母替换为小写，形如：$sent_http_content_length 4096即可。 $server_addr 服务器端地址，需要注意的是：为了避免访问linux系统内核，应将ip地址提前设置在配置文件中。 $server_name 服务器名 $server_port 服务器端口 $server_protocol 服务器的HTTP版本, 通常为 “HTTP/1.0” 或 “HTTP/1.1” $status HTTP响应代码 $time_iso8601 服务器时间的ISO 8610格式 $time_local 服务器时间（LOG Format 格式） ，nginx处理完成打印日志的时间，不是请求发出的时间 $uri 请求中的当前URI(不带请求参数，参数位于$args)，可以不同于浏览器传递的$request_uri的值，它可以通过内部重定向，或者使用index指令进行修改，$uri不包含主机名，如”/foo/bar.html”。 apache服务器变量可看[备忘] apache服务端变量 参考： 中文文档 Nginx 相关文章： Nginx 负载均衡 Nginx 添加 lua 模块 Nginx 配置常用参数，看这一篇就够了 Nginx 代理缓存","tags":["Nginx"],"categories":["Nginx"]},{"title":"Nginx添加lua-nginx模块","path":"/2019/11/20/Nginx9/","content":"ngx_lua是Nginx的一个模块，将Lua嵌入到Nginx中，从而可以使用Lua来编写脚本，这样就可以使用Lua编写应用脚本，部署到Nginx中运行，即Nginx变成了一个Web容器；这样开发人员就可以使用Lua语言开发高性能Web应用了。 安装luawget http://luajit.org/download/LuaJIT-2.0.5.tar.gz tar -zxvf LuaJIT-2.0.5.tar.gzcd LuaJIT-2.0.5make &amp;&amp; make install PREFIX=/usr/local/LuaJIT etc/profile加入# luaexport LUAJIT_LIB=/usr/local/LuaJIT/lib export LUAJIT_INC=/usr/local/LuaJIT/include/luajit-2.0 source etc/profile 下载ngx_devel_kit模块wget https://github.com/simpl/ngx_devel_kit/archive/v0.3.0.tar.gz NDK(nginx development kit)模块是一个拓展nginx服务器核心功能的模块，第三方模块开发可以基于它来快速实现。 NDK提供函数和宏处理一些基本任务， 减轻第三方模块开发的代码量 下载lua-nginx-module模块wget https://github.com/openresty/lua-nginx-module/archive/v0.10.9rc7.tar.gz lua-nginx-module 模块使nginx中能直接运行lua 查看原始编译 nginx -V 如：configure arguments: --user=www --group=www --prefix=/usr/local/nginx --with-http_stub_status_module --with-http_ssl_module --with-http_gzip_static_module --with-http_sub_module --with-http_v2_module 进入nginx原始目录： ./configure --user=www --group=www --prefix=/usr/local/nginx --with-http_stub_status_module --with-http_ssl_module --with-http_gzip_static_module --with-http_sub_module --with-http_v2_module --add-module=/root/lua-nginx-module-0.10.9rc7/ --add-module=/root/ngx_devel_kit-0.3.0 只make，不执行make install。 编译报错应该就是lua环境变量不对。 nginx -V 命令报错./nginx: error while loading shared libraries: libluajit-5.1.so.2: cannot open shared object file: No such file or directory解决：echo &quot;/usr/local/LuaJIT/lib&quot; &gt;&gt; /etc/ld.so.confldconfig 成功之后可以nginx -V查看，无报错即可。 把原来的nginx备份为nginx_old cp objs/nginx到原来的nginx并覆盖。 在编译目录执行 make upgrade 测试： server&#123; ... location /lua &#123; default_type &#x27;text/html&#x27;; content_by_lua &#x27; ngx.say(&quot;hello, lua!&quot;) &#x27;; &#125; ...&#125; 浏览器打开： http://blog.puresai.com/lua 可以看到hello, lua! 此安装方法也适用于Nginx其他module安装。","tags":["Nginx"],"categories":["Nginx"]},{"title":"git回退远程分支版本","path":"/2019/10/29/201/","content":"偶尔会有代码提交错误，又提交到远程分支了，怎么回退呢？ 强制回退# 查看日志，找到对应的commit idgit loggit reset --hard 回退的版本idgit push -f origin 分支名 这样回退是清除了回退的版本id之后的提交，连日志都没有了。 回退版本# 查看日志，找到对应的commit idgit loggit reset --soft 回退的版本idgit commit 这样回退是改回回退的版本id之后的提交，日志仍然存在。","tags":["git"],"categories":["CI"]},{"title":"php+nginx上传文件413","path":"/2019/10/09/200/","content":"最近在项目中上传文件的时候，上传出错，返回413 Request Entity Too Large 解决方法：（具体大小视业务而定） 以下代码加入 nginx.conf 文件中的 http{ … } 块中 client_max_body_size 32M; PHP 设置上传大小 打开php.ini 文件中 修改以下几个参数 memory_limit = 32Mupload_max_filesize = 8Mpost_max_size = 16M 重启nginx，fpm即可。","tags":["PHP","Nginx"],"categories":["PHP"]},{"title":"通过mysqlbinlog恢复误操作清空的表","path":"/2019/09/08/198/","content":"今天跟大家分享通过mysqlbinlog恢复误操作清空的表，分享来源于发生在自己身上的真实事件。 背景某个月黑风高的夜晚，朋友微信找到我说，数据库中某个表被开发人员误删了，老板还在正在测试功能，开发学艺不精，慌了，不知道怎么办了。 我问他是否开启了binlog，并把以下命令发给他。 show variables like ‘log_bin’; 值得庆幸的是，他们的生产数据库开了binlog。然后跟他说了下可以恢复，并分享了文章让那边开发人员操作一下。 结果半小时之后，朋友问我能不能帮忙操作，其实我内心是拒绝的，因为不想给自己找麻烦，但想到我貌似没有线上实操过，说明顾虑及安全性问题后，对方同意便决定尝试一下。 恢复步骤操作步骤如下: 找到存放binlog的目录，使用 mysqlbinlog mysqlbinlog mysql-bin.000011 &gt; bak.log 找到删除的语句时间，使用的是truncate，因为项目未上线，log 不大，直接 grep 即可 再次利用 mysqlbinlog 导出sql 语句，方便后续快速导入 mysqlbinlog –stop-datetime=”2019-09-07 17:30:31” mysql-bin.000011 &gt;all.sql stop-datetime应该是误删操作前一刻时间。 下载 all.sql 倒入本地数据库，检查无异常，导出误删表，直接将误删表导入生产数据库。 告知对方检测生产数据库 这个事情就这么告一段落了，没有任何酬劳，真小气。。。 反思晚上我反思了一下，总结如下： 数据库重要数据尽量一天一备份，然后开启binlog，为了减少硬盘空间占用，设置expire_logs_days 生产数据库不使用root用户，新建用户，限制drop，truncate等危险操作权限 遇事别慌，自己尝试解决，解决不了请教别人，快速解决问题才是关键 帮忙可以帮，但要说清楚，别被坑了 导出sql时应该指定数据库，比如 mysqlbinlog –stop-datetime=”2022-09-07 17:30:31” –database=test mysql-bin.000893 &gt;all.sql 参考 mysqlbin","tags":["MySQL"],"categories":["db"]},{"title":"laravel默认分页带参","path":"/2019/09/02/196/","content":"默认的laravel分页是只带分页参数的，那么如何加入其它参数呢？比如搜索项。 后端带参 $list = $model::paginate(2);$list-&gt;appends([ name=&gt;$name, city=&gt;$city,])-&gt;render();return view(admin, [ list =&gt; $list]);// blade使用&#123;&#123; $list-&gt;links() &#125;&#125; 前端带参 $list = $model::paginate(2);return view(admin.apply.apply, [ list =&gt; $list, name =&gt; $name, city =&gt; $city]);//前端&#123;&#123; $list-&gt;appends([name=&gt;$name, city =&gt; $city])-&gt;links() &#125;&#125; 两种方法均可！","tags":["Laravel"],"categories":["PHP"]},{"title":"学习go遇到的一些问题和概念汇总","path":"/2019/08/25/195/","content":"go get安装x/sys失败的解决// $GOPATH这段地址请自行修改，下载到goroot和gopath对应位置即可，不同系统略有不同git clone https://github.com/golang/net.git $GOPATH/src/github.com/golang/netgit clone https://github.com/golang/sys.git $GOPATH/src/github.com/golang/sysgit clone https://github.com/golang/tools.git $GOPATH/src/github.com/golang/toolsln -s $GOPATH/src/github.com/golang $GOPATH/src/golang.org/x go get命令安装golang.org比较慢的话，一般都可以在github.com找到对应的package，下载后放到对应的目录即可 go的环境变量设置在/etc/profile最下面加入以下代码： # 可自行改成你的目录export GO_INSTALL_DIR=$HOMEexport GOROOT=$GO_INSTALL_DIR/goexport GOPATH=$HOME/mygoexport PATH=$GOPATH/bin:$PATH:$GO_INSTALL_DIR/go/bin import import _ 执行init函数，但不需要包所有函数 import . 解决循环依赖问题 &amp;和* &amp;符号的意思是对变量取地址，如：变量a的地址是&amp;a符号的意思是对指针取值，和聽&amp;聽可以互相抵消,同时注意，*&amp;可以抵消掉，但&amp;*是不可以抵消的 切片容量 容量当做成总长度减去左指针走过的元素值 一旦一个切片无法容纳更多的元素，Go语言就会想办法扩容。但它并不会改变原来的切片，而是会生成一个容量更大的切片，然后将把原有的元素和新元素一并拷贝到新切片中。在一般的情况下，你可以简单地认为新切片的容量（以下简称新容量）将会是原切片容量（以下简称原容量）的2倍。但是，当原切片的长度（以下简称原长度）大于或等于1024时，Go语言将会以原容量的1.25倍作为新容量的基准（以下新容量基准）。新容量基准会被调整（不断地与1.25相乘），直到结果不小于原长度与要追加的元素数量之和（以下简称新长度）。最终，新容量往往会比新长度大一些，当然，相等也是可能的。另外，如果我们一次追加的元素过多，以至于使新长度比原容量的2倍还要大，那么新容量就会以新长度为基准。 大小写 在Go语言中，没有特别的关键字来声明一个方法、函数或者类型是否为公开的，Go语言提供的是以大小写的方式进行区分的，如果一个类型的名字是以大写开头，那么其他包就可以访问；如果以小写开头，其他包就不能访问。 go的并发 概念 说明 进程 一个程序对应一个独立程序空间 线程 一个执行空间，一个进程可以有多个线程 逻辑处理器 执行创建的goroutine，绑定一个线程 调度器 Go运行时中的，分配goroutine给不同的逻辑处理器 全局运行队列 所有刚创建的goroutine都会放到这里 本地运行队列 逻辑处理器的goroutine队列 并发的概念和并行不一样，并行指的是在不同的物理处理器上同时执行不同的代码片段，并行可以同时做很多事情，而并发是同时管理很多事情，因为操作系统和硬件的总资源比较少，所以并发的效果要比并行好的多，使用较少的资源做更多的事情，也是Go语言提倡的。 通道h:=make(chan int)通道类型和Map这些类型一样，可以使用内置的make函数声明初始化，这里我们初始化了一个chan int类型的通道，所以我们只能往这个通道里发送int类型的数据，当然接收也只能是int类型的数据。我们知道，通道是用于在goroutine之间通信的，它具有发送和接收两个操作，而且这两个操作的运算符都是&lt;-。ch &lt;- 2 //发送数值2给这个通道x:=&lt;-ch //从通道里读取值，并把读取的值赋值给x变量&lt;-ch //从通道里读取值，然后忽略看例子，慢慢理解发送和接收的用法。发送操作&lt;-在通道的后面，看箭头方向，表示把数值2发送到通道ch里；接收操作&lt;-在通道的前面，而且是一个一元操作符，看箭头方向，表示从通道ch里读取数据。读取的数据可以赋值给一个变量，也可以忽略。通道我们还可以使用内置的close函数关闭。close(ch) 无缓冲的通道无缓冲的通道指的是通道的大小为0，也就是说，这种类型的通道在接收前没有能力保存任何值，它要求发送goroutine和接收goroutine同时准备好，才可以完成发送和接收操作。 从上面无缓冲的通道定义来看，发送goroutine和接收gouroutine必须是同步的，同时准备后，如果没有同时准备好的话，先执行的操作就会阻塞等待，直到另一个相对应的操作准备好为止。这种无缓冲的通道我们也称之为同步通道。 func main() &#123; ch := make(chan int) go func() &#123; var sum int = 0 for i := 0; i &lt; 10; i++ &#123; sum += i &#125; ch &lt;- sum &#125;() fmt.Println(&lt;-ch)&#125; 有缓冲的通道有缓冲通道，其实是一个队列，这个队列的最大容量就是我们使用make函数创建通道时，通过第二个参数指定的。 ch := make(chan int, 3)这里创建容量为3的，有缓冲的通道。对于有缓冲的通道，向其发送操作就是向队列的尾部插入元素，接收操作则是从队列的头部删除元素，并返回这个刚刚删除的元素。 当队列满的时候，发送操作会阻塞；当队列空的时候，接受操作会阻塞。有缓冲的通道，不要求发送和接收操作时同步的，相反可以解耦发送和接收操作。 想知道通道的容量以及里面有几个元素数据怎么办？其实和map一样，使用cap和len函数就可以了。 cap(ch)len(ch) cap函数返回通道的最大容量，len函数返回现在通道里有几个元素。 func mirroredQuery() string &#123; responses := make(chan string, 3) go func() &#123; responses &lt;- request(&quot;asia.gopl.io&quot;) &#125;() go func() &#123; responses &lt;- request(&quot;europe.gopl.io&quot;) &#125;() go func() &#123; responses &lt;- request(&quot;americas.gopl.io&quot;) &#125;() return &lt;-responses // return the quickest response&#125;func request(hostname string) (response string) &#123; /* ... */ &#125; 单向通道有时候，我们有一些特殊场景，比如限制一个通道只可以接收，但是不能发送；有时候限制一个通道只能发送，但是不能接收，这种通道我们称为单向通道。这个在生产者消费者很实用。 定义单向通道也很简单，只需要在定义的时候，带上&lt;-即可。 var send chan&lt;- int //只能发送var receive &lt;-chan int //只能接收","tags":["go"],"categories":["go"]},{"title":"利用jenkins发布代码","path":"/2019/07/31/194/","content":"安装jenkinsdocker run \\ -u root \\ --rm \\ -d \\ -p 8090:8080 \\ -p 50000:50000 \\ -v jenkins-data:/var/jenkins_home \\ -v /var/run/docker.sock:/var/run/docker.sock \\ jenkinsci/blueocean 进入容器查看密码： docker exec -it 6d1a7f988069 /bin/bash 密码存储路径 /var/jenkins_home/secrets/initialAdminPassword jenkins关联git，拉取无需密码验证// 产生公钥与私钥对.ssh-keygen// 用ssh-copy-id将公钥复制到远程机器中(gitlab等)ssh-copy-id -i .ssh/id_rsa.pub git@xxx.com jenkins关联代码服务器，同步无需密码验证// 尽量使用内网ipscp -p .ssh/id_rsa.pub www@172.17.158.15:/home/www/.ssh/authorized_keys 新建项目 选择自由风格项目 Source Code Management填写git地址 Build执行shell脚本 shell demo #!/bin/bashecho $&#123;BUILD_USER&#125;SOURCE_DIR=/var/jenkins_home/workspace/$&#123;JOB_NAME&#125;/DEST_DIR=/usr/local/nginx/html/jenkinsREMOTE_IP=172.17.158.15scp -r $SOURCE_DIR www@$REMOTE_IP:$DEST_DIR 保存后点击构建。原理：jenkins拉取git代码jenkins服务器，scp同步代码到代码服务器。 易出错点： 服务器目录权限问题 git拉取ssh验证 目录 构建时可查看Console Output信息，能看出哪一步错误，然后处理即可。","tags":["jenkins"],"categories":["CI"]},{"title":"nginx日志按日配置","path":"/2019/07/23/Nginx8/","content":"老实说，我觉得nginx没有日志按日配置功能缺失有点费解，不过我们可以通过代码实现。配置如下： if ($time_iso8601 ~ &quot;^(\\d&#123;4&#125;)-(\\d&#123;2&#125;)-(\\d&#123;2&#125;)&quot;) &#123; set $day $1$2$3;&#125;access_log logs/access-$day.log main;","tags":["Nginx"],"categories":["Nginx"]},{"title":"lua+nginx实现黑名单禁止访问","path":"/2019/07/16/192/","content":"Lua 是可以很好地和Nginx配合使用的，带直接使用 Nginx 是需要安装扩展的，这里我们力求简单，省去安装，使用OpenResty（基于 Nginx 与 Lua 的高性能 Web 平台），地址:OpenResty地址 说明：我是在windows7电脑上测试使用 主要配置代码如下： lua_shared_dict ip_blacklist 1m;server &#123; listen 80; server_name localhost; root E:/www/web/test; access_log logs/host.access.log ; error_log logs/host.error.log; location / &#123; access_by_lua_file ../lua/black.lua; index index.html index.htm; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; location ~ \\.php$ &#123; access_by_lua_file &quot;D:\\openresty-1.15.8.1-win64/lua/black.lua&quot;; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; &#125;&#125; 简要说明: lua_shared_dict 分配给ip_blacklist的内存，可根据业务量自行决定access_by_lua_file 指定 lua 文件 black.lua 代码如下[说明较多，直接放注释了]: local Redis_host = &quot;127.0.0.1&quot; -- Redis的IP地址local Redis_port = &quot;6379&quot;-- 连接超时时间，单位ms，不建议设置太高local Redis_connection_timeout = 1000local Redis_key = &quot;ip_blacklist&quot;-- 缓存时间，单位 slocal cache_ttl = 100-- 以上是配置local ip = ngx.var.remote_addrlocal ip_blacklist = ngx.shared.ip_blacklistlocal last_update_time = ip_blacklist:get(&quot;last_update_time&quot;);-- 当缓存时间到期更新blacklistif last_update_time == nil or last_update_time &lt; ( ngx.now() - cache_ttl ) then local Redis = require &quot;resty.Redis&quot;; local red = Redis:new(); red:set_timeout(Redis_connect_timeout); local ok, err = red:connect(Redis_host, Redis_port); if not ok then ngx.say(&quot;Redis connect failed: &quot;, err) ngx.log(ngx.DEBUG, &quot;Redis connection error while retrieving ip_blacklist: &quot; .. err); return ngx.exit(ngx.HTTP_INTERNAL_SERVER_ERROR) else -- local res, err = red:auth(&quot;foobared&quot;) -- 配置Redis的密码，我测试未设置密码，代码注释 --if not res then --ngx.say(&quot;Redis auth is error: &quot;, err) --return --end red:select(0) local new_ip_blacklist, err = red:smembers(Redis_key); if err then ngx.log(ngx.DEBUG, &quot;Redis read error while retrieving ip_blacklist: &quot; .. err); else -- 情况本地存储 ip_blacklist:flush_all(); for index, banned_ip in ipairs(new_ip_blacklist) do ip_blacklist:set(banned_ip, true); end -- 更新时间 ip_blacklist:set(&quot;last_update_time&quot;, ngx.now()); end endendif ip_blacklist:get(ip) then --ngx.say(ip) ngx.log(ngx.DEBUG, &quot;Banned IP detected and refused access: &quot; .. ip); return ngx.exit(ngx.HTTP_FORBIDDEN);end 这样就完成了一个黑名单功能完成。 当然了，这只是个基础版本，你可以让这个禁止访问功能更强大，比如增加可疑ip写入，比如增加ip限流等等。","tags":["Linux"],"categories":["linux"]},{"title":"Laravel管理日志","path":"/2019/07/04/191/","content":"日志是很重要的东西，那么如何配置能让Laravel更好管理和查看呢？ 按日查看设置简单，在.env加入APP_LOG=daily，另外可定义最大日志保存天数在配置文件config/app.php中添加如下代码：log_max_files=&gt;30 收集重要日志Log::useFiles(storage_path(logs/important.log));// 按日，存储30天的Log::useDailyFiles(storage_path(logs/importantDaily.log, 30));","tags":["Laravel"],"categories":["PHP"]},{"title":"Laravel模板渲染的问题","path":"/2019/05/22/189/","content":"1. laravel模板变量符更改前几天改版时，前后端分离，前端使用了art-template，刚好有和Laravel默认的变量符号，就发现了点问题。 解决方法： 前端修改art-template的符号，防止和Laravel冲突； 修改Laravel模板变量符-双大括号 可以在控制器调用view方法之前加入 Blade::setContentTags([[, ]]);Blade::setEscapedContentTags(&#123;[@, @]&#125;); 便可以用{[@, @]}替代原来的双大括号。 2. 加载html不使用blade模板引擎除了这个还有一个问题，比如前后端分离的时候，我只想加载html，不需要渲染替换，这时候怎么办呢？ Route::get(/, function () &#123; \\View::addExtension(html, php); return view()-&gt;file(index.html);//注意此处路径是public&#125;); 就这样加载就ok 了。","tags":["Laravel"],"categories":["PHP"]},{"title":"Linux的top命令详解","path":"/2019/04/26/186/","content":"top命令是Linux下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，常用于服务端性能分析。 统计信息区前五行是系统整体的统计信息。具体如下： 第一行服务器运行信息：09:46:41 当前时间up 71days，16:51 系统运行时间，格式为天，时:分2 users 当前登录用户数load average: 0.00, 0.00, 0.00 系统负载，即任务队列的平均长度。三个数值分别为 1分钟、5分钟、15分钟前到现在的平均值。 第二行为进程信息Tasks:total 进程总数running 正在运行的进程数sleeping 睡眠的进程数stopped 停止的进程数zombie 僵尸进程数第三行CPU信息Cpu(s): 0.5% us 用户空间占用CPU百分比0.3% sy 内核空间占用CPU百分比0.0% ni 用户进程空间内改变过优先级的进程占用CPU百分比99.0% id 空闲CPU百分比0.0% wa 等待输入输出的CPU时间百分比0.2%hi：硬件CPU中断占用百分比0.0%si：软中断占用百分比0.0%st：虚拟机占用百分比 第四行Mem内存信息:8189652k total 物理内存总量7885740k used 使用的物理内存总量303912k free 空闲内存总量566272k buffers 用作内核缓存的内存量第五行swap交换分区信息: 4194300k total 交换区总量15544k used 使用的交换区总量4178756k free 空闲交换区总量1318852k cached 缓存的交换区总量，即可用交换区内存 当然，也推荐使用其他运行分析可视化工具，如htop，功能相比top更为强大。","tags":["Linux"],"categories":["linux"]},{"title":"windows下的elasticsearch尝试","path":"/2019/04/10/183/","content":"环境：windows7 64位 ElasticSearch（后面简称es）基于java，所以务必先安装java，java安装省略，建议安装最新的稳定版。 安装eses下载 解压后进入目录，启动bin/elasticsearch.bat 访问： http://localhost:9200/ 可以看到一些信息，版本等，就表明已经安装病启动成功！ 安装HEAD插件 git clone git://github.com/mobz/elasticsearch-head.gitcd elasticsearch-headnpm installnpm run start 浏览器打开， http://localhost:9100/，可以看到刚开启动的ES实例。 伪集群打开config下得elasticsearch.yml 加入以下配置： # 自定义配置cluster.name: sai_esnode.name: es0node.master: truehttp.port: 9200 复制es文件夹到es1,es2,修改配置: es1:# 自定义配置cluster.name: sai_esnode.name: es1node.master: falsehttp.port: 9201discovery.zen.ping.unicast.hosts: [&quot;127.0.0.1&quot;]es2:# 自定义配置cluster.name: sai_esnode.name: es2node.master: falsehttp.port: 9202discovery.zen.ping.unicast.hosts: [&quot;127.0.0.1&quot;] 注意，此时要保证es1，es2下面data目录为空，否则启动时会因为冲突id连接不上es0。 然后启动es1，es2，通过head插件，我们可以看到集群搭建完成！sai_es集群下有3个实例：es0，es1，es2。 集群搭建成功！","tags":["ElasticSearch"],"categories":["ElasticSearch"]},{"title":"Redis集群配置","path":"/2019/03/29/182/","content":"Redis Cluster 是什么Redis Cluster 是 Redis 的分布式实现，官网说明中阐述了以下几点目标： 高性能和线性可扩展性高达 1000 个节点。没有代理，使用异步复制，不对值执行合并操作。 可接受的写入安全程度：系统尝试（以最大努力的方式）保留所有来自与大多数主节点连接的客户端的写入。通常有一些小窗口，其中确认的写入可能会丢失。当客户端位于少数分区中时，丢失已确认写入的窗口更大。 可用性：Redis 集群能够在大多数主节点可访问的分区中存活下来，并且每个不再可访问的主节点至少有一个可访问 环境 centos7.5，Redis5.0.0 Redis 下载后安装在合适的目录，我是安装在/usr/local/Redis-5.0.0下，过程比较简单，就不赘述了。【官网提及3.0之后的版本即可支持集群操作】 配置同级下新建cluster文件夹，拷贝 redis.conf 文件进来，copy 4个文件Redis_2001.conf、Redis_2002.conf、Redis_2003.conf、Redis_2004.conf，修改对应配置，主要是端口，节点配置 rdb aof 等。 可参考配置如下： # 端口号port 2001# 后台启动daemonize yes# 开启集群cluster-enabled yes# 集群节点配置文件cluster-config-file nodes-2001.conf# 进程pid的文件位置pidfile /var/run/Redis-2001.pid# 持久化配置# 开启aofappendonly yes# aof文件路径appendfilename &quot;appendonly-2001.aof&quot;# rdb文件路径dbfilename dump-2001.rdb 启动根据上述配置文件依次启动Redis进程 redis-server cluster/Redis-2001.confredis-server cluster/Redis-2002.confredis-server cluster/Redis-2003.confredis-server cluster/Redis-2004.conf 启动完成后，照着某个文章说明连接构建Redis集群: ./Redis-trib.rb create –replicas 1 127.0.0.1:2001 127.0.0.1:2002 127.0.0.1:2003 127.0.0.1:2004 抛出警告： WARNING: Redis-trib.rb is not longer available! 查看文档发现：Redis 5.0彻底抛弃了ruby【优先看官方文档，优先看官方文档，优先看官方文档】 You should use redis-cli instead. 行，换redis-cli： redis-cli –cluster create 127.0.0.1:2001 127.0.0.1:2002 127.0.0.1:2003 127.0.0.1:2004 –cluster-replicas 1 又有错误，输出如下： *** ERROR: Invalid configuration for cluster creation.*** Redis Cluster requires at least 3 master nodes.*** This is not possible with 4 nodes and 1 replicas per node.*** At least 6 nodes are required. 因为是单机测试而已，去掉复制，至少6个节点 我们先忽略。 Redis-cli –cluster create 127.0.0.1:2001 127.0.0.1:2002 127.0.0.1:2003 127.0.0.1:2004 然后有个保存配置的确认，yes之后启动成功！ [OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered. 进入客户端 redis-cli -p 2001 查看节点: cluster nodes 90a734c7716a00060584acb82cb3dd7e437a5459 127.0.0.1:2003@12003 master - 0 1541042930063 3 connected 8192-122877ac1fab72c275ba9549a9da71245fdd29a3920a6 127.0.0.1:2002@12002 master - 0 1541042930563 2 connected 4096-8191490035c372472798a224b6d00c249d8b41508b78 127.0.0.1:2001@12001 myself,master - 0 1541042928000 1 connected 0-40959101d285b991c6dcb086cf3da4cd0eae7777ece0 127.0.0.1:2004@12004 master - 0 1541042929563 4 connected 12288-16383 可以看出集群已搭建成功！你可以进行测试了。 当然需要说明的是，这只是我们自己测试用，产线上还是需要开启复制，且按需配置节点，至少 6 个，不然叫啥高可用，还不如单机使用。","tags":["Redis"],"categories":["Redis"]},{"title":"php小试rabbitmq","path":"/2019/03/29/181/","content":"RabbitMQ is lightweight and easy to deploy on premises and in the cloud. It supports multiple messaging protocols. RabbitMQ can be deployed in distributed and federated configurations to meet high-scale, high-availability requirements. 1. 安装：windows安装十分简单，印象中装的过程几乎无障碍，忽略。 centos7安装过程如下： 依赖安装 yum -y install make gcc gcc-c++ kernel-devel m4 ncurses-devel openssl-devel unixODBC-devel socat 安装erlang，务必在下面的地址下载，之前在官网下载，安装总是有问题，浪费了大把时间。 https://dl.bintray.com/rabbitmq/rpm/erlang/20/el/7/ 官网下载rabiitmq，rpm安装 rpm -ivh (rpm包) 2. 配置启动rabbitmq /bin/systemctl start rabbitmq-server.service 片刻之后，可以查看状态是否active bin/systemctl status rabbitmq-server.service cp rabbitmq.config.example /etc/rabbitmq/cd /etc/rabbitmq/mv rabbitmq.config.example rabbitmq.config 修改成你想要的配置，然后重启。 3. UI启动 rabbitmq-plugins enable rabbitmq_management 然后根据配置打开界面 安全性问题，可以禁止外部guest访问，新建账户 rabbitmqctl add_user puresai 12345678rabbitmqctl set_user_tags puresai administrator 并修改配置： {loopback_users, [&lt;&lt;”guest”&gt;&gt;]} 重启rabbitmq服务。 4. 简单实例生产者： &lt;?php/** * Created by PhpStorm. * User: puresai * Date: 2018/11/5 * Time: 10:39 */// 配置信息$config = [ host =&gt; localhost, port =&gt; 5672, login =&gt; sai, password =&gt; 123456, vhost=&gt;/];$exName = changes; //交换机名$route = key; //路由key// 创建连接和channel$conn = new AMQPConnection($config);if (!$conn-&gt;connect()) &#123; die(&quot;连接失败&quot;);&#125;$channel = new AMQPChannel($conn);//消息内容$message = &quot;消息测试&quot;;//创建交换机$ex = new AMQPExchange($channel);$ex-&gt;setName($exName);//发送消息，注意持久化也要设置[delivery_mode =&gt; AMQP_DURABLE]for($i=0; $i&lt;5; $i++)&#123; echo &quot;Send Message:&quot;.$ex-&gt;publish($i.:.$message, $route, AMQP_DURABLE, [delivery_mode =&gt; AMQP_DURABLE]).&quot;&quot;;&#125;$conn-&gt;disconnect(); 消费者： &lt;?php/** * Created by PhpStorm. * User: puresai * Date: 2018/11/5 * Time: 10:39 */$config = [ host =&gt; localhost, port =&gt; 5672, login =&gt; sai, password =&gt; 123456, vhost=&gt;/];$exName = changes; //交换机名$queueMame = queue1; //队列名$route = key; //路由key// 创建连接和channel$conn = new AMQPConnection($config);if (!$conn-&gt;connect()) &#123; die(&quot;连接失败&quot;);&#125;$channel = new AMQPChannel($conn);// 创建交换机$ex = new AMQPExchange($channel);$ex-&gt;setName($exName);$ex-&gt;setType(AMQP_EX_TYPE_DIRECT); //direct类型$ex-&gt;setFlags(AMQP_DURABLE); //持久化，很重要echo &quot;Exchange Status:&quot;.$ex-&gt;declare().&quot;&quot;;// 创建队列$queue = new AMQPQueue($channel);$queue-&gt;setName($queueMame);$queue-&gt;setFlags(AMQP_DURABLE); //持久化echo &quot;Message Total:&quot;.$queue-&gt;declare().&quot;&quot;;//绑定交换机与队列，并指定路由键echo Queue Bind: .$queue-&gt;bind($exName, $route).&quot;&quot;;//阻塞模式接收消息echo &quot;Message:&quot;;while(True)&#123; $queue-&gt;consume(processMessage);&#125;$conn-&gt;disconnect();/** * 消费回调函数 * 处理消息 */function processMessage($envelope, $queue) &#123; $msg = $envelope-&gt;getBody(); echo $msg.&quot;&quot;; //处理消息 $queue-&gt;ack($envelope-&gt;getDeliveryTag()); //手动发送ACK应答&#125; 花了些时间，不过弄出来还是感觉不错的。","tags":["RabbitMQ"],"categories":["MQ"]},{"title":"LNMP设置开机自启动","path":"/2019/03/29/180/","content":"服务器重启后，一步步启动各种程序是个非常麻烦也是容易出错的事情，遇到过不止一次，有某个服务忘记起来的情况，必须得彻底解决这种问题，这种情况我们可以尝试配置开机自启动。 环境centos 7.5 我的版本跟低版本有很多不同，不能通过chkconfig add命令加入自启动，我们先进入目录 /lib/systemd/system 依次新建若干个服务： mysqld.service [Unit]Description=mysqlAfter=network.target[Service]Type=forkingExecStart=/usr/bin/mysql.serverExecReload=/bin/systemctl restart mysqld.serviceExecStop=/bin/systemctl stop mysqld.servicePrivateTmp=true[Install]WantedBy=multi-user.target nginx.service[Unit]Description=nginxAfter=network.target[Service]Type=forkingExecStart=/usr/bin/nginxExecReload=/usr/bin/nginx -s reloadExecStop=/usr/bin/nginx -s quitPrivateTmp=true[Install]WantedBy=multi-user.target php-fpm.service[Unit]Description=php-fpmAfter=network.target[Service]Type=forkingExecStart=/usr/bin/php-fpmExecReload=ps -ef|grep php-fpm|awk -F &#123;print &#125;|xargs kill -USR2ExecStop=ps -ef|grep php-fpm|awk -F &#123;print &#125;|xargs kill -INTPrivateTmp=true[Install]WantedBy=multi-user.target Redis.service[Unit]Description=RedisAfter=network.target[Service]Type=forkingExecStart=/usr/bin/Redis-server /usr/local/Redis-5.0.0/Redis.confExecStop=/usr/local/Redis-5.0.0/Redis-cli shutdownPrivateTmp=true[Install]WantedBy=multi-user.target ExecStart, ExecStop, ExecReload各有不同，可根据业务自行修改 并且把尚需几个服务 systemctl enable 启动。 测试完成后我们重启机器： reboot 测试一下【别再生产随意reboot哟】，几个定义的服务都陆续启动成功。 参数说明主要有以下三部分 [unit] :定义与Unit类型无关的通用选项；用于提供unit的描述信息、 unit行为及依赖关系等 [Service]：与特定类型相关的专用选项；此处为Service类型 [Install]：定义由“ systemctl enable”以及”systemctl disable“命令在实现服务启用或禁用时用到的一些选项 Service参数： EnvironmentFile：环境配置文件 ExecStart：指明启动unit要运行命令或脚本的绝对路径 ExecStartPre： ExecStart前运行 ExecStartPost： ExecStart后运行 ExecRsload: 重启当前服务时执行的命令 ExecStopPost：停止当前服务之后执行的命令 ExecStartSec：自动重启当前服务间隔的秒数 ExecStop：指明停止unit要运行的命令或脚本 Restart：当设定Restart=1时，则当次daemon服务意外终止后，会再次自动启动此服务。 TimeoutSec：定义 Systemd 停止当前服务之前等待的秒数。 Environment：指定环境变量。 Install参数： Alias：别名，可使用systemctl command Alias.service RequiredBy：被哪些units所依赖，强依赖 WantedBy：被哪些units所依赖，弱依赖 Also：安装本服务的时候还要安装别的相关服务 参考 在linux下创建自定义服务 linux中的unit的配置文件","tags":["Linux"],"categories":["linux"]},{"title":"2018,这一年","path":"/2019/02/04/2018/","content":"大家，过年好啊！ 今天是除夕，窗外还有一阵阵的鞭炮声，现在吃完午饭不久，爸妈买东西去了，一人在家，暂时无事，写下这篇年终总结。 工作今年工作的主题词应该是——加班。 一年的节奏是从春节后的清闲到四月份的偶尔加班到夏季的接连两个项目的996，再到10月份新入职后的缓慢的熟悉，最后又是项目重构的996…… 今年的技术成长是很明显的，从简单的业务实现到追求业务效率再到年末高可用的研究。学习、了解很多之前从没用过的技术，也尝试了一些更深入的源码级别的探索。虽然自己捣鼓的这些不一定对未来的工作有用，但兴致盎然，一如七月份写《魏晋史话》的热情。 除了技术上的，心态角度上也有了变化，会有自己看待问题和处理问题的方式，即便我不知道这些转变是好是坏，或者说我无法去评判这些是好是坏。只是转变似乎能自己工作地更为轻松顺畅，不容易出现倦怠感。 成长固然可喜，然而学无涯知亦无涯。随着学习和工作的深入，认识到自己可以去研究更多更高效更先进的中间件、设计模式、技术栈，以及可能比技术可能更有力的与人协作沟通的“tips”。 生活工作是一件重要的事，然而过好自己的生活更是一件重要的事。 生活的主题词是—–质感。 以下段落毫无连贯性可言，预警。 七月份写《魏晋史话》的《八王之乱》真的是一件特别有趣的事情，但同时也是一件耗费心力的事。全文五千多字，花了前后十天，增删改n次，完成的满意度很高。但也因此让这个系列夭折（“出道即巅峰”，感觉后面压根写不出来能盖过这篇风头的了）。 近两年感觉身体状况和活动量远不比大学时期，恰好新住处离健身房很近，加班之后去健身房又没什么激情，便早起健身，11月中旬一直坚持了到假期前，虽然体重变化很小，但体脂率有小幅下降，白天工作的精神状态要比之前好很多。 换工作后双休，又想起了近一年没去上课的乐器课程，便继续去学习剩余课程，现在自己也能保证平均两天一次的练习，课上也不再拘谨，也能跟老师唠唠嗑，说说笑。 很遗憾的是，相机用的次数屈指可数，所以水平可想而知，看了一些摄影技巧和构图的书，然而更应该去实践与尝试。 看电影依旧是最大的娱乐活动，会去做一些评价，演技、镜头、配乐，还有剧情。看片量不及去年，但也看了几部好电影。 书籍方面，文学方面的书看得很少了，印象中有毛姆的《月亮与六便士》和卡尔维诺的《树上的男爵》，其他的我有点想不起了。更多是技术方面的书，不会通篇读完，一般都是读感兴趣的点。 其他的，还有么？ 其他碎碎念 总是对时下有热度的事物有所抵触，比如大热的剧，大热的作者，大热的科技产品。唯独除了大热的电影，我不知道是为了凸显个人立场还是其他什么，总觉得，时下大热的总要经过时间的选择。若真的那么好，我倒是乐意去试试看。社会很浮华，如今我也很浮躁，只希望很多时候，纯粹一点，随性一点，虽然很多时候很难，但终究还有些许内立的度与不被外化的些许抵抗。 – 2018-07-10 旅行能带给我的是什么，并没有那么畅快，是因为独自的原因？我想也不是，是去的地方不够触动我的心么？我不知道。 旅行能带来的并没有那么多，并没有让自己心静，也没有带来那么多精神方面的，多读些书吧，多听点好音乐，多看好电影。– 2018-09-23 最后依旧改吴文英的半阙词祝大家除夕快乐，新年顺意。 自唱新词送岁华。亲友伴我醉生涯。十年寻梦终归处，几度新春共繁华。 2019/02/04戊戌除夕记at 安庆","tags":["oneyear"],"categories":["oneyear"]},{"title":"如何恢复误删的数据库","path":"/2019/01/11/176/","content":"前段时间，某开发人员误删了一个数据库，导致我们的服务，最后是恢复了，过程我并不清楚，但引起了我的兴趣。因为误操作真的是很难避免的，开发人员那么多，一个不小心，就可能影响了其他人的使用，所以慎重操作，最好能禁用一些操作，比如drop！ 那么如何来恢复呢？ 如果有备份的话，当然去寻找最新的，然后恢复，如果不在意新增的数据，那么这样就足够了。 来看一下备份， // 备份某个数据库某些表mysqldump [options] db_name [tbl_name ...] &gt; bak.sql// 备份多个数据库mysqldump [options] --databases db_name ...&gt; bak.sql// 备份所有数据库mysqldump [options] --all-databases&gt; bak.sql 个人建议单个备份，好独立操作。 了解更多请看：mysqldump 恢复操作（以单个数据库为例） mysql -h127.0.0.1 -uroot -p del &lt; bak.sql 操作是不是很简单？ 那么如果没有备份怎么办呢？ 第二种操作前提是开启了binlog，通过log恢复。 误删后可以保存下binlog mysqlbinlog mysql-bin.000011 &gt; del.log 打开文件，去掉drop操作并保存。 mysql -h127.0.0.1 -uroot -p &lt;del.log 当然，比较建议通过dump全备份操作，然后找出备份到drop的pos。 通过mysqlbinlog 的start-position和stop-position生成sql后恢复。这里就不赘述了。 有兴趣可以看看mysqlbinlog 好了，就说到这里，希望对你有所帮助。","tags":["MySQL"],"categories":["db"]},{"title":"MySQL高可用探讨（读写分离）","path":"/2018/12/30/175/","content":"上一篇我们聊到TP做读写分离的底层实现，相对来说，其实思路是清晰简单的，但这些其实都是基于数据库已经做到了主从配置。 如果你不知道，可以mysql主从实战 建议给从库单独开个账号只授权读的权限，而不是设置slave为read_only（我配置了，but没啥用） 但我们稍微深入思考一下，PHP框架里有做到高可用吗？加入从库其中一个挂了，照着TP的思路，依旧有可能去这个从库读取数据，这是我们不能接受的。 一主一从甚至一主多从的架构显然只能满足读写性能，而不能保证服务的高可用。我们知道任何一个服务挂掉的可能性都是存在的，我们说的高可用只能是尽可能小的避免整个服务挂掉的可能。由此你应该能想到多主多从，这个仅仅文章里的配置是完成不了的，PHP框架也是检测不了的。 我觉得PHP框架来做读写分离是不科学的，因为增加了代码的复杂度，我认为这些应该交给数据库来做，或者数据库中间件来做，各司其职吗。 我不知道是不是很多人会想到mysql_proxy，然而官方已经不推荐使用了，推荐使用mysql_router，有在自己的ECS上尝试了一下，配置相对还是简单的，没测试性能，但确实实现了一定程度的高可用。 当然你也可以去使用变形虫等中间件，他们的功能相比mysql_router更为强大。 此篇没有干货，只是纯技术探讨，我不过是在南京南站，没事码码字罢了！","tags":["sql"],"categories":["db"]},{"title":"ThinkPHP读写分离的内部实现","path":"/2018/12/17/174/","content":"分析的版本是TP3.2.3 此版本已经支持mysql数据库读写分离，配置比较简单，具体可看分布式数据库支持 我们尝试分析下源码实现： 不妨先yy一下，在写操作和读操作时区分开数据库连接分别连接master和slave。 我们可以看见Model.class.php的db初始化 public function db($linkNum = , $config = , $force = false) &#123; if ( === $linkNum &amp;&amp; $this-&gt;db) &#123; return $this-&gt;db; &#125; if (! isset ( $this-&gt;_db [$linkNum] ) || $force) &#123; // 创建一个新的实例 if (! empty ( $config ) &amp;&amp; is_string ( $config ) &amp;&amp; false === strpos ( $config, / )) &#123; // 支持读取配置参数 $config = C ( $config ); &#125; $this-&gt;_db [$linkNum] = Db::getInstance ( $config ); &#125; elseif (NULL === $config) &#123; $this-&gt;_db [$linkNum]-&gt;close (); // 关闭数据库连接 unset ( $this-&gt;_db [$linkNum] ); return; &#125; // 切换数据库连接 $this-&gt;db = $this-&gt;_db [$linkNum]; $this-&gt;_after_db (); // 字段检测 if (! empty ( $this-&gt;name ) &amp;&amp; $this-&gt;autoCheckFields) $this-&gt;_checkTableInfo (); return $this;&#125; 接着看DB单例， static public function getInstance($config = array()) &#123; $md5 = md5 ( serialize ( $config ) ); if (! isset ( self::$instance [$md5] )) &#123; // 解析连接参数 支持数组和字符串 $options = self::parseConfig ( $config ); // 兼容mysqli if (mysqli == $options [type]) $options [type] = mysql; // 如果采用lite方式 仅支持原生SQL 包括query和execute方法 $class = $options [lite] ? ThinkDbLite : Think\\Db\\Driver\\ . ucwords ( strtolower ( $options [type] ) ); if (class_exists ( $class )) &#123; self::$instance [$md5] = new $class ( $options ); &#125; else &#123; // 类没有定义 E ( L ( _NO_DB_DRIVER_ ) . : . $class ); &#125; &#125; self::$_instance = self::$instance [$md5]; return self::$_instance;&#125; 接着看见mysql驱动继承了抽象类Driver。 不妨找两个Model操作读（find）和写(add): public function find($options = array()) &#123; ... $resultSet = $this-&gt;db-&gt;select ( $options ); ...&#125;public function add($data = , $options = array(), $replace = false) &#123; ... $result = $this-&gt;db-&gt;insert ( $data, $options, $replace ); ...&#125; 我们只聚焦关键代码select 和insert 。然后去查看数据库驱动类代码： public function select($options = array()) &#123; ... $result = $this-&gt;query ( $sql, ! empty ( $options [fetch_sql] ) ? true : false ); ...&#125;public function insert($data, $options = array(), $replace = false) &#123; ... return $this-&gt;execute ( $sql, ! empty ( $options [fetch_sql] ) ? true : false );&#125; 继续寻根，我们看见 /** * 执行查询 返回数据集 */public function query($str, $fetchSql = false) &#123; $this-&gt;initConnect ( false ); ...&#125;/** * 执行语句 */public function execute($str, $fetchSql = false) &#123; $this-&gt;initConnect ( true ); ...&#125; 我们终于找到了根本， /** * 初始化数据库连接 * * @access protected * @param boolean $master * 主服务器 * @return void */\tprotected function initConnect($master = true) &#123; if (! empty ( $this-&gt;config [deploy] )) // 采用分布式数据库 $this-&gt;_linkID = $this-&gt;multiConnect ( $master ); else // 默认单数据库 if (! $this-&gt;_linkID) $this-&gt;_linkID = $this-&gt;connect ();\t&#125; /** * 连接分布式服务器 * * @access protected * @param boolean $master * 主服务器 * @return void */\tprotected function multiConnect($master = false) &#123; // 分布式数据库配置解析 $_config [username] = explode ( ,, $this-&gt;config [username] ); $_config [password] = explode ( ,, $this-&gt;config [password] ); $_config [hostname] = explode ( ,, $this-&gt;config [hostname] ); $_config [hostport] = explode ( ,, $this-&gt;config [hostport] ); $_config [database] = explode ( ,, $this-&gt;config [database] ); $_config [dsn] = explode ( ,, $this-&gt;config [dsn] ); $_config [charset] = explode ( ,, $this-&gt;config [charset] ); $m = floor ( mt_rand ( 0, $this-&gt;config [master_num] - 1 ) ); // 数据库读写是否分离 if ($this-&gt;config [rw_separate]) &#123; // 主从式采用读写分离 if ($master) // 主服务器写入 $r = $m; else &#123; if (is_numeric ( $this-&gt;config [slave_no] )) &#123; // 指定服务器读 $r = $this-&gt;config [slave_no]; &#125; else &#123; // 读操作连接从服务器 $r = floor ( mt_rand ( $this-&gt;config [master_num], count ( $_config [hostname] ) - 1 ) ); // 每次随机连接的数据库 &#125; &#125; &#125; else &#123; // 读写操作不区分服务器 $r = floor ( mt_rand ( 0, count ( $_config [hostname] ) - 1 ) ); // 每次随机连接的数据库 &#125; if ($m != $r) &#123; $db_master = array ( username =&gt; isset ( $_config [username] [$m] ) ? $_config [username] [$m] : $_config [username] [0], password =&gt; isset ( $_config [password] [$m] ) ? $_config [password] [$m] : $_config [password] [0], hostname =&gt; isset ( $_config [hostname] [$m] ) ? $_config [hostname] [$m] : $_config [hostname] [0], hostport =&gt; isset ( $_config [hostport] [$m] ) ? $_config [hostport] [$m] : $_config [hostport] [0], database =&gt; isset ( $_config [database] [$m] ) ? $_config [database] [$m] : $_config [database] [0], dsn =&gt; isset ( $_config [dsn] [$m] ) ? $_config [dsn] [$m] : $_config [dsn] [0], charset =&gt; isset ( $_config [charset] [$m] ) ? $_config [charset] [$m] : $_config [charset] [0] ); &#125; $db_config = array ( username =&gt; isset ( $_config [username] [$r] ) ? $_config [username] [$r] : $_config [username] [0], password =&gt; isset ( $_config [password] [$r] ) ? $_config [password] [$r] : $_config [password] [0], hostname =&gt; isset ( $_config [hostname] [$r] ) ? $_config [hostname] [$r] : $_config [hostname] [0], hostport =&gt; isset ( $_config [hostport] [$r] ) ? $_config [hostport] [$r] : $_config [hostport] [0], database =&gt; isset ( $_config [database] [$r] ) ? $_config [database] [$r] : $_config [database] [0], dsn =&gt; isset ( $_config [dsn] [$r] ) ? $_config [dsn] [$r] : $_config [dsn] [0], charset =&gt; isset ( $_config [charset] [$r] ) ? $_config [charset] [$r] : $_config [charset] [0] ); return $this-&gt;connect ( $db_config, $r, $r == $m ? false : $db_master );\t&#125; 其实就是通过传入initConnect来区分读写操作，并根据配置去连接操作。 今天分析就到这里了，其实与我们yy的基本一致。","tags":["ThinkPHP"],"categories":["PHP"]},{"title":"swoole发邮件","path":"/2018/11/29/171/","content":"Swoole：面向生产环境的 PHP 异步网络通信引擎 很早就知道了swoole，但一直没有实际用到生产中，最近在重构博客，就想着做点东西，先swoole发邮件练练手。 回顾下发邮件，我们使用PHPMailer来发送。 &lt;?php/** * Created by PhpStorm. * User: puresai * Date: 2018/11/29 * Time: 11:16 */require &#x27;../vendor/autoload.php&#x27;;use PHPMailer\\PHPMailer\\PHPMailer;use PHPMailer\\PHPMailer\\Exception;$mail = new PHPMailer(true);try &#123; //Server settings // $mail-&gt;SMTPDebug = 2; // Enable verbose debug output $mail-&gt;isSMTP(); // Set mailer to use SMTP $mail-&gt;Host = &#x27;smtp.163.com&#x27;; // Specify main and backup SMTP servers $mail-&gt;SMTPAuth = true; // Enable SMTP authentication $mail-&gt;Username = &#x27;sai@163.com&#x27;; // SMTP username $mail-&gt;Password = &#x27;*&#x27;; // SMTP password $mail-&gt;SMTPSecure = &#x27;tls&#x27;; // Enable TLS encryption, ssl also accepted $mail-&gt;Port = 25; // TCP port to connect to //收件人 $mail-&gt;setFrom(&#x27;sai@163.com&#x27;, &#x27;puresai&#x27;); $mail-&gt;addAddress(&#x27;957042781@qq.com&#x27;); // Name is optional $mail-&gt;addReplyTo(&#x27;957042781@qq.com&#x27;, &#x27;Information&#x27;);// $mail-&gt;addCC(&#x27;cc@example.com&#x27;);// $mail-&gt;addBCC(&#x27;bcc@example.com&#x27;); //附件 $mail-&gt;addAttachment(&#x27;/var/file.tar.gz&#x27;); // Add attachments $mail-&gt;addAttachment(&#x27;/tmp/image.jpg&#x27;, &#x27;new.jpg&#x27;); // Optional name //html $mail-&gt;isHTML(true); $mail-&gt;Subject = &#x27;Here is the subject&#x27;; $mail-&gt;Body = &#x27;This is the HTML message body &lt;b&gt;in bold!&lt;/b&gt;&#x27;; $mail-&gt;AltBody = &#x27;This is the body in plain text for non-HTML mail clients&#x27;; $mail-&gt;send(); echo &#x27;Message has been sent&#x27;;&#125; catch (Exception $e) &#123; echo &#x27;Message could not be sent.&#x27;; echo &#x27;Mailer Error: &#x27; . $mail-&gt;ErrorInfo;&#125; 运行发送，收到邮件。 主程序&lt;?php/** Created by PhpStorm. User: puresai Date: 2018/11/29 Time: 14:06/require dirname(DIR).&#x27;/vendor/autoload.php&#x27;;use PHPMailer\\PHPMailer\\PHPMailer;use PHPMailer\\PHPMailer\\Exception;class Mailer&#123; protected $server; protected $host = &#x27;127.0.0.1&#x27;; protected $port = 9502; // 进程名称 protected $taskName = &#x27;swooleMailer&#x27;; // PID路径 protected $pidPath = &#x27;/run/swooleMail.pid&#x27;; // 设置运行时参数 protected $options = [ &#x27;worker_num&#x27; =&gt; 4, //worker进程数,一般设置为CPU数的1-4倍 &#x27;daemonize&#x27; =&gt; true, //启用守护进程 &#x27;log_file&#x27; =&gt; &#x27;/data/logs/swoole.log&#x27;, //指定swoole错误日志文件 &#x27;log_level&#x27; =&gt; 0, //日志级别 范围是0-5，0-DEBUG，1-TRACE，2-INFO，3-NOTICE，4-WARNING，5-ERROR &#x27;dispatch_mode&#x27; =&gt; 1, //数据包分发策略,1-轮询模式 &#x27;task_worker_num&#x27; =&gt; 4, //task进程的数量 &#x27;task_ipc_mode&#x27; =&gt; 3, //使用消息队列通信，并设置为争抢模式 //&#x27;heartbeat_idle_time&#x27; =&gt; 600, //一个连接如果600秒内未向服务器发送任何数据，此连接将被强制关闭 //&#x27;heartbeat_check_interval&#x27; =&gt; 60, //启用心跳检测，每隔60s轮循一次 ]; // 邮件服务器配置 protected $mailConfig = [ &#x27;smtp_host&#x27; =&gt; &#x27;smtp.163.com&#x27;, &#x27;username&#x27; =&gt; &#x27;sai0556@163.com&#x27;, &#x27;password&#x27; =&gt; &#x27;xmw1015&#x27;,// SMTP 密码/口令 &#x27;secure&#x27; =&gt; &#x27;ssl&#x27;, //Enable TLS encryption, ssl also accepted &#x27;port&#x27; =&gt; 465, // tcp邮件服务器端口 ]; public function __construct($mailConfig, $options = []) &#123; // 构建Server对象，监听端口 $this-&gt;server = new swoole_server($this-&gt;host, $this-&gt;port); if (!empty($options)) &#123; $this-&gt;options = array_merge($this-&gt;options, $options); &#125; $this-&gt;server-&gt;set($this-&gt;options); $this-&gt;mailConfig = $mailConfig; // 注册事件 $this-&gt;server-&gt;on(&#x27;Start&#x27;, [$this, &#x27;onStart&#x27;]); $this-&gt;server-&gt;on(&#x27;Connect&#x27;, [$this, &#x27;onConnect&#x27;]); $this-&gt;server-&gt;on(&#x27;Receive&#x27;, [$this, &#x27;onReceive&#x27;]); $this-&gt;server-&gt;on(&#x27;Task&#x27;, [$this, &#x27;onTask&#x27;]); $this-&gt;server-&gt;on(&#x27;Finish&#x27;, [$this, &#x27;onFinish&#x27;]); $this-&gt;server-&gt;on(&#x27;Close&#x27;, [$this, &#x27;onClose&#x27;]); // 启动服务 //$this-&gt;server-&gt;start(); &#125; protected function init() &#123; // &#125; public function start() &#123; // Run worker $this-&gt;server-&gt;start(); &#125; public function onStart($server) &#123; // 设置进程名 cli_set_process_title($this-&gt;taskName); //记录进程id,脚本实现自动重启 $pid = &quot;&#123;$server-&gt;master_pid&#125;&#123;$server-&gt;manager_pid&#125;&quot;; file_put_contents($this-&gt;pidPath, $pid); &#125; //监听连接进入事件 public function onConnect($server, $fd, $from_id) &#123; $server-&gt;send($fd, &quot;Hello &#123;$fd&#125;!&quot; ); &#125; // 监听数据接收事件 public function onReceive(swoole_server $server, $fd, $from_id, $data) &#123; $res[&#x27;result&#x27;] = &#x27;success&#x27;; $server-&gt;send($fd, json_encode($res)); // 同步返回消息给客户端 $server-&gt;task($data); // 执行异步任务 &#125; /* @param $server swoole_server swoole_server对象 @param $task_id int 任务id @param $from_id int 投递任务的worker_id @param $data string 投递的数据 / public function onTask(swoole_server $server, $task_id, $from_id, $data) &#123; $res[&#x27;result&#x27;] = &#x27;failed&#x27;; $req = json_decode($data, true); $action = $req[&#x27;action&#x27;]; echo date(&#x27;Y-m-d H:i:s&#x27;).&quot; onTask: [&quot;.$action.&quot;].&quot;; switch ($action) &#123; case &#x27;sendMail&#x27;: //发送单个邮件 $mailData = [ &#x27;emailAddress&#x27; =&gt; $req[&#x27;to&#x27;], //接收方，改成自己的邮箱可以测试接收邮件 &#x27;subject&#x27; =&gt; $req[&#x27;subject&#x27;], &#x27;body&#x27; =&gt; $req[&#x27;body&#x27;], ]; $this-&gt;sendMail($mailData); break; default: break; &#125; &#125; /* @param $server swoole_server swoole_server对象 @param $task_id int 任务id @param $data string 任务返回的数据 */ public function onFinish(swoole_server $server, $task_id, $data) &#123; // &#125; // 监听连接关闭事件 public function onClose($server, $fd, $from_id) &#123; echo &quot;Client &#123;$fd&#125; close connection&quot;; &#125; public function stop() &#123; $this-&gt;server-&gt;stop(); &#125; private function sendMail($mailData = []) &#123; $mail = new PHPMailer(true); try &#123; $mailConfig = $this-&gt;mailConfig; $mail-&gt;isSMTP(); // TCP port to connect to $mail-&gt;Host = $mailConfig[&#x27;smtp_host&#x27;]; // SMTP服务 $mail-&gt;SMTPAuth = true; // Enable SMTP authentication $mail-&gt;Username = $mailConfig[&#x27;username&#x27;]; // SMTP 用户名 $mail-&gt;Password = $mailConfig[&#x27;password&#x27;]; // SMTP 密码/口令 $mail-&gt;SMTPSecure = $mailConfig[&#x27;secure&#x27;]; // Enable TLS encryption, ssl also accepted $mail-&gt;Port = $mailConfig[&#x27;port&#x27;]; // TCP 端口 //Recipients $mail-&gt;setFrom(&#x27;sai0556@163.com&#x27;, &#x27;puresai&#x27;); $mail-&gt;addAddress(&#x27;957042781@qq.com&#x27;); // Name is optional $mail-&gt;addReplyTo(&#x27;957042781@qq.com&#x27;, &#x27;Information&#x27;); //Content $mail-&gt;isHTML(true); // Set email format to HTML $mail-&gt;Subject = &#x27;Here is the subject&#x27;; $mail-&gt;Body = &#x27;This is the HTML message body &lt;b&gt;in bold!&lt;/b&gt;&#x27;; $mail-&gt;AltBody = &#x27;This is the body in plain text for non-HTML mail clients&#x27;; $mail-&gt;send(); echo &#x27;Message has been sent&#x27;; &#125; catch (Exception $e) &#123; echo &#x27;Message could not be sent.&#x27;; echo &#x27;Mailer Error: &#x27; . $mail-&gt;ErrorInfo; &#125; try &#123; $mailConfig = $this-&gt;mailConfig; $mail-&gt;isSMTP(); // Set mailer to use SMTP $mail-&gt;Host = $mailConfig[&#x27;smtp_host&#x27;]; // SMTP服务 $mail-&gt;SMTPAuth = true; // Enable SMTP authentication $mail-&gt;Username = $mailConfig[&#x27;username&#x27;]; // SMTP 用户名 $mail-&gt;Password = $mailConfig[&#x27;password&#x27;]; // SMTP 密码/口令 $mail-&gt;SMTPSecure = $mailConfig[&#x27;secure&#x27;]; // Enable TLS encryption, ssl also accepted $mail-&gt;Port = $mailConfig[&#x27;port&#x27;]; // TCP 端口 $mail-&gt;CharSet = &quot;UTF-8&quot;; //字符集 $mail-&gt;setFrom($mailConfig[&#x27;username&#x27;], &#x27;puresai&#x27;); //发件人地址，名称 $mail-&gt;addAddress($mailData[&#x27;emailAddress&#x27;], &#x27;亲&#x27;); // 收件人地址和名称 //$mail-&gt;addCC(&#x27;hellowebanet@163.com&#x27;); // 抄送 if (isset($mailData[&#x27;attach&#x27;])) &#123; $mail-&gt;addAttachment($mailData[&#x27;attach&#x27;]); // 添加附件 &#125; //$mail-&gt;addAttachment(&#x27;/tmp/image.jpg&#x27;, &#x27;new.jpg&#x27;); // Optional name //Content $mail-&gt;isHTML(true); // Set email format to HTML $mail-&gt;Subject = $mailData[&#x27;subject&#x27;]; $mail-&gt;Body = $mailData[&#x27;body&#x27;]; $mail-&gt;send(); return true; &#125; catch (\\Exception $e) &#123; echo &#x27;Message could not be sent. Mailer Error: &#x27;. $mail-&gt;ErrorInfo; return false; &#125; &#125;&#125; 服务：&lt;?php/* Created by PhpStorm. User: puresai Date: 2018/11/29 Time: 14:09 /require DIR . &#x27;/Mailer.php&#x27;;$config = [ &#x27;smtp_host&#x27; =&gt; &#x27;smtp.163.com&#x27;, &#x27;username&#x27; =&gt; &#x27;sai@163.com&#x27;, &#x27;password&#x27; =&gt; &#x27;&#x27;, &#x27;secure&#x27; =&gt; &#x27;ssl&#x27;, &#x27;port&#x27; =&gt; 465];$server = new Mailer($config);$server-&gt;start(); 发送&lt;?php/** Created by PhpStorm. User: puresai Date: 2018/11/29 Time: 14:14 /class Client&#123; private $client; public function __construct() &#123; $this-&gt;client = new swoole_client(SWOOLE_SOCK_TCP); &#125; public function send() &#123; if( !$this-&gt;client-&gt;connect(&quot;127.0.0.1&quot;, 9502 , 1) ) &#123; echo &quot;Error: &#123;$this-&gt;client-&gt;errMsg&#125;[&#123;$this-&gt;client-&gt;errCode&#125;]&quot;; &#125; $action = &#x27;sendMail&#x27;; $time = time(); $data = [ &#x27;action&#x27; =&gt; $action, &#x27;to&#x27; =&gt; &#x27;957042781@qq.com&#x27;, &#x27;subject&#x27; =&gt; &#x27;wow&#x27;, &#x27;body&#x27; =&gt; &#x27;hello, puresai!&#x27; ]; $msg = json_encode($data); $this-&gt;client-&gt;send( $msg ); $message = $this-&gt;client-&gt;recv(); echo &quot;Get Message From Server:&#123;$message&#125;&quot;; &#125;&#125;$client = new Client();$client-&gt;send(); 测试通过！ 注意： 此处我用了25端口，部署到Linux时上发送邮件发不出去，把PHPMailer的错误说明查了个遍，wrong，端口改为465，使用ssl发送，ok！ 心累。","tags":["swoole"],"categories":["PHP"]},{"title":"nginx健康检查","path":"/2018/10/19/Nginx4/","content":"面试被问到健康检测，自己不了解，便有了下文。 当项目访问量比较大时，我们经常使用nginx做负载均衡。 如下： #设定http服务器，利用它的反向代理功能提供负载均衡支持http &#123; #设定mime类型,类型由mime.type文件定义 include /etc/nginx/mime.types; default_type application/octet-stream; #设定日志格式 access_log /var/log/nginx/access.log; #省略上文有的一些配置节点 #。。。。。。。。。。 #设定负载均衡的服务器列表 upstream sai&#123; #weigth参数表示权值，权值越高被分配到的几率越大 server 192.168.8.1:3128 weight=5; #本机上的Squid开启3128端口,不是必须要squid server 192.168.8.2:80 weight=1; server 192.168.8.3:80 weight=6; &#125; #第一个虚拟服务器 server &#123; #侦听192.168.8.x的80端口 listen 80; server_name www.puresai.com; #对aspx后缀的进行负载均衡请求 location ~ .*.php$ &#123; #定义服务器的默认网站根目录位置 root /root; #定义首页索引文件的名称 index index.php index.html index.htm; #请求转向mysvr 定义的服务器列表 proxy_pass http://sai; #以下是一些反向代理的配置可删除. proxy_redirect off; #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #允许客户端请求的最大单文件字节数 client_max_body_size 10m; #缓冲区代理缓冲用户端请求的最大字节数， client_body_buffer_size 128k; #nginx跟后端服务器连接超时时间(代理连接超时) proxy_connect_timeout 90; #连接成功后，后端服务器响应时间(代理接收超时) proxy_read_timeout 90; #设置代理服务器（nginx）保存用户头信息的缓冲区大小 proxy_buffer_size 4k; #proxy_buffers缓冲区，网页平均在32k以下的话，这样设置 proxy_buffers 4 32k; #高负荷下缓冲大小（proxy_buffers*2） proxy_busy_buffers_size 64k; #设定缓存文件夹大小，大于这个值，将从upstream服务器传 proxy_temp_file_write_size 64k; &#125; &#125;&#125; 这是nginx中文网上的一个实例（有删改），这样处理分发服务器，我们加入了三台机器，保证了项目的负载量。 然而，我们常常忽略另一件事，就是健康检查。（好吧，其实我也忽略了这个问题，面试被问到，一脸懵！！！） 何为健康监测？ 假如我们加入的3台机器中有一台因为其他原因挂掉了，但分发的服务器是不知道的，依旧正常分发请求，必然就导致部分用户访问失败，这是很严重的问题，那么这个时候就需要用到健康检查了。 下面我们介绍两种健康检查： 被动检查： 如果 Nginx 在 10 秒内有 2 个请求发送失败或没有接收到响应，则标记服务器为不可用 upstream sai&#123; server 192.168.8.1:3128 max_fails=2 fail_timeout=10s weight=5; server 192.168.8.2:80 max_fails=2 fail_timeout=10s weight=1; server 192.168.8.3:80 max_fails=2 fail_timeout=10s weight=6;&#125;Copy 主动检查： 需要先开启health_check upstream sai&#123; zone sai 64k; server 192.168.8.1:3128 max_fails=2 fail_timeout=10s weight=5; server 192.168.8.2:80 max_fails=2 fail_timeout=10s weight=1; server 192.168.8.3:80 max_fails=2 fail_timeout=10s weight=6;&#125;location ~ .*.php$ &#123; #其他省略 … proxy_pass http://sai; health_check interval=10 fails=3 passes=2; # 也可以使用此种，指定特定接口 health_check uri=/some/path;&#125;Copy 配置起来还是比较简单的。 proxy_next_upstream# 开启proxy_next_upstream proxy_next_upstream onupstream proxy_web&#123; server 192.168.1.120:7851 weight=2 max_fails=3 fail_timeout=100s; server 192.168.1.121:7851 weight=2 max_fails=3 fail_timeout=100s;&#125;server &#123; listen 80; server_name blog.puresai.com; root /www; index index.html; location /sys &#123; proxy_pass http://proxy_web; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\t// 502,404,error自动代理到下一个server proxy_next_upstream http_502 http_504 error timeout invalid_header; &#125;&#125; 如要了解更多可以查看nginx手册： nginx健康监测","tags":["Nginx"],"categories":["Nginx"]},{"title":"基于Redis的秒杀","path":"/2018/08/09/165/","content":"随着电商业务的发展，秒杀是个十分常见的场景，今天我们来利用Redis实现一个简单的秒杀系统。 假定我们有一个商品id为1，秒杀数量是5。 一般场景： include &#x27;db.php&#x27;;$db = new db([ &#x27;database_type&#x27; =&gt; &#x27;mysql&#x27;, &#x27;database_name&#x27; =&gt; &#x27;test&#x27;, &#x27;server&#x27; =&gt; &#x27;www.puresai.com&#x27;, &#x27;username&#x27; =&gt; &#x27;puresai&#x27;, &#x27;password&#x27; =&gt; &#x27;*&#x27;, &#x27;charset&#x27; =&gt; &#x27;utf8&#x27;]);$stock_num= $db-&gt;get(&#x27;goods&#x27;, &#x27;stock_num&#x27;, [&#x27;id&#x27; =&gt; 1]);// 检测库存if ($stock_num&gt; 0) &#123; sleep(1); //模拟真实环境 $db-&gt;update(&#x27;goods&#x27;, [&quot;stock_num[-]&quot; =&gt; 1], [&#x27;id&#x27; =&gt; 1]); print_r(&#x27;ok&#x27;)&#125; else &#123; print_r(&#x27;sorry&#x27;)&#125; 我们尝试模拟高并发场景，使用ab压测工具， ab -n 500 -c 500 http://www.puresai.com/test/miaosha.php 运行后发现库存stock_num很可能已经变成负数了，出现了超卖问题。 引入Redis //实例化Redis$Redis = new Redis();//连接$Redis-&gt;connect(&#x27;127.0.0.1&#x27;, 6379);$key = &#x27;sale&#x27;;//检测是否连接成功// echo &quot;Server is running: &quot; . $Redis-&gt;ping();$Redis-&gt;setnx($key, 0);$Redis-&gt;watch($key); //监测一个key的值是否被更改$sale_num = $Redis-&gt;get($key);if ($sale_num &gt; 4) &#123; exit();&#125;$Redis-&gt;multi(); //标记事务$Redis-&gt;incr($key); //销量+1sleep(1); //模拟真实环境$ret = $Redis-&gt;exec(); // 事务块内所有命令的返回值，按命令执行的先后顺序排列。if ($ret) &#123; include &#x27;db.php&#x27;; $db = new db([ &#x27;database_type&#x27; =&gt; &#x27;mysql&#x27;, &#x27;database_name&#x27; =&gt; &#x27;test&#x27;, &#x27;server&#x27; =&gt; &#x27;www.puresai.com&amp;#39;, &#x27;username&#x27; =&gt; &#x27;puresai&#x27;, &#x27;password&#x27; =&gt; &#x27;*&#x27;, &#x27;charset&#x27; =&gt; &#x27;utf8&#x27; ]); $db-&gt;update(&#x27;goods&#x27;, [&quot;stock_num[-]&quot; =&gt; 1], [&#x27;id&#x27; =&gt; 1]);&#125; 重新增加库存到5，多次测试，发现库存并无出现负数情况，测试通过。","tags":["Redis"],"categories":["Redis"]},{"title":"两个关于Linux的问题","path":"/2018/07/06/163/","content":"最近有点忙，一会下班，也不想敲代码了，写写前段时间遇到的两个关于Linux的问题。虽然两个问题都是同事解决的，但有必要分享一下。 OOM OOM killer（Out-Of-Memory killer），该机制会监控那些占用内存过大，尤其是瞬间很快消耗大量内存的进程，为了防止内存耗尽而内核会把该进程杀掉。 起因：导出相当大的数据时导致内存溢出的问题，服务器负载很大，然后OOM这个进程每次就把我导出的进程干趴下了。 文件最大打开数ulimit -n //查看文件最大打开数lsof |wc -l //当前文件打开数量 起因：守护进程里有个程序，一直在fopen，导致文件打开数过大，服务器挂掉了。 解决方案比较简单，就不赘述了。","tags":["Linux"],"categories":["linux"]},{"title":"关于大表查询最后几页过慢的原因","path":"/2018/05/31/157/","content":"mysql数据量很大使用limit查询最后几页很慢，你知道原因么？ 我们不妨先来看看几条查询语句与结果。 select * from test_user where id&gt;9900000 limit 0,10;select * from test_user limit 9900000,10;select * from test_user where id in (select b.id from (select id from test_user where id&gt;9900000 limit 0,10) as b); //子查询 [SQL]select * from test_user where id&gt;9900000 limit 0,10;受影响的行: 0时间: 0.019s[SQL]select * from test_user limit 9900000,10;受影响的行: 0时间: 1.147s[SQL]select * from test_user where id in (select b.id from (select id from test_user where id&gt;9900000 limit 0,10) as b);受影响的行: 0时间: 0.001s 其实，原因就在于： limit10000,20的意思扫描满足条件的10020行，扔掉前面的10000行，返回最后的20行，问题就在这里。 解决方案： 过一半数据采用倒序查询 运用子查询","tags":["MySQL"],"categories":["db"]},{"title":"git解决总要输入密码的问题","path":"/2018/05/09/153/","content":"之前每次pull和push总要输入密码，繁琐。操作两步，解决问题！生成公钥cd&nbsp;~/.ssh ssh-keygen&nbsp;-t&nbsp;rsa&nbsp;-C&nbsp;&quot;注释&quot;拷贝公钥到远程主机ssh-copy-id&nbsp;git@xxx.comok！","tags":["git"],"categories":["CI"]},{"title":"MySQL触发器","path":"/2018/04/18/152/","content":"去年年底做新功能时考虑使用触发器，来聊聊触发器。 触发器是与表有关的数据库对象，在满足定义条件时触发，并执行触发器中定义的语句集合。触发器的这种特性可以协助应用在数据库端确保数据的完整性。 DELIMITER;;//定义结束符 CREATE TRIGGER `updateData` AFTER UPDATE ON `buyer` FOR EACH ROW begin set @phone = right(new.phone,11); // 取手机号 set @main_id = (select id from main where u_id = new.u_id); // 从表main取id set @new_last_trade_time = IF( UNIX_TIMESTAMP(new.last_trade_time) &amp;gt; @old_last_trade_time, UNIX_TIMESTAMP(new.last_trade_time), @old_last_trade_time); set @add_trade_count = (new.trade_count - old.trade_count); set @add_trade_amount = (new.trade_amount - old.trade_amount); // 更新操作 update member set trade_count=trade_count+@add_trade_count, trade_amount=trade_amount+@add_trade_amount, last_trade_time=@new_last_trade_time where main_id = @main_id and phone = @phone; end ;; DELIMITER ; 性能问题： 通过测试，若我每秒钟向数据库中插入700条左右的告警信息，此时若使用触发器，每秒中只会插入数据库中50左右，若不开启触发器，那么700条全部可以插入数据库中。（来自网络）","tags":["mysql"],"categories":["MySQL"]},{"title":"2017,这一年","path":"/2018/02/13/2017/","content":"大家过年好！ 似水流年是一个人所有的一切，只有这个东西，才真正归你所有。 其余的一 切，都是片刻的欢娱和不幸， 转眼间就已跑到那似水流年里去了。——王小波 上学时年终总结是个烦人的东西，工作后反倒会自觉地写一写，真是奇怪。自己的总结嘛，随意一点。 工作如果要给这一年的工作定个主题词，我想是——浪荡。 深切认识到自己能力不足，有点厌倦反复的工作，于8月初离开待了一年多且很有感情的公司。 9月初入职新公司，待了两个月，工作非我想，完全不在状态，10月底辞职。 11月初到现在的公司，前不久刚转正，算是稳定下来了。新公司氛围不错，很有活力，能学到些之前想学的东西，蛮好，工资福利方面还算满意。 工作相关技术方面，有所提高，但仍需继续努力。 生活生活的主题词，我想应该是——尝试。 年初定的7个小目标，完成了4.25，还算满意。 开始注意健康，注意体重，注意饮食，不暴饮暴食，辣口有意识少吃，早睡早起而一直没成功进行。 作为服务行业工作者，生活中也开始注意服务的体验，开始对不好的服务say no，开始注重生活的质感。 看了几本闲书，看了几部老电视剧，看了20多部电影。 年底开始学琴，最近太忙，几周没去上课，也没去练琴了，技术现在大概能拉小星星吧！ 7月份申请了个人公众号，到现在写了十多篇文章，12月份开心地被添加原创。 两次旅行，一次九华山家庭旅行，一次桂林五日游。旅行前，买了个750，偶尔也会去拍拍照，只是技术菜了点，没有多少好照片。 此外，对于以前看不惯的人，尝试保持开放的心态，不去指点。对于以前很在意的事，尝试保持初心，不去争。 人之所以痛苦，在于追求错误的东西。如果你不给自己烦恼，别人也永远不可能给你烦恼。因为你自己的内心，你放不下。好好的管教你自己，不要管别人。——路遥 总结如果给这一年打个分，我会打8分。成长和转变是可喜的，但走了不少冤枉路，而一些尝试也是烧钱的，所以成了月光族。 希望新的一年，继续忠于自我的认知，有趣地生活，开心地工作。 几乎附上2018的todolist： 写一写魏晋的文章，好好经营公众号 继续学习爬虫技能，做一个爬取的数据相关APP 练出腹肌 提高摄影技巧，拍一些好照片 理财&amp;存钱 早睡&amp;三餐规律 体验蹦极 改一首赵长卿的《探春令》以作结尾 漂泊半载恰如意。新春伴心怡。万里晴空，炊烟细细。和气入，东风里。素手红眷在命理。缘来便知伊。不见晨雾起，戊戌吉利，百事皆如意。 丁酉腊月廿八记at 杭州2018-02-13","tags":["oneyear"],"categories":["oneyear"]},{"title":"self和static","path":"/2017/12/07/142/","content":"PHP官方也说过，大概是说self调用的就是本身代码片段这个类，而static调用的是从堆内存中提取出来，访问的是当前实例化的那个类，那么 static 代表的就是那个类。 class A &#123; protected static $str = &quot;This is class A&quot;; public static function getStr() &#123; echo self::$str; &#125;&#125;class B extends A&#123; protected static $str = &quot;This is class B&quot;;&#125;B::getStr();// 输出This is class Aclass A &#123; protected static $str = &quot;This is class A&quot;; public static function getStr() &#123; echo static::$str; &#125;&#125;class B extends A&#123; protected static $str = &quot;This is class B&quot;;&#125;B::getStr();// 输出This is class B self - 就是这个类，是代码段里面的这个类。static - PHP 5.3新特性。当前这个类，有点像$this的意思，从堆内存中提取出来，访问的是当前实例化的那个类，那么 static 代表的就是那个类。 class A&#123; public function getSelf() &#123; return new self(); &#125; public function getStatic() &#123; return new static(); &#125;&#125;$f = new A();print get_class($f-&gt;getSelf());print get_class($f-&gt;getStatic());class B extends A&#123; public function getSelf2() &#123; return new self(); &#125; public function getStatic2() &#123; return new static(); &#125;&#125;$f = new B();print get_class($f-&gt;getSelf());print get_class($f-&gt;getStatic());print get_class($f-&gt;getSelf2());print get_class($f-&gt;getStatic2());// 输出AAABBB","tags":["PHP"],"categories":["PHP"]},{"title":"Git常用命令","path":"/2017/11/17/141/","content":"之前没用过git，还在持续踩坑中，后续继续更新。。。。。。 列出tag git tag # 在控制台打印出当前仓库的所有tag&gt; git tag -l ‘v0.1.*’ # 搜索符合模式的Tag 打tag git tag分为两种类型：轻量tag和附注tag。轻量tag是指向提交对象的引用，附注Tag则是仓库中的一个独立对象。建议使用附注Tag。 创建轻量Tag git tag v0.1.2-light 创建附注Tag git tag -a v0.1.2 -m “0.1.2版本” 创建轻量Tag不需要传递参数，直接指定Tag名称即可。 创建附注Tag时，参数a即annotated的缩写，指定Tag类型，后附Tag名。参数m指定Tag说明，说明信息会保存在Tag对象中。 切换到Tag与切换分支命令相同，用 git checkout [tagname] 查看Tag信息用git show命令可以查看Tag的版本信息： git show v0.1.2 删除Tag误打或需要修改Tag时，需要先将Tag删除，再打新Tag。 git tag -d v0.1.2 # 删除Tag 参数d即delete的缩写，意为删除其后指定的Tag。 给指定的commit打Tag 打Tag不必要在head之上，也可在之前的版本上打，这需要你知道某个提交对象的校验和（通过git log获取）。 补打Tag git tag -a v0.1.1 9fbc3d0 Tag推送到服务器 通常的git push不会将Tag对象提交到git服务器，我们需要进行显式的操作： git push origin v0.1.2 # 将v0.1.2 Tag提交到git服务器&gt; git push origin –-tags # 将本地所有Tag一次性提交到git服务器 注意：如果想看之前某个Tag状态下的文件，可以这样操作 git tag 查看当前分支下的Tag git checkout v0.21 此时会指向打v0.21 Tag时的代码状态，（但现在处于一个空的分支上） 删除远程分支和tag在Git v1.7.0 之后，可以使用这种语法删除远程分支： git push origin –delete 删除tag这么用： git push origin –delete tag 否则，可以使用这种语法，推送一个空分支到远程分支，其实就相当于删除远程分支： git push origin : 这是删除tag的方法，推送一个空tag到远程tag： git tag -d &gt; git push origin :refs/tags/ 重命名远程分支删除远程分支： git push –delete origin devel 重命名本地分支： git branch -m devel develop 推送本地分支： git push origin develop 把本地tag推送到远程 git push –tags # 推送所有tag&gt; git push origin :tag # 推送tag —— 2017/12/04 工作区（Working Directory） 就是你在电脑里能看到的目录，比如我的git文件夹就是一个工作区。 版本库（Repository） 工作区有一个隐藏目录.git，这个不算工作区，而是Git的版本库。 暂存区 Git的版本库里存了很多东西，其中最重要的就是称为stage（或者叫index）的暂存区，还有Git为我们自动创建的第一个分支master，以及指向master的一个指针叫HEAD。 git add把文件添加进去，实际上就是把文件修改添加到暂存区； git commit提交更改，实际上就是把暂存区的所有内容提交到当前分支。 命令说明git clone克隆git branch (分支名)创建分支 -D删除分支git checkout (分支名)切换分支 -b创建并切换git checkout (文件名)撤销此文件修改git add将该文件添加到缓存git status查看在你上次提交之后是否有修改git commit将缓存区内容添加到仓库中git diff来查看执行 git status 的结果的详细信息git reset HEAD命令用于取消已缓存的内容git rm 文件删除文件-f强制删除git mv移动文件git merge合并分支git fetch从远程获取最新版本到本地git push :将本地分支的更新，推送到远程主机git push origin --delete test删除远程分支testgit pull :将远程存储库中的更改合并到本地分支中git rebase命令在另一个分支基础之上重新应用，用于把一个分支的修改合并到当前分支。git log命令用于显示提交日志信息。git reflog显示每一次命令git revert生成一个新的提交来撤销某次提交，此次提交之前的commit都会被保留git reset HEAD 如果发现错误的将不想暂存的文件被git add进入索引之后，想回退取消，则可以使用 设置用户名邮箱： git config –global user.name “puresai” git config –global user.email “&#x39;&#53;&#55;&#48;&#52;&#50;&#x37;&#x38;&#x31;&#x40;&#113;&#x71;&#46;&#x63;&#111;&#x6d;“ fatal: No configured push destination.解决：$ git remote add -f -t master -m master origin git://example.com/git.git/fatal: The current branch test has no upstream branch.解决：git push --set-upstream origin test模仿 git clone，但只跟踪选定的分支$ mkdir project.git$ cd project.git$ git init$ git remote add -f -t master -m master origin git://example.com/git.git/$ git merge originfatal：Unable to create &#x27;E:/project/scrm/.git/index.lock&#x27;: File exists.rm -f ./.git/index.lock git log-p 查看差异-n(n为正整数) 查看最近n次的提交--pretty 按指定格式显示日志信息,可选项有：oneline,short,medium,full,fuller,email,raw以及format:&lt;string&gt;,默认为medium，可以通过修改配置文件来指定默认的方式。e.g. git log (--pretty=)oneline--stat 列出文件的修改行数--sortstat 只显示--stat中最后行数修改添加移除的统计--graph 以简单的图形方式列出提交记录--abbrev-commit 仅显示 SHA-1 的前几个字符，而非所有的 40 个字符。--relative-date 使用较短的相对时间显示（比如，“2 weeks ago”）。--name-only 仅在提交信息后显示已修改的文件清单。--name-status 显示新增、修改、删除的文件清单。 ——2017/12/01 命令 说明 git clone 克隆 git branch (分支名) 创建分支 -D删除分支 git checkout (分支名) 切换分支 -b创建并切换 git add 将该文件添加到缓存 git status 查看在你上次提交之后是否有修改 git commit 将缓存区内容添加到仓库中 git diff 来查看执行 git status 的结果的详细信息 git reset HEAD 命令用于取消已缓存的内容 git rm 文件 删除文件-f强制删除 git mv 移动文件 git merge 合并分支 git fetch 从远程获取最新版本到本地 git push : 将本地分支的更新，推送到远程主机 git push origin --delete test 删除远程分支test git pull : 将远程存储库中的更改合并到本地分支中 git rebase 命令在另一个分支基础之上重新应用，用于把一个分支的修改合并到当前分支。 fatal: No configured push destination.解决：$ git remote add -f -t master -m master origin git://example.com/git.git/fatal: The current branch test has no upstream branch.解决：git push --set-upstream origin test模仿 git clone，但只跟踪选定的分支$ mkdir project.git$ cd project.git$ git init$ git remote add -f -t master -m master origin git://example.com/git.git/$ git merge origin","tags":["git"],"categories":["CI"]},{"title":"初识gulp","path":"/2017/11/12/140/","content":"使用 gulp 之前请安装好node和npm，为了速度，可以使用cnpm。 全局安装 cnpm install gulp -g glup -v // 输入版本，则说明安装成功。 新建package.json&#123;\t&quot;name&quot;: &quot;sai&quot;,\t&quot;version&quot;: &quot;1.0&quot;,\t&quot;description&quot;: &quot;gulp css!&quot;,\t&quot;author&quot;: &#123; &quot;name&quot;: &quot;puresai&quot;, &quot;email&quot;: &quot;95742781@qq.com&quot;\t&#125;,\t&quot;license&quot;: &quot;MIT&quot;,\t&quot;devDependencies&quot;: &#123; &quot;gulp&quot;: &quot;^3.9.1&quot;, &quot;gulp-minify-css&quot;: &quot;^1.2.4&quot;\t&#125;&#125; 本地安装gulp，gulp-minify-css。cnpm install gulp --save-dev cnpm install gulp-minify-css --save-dev 新建gulpfile.jsvar gulp = require(&#x27;gulp&#x27;), mincss = require(&#x27;gulp-minify-css&#x27;);//定义一个sai任务gulp.task(&#x27;sai&#x27;, function () &#123; gulp.src(&#x27;assets/css/*.css&#x27;) //该任务针对的文件 .pipe(mincss()) //该任务调用的模块 .pipe(gulp.dest(&#x27;assets/mini&#x27;)); //将会在assets/mini下生成css&#125;); gulp.task(&#x27;default&#x27;,[&#x27;sai&#x27;]); //定义默认任务 cmd执行gulp gulp 会看到任务sai开始，完成，这样就完成了gulp压缩css。 此外，gulp还可以压缩js，img。","tags":["gulp"],"categories":["js"]},{"title":"SVN服务器与web站点代码同步更新","path":"/2017/10/09/138/","content":"因为SVN服务器与web站点代码是放在同一个服务器上的，所以我们尝试来做一个同步更新。 但是文件上传到SVN版本库后,上传的文件不再以文件原来的格式存储,而是被svn以它自定义的格式压缩成版本库数据,存放在版本库中。 这样我们就选择使用SVN自带的hooks来做web站点代码更新。 进入对应版本库下的hooks目录，复制 post-commit.tmpl为post-commit。 打开，修改代码如下： export.UTF-8 REPOS=&quot;$1&quot; REV=&quot;$2&quot; SVN_PATH=/usr/bin/svn #注意，此处是svn命令目录 WEB_PATH=/web/trunk #站点目录 LOG_PATH=/home/svn/trunk/svn.log echo &quot;##########开始提交 &quot; `date &quot;+%Y-%m-%d %H:%M:%S&quot;` &#x27;##################&#x27; &gt;&gt; $LOG_PATH $SVN_PATH update --username puresai --password 123456 $WEB_PATH --no-auth-cache &gt;&gt; $LOG_PATH 记得要修改下post-commit的执行权限，然后测试，如果成功了，那恭喜你！","tags":["svn"],"categories":["CI"]},{"title":"linux搭建svn服务器","path":"/2017/10/09/137/","content":"环境：centos6.3安装svn yum install subversion 创建版本库 svnadmin create /home/repo //文件目录自己设置 配置 cd /home/repo/conf // 进入目录 配置目录下有三个文件 authz 权限passwd 账号密码svnserve.conf 版本库配置 编辑用户文件passwd，新增两个用户：admin和guest。 [users]admin = 111111guest = 123456 编辑权限文件authz，用户admin设置可读写权限，guest设置只读权限。 [/]admin = rwguest = r 编辑svnserve.conf： [general]anon-access = none #控制非鉴权用户访问版本库的权限auth-access = write #控制鉴权用户访问版本库的权限password-db = passwd #指定用户名口令文件名authz-db = authz #指定权限配置文件名realm = repo #指定版本库的认证域，即在登录时提示的认证域名称 配置ip，打开3369端口并重启启动svn svnserve -d -r /home/repo 本地测试cmd输入svn checkout svn://***/repo，加入提示输入用户名密码，并能用之前账号登录，就表示配置成功。 如果本地装了类似TortoiseSVN软件，可以新建文件夹，然后checkout，输入用户名密码，测试成功！","tags":["SVN"],"categories":["CI"]},{"title":"阿里云身份证实名认证","path":"/2017/07/25/130/","content":"直接上代码，使用的是阿里云的接口。 /* * 身份证校验 * */function sfz_verify($idcard, $name)&#123; $host = &quot;http://idcard.market.alicloudapi.com&quot;; $path = &quot;/lianzhuo/idcard&quot;; $method = &quot;GET&quot;; $appcode = z_get_config(&#x27;sfz_appcode&#x27;); $headers = array(); array_push($headers, &quot;Authorization:APPCODE &quot; . $appcode); $querys = &quot;cardno=$idcard&amp;name=$name&quot;; $bodys = &quot;&quot;; $url = $host . $path . &quot;?&quot; . $querys; $curl = curl_init(); curl_setopt($curl, CURLOPT_CUSTOMREQUEST, $method); curl_setopt($curl, CURLOPT_URL, $url); curl_setopt($curl, CURLOPT_HTTPHEADER, $headers); curl_setopt($curl, CURLOPT_FAILONERROR, false); curl_setopt($curl, CURLOPT_RETURNTRANSFER, true); curl_setopt($curl, CURLOPT_HEADER, true); if (1 == strpos(&quot;$&quot;.$host, &quot;https://&quot;))&#123; curl_setopt($curl, CURLOPT_SSL_VERIFYPEER, false); curl_setopt($curl, CURLOPT_SSL_VERIFYHOST, false); &#125; $output = curl_exec($curl); if (curl_getinfo($curl, CURLINFO_HTTP_CODE) == &#x27;200&#x27;) &#123; list($header, $body) = explode(&quot;\\r \\r &quot;, $output, 2); &#125; //dump($output); curl_close($curl); return $body;&#125; 正确返回值如下： &#123; &quot;resp&quot;: &#123; &quot;code&quot;: 0, &quot;desc&quot;: &quot;匹配&quot; &#125;, &quot;data&quot;: &#123; &quot;sex&quot;: &quot;男&quot;, &quot;address&quot;: &quot;广东省清远市清新县&quot;, &quot;birthday&quot;: &quot;1989-05-25&quot; &#125;&#125;","tags":["PHP"],"categories":["PHP"]},{"title":"ueditor远程图片本地化的实现","path":"/2017/07/13/127/","content":"前不久客户反馈说，在秀米网上编辑好文章，发布到我们后台，前台图片无法显示，最先想到的是图片域名限制。发邮件给秀米，秀米给出的建议是类似微信后台做图片本地化。开发组内部讨论后，看到了这篇文章，UEditor编辑器如何关闭抓取远程图片本地化功能，so easy?按文章说明设置，测试,失败！百度看了下，大都是这样解答，说明应该是有人实现了，秀米编辑器核心代码也正是ueditor核心代码，那就只能自己捣鼓了。具体捣鼓过程如下：注意：捣鼓前先备份下，以备修改错误导致其他问题打开ueditor.config.js，在配置项中加入,catchRemoteImageEnable:true打开ueditor.config.js，搜索catchremoteimage，在加入console.warn(url)，看看上传地址。前台测试后看到/Skin/public/ueditor/php/controller.php?action=catchimage打开php/controller.php 可以看到case&nbsp;&#39;catchimage&#39;: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$result&nbsp;=&nbsp;include(&quot;action_crawler.php&quot;);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;break;接着打开统计目录下action_crawler.phpinclude(&quot;Uploader.class.php&quot;); $item&nbsp;=&nbsp;new&nbsp;Uploader($imgUrl,&nbsp;$config,&nbsp;&quot;remote&quot;);看到这两段代码。继续打开统计目录下Uploader.class.php//构造函数如下 public&nbsp;function&nbsp;__construct($fileField,&nbsp;$config,&nbsp;$type&nbsp;=&nbsp;&quot;upload&quot;) &nbsp;&nbsp;&nbsp;&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;$this-&gt;fileField&nbsp;=&nbsp;$fileField;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;$this-&gt;config&nbsp;=&nbsp;$config;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;$this-&gt;type&nbsp;=&nbsp;$type; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;($type&nbsp;==&nbsp;&quot;remote&quot;)&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$this-&gt;saveRemote(); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;if($type&nbsp;==&nbsp;&quot;base64&quot;)&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$this-&gt;upBase64(); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$this-&gt;upFile(); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$this-&gt;stateMap[&#39;ERROR_TYPE_NOT_ALLOWED&#39;]&nbsp;=&nbsp;iconv(&#39;unicode&#39;,&nbsp;&#39;utf-8&#39;,&nbsp;$this-&gt;stateMap[&#39;ERROR_TYPE_NOT_ALLOWED&#39;]); &nbsp;&nbsp;&nbsp;&nbsp;}搜索saveRemote，主要修复fileType与oriName两块。/** &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*&nbsp;拉取远程图片 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*&nbsp;@return&nbsp;mixed &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*/ &nbsp;&nbsp;&nbsp;&nbsp;private&nbsp;function&nbsp;saveRemote() &nbsp;&nbsp;&nbsp;&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$imgUrl&nbsp;=&nbsp;htmlspecialchars($this-&gt;fileField); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$imgUrl&nbsp;=&nbsp;str_replace(&quot;&amp;amp;&quot;,&nbsp;&quot;&amp;&quot;,&nbsp;$imgUrl); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//http开头验证&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(strpos($imgUrl,&nbsp;&quot;http&quot;)&nbsp;!==&nbsp;0)&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$this-&gt;stateInfo&nbsp;=&nbsp;$this-&gt;getStateInfo(&quot;ERROR_HTTP_LINK&quot;);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;preg_match(&#39;/(^https*://[^:/]+)/&#39;,&nbsp;$imgUrl,&nbsp;$matches);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$host_with_protocol&nbsp;=&nbsp;count($matches)&nbsp;&gt;&nbsp;1&nbsp;?&nbsp;$matches[1]&nbsp;:&nbsp;&#39;&#39;; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;判断是否是合法&nbsp;url&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(!filter_var($host_with_protocol,&nbsp;FILTER_VALIDATE_URL))&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$this-&gt;stateInfo&nbsp;=&nbsp;$this-&gt;getStateInfo(&quot;INVALID_URL&quot;);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;preg_match(&#39;/^https*://(.+)/&#39;,&nbsp;$host_with_protocol,&nbsp;$matches);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$host_without_protocol&nbsp;=&nbsp;count($matches)&nbsp;&gt;&nbsp;1&nbsp;?&nbsp;$matches[1]&nbsp;:&nbsp;&#39;&#39;; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;此时提取出来的可能是&nbsp;ip&nbsp;也有可能是域名，先获取&nbsp;ip&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$ip&nbsp;=&nbsp;gethostbyname($host_without_protocol);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;判断是否是私有&nbsp;ip&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if(!filter_var($ip,&nbsp;FILTER_VALIDATE_IP,&nbsp;FILTER_FLAG_NO_PRIV_RANGE))&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$this-&gt;stateInfo&nbsp;=&nbsp;$this-&gt;getStateInfo(&quot;INVALID_IP&quot;);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//获取请求头并检测死链&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$heads&nbsp;=&nbsp;get_headers($imgUrl,&nbsp;1);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(!(stristr($heads[0],&nbsp;&quot;200&quot;)&nbsp;&amp;&amp;&nbsp;stristr($heads[0],&nbsp;&quot;OK&quot;)))&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$this-&gt;stateInfo&nbsp;=&nbsp;$this-&gt;getStateInfo(&quot;ERROR_DEAD_LINK&quot;);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//格式验证(扩展名验证和Content-Type验证)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$fileType&nbsp;=&nbsp;strtolower(strrchr($imgUrl,&nbsp;&#39;.&#39;));&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//puresai&nbsp;20170712&nbsp;&nbsp;秀米网链接接如下http://img.xiumi.us/xmi/ua/h4qG/i/b8f2af6986e8dba51615a9d85cc82f3b-sz_1952250.JPG?x-oss-process=style/xm&nbsp;，我们完善下&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$fileType&nbsp;=&nbsp;(strpos($fileType,&nbsp;&#39;?&#39;)&nbsp;&gt;&nbsp;0)?&nbsp;strtolower(substr($fileType,0,strpos($fileType,&#39;?&#39;)))&nbsp;:&nbsp;strtolower($fileType);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//echo&nbsp;$fileType;die();&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(!in_array($fileType,&nbsp;$this-&gt;config[&#39;allowFiles&#39;])&nbsp;||&nbsp;!isset($heads[&#39;Content-Type&#39;])&nbsp;||&nbsp;!stristr($heads[&#39;Content-Type&#39;],&nbsp;&quot;image&quot;))&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$this-&gt;stateInfo&nbsp;=&nbsp;$this-&gt;getStateInfo(&quot;ERROR_HTTP_CONTENTTYPE&quot;);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//打开输出缓冲区并获取远程图片&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ob_start();&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$context&nbsp;=&nbsp;stream_context_create(&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;array(&#39;http&#39;&nbsp;=&gt;&nbsp;array(&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&#39;follow_location&#39;&nbsp;=&gt;&nbsp;false&nbsp;//&nbsp;don&#39;t&nbsp;follow&nbsp;redirects&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;))&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;readfile($imgUrl,&nbsp;false,&nbsp;$context);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$img&nbsp;=&nbsp;ob_get_contents();&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ob_end_clean();&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//puresai&nbsp;20170712&nbsp;&nbsp;此处正则有问题，修改如下&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//preg_match(&quot;//[.]?[^./]*$/&quot;,&nbsp;$imgUrl,&nbsp;$m);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;preg_match(&quot;//[A-za-z0-9-]+.&quot;.$fileType.&quot;/&quot;,&nbsp;strtolower($imgUrl),&nbsp;$m);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//var_dump($m);die(); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$this-&gt;oriName&nbsp;=&nbsp;$m&nbsp;?&nbsp;ltrim($m[0],&#39;/&#39;):&quot;&quot;;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//$this-&gt;oriName&nbsp;=&nbsp;$m&nbsp;?&nbsp;$m[1]:&quot;&quot;;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//echo&nbsp;$this-&gt;oriName;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//die();&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$this-&gt;fileSize&nbsp;=&nbsp;strlen($img);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$this-&gt;fileType&nbsp;=&nbsp;$this-&gt;getFileExt();&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$this-&gt;fullName&nbsp;=&nbsp;$this-&gt;getFullName();&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$this-&gt;filePath&nbsp;=&nbsp;$this-&gt;getFilePath();&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$this-&gt;fileName&nbsp;=&nbsp;$this-&gt;getFileName();&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$dirname&nbsp;=&nbsp;dirname($this-&gt;filePath); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//检查文件大小是否超出限制&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(!$this-&gt;checkSize())&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$this-&gt;stateInfo&nbsp;=&nbsp;$this-&gt;getStateInfo(&quot;ERROR_SIZE_EXCEED&quot;);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//创建目录失败&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(!file_exists($dirname)&nbsp;&amp;&amp;&nbsp;!mkdir($dirname,&nbsp;0777,&nbsp;true))&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$this-&gt;stateInfo&nbsp;=&nbsp;$this-&gt;getStateInfo(&quot;ERROR_CREATE_DIR&quot;);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;if&nbsp;(!is_writeable($dirname))&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$this-&gt;stateInfo&nbsp;=&nbsp;$this-&gt;getStateInfo(&quot;ERROR_DIR_NOT_WRITEABLE&quot;);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//移动文件&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(!(file_put_contents($this-&gt;filePath,&nbsp;$img)&nbsp;&amp;&amp;&nbsp;file_exists($this-&gt;filePath)))&nbsp;{&nbsp;//移动失败&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$this-&gt;stateInfo&nbsp;=&nbsp;$this-&gt;getStateInfo(&quot;ERROR_WRITE_CONTENT&quot;);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{&nbsp;//移动成功&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$this-&gt;stateInfo&nbsp;=&nbsp;$this-&gt;stateMap[0];&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;}打开php/config.json，修改大小、格式、存储路径等参数/&nbsp;抓取远程图片配置&nbsp;/&nbsp;&nbsp;&nbsp;&nbsp;&quot;catcherLocalDomain&quot;:&nbsp;[&quot;127.0.0.1&quot;,&nbsp;&quot;localhost&quot;,&nbsp;&quot;img.baidu.com&quot;],&nbsp;&nbsp;&nbsp;&nbsp;&quot;catcherActionName&quot;:&nbsp;&quot;catchimage&quot;,&nbsp;/&nbsp;执行抓取远程图片的action名称&nbsp;/&nbsp;&nbsp;&nbsp;&nbsp;&quot;catcherFieldName&quot;:&nbsp;&quot;source&quot;,&nbsp;/&nbsp;提交的图片列表表单名称&nbsp;/&nbsp;&nbsp;&nbsp;&nbsp;&quot;catcherPathFormat&quot;:&nbsp;&quot;/Upload/ueditor/image/{yyyy}{mm}{dd}/{time}{rand:6}&quot;,&nbsp;/&nbsp;上传保存路径,可以自定义保存路径和文件名格式&nbsp;/&nbsp;&nbsp;&nbsp;&nbsp;&quot;catcherUrlPrefix&quot;:&nbsp;&quot;&quot;,&nbsp;/&nbsp;图片访问路径前缀&nbsp;/&nbsp;&nbsp;&nbsp;&nbsp;&quot;catcherMaxSize&quot;:&nbsp;20480000,&nbsp;/&nbsp;上传大小限制，单位B&nbsp;/&nbsp;&nbsp;&nbsp;&nbsp;&quot;catcherAllowFiles&quot;:&nbsp;[&quot;.png&quot;,&nbsp;&quot;.jpg&quot;,&nbsp;&quot;.jpeg&quot;,&nbsp;&quot;.gif&quot;,&nbsp;&quot;.bmp&quot;],&nbsp;/&nbsp;抓取图片格式显示&nbsp;/5.保存修改上传，测试成功！","tags":["ueditor"],"categories":["web"]},{"title":"python爬虫","path":"/2017/01/14/98/","content":"最近在玩Python，自己平时喜欢和同事看电影，就寻思写了个爬虫来定时爬取优惠电影。 # author: puresai # code: utf-8 from urllib.request import urlopen from bs4 import BeautifulSoup import re import datetime now = datetime.datetime.now() week = now.weekday() if week &lt; 5: week = 4 - week else: week = 12 - week delta = datetime.timedelta(days=week) n_days = now + delta nowtime = n_days.strftime(&#x27;%Y-%m-%d&#x27;) # 每周五 jiage = int(30) #价格 url_gwl = urlopen(&quot;http://www.gewara.com/cinema/ajax/getOpiItemPage.xhtml?cid=cinemaid&amp;mid=&amp;fyrq=&quot;+nowtime).read().decode(&quot;utf-8&quot;) soupurl_gwl = BeautifulSoup(url_gwl,&quot;html.parser&quot;) ids_gwl = soupurl_gwl.findAll(&quot;a&quot;,attrs =&#123;&quot;href&quot;:&quot;javascript:void(0);&quot;&#125;) str = &#x27;&#x27; str1 = &#x27;&#x27; str2 = &#x27;&#x27; for idattr_gwl in ids_gwl: res_gwl = urlopen(&quot;http://www.gewara.com/movie/ajax/getOpiItemNew.xhtml?movieid=&quot;+idattr_gwl[&#x27;id&#x27;]+&quot;&amp;fyrq=&quot;+nowtime+&quot;&amp;cid=cinemaid&quot;).read().decode(&quot;utf-8&quot;) soup_gwl = BeautifulSoup(res_gwl,&quot;html.parser&quot;) # print(soup) links_gwl = soup_gwl.findAll(&quot;span&quot;,attrs =&#123;&quot;class&quot;:&quot;opiPrice&quot;&#125;) arrtime_gwl = soup_gwl.findAll(&quot;span&quot;,attrs =&#123;&quot;class&quot;:&quot;opitime&quot;&#125;) for i in range(0,len(links_gwl)): if links_gwl[i].find(&quot;b&quot;) != None: if int(links_gwl[i].find(&quot;b&quot;).get_text()) &lt; jiage: str1 = str1+&quot;&lt;p&gt;&quot;+arrtime_gwl[i].get_text()+&quot;票价：&quot;+links_gwl[i].find(&quot;b&quot;).get_text()+idattr_gwl.find(&#x27;img&#x27;)[&#x27;alt&#x27;]+&quot;&lt;a href=&#x27;http://www.gewara.com/movie/ajax/getOpiItemNew.xhtml?movieid=&quot;+idattr_gwl[&#x27;id&#x27;]+&quot;&amp;fyrq=&quot;+nowtime+&quot;&amp;cid=cinemaid&#x27;&gt;点击查看&lt;/a&gt;&lt;/p&gt;&quot; url_tb = urlopen(&quot;http://dianying.taobao.com/showList.htm?spm=a1z21.3046609.w2.3.9ilG5t&amp;n_s=new&quot;).read().decode(&quot;utf-8&quot;) soupurl_tb = BeautifulSoup(url_tb,&quot;html.parser&quot;) ids_tb = soupurl_tb.findAll(&quot;a&quot;,attrs =&#123;&quot;class&quot;:&quot;movie-card&quot;&#125;) for idattr_tb in ids_tb: pattern = re.compile(r&quot;showId=(\\d+)&quot;) id_group_tb = pattern.search(idattr_tb[&#x27;href&#x27;]) if id: res_tb = urlopen(&quot;http://dianying.taobao.com/cinemaDetailSchedule.htm?cinemaId=cinemaid&amp;activityId=&amp;fCode=&amp;showId=&quot;+id_group_tb.group(1)+&quot;&amp;showDate=&quot;+nowtime).read().decode(&quot;utf-8&quot;) soup_tb = BeautifulSoup(res_tb,&quot;html.parser&quot;) # print(soup) links_tb = soup_tb.findAll(&quot;td&quot;,attrs =&#123;&quot;class&quot;:&quot;hall-price&quot;&#125;) arrtime_tb = soup_tb.findAll(&quot;td&quot;,attrs =&#123;&quot;class&quot;:&quot;hall-time&quot;&#125;) for i in range(0,len(links_tb)): if links_tb[i].find(&quot;em&quot;) != None: if float(links_tb[i].find(&quot;em&quot;).get_text()) &lt; jiage: name_tb = idattr_tb.find(&#x27;span&#x27;,attrs=&#123;&quot;class&quot;:&quot;bt-l&quot;&#125;) str2 = str2+&quot;&lt;p&gt;&quot;+arrtime_tb[i].get_text()+&quot;票价：&quot;+links_tb[i].find(&quot;em&quot;).get_text()+name_tb.get_text()+&quot;&lt;a href=&#x27;http://dianying.taobao.com/cinemaDetailSchedule.htm?cinemaId=cinemaid&amp;activityId=&amp;fCode=&amp;showId=&quot;+id_group_tb.group(1)+&quot;&amp;showDate=&quot;+nowtime+&quot;&#x27;&gt;点击查看&lt;/a&gt;&lt;/p&gt;&quot; str1 = str1.strip() str2 = str2.strip() if str1 != &#x27;&#x27; or str2 != &#x27;&#x27;: from email import encoders from email.header import Header from email.mime.text import MIMEText from email.utils import parseaddr, formataddr import smtplib # 第三方 SMTP 服务 mail_host=&quot;smtp.qq.com&quot; #设置服务器 mail_user=&quot;@&quot; #用户名 mail_pass=&quot;@&quot; #口令,QQ邮箱是输入授权码 sender = &#x27;@&#x27; receivers = [&#x27;@&#x27;] # 接收邮件，可设置为你的QQ邮箱或者其他邮箱 if str1 != &#x27;&#x27;: str = &quot;格瓦拉：&lt;br/&gt;&quot;+str1+&quot;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&quot; if str2 != &#x27;&#x27;: str = str+&quot;淘票票：&lt;br/&gt;&quot;+str2+&quot;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&quot; message = MIMEText(str, &#x27;html&#x27;, &#x27;utf-8&#x27;) message[&#x27;From&#x27;] = Header(&quot;@&quot;, &#x27;utf-8&#x27;) message[&#x27;To&#x27;] = Header(&quot;@&quot;, &#x27;utf-8&#x27;) subject = &#x27;优惠电影&#x27; message[&#x27;Subject&#x27;] = Header(subject, &#x27;utf-8&#x27;) try: smtpObj = smtplib.SMTP_SSL(mail_host, 465) smtpObj.login(mail_user,mail_pass) smtpObj.sendmail(sender, receivers, message.as_string()) smtpObj.quit() print(&quot;邮件发送成功&quot;) except smtplib.SMTPException: print(smtplib.SMTPException) else: print(&quot;暂无优惠电影&quot;)","tags":["python","爬虫"],"categories":["python"]},{"title":"windows7创建任务计划","path":"/2017/01/05/95/","content":"最近在做个程序，爬取优惠电影票的程序，程序存在本地，每次需要cmd运行下，有点麻烦，有时候会忘记，因为考虑创建任务计划。创建其实很简单，第一步，进入任务计划管理（控制面板或者直接搜索程序）你可以看见本机的任务计划列表。点击右侧创建基本任务，名称描述触发时间就由你定，选择启动程序，程序脚本写在上面，起始于写入改程序所在目录。点击下一步，点击完成，这样就完成了。是不是很简单。","tags":["windows"],"categories":["windows"]},{"title":"background-image的url属性为空","path":"/2016/10/11/76/","content":"前天同事开发时，遇到一个诡异的问题，每次刷新页面，浏览量会加2，而不是想要的加1。 检查了代码控制器，没有丝毫问题，上次出现浏览量会加2的情况是因为多写了一次display，只能去头去尾，一部分一部分排查，最后发现是头部用了个background，里面的url是空值，去掉，正常。 刚查了下网上确实有出现background-image的url属性为空导致二次提交的情况，同事出现浏览量加2也是因此导致。 说明： 改变代码习惯。严禁代码中，url/href/src 值为空或 # . 这应该是目前最好的一种方式。 避免空链接属性空的链接属性是指img、link、script、ifrrame元素的src或href属性被设置了，但是属性却为空。早些版本的Webkit内核浏览器 与Firefox 会把空地址解析为当前页面的地址。如果页面内有多个空链接属性元素，当前页面的服务器则会被请求多次，增加服务器的负载。相较桌面浏览器对内核的更新升级较积极，这个问题在移动浏览器上问题可能较严重。 幸运的是所有主流浏览器面对iframe的src属性为空时，会把空地址解析为about:blank地址，而不会向服务器发出额外的请求。因此链接避免不了出现空的情况，可以用about：blank来代替空的情况。 贴上文章: 空路径对页面性能的影响","tags":["html"],"categories":["web"]},{"title":"多种font-family","path":"/2016/04/06/38/","content":"修改一个中英文混合css需求时，看到了以下样式。 font: 12px/25px &quot;Microsoft Yahei&quot;, &quot;微软雅黑&quot;, &quot;宋体&quot;, &quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif; 居然设置了这么多字体。然后就查了查，贴上来。 font-family的调用方法: 代码如下: div &#123; font-family:Arial,&#x27;Times New Roman&#x27;,&#x27;Microsoft YaHei&#x27;,SimHei; font:bold 12px/0.75em Arial,&#x27;Times New Roman&#x27;,&#x27;Microsoft YaHei&#x27;,SimHei; &#125; font-family 可以把多个字体名称作为一个“回退”系统来保存。如果浏览器不支持第一个字体，则会尝试下一个。也就是说，font-family 属性的值是用于某个元素的字体族名称或/及类族名称的一个优先表。浏览器会使用它可识别的第一个值。 根据font-family的字体调用原则我们可以为英文,中文,等两种字体调用不同的字体来渲染。 如:Arial,’Times New Roman’这两种字体不认识中文,只认识英文,所以,这两种字体只能渲染英文数字和一些特殊符号,而页面中的中文就会自动调用第三种字体Microsoft YaHei(PS:假如存在这种字体的话)。 所以,在定义字体的时候把英文的字体写在前面把中文的写在后面。这样，系统就会自动按顺序依次给字用字体，如果当前字体不支持文本，自动换用列表中的下一个字体。 经过测试，IE9、IE9兼容模式（兼容IE8）、Chrome浏览器最新版本（34.0）、 Firefox浏览器最新版本（29.0）支持该font-family属性；但是某些版本的IE浏览器（IE7、IE8）无法实现该font-family属性的要求，还会暴露出一些奇怪的 bug。如在这些版本的浏览器下使用中文字体（比如微软雅黑），需要把该中文字体放到font-family属性的首位，但是会导致英文字体也会使用该中 文字体渲染。即在这些浏览器（IE7、IE8）下不支持在font-family属性中为英文和中文字体分别使用不同的字体。 我改成这样， font: 12px/25px &quot;Times New Roman&quot;, &quot;Microsoft Yahei&quot;, &quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif; 用360兼容模式测了下，IE7，8都没发现文章中说的问题。","tags":["css"],"categories":["css"]},{"title":"去掉块状元素与img之间间隙","path":"/2015/12/22/7/","content":"造成图片与容器下边界有空隙的原因 在网上搜了一下， 图片文字等inline元素默认是和父级元素的baseline对齐的，而baseline又和父级底边有一定距离（这个距离和 font-size，font-family 相关，不一定是 3px），所以设置 vertical-align:top/bottom/text-top/text-bottom 都可以避免这种情况出现。而且不光li，其他的block元素中包含img也会有这个现象。 只要vertical-align不取baseline，这个空隙就消失了。 请看如下实例(注意::测试工具：ff，chrome，360–支持IE7+) &lt;style&gt;#l1 &#123;float:left;background:#000;&#125;#l1 ul li &#123;list-style:none;padding:0;margin:0&#125;img &#123;height:100px;&#125;&lt;/style&gt;&lt;div id=&quot;l1&quot;&gt; &lt;ul&gt; &lt;li&gt;&lt;img src=&quot;30-023131_451.jpg&quot; /&gt;&lt;/li&gt; &lt;li&gt;&lt;img src=&quot;30-023131_451.jpg&quot; /&gt;&lt;/li&gt; &lt;li&gt;&lt;img src=&quot;30-023131_451.jpg&quot; /&gt;&lt;/li&gt; &lt;/ul&gt;&lt;/div&gt; 我们会发现li底部与img底部有间隙，so bad！ 第一，给图片img标签display:block。 兼容性IE8+，firefox，chrome 第二，定义容器里的字体大小为0。font-size:0 兼容性IE8+，firefox，chrome 第三，定义图片img标签vertical-align:bottom，vertical-align:middle，vertical-align:top img&#123;vertical-align:bottom&#125; 兼容性IE7+，firefox，chrome 第四，给li加高度 兼容性IE7+，firefox，chrome 测试发现，给img加vertical-align效果最佳","tags":["css"],"categories":["web"]},{"title":"puresai","path":"/about/index.html","content":"Over 10 years of hands-on development experience, 2 years of project management and side venture exploration, and 2 years of remote work experience. Skills: BackEnd &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Frontend &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; DevOps &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;"},{"title":"puresai 的阅读单","path":"/collect/index.html","content":"goLinux"}]